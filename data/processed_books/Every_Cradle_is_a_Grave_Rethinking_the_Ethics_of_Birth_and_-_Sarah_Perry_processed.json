{
  "metadata": {
    "title": "Sarah Perry-Every Cradle Is a Grave Rethinking the Ethics of Birth and Suicide-Nine-Banded Books (2014)",
    "author": "Unknown",
    "publisher": null,
    "publication_date": "0101-01-01T00:00:00+00:00",
    "language": "en",
    "isbn": null,
    "description": null,
    "subject": null,
    "total_chapters": 22,
    "total_words": 55385,
    "file_path": "ebooks/downloads/Every Cradle is a Grave Rethinking the Ethics of Birth and - Sarah Perry.epub"
  },
  "chapters": [
    {
      "title": "Chapter 4",
      "content": "Table of Contents Preface Introduction: Breaking the Ring of Motivated Ignorance PART I: A Worldview of Worldviews Chapter One: Free Disposal and the Burden of Life The Suicide Prohibition The Cost of Disposal The Land of Free Disposal The Burden of Life Chapter Two: The Empirical Nature of the Meaning of Life The Needs for Meaning Value Social belonging Purpose Efficacy Self-worth or status How Meaning Operates: Methods and Illusions Meaning infection False permanence Suffering measures meaning Illusion of control The Story Non-fungibility of meaning Chapter Three: The Modern Sacredness and Moral Foundations Morphology of the Sacred A Window into Sacredness: The Violation Sacredness Negotiations Moral Foundations Sacrednesses Old and New A Necessary Danger Chapter Four: Experience Machines and Their Ratification The True Gifts of the Good People: How Experience Machines Help Us Escape Uncertainty Friendly Neighborhood Experience Machines: Where Do They Come From? Aesthetics and Religions: A Minor Distinction A Sneaky Dualism The Co-Evolution of Humans and Their Experience Machines The Protection of an Aesthetic Ourselves as Experience Machines PART II: The Ethics of Suicide and the Suicide Prohibition Chapter Five: Moral Foundations Analysis of Suicide and Childbearing Suicide and Moral Foundations Childbearing and Moral Foundations Chapter Six:What Really Causes Suicide Failed Social Belonging Burdensomeness Competence What Doesn’t Cause Suicide Evolutionary Considerations Attempted Suicide as an Adaptive Behavior: Suicide Gambles Chapter Seven: On Contagion Behavioral Contagion Ethical Perspectives on Suicide Contagion The Science of Suicide Contagion Moral Contagion or Informational Contagion? Mass Clusters and Point Clusters The Death of Marilyn Monroe Why Women? Other Factors in Contagion: Negative Definition of Suicide Chapter Eight: The Censorship of Suicide Censorship of Suicide versus Censorship of Violence Contagion and Moral Responsibility Moral Responsibility and Willingness to Censor PART III: The Ethics of Procreation Chapter Nine: Procreative Responsibility: A Road Map Liberty Harm and Measurement: Preferentist and Non-Preferentist Approaches Preferentist Approaches and Evidence Free Disposal and the Imaginary Survey Revealed Preference in Non-Suicidal Behavior Non-Preferentist Approaches Naive Weighing Benatar’s Asymmetry Shiffrin’s Asymmetries Uncertainty Chapter Ten: The Mathematics of Misery Truncated Utility Functions and the Value of Life Negative Utility and the Death Wish Economy Policy Implications What Real Human Utility Functions Are Functions Of Poor Baby or Rich Baby: Which is Worse? The Economics of Palliation and Bullshit Chapter Eleven: The Burden of Life Work and Leisure Poverty and Pain The Demand for Pain Relief Is Loss Aversion Irrational? A Place for Quantitative Methods Chapter Twelve: Hurting People and Doing Good Chapter Thirteen: The World of Nature of Which We Are a Part 1. On The Ways In Which Nature Makes Andrea Yates Look Like June Cleaver 2. The Incoherence of Species-Relative Morality 3. Respect for Species? 4. Use Nature As We Please? 5. Is Being Human-Like Better? Appendix: Living in the Epilogue: Social Policy as Palliative Care The Story as a Cognitive Bias Living in the Epilogue There Are No Stories In Heaven The Cheery and the Damned Palliative Care: A Double Standard for People in the Epilogue Toward Social Policy as Palliative Care Acknowledgments",
      "chapter_number": 2,
      "section_number": null,
      "word_count": 503,
      "file_path": "index_split_002.html",
      "spine_order": 3
    },
    {
      "title": "Preface",
      "content": "Preface This is a book about ethics. People don’t often change their minds about ethics. When they do, it is generally for social reasons, not because they are exposed to reasoned argument. Reasoned arguments more often allow people to cement their existing opinions. Ethical beliefs are, in any case, extremely limited in their ability to influence actions. I will advocate several ethical positions that are counterintuitive, and that some people would describe as evil. These ethical positions include the view that life—not just human life, but all life capable of having experiences—is very bad. It is very immoral, I will argue, to have babies or to otherwise create aware beings. I will also argue that suicide is not wrong or a product of mental illness, but an ethically privileged, rational response to the badness of life. You might imagine these to be positions held by a comic book villain bent on destroying all life in the universe for its own good. That’s fine with me. In fact, it’s a good place to start. Because in presenting what I hope is a reasoned and factually supported ethical argument advocating such extreme ideas, I do not expect to persuade. It is more likely that I will be mentally categorized by the reader as such a cartoon villain (assuming the reader is not one of those few to whom these cartoon villain ideas seem obviously right). And to the extent that the reader holds contrary, prolife, anti-suicide beliefs, I understand that exposure to my unorthodox views may only reinforce those beliefs. Believe it or not, that seems pretty rational to me. To respond to crazy-sounding out-group beliefs with increased faith in the in-group beliefs validated by known and trusted authority—is a smart strategy. From the trenches of interpersonal communication, I don’t think “ad hominem” is even much of a fallacy. On the contrary, consciousness—and all knowledge—is social in nature; and most of our knowledge comes not from direct experience or through reasoning, but from trusted sources. Though some of our beliefs about the physical world come from direct experience, we mostly rely on the trusted testimony of teachers, scientists, and friends to understand such things that we have no direct experience of, or of which our direct experience is understood to be limited or mistaken. The Earth appears to be flat, and the sun, which looks like it is smaller than the Earth, appears to be moving around the earth. We know better only because we are reliably advised that our initial sensory impressions are incorrect. In a similar way, we get some of our ethical beliefs from direct intuitive perception, but we also rely on the ethical beliefs of those around us to shape our own beliefs and actions. We are much more likely to be vegetarians if our friends are vegetarians. We are much less likely to support gun control if our friends are gun enthusiasts. Many readers will find it natural to think of the self as the ultimate arbiter of ethical questions, but this is based on a modern and distinctly Western conception of the self. And even self-heavy moderns will sometimes admit to confusion as to what is the right thing to do in a morally unclear situation. Who, then, is to be consulted and trusted on issues of moral relevance? And what should be the result if one disagrees with a trusted friend on a moral matter? There are some people—crazy people, evil people, people who have taken large amounts of methamphetamines for days on end—whose disagreements with our opinions on ethical matters would not cause us to have any doubts as to the correctness of our own opinions (possibly the opposite, as noted above). But any socially well-adjusted human being is likely from time to time to encounter a person whose contrary opinions are less easily dismissed. When we engage with such a person—who is so trusted, whose mental apparatus has been so verified to work well, and whose motives are so clearly earnest—we may come away less certain about the correctness of our own views. I like the term “epistemic peer” for a person so trusted, brain-wise and team-wise, that his opinion will be taken very seriously when it disagrees with our own. I am more interested in establishing myself as an epistemic peer of the reader than in autistically presenting a logical argument for the correctness of my views. When you find yourself coming to an unusual conclusion and you can’t find a flaw in your own reasoning, the epistemically proper path, I think, is to show your brain and show your work. You display the way your mind (your laboratory apparatus) approaches the problem, and you present your argument (your laboratory protocol) in a clear way so that others may examine it. As I would rather participate in social reasoning than table-pound in my corner, I will not only present the extreme forms of my arguments (many of which I think are correct); I will also attempt to present the continuum for each position, many points along which are uncontroversially reasonable. More important, I will show that such continua exist. I consider many people reasonable who do not go full cartoon villain and agree with me that all life is unfortunate and nobody should ever have babies. What makes such people seem reasonable to me is that they recognize the possibility that a given life could go very badly, and that the joys of life might not outweigh the suffering. At the very least, they recognize that the interests of an aware being are very hard to predict before that being is created. What I would like readers of this book to come away with is not the urge to bomb IVF clinics or dismantle suicide barriers on bridges. I would prefer that readers simply and sincerely consider the question of whether existence is a blessing or a burden, and I hope to encourage the understanding that for many people, it is a useless burden. I would like the reader to think of parenthood as a moral decision affecting a new human being, rather than an event that merely happens to oneself. I would like the reader to consider that it may be both more important and more possible to prevent harm than to do active good in the world. I would like readers to consider the mental states of aware beings as being a very important, if not terminal, locus of ethical value in the universe. Finally, I would like readers to dig further into the nature of their own values, especially the primitive values of survival and longevity. If these points are communicated, I will have done my duty to the late Dr. Jack Kevorkian, who suffered much in his life for the good of others and who, before his death, kindly gave me permission to use one of his paintings on the cover of my book. The prevailing views on birth and suicide, I will argue, are very misguided. But they are misguided in characteristically human and evolutionarily adaptive ways. In order to reject them, we must approach what David Eubanks has called the Frontier of Occam—the highest intelligence achievable by a civilization before it figures out better ways to achieve its ends than by continuing to pursue the goals of its alien creator, evolution. I suspect that I have made more converts to the cause of questioning life’s value simply by being an adorable housewife who makes a killer chanterelle risotto than by any particular argument I’ve constructed. Since I can’t make you risotto, I have tried to present my arguments in a calm and reasoned manner, with abiding respect for the humanity that we all share. Perhaps I will come across as the sort of cartoon villain you should accept as an epistemic peer. But whether or not you allow me to influence you with my dangerous ideas, I hope you will believe me when I tell you that I am very much on your side. You are, after all, an aware being having experiences. This is true whether or not you have had or will have children, and this is true whether you want to live or want to die. Thank you for reading my book.",
      "chapter_number": 4,
      "section_number": null,
      "word_count": 1379,
      "file_path": "index_split_004.html",
      "spine_order": 5
    },
    {
      "title": "Introduction: Breaking the Ring of Motivated Ignorance",
      "content": "Introduction: Breaking the Ring of Motivated Ignorance Human cognition is a mixture of the rational and the magical. Religious thinking is even more important than rational thinking for people deciding how to behave, and this is the case even for people who do not consider themselves religious. The rationality of analytic philosophy is a powerful tool for understanding the world, but the world of human cognition cannot be comprehended without attention to the religious, the magical, and the sacred. The first part of this book deals with the irrational side of human cognition, exploring our need for meaning and our attribution of meaning and sacredness. The second and third parts of this book engage with rationality. Here is an overview of the central thread connecting the parts: People have innate needs for meaning—needs for some ultimate, foundational value that justifies all other values; for purpose in life; for a sense of efficacy and control; and for a sense of self-worth. The meanings that people find in the world are generally illusory—for instance, promised future states of fulfillment that never occur. Since meaning is both necessary AND illusory, people must protect their valuable sources of meaning from disparagement with the armor of sacredness. One of the most sacred and meaning-giving beliefs is the idea that life is a desirable, precious thing to have and to give to others. This sacredness prevents us from thinking clearly about suicide and birth. It is the most poignant example of Jonathan Haidt’s “ring of motivated ignorance” that surrounds the sacred. However, for the most intrepid explorers, challenging the essential sacredness of life—one of the most powerful shared sources of meaning in our sacredness-deprived culture—may mean crossing a frontier into new and unexpected insights and new ways of conceiving of humanity and compassion, especially with respect to suicide and procreation. *** This book engages with analytic philosophy, particularly in its approach to antinatalism and suicide rights. But it also engages with the responses of non-philosophers, whose approaches are probably more representative of ordinary human thought than are more sophisticated treatments found in the literature of analytic philosophy. Chapter 1 engages with Bryan Caplan’s self-described “cursory rejection” of antinatalism, grounded in the claim that if life is so bad you can always commit suicide (in my experience, an overwhelmingly common first response to antinatalism). This chapter introduces antinatalism and explains the connection between antinatalism and suicide. Chapter 2 is about meaning—what kinds of meaning we require as humans, and how we find that meaning in the world. The connection between meaning and suffering is explored. Chapter 3 introduces Jonathan Haidt’s “moral foundations” approach, illustrating how sacredness and purity, care for others, fairness concerns, and loyalty influence our beliefs. Chapter 4 elaborates on Robert Nozick’s famous “Experience Machine” thought experiment, motivating a radical perspective in which mental states are the only objects of moral consideration. Ethical issues are explored from this perspective. Part II focuses on suicide. Chapter 5 analyzes suicide and childbearing from a moral foundations perspective. Chapter 6 examines the causes of suicide, including an exploration of the evolutionary biology of suicide. Chapter 7 engages with the work of Jennifer Michael Hecht, whose popular philosophy book argues that we have a duty to not kill ourselves because doing so gives moral license to others to also commit suicide. This chapter examines the phenomenon of suicide contagion, presenting evidence that it is not moral license but rather the transmission of much-desired information that is responsible for the rare phenomenon of suicide “contagion.” The phenomenon of suicide contagion is also cited in favor of censoring media reports of suicide as well as the depiction of suicide in art and discussion; Chapter 8 examines the censorship of suicide. Part III is about procreation. Chapter 9 provides a roadmap to the ethical arguments involved, both preferentist (believing that people know what is good for them) and non-preferentist (believing that people do not necessarily know what is good for them). Chapters 10 and 11 explore preferentist arguments, demonstrating that people frequently act as if life is a burden rather than a precious gift. Chapter 12 presents non-preferentist arguments against procreation. Chapter 13 connects the human predicament to that of the rest of the creatures in the world and in our evolutionary history. Finally, I include as an appendix a personal essay about the lack of narrative meaning.",
      "chapter_number": 5,
      "section_number": null,
      "word_count": 726,
      "file_path": "index_split_005.html",
      "spine_order": 6
    },
    {
      "title": "Chapter One: Free Disposal and the Burden of Life",
      "content": "Chapter One: Free Disposal and the Burden of Life When people are considering whether to have a child, is it appropriate for them to consider whether the child might be harmed just by being created? Should they think about whether life for this child might be a great burden, rather than a gift? In a blog post entitled “Free Disposal,” economist Bryan Caplan says that it is not appropriate to consider such things.1 We can see that life is always a blessing and never a burden, he says, because people may freely dispose of their lives if they wish, but few take advantage of this opportunity. By revealed preference—an economic term for a person’s actions revealing his true desires—it is clear that people overwhelmingly find their lives to be of positive value. Caplan writes: Actually, this may well be the easiest utility inference in the world. We know that people almost universally prefer existing to not existing because there are so many cheap and easy ways to stop existing. As intro econ teachers might say, life is a good with free (or nearly free) disposal. To bolster his position, Caplan cites the following passage by Epicurus: Yet much worse still is the man who says it is good not to be born, but “once born make haste to pass the gates of Death.” [Theognis, 427] For if he says this from conviction why does he not pass away out of life? For it is open to him to do so, if he had firmly made up his mind to this. But if he speaks in jest, his words are idle among men who cannot receive them. In another blog post entitled “A Cursory Rejection of Antinatalism,”2 Caplan makes a similar claim: Almost everyone’s behavior confirms that they’re glad to be alive. After all, no mobile adult needs to be miserable for long. Tall buildings and other routes to painless suicide are all around us; in economic jargon, life is a good with virtually ‘free disposal.’ Yet suicide is incredibly rare nonetheless. Bryan Caplan believes that we live in the Land of Free Disposal. We do not. While legal in a narrow sense, suicide is still very much the subject of prohibition. The costs of making a serious suicide attempt are actually very high, and prohibition increases these costs. In this chapter, we will explore the suicide prohibition and the costs of suicide, and then imagine a world very different from our own—the Land of Free Disposal, where suicide is not meaningfully prohibited and the costs of making a serious suicide attempt are actually minimized. It might not be a nice place to visit, but it is certainly not the world we live in. The Suicide Prohibition In the United States, a person is not guilty of a crime for attempting to kill himself. This is the only sense in which suicide is legal in the modern Western world. The first sense in which suicide is prohibited is that a person may be imprisoned against his will in a hospital for attempting suicide. If a person is judged to pose a danger to himself, such as by attempting suicide or even expressing the desire to commit suicide, he may be held against his will on the locked ward of a psychiatric hospital. The length of the legal period of incarceration varies by jurisdiction. Once on the locked ward, the patient is not free to leave; guards, alarmed doors, and other measures are in place to prevent him from “eloping.” If he has attempted suicide, or is suspected of harboring suicidal thoughts, he may be obliged to remove his jewelry and clothing and be forced to wear paper clothing instead (paper clothing poses less of a hanging risk). Staff may watch him while he sleeps, through a suicide watch window. He will be monitored while he shaves, if he is allowed to shave. Freedom is an imprecise term. But when the government authorizes the imprisonment of a person for attempting or even seriously discussing a particular action, it seems natural to conclude that he is not free to do that action. The person contemplating suicide has more to fear from the hospital than from incarceration. If he survives his suicide attempt or is discovered before he has died, then a progression of paramedics, nurses, doctors, and perhaps even surgeons will attempt to foil his plans by saving his life. Even people who choose very lethal methods by which to exit the world, such as a jump from heights or a gunshot to the head, frequently fail to end their lives, in large part due to modern medicine. Across the United States, four billion dollars are spent annually on emergency room and hospital treatment for people who attempted suicide but were caught before they could die. A person is not “free” to do something that he must either get away with in secret or be forcibly prevented from doing if caught. It gets worse. Those brought back from the brink of death often suffer debilitating injuries that significantly decrease quality of life—below a baseline that was already not worth living. One such patient was the focus of a 2007 single-patient study in the Annals of Neurology.3 The patient, a 48-year-old woman, had at that time been kept alive for over two years in a state of akinetic mutism—she was conscious, but could not move or speak. She experienced severe brain damage from a suicide attempt and was kept alive for years while scientists performed experiments on her. She may be alive still. Life may not be disposed of freely if those who attempt to dispose of it are routinely “rescued” and brought back to life. The policy makes successful disposal less likely, and the risk of being preserved alive in a maimed condition increases the cost of a suicide attempt. And those tall buildings that are supposed to provide for the free disposal of life do not work very reliably. Even the jump from the 64-meter Bosphorus Bridge in Istanbul fails to result in death around 3% of the time. A gunshot to the head is similarly risky, and methods like slashing arteries, hanging, or suffocation by automobile exhaust are even more likely to fail. More important, these methods are horrible; the need to endure the experience makes the cost of the attempt very high. Aversion to heights and body envelope violation are installed by evolution and difficult to overcome, even for people who truly desire death. An observation an economist might make is that methods of suicide are not good substitutes for each other. When a popular method of suicide is made illegal or more difficult, the overall suicide rate often goes down; people do not simply substitute a different method of suicide. After Australia tightened motor vehicle exhaust restrictions, making suicide by carbon monoxide poisoning more difficult, the regional suicide rate decreased. Suicide attempts using this method remained popular but became less lethal, resulting in fewer suicides. More impressively, a few studies of suicide barriers on bridges have found that installing a suicide barrier on a bridge does not increase suicides from nearby bridges. Gun ownership increases the risk of suicide; the availability of a method that is fairly reliably lethal confers such a reduction in the cost of suicide that merely owning a gun makes one more likely to commit suicide. One of the most universal findings about suicide is that men successfully commit suicide about four times more often than women; but where methods preferred by women are available, such as the lethal poisons that may be ingested by mouth that are available in China and India, the female suicide rate sometimes exceeds that of men! People do not seem to freely substitute one method for another. Low rates of substitution indicate that for disposal to be free, desirable methods must not be restricted. And there is a clear, best method. It is reliable, reasonably free from pain, and does not require the suicide to endure a frightening body envelope violation or similar trauma. In those jurisdictions in which suicide is legal under limited circumstances for humane reasons, this is the method used. This is the method preferred by doctors, nurses, veterinarians, and others with relevant knowledge and the ability to acquire the means. This method is, of course, a drug overdose, either by barbiturates or by a synthetic opiate like Fentanyl. The drug prohibition (or drug war) means that barbiturates and Fentanyl are not legally available to people who wish to use the best method to commit suicide. If the best method of disposal requires committing a crime, even though it hurts no one, then disposal is hardly free. In our interconnected market society, it is difficult to do anything alone, with no one’s help. Suicide is a particularly difficult task, and the resources, information, and assistance provided by another person might make the difference between success and failure. Such assistance is illegal. Helping another person to commit suicide is prosecuted as a crime in all but the most limited situations in the few states that allow physician-assisted suicide. Suicide is the only act that is not itself a crime, but which assisting another person to commit is a crime. Even trying to die together may be interpreted as assistance for prosecutorial purposes; the survivor of a suicide pact has sometimes been prosecuted for the death of his luckier comrade. To forbid assistance makes the act less free. The suicidal person is not only prevented from enlisting friendly volunteers to help him, he is denied the ability to freely use markets to achieve his ends. This is a severe handicap indeed, because of both the power of the market and the impotence of the disconnected individual. And so we might amend Bryan Caplan’s confident assertion thus: Disposal is free—except that you will be locked up in a hospital if you are caught trying to exercise this freedom; except that your unwanted life will be returned to you if possible, perhaps in worse condition than before; except that you may not use the most painless, reliable method that puts no bystanders at risk, but must take your chances with painful, violent methods. And no one may help you. If disposal is not “free” in the sense that it is legally permissible, it is also not “free” in terms of costs. We will now look at some of the costs facing a person considering a suicide attempt. The Cost of Disposal So far, we have seen that a major downside to a suicide attempt is the risk that it will fail or be discovered before it is complete. The risk of ending up on a locked ward of a psychiatric hospital, perhaps grievously and permanently injured, is one kind of cost of disposal. But there are many. From the gene’s-eye perspective of evolution, it is very dangerous for an organism to have the capacity to realize that it can escape all of its pain and sorrow by ending its own life. If an organism is given this capacity, either it must be kept content enough that it never wishes to commit suicide, or it must be inhibited from committing suicide, physically or psychologically.4 Many of the costs of a suicide attempt stem from these built-in inhibitions. The terror that a person feels, standing on a bridge or on top of a high building, desperately wishing for death and trying to summon the courage to jump, is an example of the psychological inhibition against suicide. The universal disgust response to body envelope violations is another; it is psychologically trying for a person to cut through all the skin, muscles, and tendons necessary to access his arteries. Passing out from low oxygen and vomiting when poisoned are examples of built-in physical barriers that sometimes effectively inhibit suicide. But people do not exist as individual units separate from human relationships and groups. A great deal of the cost of committing suicide faced by a person wanting to die is social and empathetic: it is resonant in the loneliness and grief that his death will cause, or at least hasten, among parents, children, siblings, a spouse, or friends. As social creatures, we begin forming bonds at least as soon as we are born; these bonds, while often no more voluntarily chosen than our own births, are powerful motivations. Those with whom we have formed social bonds rely on us, imposing a significant cost on suicide even for a miserable person who genuinely wishes to die. The person who successfully ends his life deprives his relatives and his friends of his continued company and support. Everyone dies eventually—the grief and deprivation that death entails are inescapable—but the suicide hastens death, and so appears responsible for it in the eyes of his community. And it is not just the loss of company and support. The suicide of a close associate is usually regarded as much more painful than the event of such a person moving across the country and losing touch, even though the deprivation is similar in either case. Some social costs are artifacts of the prohibition. The suicide must act in secret, sneaking and hiding to avoid detection and unwanted rescue. But who will discover his dead body? It will be especially traumatic for a relative or close friend to happen upon the dead body of a suicide. But often the other option is to risk not being discovered for a long period of time, during which those close relatives will need to endure the fear and uncertainty of “missing person” status. And because of the prohibition, the person determined to commit suicide cannot calmly discuss his intention with his close associates. He cannot say goodbye, or he will likely be locked up in a hospital. Part of what makes suicide seem devastating for those left behind is that it is framed as a tragic, preventable loss rather than the lucky escape of a miserable person. The presence or absence of strong social bonds is actually more determinative of suicide than misery or suffering. Thomas Joiner, in his influential study of suicide,5 found that failed social belonging—and, to a lesser extent, a sense of burdensomeness rather than helpfulness—is a better predictor of suicide than any other kind of unhappiness or misery. The only other strong predictor of suicide in his model is the competence necessary to use one’s chosen method, i.e. access to drugs, knowledge of guns, etc. Unhappy countries do not experience more suicide than happy countries. A major study recently found that countries with higher levels of happiness actually have higher suicide rates than less happy countries.6 (This finding was replicated at the level of individual states of the United States.7) Simple misery does not seem to reliably cause suicide, the way it would in Bryan Caplan’s naive model; rather, people seem to commit suicide when they are freed from, or perhaps rather deprived of, the social bonds that were keeping them alive. There are significant costs associated with suicide apart from the loss of one’s life, and when these costs are removed (whether by weakening social bonds or making desirable methods available), suicide is made more likely. It does not seem to be the case that people are avoiding suicide simply because they are happy to be alive. The Land of Free Disposal Bryan Caplan’s assertion that creating lives can never be wrong because we live in a world with many tall buildings to jump off of (yet only a small proportion of humans actually utilize these free disposal services) is based on a faulty understanding of reality. But what would Caplan’s ideal Land of Free Disposal look like? We turn now to imagining such a land in which suicide is really free—in which legal barriers to suicide are removed, and in which people are permitted to subvert the natural (but unwanted) barriers to suicide. This imaginary land does not necessarily represent my policy prescriptions (for instance, I think parents lose their moral right to commit suicide when they take on the responsibility for a child), and we will find it is not a utopia. The thought experiment is meant to illustrate the high cost our own world places on “disposal,” and how this cost is related to the burden of having been born. In the Land of Free Disposal, the main guiding intention is that it is easy to commit suicide. When a person makes a suicide attempt, he is not sent to a hospital prison; instead, if he has followed proper procedures for signaling his intention, he dies. The most lethal, comfortable methods are widely available, and since suicide is fine, a competitive market arises to provide the most appealing methods. The power of the market is brought to bear on the problem of finding desirable ways to die. Not just “Ask your doctor if Obliviall is right for you,” but also death arcades. The technological burdens of suicide are taken care of in the Land of Free Disposal. The market is a powerful instrument, and allowing it to solve the problems of suicide makes disposal relatively comfortable and efficient. No one has to cut his arteries or shoot himself fourteen times with a .22. Only rarely does someone jump off of a tall building. Suicide is easy, painless, and guaranteed. Technology can go a long way toward undermining our unchosen, Nature-programmed, often irrational fixation on our own continued existence. Of course, it is unlikely to completely free a human being of the biological costs of disposal, but in the Land of Free Disposal these costs are at least minimized. But the technology is not everything. The guarantee of death is very important, perhaps more important than the technological aspect. Even a small possibility of surviving a suicide attempt, in maimed and helpless condition, is rationally a major concern. If one is at all tempted toward a Many Worlds8 analogy for probability, after a good, strong suicide attempt, most of the future selves are gone—but a few, the only conscious ones, are trapped in a hospital incommunicado for decades. Even if the probability is very tiny, the potential consequences are so bad that it may not be worth the gamble. But no one needs to worry about this in the Land of Free Disposal. So everyone who wants to die may die. But to ensure that disposal is truly free, other costs must be removed from the suicide as well. Suicide has no stigma in the Land of Free Disposal. In kindergarten your kid’s teacher has each student draw a picture on the topic of “When Would I Kill Myself?” What has he drawn there? It is very sad when children commit suicide—and many of them do, even in our world—but preventing them from doing so is not free disposal. Many people do not want to die alone. As in our world, people sometimes post pictures of their last moments to Facebook, but in the Land of Free Disposal the pictures are taken automatically at the death arcades and resemble on-ride photography at Disneyland. In this way and in many other ways, the path to death is made easier by the possibility of social connection. Unlike in our world, people in the Land of Free Disposal may sit with a dying suicide to comfort and even assist him without fear of imprisonment. The desire for some kind of connection to the future after one’s death—a kind of immortality—is recognized as a strong psychological motivation, and provided for in the public policy allowing suicides to donate their organs at a hospital. There is no organ shortage in the Land of Free Disposal, and since suicide isn’t creepy at all, everybody wins. There have been changes in lending and credit, and in contract law in general, in the Land of Free Disposal, but institutions have adjusted. Standard clauses have been drafted to amend insurance policies and other formal agreements. Of course, the loneliness of family and friends must be considered a cost of suicide not likely to be attenuated by social interventions. We may not wish to reduce these bonds—to do so might create a very undesirable society— but they form a cost of suicide that may make a person suffer through a miserable, unwanted life for the good of others. The Land of Free Disposal might experiment with weakening social bonds through alternative methods of childrearing, as with kibbutzim, or alternative relationship structures, such as arm’s-length polyamory rather than mutually dependent monogamy. Policies designed to reduce interdependence between humans might make suicide easier for those who desire it, but to the extent they are successful, they would also likely reduce the aggregate quality of life experienced by everyone. A social species like ours is unlikely to achieve truly Free Disposal, except perhaps among our most isolated members. But other interventions could at least partially balance the burdens that social bonds place on the person desiring to be rid of his existence. A posthumous tax credit for suicides, for example, might decrease the socially-imposed cost of suicide for a miserable person. And rather than spending tens of millions on suicide prevention efforts (as our government does through the National Institutes of Health, the military, and other agencies), the governing body of the Land of Free Disposal spends money on campaigns to promote the right to suicide. In the Land of Free Disposal, billboards, television, and the Internet carry the message that suicide is a sacred right, rather than the message that suicide is wrong and a sign of illness. PSAs remind people that “No One Owns You—Suicide is Your Right!” On the chance that suicide “contagion” is real and social proof removes a major cost of suicide, fictional and nonfictional accounts of successful suicides are broadcast widely in approving terms. Curricula in schools emphasize personal autonomy, vilify interpersonal possessiveness, and treat suicide as a positive life choice to be seriously considered. “Do You Love Her Enough to Let Her Go?” The Burden of Life The distance between the Land of Free Disposal and our own world is a measure of the burden of life placed on anyone born into our society. In our world, only about a million people a year successfully commit suicide; in the absence of restrictions and costs, this number would be much higher. Bryan Caplan’s “easiest utility inference in the world” is, as we have seen, incorrect. Creating a person places a burden on him that he may be obliged to bear against his genuine desire to be rid of it. Creating children in a cavalier and thoughtless manner is not a morally responsible option. We must look deeper to determine whether creating a particular child is in that child’s best interests.",
      "chapter_number": 7,
      "section_number": null,
      "word_count": 3795,
      "file_path": "index_split_007.html",
      "spine_order": 8
    },
    {
      "title": "Chapter Two: The Empirical Nature of the Meaning of Life",
      "content": "Chapter Two: The Empirical Nature of the Meaning of Life Even the best human lives include substantial suffering. A typical person experiences considerable pain, loneliness, and boredom in his lifetime, together with aging and the inevitability of death. What is it that justifies the human species in reproducing itself despite all the suffering? One possible answer is the happiness and pleasure that life is expected to provide, and this happiness-and-pleasure hypothesis will be treated seriously in later chapters. But happiness is not the reason most people feel that life is valuable despite all the suffering; rather, it is meaning. The feeling that life is meaningful is the real reason that people think human lives are worth making. The conviction of meaning functions as an intuitive justification for creating the lives of others; whether or not this justification is valid, it does seem to be true that finding a sense of meaning eases the experience of suffering in actual lives. Subjectively, the feeling that life is meaningful—that there are ultimate values, that life has a purpose—tends to point to a source of meaning, something higher than and external to the mere feeling or intuition of meaning. While sources of meaning vary greatly (and often contradict each other), the sense and expectation of meaning itself is surprisingly universal—so universal that the intuition is almost never challenged. This very universality should motivate us to be cautious about taking meaning’s claims at face value. One should be suspicious of any claim that is defended for contradictory reasons, and most people who agree that life is meaningful disagree as to what makes it so. The belief that life is meaningful tends to take the form of a strong feeling rather than a reasoned conclusion; indeed, one of the functions of meaning is to shield a person from the harmful effects of reasoning by providing a value that is justified for its own sake, a foundational rock for cognition below which no “whys” need be answered. It is this feeling of meaning that may be profitably investigated. We will examine the needs that motivate people to seek meaning, then explain the methods used by various sources of meaning to meet those needs. Along the way, we will look at some of the trends in meaning in the rapidly changing modern world from a cultural evolution perspective. The Needs for Meaning The social psychologist Roy Baumeister has been studying how people experience meaning in their lives for decades, and continues to publish on the topic to this day. His 1991 book Meanings of Life proposed four needs that must be filled with sources of meaning: a need for an ultimate value base a need for personal purpose a need for self-worth or status a need for efficacy or control Both Baumeister’s later work and the work of psychologist Thomas Joiner indicate that a fifth need is also critical for human well-being: the need for social belonging. The satisfaction of this need is crucial for the sense of meaning. Thwarted belonging (through, for example, divorce, job loss, or social rejection) is painful and so destructive of meaning that Thomas Joiner found it to be a major predictor of suicide. It is the social group that maintains sources of meaning most effectively; people are rarely successful at supplying meaning for themselves without outside assistance. Even the ultimate value of the self is most effective when reinforced by the social group. Value Human cognition is characterized by asking “why?”—explicitly as a child, internally as an adult. If an action is difficult or undesirable, it must be justified. More general principles justify specific cases. Stop at intersections because it is part of one’s duty to drive carefully; drive carefully to avoid hitting people; avoid hitting people because injuring others through carelessness is wrong. To avoid infinite regression (and all the cognitive trouble that would go along with it), there must be some end to this process of justification: humans need values that are valuable for their own sake, ultimate values not relying on anything else for justification. A value is an end, as opposed to a means to an end, and offers an end to thinking uncomfortable thoughts that have no answer. Ultimate values may be positive (for example, space exploration, or “the show must go on” in theater) or negative (for example, eschewing racism or adultery as purity violations). They are often experienced as sacred—self-evident, not to be traded off against non-sacred values, and perhaps even surrounded by a protective zone of “motivated ignorance,” as Jonathan Haidt puts it.9 Sacred values may be lost if not protected, and are difficult to recreate once lost. Social belonging Successful social belonging has been a prerequisite for survival and reproduction in the human line for millions of years. It is a need on par with the need for food. Indeed, humans in dire poverty often choose to spend money on social belonging rather than on more food. Even minor threats of social rejection cause anxiety and insecurity; one line of research suggests that social rejection hurts like physical pain. Philippe Rochat, in his book Others in Mind,10 calls social rejection the mother of all fears, the driving force behind most higher-order human psychology, particularly the exacerbated human care about reputation and the control of public presentation of the self. He continues: I propose that the need to affiliate and its counterpart, the fear of social rejection, together form the bottom line of what underlies the experience of shame, embarrassment, contempt, empathy, hubris, or guilt. This underlies all the powerful and often devastating self-conscious emotions that are presumably unique to our species. Social groups, rather than individuals, are the units that maintain sacred values. People generally adjust toward accepting the meaning sources of their near peers. Religious people who leave their community have difficulty maintaining old beliefs while surrounded by people with alien values and meaning structures. On the other hand, people with extreme religious beliefs report more happiness than less religious or non-religious people; the religious community provides both a reliable social belonging experience and a solid, clear basis for value whose self-evident truth is made easier to see by interaction with fellow believers. Isolation is profoundly disturbing, as prisoners detained in solitary confinement learn. Thwarted social belonging predicts suicide, as noted above. People faced with the loss of social belonging (especially stemming from the loss of a job or a romantic partner) are more likely to commit suicide. Those with sources of social belonging, such as a spouse or small children, are less likely to kill themselves. An important exception that proves this particular rule involves married prisoners. Research has shown that prisoners who were married or employed at the time they were incarcerated are actually more likely to commit suicide than unmarried, unemployed prisoners.11 In this case, the married, employed men experienced prison as a loss of a high level of social belonging in the outside world; unmarried and unemployed prisoners experienced less of a drop in social belonging, and may have even viewed prison as a continuation of previous belonging experiences, such as through participation in gangs. We rely on each other for belonging, and we rely on each other to maintain the collective sources of meaning. We cannot do these things for ourselves. Purpose The need for purpose is the need for a present idea of something in the future that motivates present action. All the sources of meaning provide ways to spread the self out over time, to consider the past and the future when weighing what to do now. Purposes provide reasons to make costly sacrifices in the present in order to improve the future. Baumeister12 divides purposes into two types: goals and fulfillments. Goals are short-term future plans that are likely to actually be achieved; once a goal is completed, a new one must be found. Fulfillments, on the other hand, are fantasies about an idealized far future. Eternal life in heaven is an example of a fulfillment, but many fulfillments are not religious in nature. Any goal that seems to offer, in one’s own mind, a permanent state of sustained positive affect, is likely to be a fulfillment rather than a normal goal. These might include fame’s promise of eternal bliss or “making it” in a high-status career, or more mundane matters like marrying or having children, or even the fantasy of “dropping out” and raising organic goat cheese on a farm. In each case, if we cared to look, we would observe that currently famous people, high-status careerists, spouses, parents, and goat farmers are not ecstatically happy all the time—they have goals and fulfillments of their own. In an important way, this is not the point: fulfillments do the job of motivating present behavior as long as they are plausible. Every aspect of meaning is characterized by illusion. The present self is fooled in order to coordinate its actions. In a later section we will consider who is doing the fooling. Efficacy People need to feel that they have control over the world around them, that they have the ability to reach goals or realize values. Efficacy means the capability to help others as well as oneself. Baumeister et al. (2013) found that a greater sense of meaning was associated with doing things for others, even though in many cases happiness was reduced even as meaning was enhanced.13 Loss of efficacy happens naturally with aging. Over time, the faculties and capabilities used to define the self erode. Similarly, disease or paralysis can harm one’s sense of efficacy. Without efficacy, it’s hard not to be a burden on others; the sense of burdensomeness, along with thwarted belonging, are among Joiner’s three predictive factors for suicide. Suicide itself may be pursued in order to restore some amount of efficacy with the act of death. Self-worth or status The need for self-worth is the need to feel that one is valuable and important relative to others. This kind of status is comparative, and is often realized by comparing oneself to those lower in status. Hierarchies provide self-worth of this kind to everyone except those at the very bottom, who must find alternative bases for self-worth. In societies without clear status hierarchies, there is less certainty about social position, hence more worry. In societies whose social system is in upheaval, for example by political or technological revolution, values of each type may be lost. It may be best to have many sources of meaning to rely on, each acting as insurance against the others’ disappearance. The old sources of meaning are cultural items—items of information that reproduce themselves using humans, in a symbiotic rather than parasitic relationship. The cultural package of religion, morals, dietary rules, and heroic stories is the result of hundreds or thousands of years of environmentally attuned replication and refinement. Old sources of meaning have a deserved prestige: they have been proven to work in the environments in which they appear for as long as they’ve been around. They represent the social capital investments made by the group’s ancestors over generations. But when the environment is changing quickly, old values may no longer fit the new conditions; conservative value-maintenance processes may not be enough to control the decline of old sources of meaning. How can you recover lost values? Deep, effective value justifications are rare, and if lost, may not be replaced. Generally, when faced with the loss of a value, people act very conservatively; rather than seeking radically new kinds of value, they seek to elaborate on an existing value. In recent decades, faced with the loss of old sources of meaning such as religion, consensus morality, and neighborhood belonging, and lacking a value justification, the existing value of self-worth began to play a greater role in carrying meaning. Prior to the nineteenth century, the self had been commonly regarded as a very bad thing, the enemy of God and of the interests of the group. But gradually, as the foundational bases for value crumbled during the twentieth century, the self, rehabilitated, took on the role of value justification and became the seat of self-worth. The heavy modern self has a hard task: it must do for itself what human religion and community did in the past. It must provide itself with meaning. Individual selves have been appointed to authorize morality after consensus morality lost its power to coordinate groups. Marriages began to be expected to be a source of personal fulfillment to the individuals involved. Opinions on divorce changed drastically during the 1960s and 70s; what started as an unthinkable act under all but the worst circumstances became a common practice, understood to be sometimes necessary in order to be true to oneself. Millennials, the most recent generation to come of age in America, have grown up attempting to define meaning for themselves in this strange post-value world. Not surprisingly, opinion polls find them to be selfish and obsessed with fame. Having grown up with only the self to look to for guidance, they have elaborated the only source of value they know. How Meaning Operates: Methods and Illusions Meaning takes many forms and operates in counterintuitive ways. Rather than exploring entirely new domains from which to derive meaning, people tend to stick with what they know, elaborating or reinforcing old sources of meaning. Mothers in prison for killing their children are a particularly meaning-deprived group.14 They have lost a great degree of social belonging. Their self-worth is very low, especially when measured against the role of “mother.” Their efficacy is limited, and they cannot find a justification for their actions. In one survey of such women, nearly every one preferred the same path toward a reunion with meaning, at least in her own mind: almost every mother wanted to have another child as soon as she got out of prison, so that she could prove (especially to herself) that she could raise a child properly and regain her self-worth as a good mother. People tend not to seek out radical new sources of meaning; when meaning is lost, they attempt to restore old sources of meaning, no matter how much this risks encountering the same harm that occurred before. Genuinely new sources of meaning do appear from time to time, with varying success at providing for people’s needs. Science and space exploration are new sources of meaning, sacralized decades ago but still closely protected in online social networks. Science is especially seen as a sacred value of liberalism in America, although certain aspects of science (such as psychometric research) conflict with other, more sacred values. Medicine is a new sacred value, especially since the invention of antibiotics gave doctors a genuinely effective tool in the 1940s. Medicine is implicitly based on another sacred value, science. Health is an acceptable value for a modern who is excessively dependent on the self for value; focusing on health provides goals or even fulfillments (the imagined endless elation when a weight-loss goal is attained) and efficacy, while preserving the self as both a value base and a seat of self-worth. The heavy modern self, expected to provide its own meaning, seeks to escape meaning when messages about the self are painful. Yet another popular new method of obtaining meaning is to identify with, or loyally fight on the side of, people who are in some manner oppressed. Old oppressed groups are mostly still around (except for the satanic ritual abuse victims, who finally had to leave), and more importantly, new oppressed groups are constantly being discovered. These groups often turn out to have value bases in and of themselves, offering ultimate value, social belonging, efficacy, and self-worth. Meaning infection Meaning in all the forms above is socially transmissible. The social group itself is powerful; group expectations can prompt behavior that an individual cannot perform on his own. In her book on religious glossolalia, Speaking in Tongues,15 Felicitas Goodman notes that her subjects could only enter a glossolalic trance in the presence of others, and the bigger and more committed the group, the more powerful the effect. You can’t make yourself speak in tongues, but being among others who believe you will speak in tongues can induce that experience. The group’s familiar presence induces a powerful disinhibition unavailable to a lone person. Meaning operates in a similar manner: as a form of social cognition. A person integrating into a new group will absorb many of the new group’s meanings and values. Group membership affects individual values and has for all time; modern geographic mobility means that individual values have recently begun to affect group membership as well. A moral: be careful whom you accept as an in-group member, as you will almost certainly absorb some of his values. False permanence Sources of meaning display false permanence. They appear to be stable, unchanging, and permanent, but this is one of many illusions involving meaning. In reality, the scrappy source of meaning must adapt and change to survive, or risk disappearing; both its stability and its permanence are illusions. Fulfillments are especially burdened by false permanence, promising eternal positive affect and endlessly satisfying high status. The stability of value bases is often exaggerated, such as with modern marriage relationships. Modern young people are starved for meaning and crave to attach it to themselves permanently, but tattoos and expensive weddings, sadly, can’t put back together what no-fault divorce has torn apart. Suffering measures meaning Happiness and meaning are correlated.16 Meaning does seem to contribute to happiness and ease suffering. There are many factors, however, that are correlated to meaning but not to happiness. Experiencing many bad events, for instance, predicts a sense of meaning but also unhappiness. Anxiety is also positively correlated with meaning but negatively correlated with happiness. Meaning increases with certain kinds of suffering; the meaningfulness of a particular group or experience is proportional to the suffering incurred to join. More intense initiation or hazing rituals create more meaningful bonds within the group. More demanding or more religious utopian communes tend to last longer than their more easy-going or secular brethren. The experience of meaning in proportion to negative experiences is somewhat malleable. When people are reminded of the costly, negative aspects of a source of meaning, such as the high economic cost of children,17 their evaluation of the source of meaning becomes more positive and more meaningful in comparison with people who are given a more positive spin on childrearing. Meaning appears in proportion to the suffering that occasions it, and meaning can quickly smooth over uncomfortable inconsistencies revealed in one’s worldview. From the outside, it appears to be an illusion; from the inside, it is experienced as powerful and profound. Illusion of control Some sources of meaning provide actual control over the world and one’s circumstances. Some only provide the illusion of control,18 which may be just as good. In 1969, researchers tested stress responses to loud noises. Subjects who were blasted with loud noise found the experience very distressing. In one group, however, each participant was given a button; this button, they were told, would turn off the noise if it got too bad. None of these subjects used their button (which wasn’t plugged in anyway), but they mostly felt a lot better about the noise. Shamans, witches, and even medical doctors often provide an illusion of control to suffering people. A love spell or a bottle of cholesterol pills probably won’t have much real-world effect, but such props can provide a much-needed sense of control to a suffering person. Life, perhaps, would be more enjoyable and less miserable if it were not mandatory. The Story When meaning takes the form of a narrative, this is another illusion, though again perhaps a benevolent one. Narratives help us organize the past according to the needs of a present self. The stories we tell ourselves about ourselves also help us plan for the future, as with goals and fulfillments. There is one particular story that is among our most resilient pieces of cultural information. It arises spontaneously on all continents at various times, and quickly spreads. Depending on its specifics and its messenger, this story can facilitate a revolution or it can protect the status quo. The story is the one about bad people doing bad things, and how they are responsible for the problems in the world. These bad people must be rooted out and stopped for the sake of the country and—often quite literally—the children. A folklore term for this kind of story is a “subversion myth.” Historical examples abound; here are a few from Jeffrey S. Victor’s paper19 “Satanic Cult Rumors as Contemporary Legend”: In Ancient Rome, the stories commonly claimed that Christians were kidnapping Roman children for use in secret ritual sacrifices. Later, during the Middle Ages, the stories claimed that Christian children were being kidnapped by Jews, again for use in secret ritual sacrifices…In France, just before the French Revolution, similar stories accused aristocrats of kidnapping the children of the poor, for use of their blood in medical baths. [Citations omitted.] Police in modern Saudi Arabia routinely hunt, arrest, prosecute, and execute witches. In the early 1980s, Christian religious programming on state-run television in Benin, Nigeria, generally condemned Western influence and blamed the country’s problems on corruption and witchcraft.20 The Benin example highlights that the vilified class need not exist in reality for the story to be effective, as with the satanic cult ritual abuse panics of the 1980s and to some extent the modern wars on terror and bigotry. What makes the story of bad guys so popular? Mainly, it provides a universally applicable justification for why things are not going well. In human societies, things are generally not going well in a variety of ways, at least from the perspective of individual members. But subversion myths arise in times of special trouble; as Victor puts it, they “usually arise at times when a society is undergoing a deep cultural crisis of values, after a period of very rapid social change has caused much disorganization and widespread social stress.” This justification for things not going well satisfies people’s need for an explanation. A story that vilifies those in power may precede (and perhaps precipitate) a revolution, as in France. Revolutions are particularly likely to occur when things are really, really not going well in a society in the first place, hence there is a great perceived need for an explanation. A story that vilifies others, however, is useful once the revolutionaries have seized power and become the government, with an interest in maintaining the status quo. When religious movements like Islamism, democracy, Christianity, and communism first come into power, things are generally pretty bad; the new government has something like regression to the mean on its side. Unfortunately, political societies are delicate, carefully evolved systems and it’s amazing that they limp along at all; attempts at reform, like mutations in DNA, usually make things worse. Yet the story offers hope. Millions of scapegoats have been executed by governments in service of this story. Despite its flaws, the story is certainly more comfortable than suddenly accepting that large human societies just can’t be very good or wise or fair or free, and that attempts to manipulate the intricate yet lumbering social ecosystem, no matter how well-meaning and carefully researched, usually make things worse. Non-fungibility of meaning A final illusion that meaning creates is one of particular specialness with regard to the source of meaning. People get attached to sources of meaning and regard them as irreplaceable. Actually, it does not seem to matter what source of meaning appears, as long as one is found.",
      "chapter_number": 8,
      "section_number": null,
      "word_count": 3942,
      "file_path": "index_split_008.html",
      "spine_order": 9
    },
    {
      "title": "Chapter Three: The Modern Sacredness and Moral Foundations",
      "content": "Chapter Three: The Modern Sacredness and Moral Foundations Sacredness is a universal human phenomenon. Emile Durkheim proposed that religion operates in all human societies, whether visibly or not: wherever there is a moral community, it will display particular beliefs and practices for the veneration and maintenance of its sacred objects. Sacredness is often invisible from the inside, but we can see its nature when it changes rapidly over a short period of time. The trajectory of smoking in American culture from the 1980s to the present is a case study in the formation of a modern sacredness. Smoking was common during the middle of the last century—in restaurants, in offices, even on airplanes. But public focus began to be drawn to the harms of smoking, especially cancer. Tobacco companies were vilified for selling deadly products and for hiding their deadly nature; cigarettes themselves absorbed some of this moral indignation. Not only the act of smoking but also images of cigarettes were regulated and prohibited. The proportion of smokers in the United States plummeted over a few decades. Cigarettes became not just harmful, but ritually impure, a sacredness violation. The prohibition’s magical, religious nature can be seen in the way that cigarettes ritually contaminate activities similar to smoking, but without any of the harm that justified the marginalization of cigarette smoking. Nicotine inhalers have gained popularity in the United States, offering nicotine delivery in a manner functionally similar to smoking, but without any of the carcinogens released by burning tobacco. This practice has been the subject of bans and strict regulation in many states, cities, and private companies. What has happened is that the impure, profane act of cigarette smoking has rubbed off its residue of moral degradation onto the behaviorally similar act of using a nicotine inhaler. Breastfeeding in the United States has undergone an opposite trajectory. A few decades ago, breastfeeding was an act performed in private, and only in desacralized areas. (My own mother remembers not being allowed to breastfeed in the Mormon church when I was a baby, over thirty years ago.) Public breastfeeding was an unspoken violation, and as such would have been disturbing to witness. However, activist pro-breastfeeding groups such as La Leche League formed networks of new mothers, transmitting pro-breastfeeding ideas from woman to woman, insisting that they conceive of breastfeeding as natural, not sexualized, and not shameful. These ideas are now widely held, even somewhat sacralized, and public breastfeeding is much more common. Employers must accommodate the breastfeeding schedules of their workers. Even the Mormon church now encourages and supports the practice. Criticism of or threats to breastfeeding are now seen as sacredness violations, whereas decades earlier public breastfeeding would have been the shocking violation. Sacredness illuminates a practice or an object with a halo of righteousness, or casts onto it an aura of contemptibility. It functions to limit the discussion that is permissible surrounding the sacred object, including the nature of its depiction in art and culture. The cognitive phenomenon of sacredness even limits the thoughts that are comfortable for an individual to have regarding the sacred object. Morphology of the Sacred What is the sacred? What does it look like, and how does it behave? Jonathan Haidt, investigator and popularizer of moral foundations theory, gives the following hint about the sacred: “The fundamental rule of political analysis from the point of psychology is, follow the sacredness, and around it is a ring of motivated ignorance.” This epistemic feature— that sacredness protects itself by tabooing the wrong kinds of thought near its foundations—is exploited in the foundational legends of a culture, origin stories that are often sources of sacredness. Folklorist Linda Dégh might be regarded as an expert on the folkloric legend (as distinct from märchen, magic stories that English speakers would refer to as “fairy tales”). The main difference is that the legend is a personal story that invites genuine disbelief (think “urban legend”), whereas märchen are impersonal stories that are clearly not intended to be believed. But sacred, foundational narratives are not ordinary legends, she says. In discussing the definition of the legend, Dégh says that there are some stories that she excludes from the label “legend”: Arguing for the disputability factor as crucial, I excluded legend-like narratives that enforce belief and that deny the right of disbelief or doubt, narratives that express majority opinion and are safeguarded by moral taboos from negation and, what is more, from deviation.21 Dégh’s examples are “religious (Christian, hagiographic, or saint’s) legends,” and the “patriotic (heroic) legends dispensed through school education by governments, confirming citizens in civil religiosity.” Not only churches may form moral communities that function as religions, but ostensibly secular societies as well. We may not really question the harmfulness of tobacco or the benefits of breastfeeding and remain truly polite. Sacred beliefs are those that are held by consensus within the moral community. It is useful for groups to share sacred beliefs—indeed, even outlandish beliefs—as these are costly signals of commitment to the group that enhance trust and cooperation within the religious community. Cognitive and social mechanisms reduce expression of ideas that threaten the sacred belief or object, and these social mechanisms have the function of a moral taboo to protect sacred truths from negation, or sacred purity from violation. As a result, people are indignant at the suggestion of trading off sacred values for ordinary values—and the more nakedly obvious the trade-off is made, the more indignant they will be. Sacred beliefs are so powerful that outlandish beliefs are often maintained—even strengthened—in the face of strong disconfirmatory evidence. In their now-classic study,22 Festinger et al. give an account of a UFO cult whose leader predicted the destruction of the earth on December 20, 1954. The leader claimed that a spaceship would come before the destruction to rescue the faithful believers, but when the spaceship did not arrive as predicted and the world was not destroyed, the group faced a serious threat to its underlying sacred beliefs for which the members had sacrificed a great deal. Yet the group did not dissolve in shame. They were receptive to a new message received by their leader, to the effect that their faithfulness had spared the world from destruction. The group is reportedly still active today. The group-maintained sacred belief was so strong that even the most damaging possible evidence was not enough to undermine it. So much for the UFO crazies. But it was only a couple of decades ago in the United States that it was widely believed that satanic cults were abusing and murdering vast numbers of children. The McMartin Preschool trial allowed prosecutors to spin a tale of the perfect sacredness violation: an evil conspiracy by entrusted adults to sexually abuse vulnerable children. As unprecedented numbers of women entered the workforce in the 1980s the expanded use of daycare increased guilt and uncertainty associated with leaving children under the supervision of unrelated caregivers, setting the stage for the perfect sacredness violation to become a moral panic. No convictions resulted from the McMartin Preschool trial, but over the course of the three-year trial the lives of the accused were irreparably damaged. Similar accusations would soon lead to the erroneous prosecution, conviction and imprisonment of many unfortunate scapegoats.23 The Arkansas teens known as the “West Memphis Three,” for example, were convicted of ritually murdering three children toward the end of the moral panic in 1994,24 despite the fact that no forensic evidence tied any of them to the crimes; they were released in 2011 after spending over eighteen years in prison. The connection between sacredness and victimhood can be understood from such examples. Innocent children left in the care of strangers provided the most vulnerable possible victims, and better yet for memetic transmissibility, this victim status was up for grabs. Recovered memory therapists sought clients with the message that anyone might be a victim of satanic ritual abuse and not know it. The offer of status and attention for “recovering” memories of abuse found many takers. It is often the case that when a sacred belief assigns special status to victims of particular holiness, the number of these extra-holy victims grows. A Window into Sacredness: The Violation Sacredness is most clearly revealed in its violation, especially in the modern world in which conflicting worldviews often collide. The violation of sacredness triggers the social mechanisms that protect the sacred object from attack. The sacredness system may be viewed as having two components: first, the individual human capacity to perceive and respond to sacredness; and second, the cultural items that are held to be sacred. There is great variety in the nature of things held to be sacred, though these follow regular patterns, generally representing collective group interests. Fashions in sacredness travel quickly, as illustrated in the introductory examples. The human capacity to perceive sacredness—sacredness susceptibility—varies within human populations and likely between populations, though probably more in magnitude than in the nature of the underlying psychological processes. The window into the workings of sacredness is especially wide in the modern world, in which members of different moral communities with conflicting sacrednesses frequently interact. In an established, insular community in which everyone understands the same sacredness and wishes to avoid giving offense (thus risking rejection from the community), sacredness violations are likely much rarer. Sacred beliefs can only be maintained by the community, but they are stored in the minds and bodies of community members as part of their individual and group identities. To a believer in a particular sacredness, an attack on that sacredness is an attack on himself. Sacredness violations are perceived as aggressions, and produce similar physiological states of arousal; the poor person experiencing an attack on his sacred foundation has no choice whether to feel this psychological pain. Relying on a particular sacredness leaves us vulnerable to violations—and our responses to this violation protect the sacred object. We must choose our sacrednesses wisely; circling the totems of our community is an excellent strategy. Thanks to the candor of Internet communications, we know something about the physiological effects of suffering a sacredness violation. When confronted with a threatening worldview, sufferers report a variety of physical symptoms, such as heart pounding, shaking, and vision changes; some think they will “black out” from rage. These symptoms line up well with a “fight or flight” arousal response to aggressive threats. Indeed, in this state, the victim of the sacredness violation wishes violence (and even a violent end) on the violator with disturbing frequency, even when the sacredness violation was not violent in nature.25 Sacredness violations threaten all four types of meaning detailed in Chapter 2. First, our sacred objects are frequently identical with our value bases or terminal values; the threat to the sacred is a threat to the foundation of all else. Second, sacredness violations may threaten the plausibility of fulfillment states, the (largely imaginary) future states of perfect happiness and justice that we are all supposed to be working toward and making it easier for each other to believe in. Third, sacredness violations that relate to identity and self-worth are particularly painful; the modern self carries a heavy burden of meaning, and even very mild and realistic reminders of one’s own ordinariness or mediocrity can be devastating. When one has attached a sacred meaning to an aspect of his identity, the threat to this sacred meaning is perceived the same as a threat to his physical person. Finally, sacredness violations threaten efficacy, making us feel powerless in the face of attack; it is common for individuals so threatened to attempt to form a coalition of sacredness violation victims with which to confront the violator. It is important to understand that sacredness violations actually do subjectively hurt the person experiencing the violation, and that he has little or no control over this process. Empathy demands attention to sacredness, and sacredness is maintained and standardized within the community as much by the desire to avoid hurting others as by the desire to avoid being exiled from the group for insufficient piety. This process means that what is held sacred by people within a moral community will tend to converge on a consensus, even if they start out with a variety of notions of the sacred. In sum, when a sacredness violation occurs the victim whose sacredness is threatened perceives an aggression and enters a state of fight-or-flight arousal. When the reaction is threatening enough the victim will seek to form a coalition condemning the sacredness violation. (Incidentally, this has the effect of spreading the offending violation to more eyes and ears; some publicity strategies specialize in triggering a sacredness reaction in the hope that it will lead to sharing as part of coalition building.) Finally, if a powerful enough coalition forms, the violator will be sanctioned, either with threats or actual harm, up to and including the loss of his social position. Sacredness Negotiations This “converging on consensus” describes the negotiations for sacredness within a group. These negotiations are vulnerable to being turned to the benefit of savvy individuals at the expense of the group; sacredness, like honesty, is as much an exploit as a feature. Honesty is a valuable quality in a cooperation partner, hence a valuable quality to signal; a display of genuine honesty may often be the most effective way to signal trustworthiness and thereby secure cooperation. Similarly, those who are susceptible to sacredness are valuable as sincere cooperation partners since they are unlikely to defect. Signaling that one is susceptible to sacredness is therefore valuable, and actually being susceptible to sacredness might be the best way to do this. Experiencing sacredness together—mutually acknowledging invisible but tacitly understood objects—enables human coordination at a high level of complexity. When groups are in conflict, sacrednesses battle rather than being negotiated; each side holds more firmly to its sacred beliefs even when—especially when—presented with threatening evidence. Within groups that reproduce cultural items, some of which are sacred, these cultural items undergo evolutionary processes. They mutate and change if not held in check, and they do so in particular patterns. Since sacredness is ultimately a kind of signal, it may become the central instrument in a process similar to that hypothesized to burden some animals with fitness-detracting sex characteristics in “runaway” sexual selection. Both humans themselves and their sacred objects evolve together; this is multi-level selection. At the level of cultural evolution, symbols acquire their own reality. Sacredness draws resources toward symbolic complexity and away from the underlying foundational reality. Old cultures achieved equilibrium with their human hosts, or disappeared; new cultures in an environment of rapid technological change mutate beyond anything seen before. Moral Foundations Jonathan Haidt’s moral foundations model describes human moral reasoning as the product of several cognitive processes, which are mostly intuitive and non-rational. The top candidates for “rational” moral foundations are the harm/care foundation (caring for others and not harming them) and the fairness/cheating foundation (regarding norms of fairness and desert). Haidt has argued that political liberals use only these two moral foundations in moral decision making, whereas conservatives have three more capacities: loyalty (the preference of the in-group over the out-group), authority (respect for hierarchy and role), and sanctity or purity (which is at the heart of this chapter on sacredness). However, Haidt recognizes that even political liberals maintain a “zone of motivated ignorance” around their sacred concepts and beliefs. Recently, Haidt has endorsed a sixth category of moral foundation, liberty/oppression, or preferring freedom to coercion; this is the moral foundation that most characterizes libertarians. It is likely that moral communities of all political varieties use all moral foundations; it is just harder to see the sacred moral foundations of the dominant moral community, as even the investigation into whether something is sacred may be seen as a sacredness violation. Haidt points out that while the students involved in the Weather Underground bombing were firmly grounded in the harm/care foundation, they were able to engage in harm—bombing—because they sacralized the victims (e.g., Native Americans) of their enemy. Many conflicts become apparent when we try to imagine that modern liberal political reasoning is immune to loyalty, authority, or sanctity. First, liberals as much as conservatives tend to confuse a sacred symbol with its referent, lending an aura of sanctity to what might otherwise be a pure harm/care consideration. Not only was smoking cigarettes restricted and prohibited, but also representations of smoking (so as not to send the wrong messages to children) and eventually smoking’s largely harmless cousin, the nicotine vaporizer. To engage with a more emotionally charged example, consider rape. Few people would deny that rape is a serious harm, but even the insufficiently pious discussion of rape may be perceived as a sacredness violation. Second, sacred beliefs that are naturally defended out of harm/care or fairness concerns (and hence presumably up for utilitarian calculus) are not, in fact, analyzed for overall harm or fairness. Anti-discrimination policies (as against women, racial groups, people with disabilities, and gay people) are enacted without provision to measure their realworld effects. To even suggest that these policies, based on sacred beliefs, have bad outcomes for the very people they were ostensibly designed to help, is treated as a sacredness violation. Health care is viewed as a clear case of harm/care, but as with anti-discrimination laws, outcome measures are often lacking compared with a refusal to “trade off ” the sacred value of health against other values that also affect quality of life. Expressions of shock over the prospect of “rationing” medical treatments or over “death panels” exemplify the sacralization of health care. Third, loyalty in the modern liberal way of thinking is imagined to be spread amongst all humanity, not limited to a petty in-group. However, in practice, modern liberals do seem to recognize a political out-group against whom calls for violence are permitted and even encouraged. Emphasis on the low social status of political enemies is a milder tactic that nevertheless illustrates the working of the loyalty foundation. Fourth, the fairness foundation would seem to be in conflict with an ideology that enshrines the “Just World Fallacy” as doctrine in its ethic of education for all, to solve all problems. This logic works out in a manner that will be familiar to theologians: on the one hand, legal policies are changed to ensure that educational opportunities are widely available to disadvantaged groups, from Head Start to college. On the other hand, these policies do not seem to lead to equality the way they should (according to the committed beliefs of political liberals). But rather than challenge the sacred beliefs underlying the conflict, an enemy is posited to explain away the apparent discord: entrenched oppression and discrimination must still be present, despite the best efforts of reformers, and true believers must renew their commitment to eradicating it. This process is reminiscent of the way many Christians resolve the Problem of Evil, or the contradiction between a loving, powerful God and the misery apparent in the world: they posit an enemy, the Devil, who is responsible for evil. Both forms of evil—discrimination and the Devil—serve the function of supporting a sacred belief system and avoiding dissonance. Sacrednesses Old and New Emile Durkheim described the death of gods as the failure of groups to maintain the sacred objects (gods) as “social technology” in the face of a rapidly changing world. He noticed the emergence of a Cult of the Individual that he hoped might take the place of gods in providing sacredness. Baumeister documented the tensions and failure modes of the self-as-source-of-meaning strategy (see Chapter 2), resulting in the unnaturally stressed modern self and the suffering it endures (and often tries to escape). Durkheim also noted the emergence of a new, modern religion whose sacred objects, rather than gods, were equality, justice, and individual freedom. Indeed, these are sacred values today, and violations that threaten them often trigger the fight-or-flight responses described earlier. A “ring of motivated ignorance” surrounds these values, protecting them from rigorous examination. Unfortunately, these sacred value bases have shown themselves to be fragile; they are more vulnerable than the old gods to exploitation by status seekers, and they are more susceptible to churn and change that leads to the destruction of social capital. Equality is the foremost sacred value of the secular religion of the West. Equality before the law is connotationally extended, in the logic of sacred things, to imply equality of important inherent characteristics. To threaten the sacred idea of racial equality is a transgression particularly likely to result in sanctions against the violator. Gender equality (and, more recently, equality across sexual orientation and gender identity) is another especially sacred value. The sacred value of women is complex and contradictory; the modern religion axiomatically defines women as equal to men, ascribing any differences to sexist rearing and social expectations, but women are also treated as special victims in need of protection. The sacralization of rape (that is, viewing rape as a special sacredness violation whose mere symbolic representation has the power to harm) harnesses this contradiction. The work ethic, Baumeister argues, is not the age-old sacred moral foundation it once pretended to be; rather, it is a novel, modern invention that filled, for a time, the value gap created by rapid industrialization. The work ethic relied on contradictions that made it ultimately unstable. “The work ethic failed because it increasingly became incompatible with actual human experience,” Baumeister says.26 Workers were expected to see work as a source of long-term reward and social mobility, but these promises were quickly seen to be bogus. Work was at once seen as having intrinsic value (work for work’s sake) and extrinsic value (for money and status). These values proved difficult to reconcile psychologically, and an ethic that demanded self-denial was at odds with a culture that increasingly promoted consumption and self-expression. And, of course, work was getting more and more boring all the time. In our time, the education ethic has replaced the work ethic. As a modern sacred value, education provides a fulfillment state both in the personal and the societal sense. In the personal sense, education promises a future state of high status and advancement, all deserved through one’s own work and skills. In a societal sense, education is extolled as a basis for advancement that can be distinguished from inherited intelligence—an idea comfortably compatible with the premise of basic equality. However, in the foundation of the education ethic one can detect cracks similar to those that were the undoing of the work ethic. High expectations of fulfillment states are met with mediocre job prospects. Analyzed economically, education appears to offer more opportunity for signaling inborn intelligence than for actually increasing intelligence, productivity, or status. Women in particular are tempted to spend years educating themselves in the hope of making a higher status match, but are often disappointed; years of aging while in school generally reduce their mating value more than the education acquired increases it. The view that education equals intelligence—that environment is everything and that genes matter not at all in important matters—is highly compatible with the sacred value of equality. Higher education—indeed, even the prison-like primary and secondary education required of young citizens—functions as a sacred and very costly ritual to ensure high status and group belonging. The costs are internalized by the young people who gamble on their culture’s sacred beliefs—and through this process the ravenous culture comes to own their future productivity, while rarely delivering on its promises. The profligate dumping of money into education can be understood as a case of runaway signaling; more and more resources are devoted to an exercise that has less and less contact with non-symbolic reality. Old sources of sacredness have survived but are now encountered in a new way. Children probably always provided a source of ultimate meaning and sacredness, but now they are more sacred than ever, and in different ways. Children, now being very costly to raise, no longer provide a financial benefit to their parents. So children must instead provide meaning to make up for the missing material benefits. Having children is also, for the first time in human experience, genuinely a choice rather than a matter of course or providence. This choice must be justified, as it did not have to be in the past. Sacredness may be detected in its violation, but it is also a positive phenomenon. The sacredness of motherhood (another old sacredness) can be detected in that marginal groups emphasize their connection to maternity in order to assert legitimacy. Sex workers emphasize that they are mothers in order to justify their stigmatized career path. “Stay-at-home-mom” has become an approved euphemism for the older term “housewife,” which is now considered embarrassing without the boost of sacralization from motherhood. A Necessary Danger Sacredness is necessary for the coordination of human action, for politics, for orderly human life. It is essentially a valuable illusion created cooperatively by the social unit, often over a long time at great cost, and then maintained and defended against mutations and competing sacredness structures. Sacredness secretly informs all of our judgments, even those that seem to be purely related to harm or fairness— indeed, even those that don’t seem to have a moral dimension. Old sacredness structures that coevolved with our ancestors over generations have crumbled in the face of rapid social and technological change. Will our new sources of sacredness provide the basis for a flourishing, stable society? Or will they too crumble—or spin off into forms of increasing complexity and fragility? It is possible that the swift mutation and spread of sacred ideologies may prove destabilizing and destructive. Like invasive species, newly coined values are untested within our rapidly changing ecosystem. Sacredness organizes human behavior and helps groups ease individual suffering by providing a sense of meaning. But sacredness is also a source of suffering and misery, with the potential for rapid, destructive sweeps. Removing the sacredness from human life is not a goal that is likely to be achieved, nor even a very desirable one. Our responsibility is to examine our own cognition as best as we are able, including that part of our cognition that perceives and responds to sacredness. By watching ourselves and others as we experience sacredness and its violation under many circumstances, we lay a foundation to be able to judge—and perhaps engineer— sacred objects.",
      "chapter_number": 9,
      "section_number": null,
      "word_count": 4392,
      "file_path": "index_split_009.html",
      "spine_order": 10
    },
    {
      "title": "Chapter Four: Experience Machines and Their Ratification",
      "content": "Chapter Four: Experience Machines and Their Ratification Suppose there were an experience machine that would give you any experience you desired. Superduper neuropsychologists could stimulate your brain so that you would think and feel you were writing a great novel, or making a friend, or reading an interesting book. All the time you would be floating in a tank, with electrodes attached to your brain. Should you plug into this machine for life, preprogramming your life’s experiences? —Robert Nozick, Anarchy, State, and Utopia I believe that we should be very cautious about creating conscious beings, and I believe that the ideal number of conscious beings (and perhaps even living beings) in the universe is probably zero, for the good of those beings themselves. Since suffering and misery are inescapable parts of life, if we are to justify creating life there must be something that outweighs suffering and misery within the space of universal judgments. Candidates generally fall into two categories. The first category is essentially hedonist: pleasure or good experiences are said to outnumber or outweigh bad experiences. This is the objection Bryan Caplan is making with his Free Disposal argument, discussed in the first chapter; assuming preferentism (that people choose what is good for them), and assuming that people have free choice in the relevant arenas, people would merely commit suicide if it were not true that the pleasure of life outweighs the suffering. And since only a million people per year commit suicide, creating life is obviously the right choice. A more subtle variation of this argument does not rely on suicide, but on a sort of imaginary survey: most people would probably report that their lives are worth living, that the good outweighs the bad, and therefore it must. The second category of responses is that there is something valuable and meaningful about life that makes it worth living even if the bad vastly outweighs the good. In the previous chapter, we explored and categorized some of the things that people find meaningful, noting how these change according to circumstance and over time. One of the most salient features of the things that make life seem meaningful is that they frequently rely on illusion: the illusion of unchanging permanence, of a future state of happiness, of one’s ability to affect the world. It is my view that the sense of meaningfulness is itself an illusion, a cognitive phenomenon that is very adaptive for individuals and groups. This illusion is maintained by communities in order to organize the behavior of individuals, in part by easing their suffering. One response to this is to counter that meaning is not an illusion—that there is real value in the world beyond what is experienced by living beings. Unfortunately, the proposed real and true meanings are often difficult to express in words to others who do not sense their truth. The feeling that life is meaningful is a pre-rational sensory perception that is widely shared. However, the specific meanings that people find satisfying and convincing are disparate and often contradictory. These underlying realities should make us question whether the sense that life is meaningful—or that some specific meaning can be found in life—is a true observation, or merely an illusion. The very adaptiveness of this belief, even if it were not true, must also make us suspect its veracity. The meaning realist has the further problem that no specific meaning is held by a majority of humanity; if there is one true meaning, then whatever it is, the majority of people’s lives go very badly because they do not perceive it. Another response is that while meanings vary, it is enough that almost everyone finds some meaning in life. In other words, the sense that life is meaningful is enough to justify life, and the myriad meanings found and elaborated by individuals are all, in fact, the meaning of life. This seems to be the most common position articulated in modern post-Christian Western societies: if a person finds his life to be meaningful, then it is meaningful—even if different people find contradictory meanings in life. One person might find a sense of meaning in fighting for equality, another in ethno-nationalism, and they are both right. This second response is actually a variation on hedonism, in that the experience of meaning, rather than the experience of pleasure, provides value. According to this view, a life of overwhelming suffering but with a deep experience of meaning might be better than a life of joy and pleasure that is internally felt to be meaningless. But ultimately, divorced from the meaning realism of the first response, this grounds meaning in subjective experiences; the sense of meaning becomes another form of pleasure. The modern idea that it is up to each individual to find meaning in life, and that this meaning justifies life, means accepting a meaning-based Experience Machine. The things that we find to be meaningful are, in fact, miniature Experience Machines. They rely on illusion and filter the information that reaches us so that we may continue to feel that life is meaningful, or continue to search for meaning in life if it is missing. They are very useful; they help us organize our behavior, coordinate with others, and manage our emotions. In a practical sense they often make the suffering of life bearable; but, once they are recognized to be illusions, they cannot justify suffering in an abstract sense any more than pleasure can. We need not jump into a Nozickian Experience Machine to get pleasure and a sense of meaning from intricate illusions. The Reverse Experience Machine experiment is close to the situation we find ourselves in—if we found out we were in an Experience Machine already, would we choose to leave it for the real world? Institutions, religions, social communities, and even individual people function as Experience Machines, creating and maintaining illusions that help us feel that life is worthwhile. A meaning realist would reject the Experience Machine, but to be consistent he must also reject those aspects of life that use illusion or information filters to provide meaning. A meaning subjectivist has little ground to reject the Experience Machine. This has implications for the justification of life’s misery based on meaningfulness. The True Gifts of the Good People: How Experience Machines Help Us Escape Uncertainty By necessity, each person must form a theory of the world that is abstracted from, and less detailed than, the territory of the world itself. There is no perfect theory; each theory must occasionally break down in the face of experience with the actual world. Many religious ideas are “gap fillers” that explain these breakdowns in models of reality. Experiences such as lost objects seeming to violate object permanence highlight the imperfect nature of one’s theory of reality. Rituals uphold the plausibility structure for the gap filler, self-signalling that the belief is real and substantial. I inherited some household rituals (mostly relating to food preparation) from my older female relatives. It’s strange that they survive to the present day. They are not religious, or rather they are performed regardless of the religion of the woman, being passed in my case with no explanation or justification. These include throwing salt over your shoulder if you should spill it (I later learned this is frequently explained as “throwing salt in the devil’s eye,” but I did not receive this explanation from the relatives I received the ritual from). Another is rubbing the cut end of cucumbers against the cut cucumber to produce a foam. This is supposed to “suck the toxins out of a cucumber.” I still perform this ritual, even though it obviously makes no sense. I am not sure why, but rituals seem valuable for their own sake. I have recently been reading a book of folklore, The Fairy-Faith in Celtic Countries by W. Y. Evans-Wentz, written in 1911. The author traveled around Ireland and its environs, interviewing people and learning their traditions involving pixies, fairies, and the like—euphemized as the Good People, the Gentle People, or sometimes even “them people.” Many of the rituals described are very appealing, and I have begun practicing some of them. One thing that interests me about the legends of the Gentle People is their inscrutable nature: they are at turns cruel and benevolent, sometimes stealing babies from their cribs and sometimes filling the house’s larder with meal. This is the background context for what follows. I recently experienced an object permanence violation, which is to say, my bright blue plastic dish scrubber completely disappeared from my kitchen. This was very strange, as I have a fairly organized kitchen and tend to know where all my kitchen implements are at any given time. But the bright blue dish scrubber was just gone—not in any hiding place big enough to hold it in my entire house. My sense of object permanence was seriously threatened. And in the context of my ritual performance, it actually occurred to me: those asshole fairies stole it! Obviously, the Gentle People did not steal my dish scrubber, inscrutable as they are. What happened was that I failed to record my own behavior, and when thinking about other things, I placed or dropped the scrubber somewhere I would not think to look for it. But it surprised me how easily this thought came to my mind—me, a proper woo-free atheist. I could see why the fairies have a dual nature, naughty and nice: they can act as a gap-filler for all sorts of violations in one’s theory of the world, such as apparent object permanence violations. And every theory violation thus explained becomes evidence for the existence of the fairies, supporting the belief. Of course, the mistaken theory in the case of a lost object is the fallacy of thinking one records one’s actions like a video camera. A lost object is a cognitive phenomenon. But it can definitely feel subjectively like a violation of object permanence. A gap-filler that explains apparent object permanence violations—such as fairies that pilfer things—can be satisfyingly called up to caulk over this hole in one’s theory of the world, supplying the gift of a comfortably whole theory of reality with no gaps. Performing rituals can facilitate belief in such gap-fillers. The act of throwing salt over one’s shoulder after spilling the salt, or taking a tiny bite of dropped food and throwing the rest back “for the fairies,” or referring to fairies euphemistically (“the good people”) creates a kind of plausibility structure for the belief. Acting on a belief makes it more real. Sharing a belief socially with others also makes it more real; there is social proof, and the belief acts as an in-group solidifier. The belief may be socially rendered magical, not subject to rational examination. Subversion myths (the belief in bad guys doing bad things, discussed in the previous chapter), and beliefs about powerful enemies in general, serve the same needs as fairy beliefs: they provide comfortable explanations for experiences that don’t fit into one’s worldview. If a subversion myth begins to be supported by rituals (and other parts of a plausibility structure), it may spread and exist stably for a long time. The Gentle People are ambiguous; they do frightening deeds and benevolent deeds, forcing those in their thrall to commit murder but also to help out around the house. They represent a worldview that is violated in both good and bad directions, one with unexpected misery but also unexpected boons. A widespread subversion myth, however, may suggest a worldview that is mostly violated by bad experiences. The motion from ambiguous, inscrutable mythic beings to purely evil mythic beings is notable. Another possibility is that it accompanies a worldview that is much too nice and positive, and hence mostly needs gap filling when bad events occur. This may be a feature of the Experience Machine that it co-exists with: the more utopian the vision, the more purely evil the gap-filling creatures must be. Another possibility is that it is a feature of the experiences that get through and affect people—a feature of the experienced world—rather than a feature of the theory. A theory will need more patches for bad information if the world gets a lot worse, even if the theory remains the same. Friendly Neighborhood Experience Machines: Where Do They Come From? The belief in fairies seems an obviously pagan belief and precedes Christianity on the islands by many centuries. However, just as Christianity co-opted pagan cultural items for its benefit, the fairy faith rendered itself compatible with Christianity. A legend collected in multiple places (explicitly believed by many sources) is that the fairies are the angels who followed Lucifer out of Heaven and sort of got locked out of Heaven by God, being condemned to live in the caves and hollows of the earth. By fitting the fairies into the Christian legend, the islanders were able to keep their valuable fairy faith with its rituals and traditions while apparently bowing to the memetic sweep of Christianity. Small-scale Experience Machines evolve just like biological organisms; they are aspects of culture subject to mutation, selection, and even extinction in the face of environmental change. Those to whom the thought experiment seems distasteful feel that experiencing life through this Experience Machine would not be real; it would not entail contact with the deepest reality, and would be limited to the creative power of human beings. It would not provide us with pleasing signals about our true selves, but only fictitious signals about an imaginary self. Of course, many people (myself included) would be more than happy to enter a nice Experience Machine rather than undergo the allegedly real slings and arrows of outrageous fortune. But my contention here is that we all utilize one or more genuine Experience Machines all the time. These real life, friendly neighborhood Experience Machines include, most notably, religions and aesthetics. These are socially created, culturally reproduced information artifacts that provide a framework for our experiences, allowing us to select experiences to some degree and to give meaning to all our experiences, selected or not. They are created solely by humans, being further selected and shaped by generations of cultural evolution. They seem to suffer from the same problems as Nozick’s hypothetical Experience Machines in terms of connection to deepest reality, offering information about the true self, and being limited by human creativity. To the extent that you buy that this is so, I argue that you must either deny the realness and desirability of experience mediated by these culturally evolved aesthetic and religious frameworks, or on the other hand allow for the choice to utilize other Experience Machines that may be superior to existing ones in the dimensions of effectiveness, voluntariness, and honesty. This manner of viewing human existence has implications for the desirability of suicide and of bringing new humans into existence. Aesthetics and Religions: A Minor Distinction A distinction between the two main ultimately-not-very-distinct types of homegrown Experience Machines will help communicate the meaning of that term as I use it. The filling out of the category is more important than the distinction. Art requires obstruction; pure, limitless freedom is the death of art. An aesthetic is necessary for the creation and experience of art. This aesthetic need not be explicit or articulable, and frequently includes inarticulable elements. But even purely legible rule sets can create much of the aesthetic context that art needs in order to be meaningful. The Dogme 95 movement (and Lars von Trier’s The Five Obstructions) the salubrious effects of even almost random limitations on art. Daniel Dennett and Douglas Hofstadter have praised the practice of JOOTSing, or jumping out of the system, but an aesthetic or cognitive leap requires a system to jump out of. Without any such system or any limitations, we see shark jumping on the level of contemporary fine art rather than the creation of meaningful experiences. Religions also allow us to create meaningful experiences from the random chaos of sensory experience—especially those scary experiences in which our best theory doesn’t match up with reality. They allow us to believe that we have a meaningful role to play in the heart of something that is deeply meaningful in and of itself. Equipped with this belief, we interpret our experiences accordingly. It is often difficult to tell aesthetics from religions—if in fact there is a difference. Both aesthetics and religions are created and maintained socially; they promote intra-tribal bonding in natural and synthetic tribes, and they facilitate the identification and rejection of outsiders. Both are experience selection devices that help us produce, select, reject, and interpret particular experiences. They are culturally evolved and variable but display observable patterns. The major difference is that aesthetics are much more explicit than religions about pointing to the experience itself, rather than to something higher beyond the experience. Many aesthetics demand that the experience itself be recognized as the ultimate value. Food criticism (along with many other aesthetic domains) has a morality of focusing on the eating experience itself; within that domain, focusing on anything but the experience (such as social signaling) is a shameful sin. Religions, on the other hand, generally claim to point to a higher something, an ultimate value that the experience only evidences and does not subsume. The proper pursuit of this “higher something” leads to meaningful experiences, but the point is not the meaningful experiences but the higher something. Insight porn27 is an aesthetic; truth seeking is a religion. One layer of meaning, one layer of about-ness, separates the aesthetic from the religion. But wild specimens need not be tidily lumped into either category; frequently they display characteristics of both. Experience Machines that are clearly aesthetics may use pointing-to-something-higher in order to produce experiences. Those that clearly seem to be religions may use honest, conscious experience selection just the same. It is common, for example, for aesthetics, not just religions, to promote magical thinking regarding objects in order to produce meaningful aesthetic experiences. The magical history of objects motivates much appreciation and meaningfully contextualizes rapture. In the summer of 2013, I was able to hear Jing Wang as concert master playing Mahler’s Third Symphony. I had never particularly noticed the first violin in that symphony, and was not informed enough to be expecting anything special. Hearing Jing Wang, though, with my mouth open and tears streaming down my face, it was immediately perceptible that he was the most special part of the experience. Reading the program after the show, I learned that he plays a special violin made by a master in the year 1700; this seemed to explain and contextualize some of the awe that I’d felt listening to him. It turns out that there is a common perception among serious violinists (and many classical music snobs) that old violins produce sounds that are not duplicable by modern violins. The magical history of the object, its induplicable nonfungibility, produces a similarly magical sound. I later found out that this idea may be spurious—at least according to one study28 that found that serious violinists wearing blindfolds did not consistently prefer ancient violins to modern ones after playing both (and in fact frequently preferred modern violins while identifying them as sounding older), and identified genuinely older violins as sounding too new. If beliefs were just “about” correctness and experimental validity, we would expect violinists and snobs to carefully update on this information. However, I would not expect nor even necessarily recommend this updating. The magical belief about old violins, I think, functions not for the purpose of making correct predictions about the world, but for social reasons, including in-group identification and bonding and satisfying the need to elevate and give meaning to rapturous experiences—experiences bought at the cost of inhuman hours of practice. It is not just any lie—it is part of an Experience Machine. Buddhism, generally identified as a religion, seems to be on the aesthetic side of the divide in the distinction presented here. It offers cognitive techniques (such as mortality salience inductions and meditation) that are explicitly designed to cause the experience of liberation. The “something greater” that various forms of Buddhism point to (such as liberation for all in Mahayana Buddhism) seem to be more afterthoughts than central to the project, though some forms of Buddhism embrace more woo than others. At its core, though, it is not so much directed at a thing for its own sake; it is more for the experience (and the rejection of experience, namely that of suffering) that it claims to be able to provide. A further set of examples will demonstrate the enmeshment of aesthetics and religion. (Hopefully, reviewing marginal cases will help us more clearly see our own, possibly more subtle religious and aesthetic Experience Machines.) The Five Percent Nation of Islam is an explicitly racist Islamic heresy that became a popular religious movement in the United States over the past few decades. Its doctrine provides that there is a tiny elite—the titular five percent—who are the Good Guys, aware of the truth and trying to spread light. Then there is a slightly less elite set of Bad Guys, and below that, a giant mob of sheeple (in Five-Percent-Nationspeak, the eighty-five percent). Only black people (referred to as the “Asiatic Blackman”) are truly people; white people are the devil. Despite its being an incredibly goofy religion, the Five Percent Nation managed to spawn one of the most productive religious artistic movements since the Shakers, inspiring Wu Tang Clan, Erykah Badu and others among the most interesting and original musicians of the end of the last century. In this case, the religion serves as a social background upon which a musical aesthetic evolves and within which geniuses flourish. Another religious movement has recently evolved that is also explicitly racist and also utilizes the Nation of Islam’s model of a tiny elite, an evil adversary group that is somewhat less elite, and an irrelevant mob of proles. The blogger known as Koanic Soul presents a world history in which a few modern humans (the elite good guys) evolved directly from Neanderthals, the evil less-elite humans evolved from Cro-Magnons, and the irrelevant mobs are, surprisingly, descended from an army genetically engineered by the ancient Cro-Magnon bad guys. The introductory come-on of this religion is the invitation to perceive an in-group aesthetic: as with n-rays,29 novices are invited to aesthetically perceive facial differences between modern humans in order to identify them as either Neanderthal or Cro-Magnon. This is a brilliant religious innovation, as aesthetic agreement over ambiguous stimuli can create a feeling of both understanding (insight) and connection to fellow perceivers. Of course, the Five Percent Nation did not invent this triarchic class structure (it shows up, among many other places, in Orwell’s 1984, albeit without the existence of good guys). It is merely one of many common patterns that exist within the patterned variation of religion and aesthetics, selecting and shaping the experiences most people accept as genuine and real enough to justify life itself. A Sneaky Dualism Aesthetics and religions, those large structures that filter and contextualize the smaller units of experience, are real in the sense that they are actually experienced by participants—but this experience is exclusively social. The experiences may not be individually or scientifically discernible (as with the violins) and the “higher something” is generally not demonstrable (as with the religious experience of speaking in tongues), but the participants nonetheless take value from the magically mediated experience. Social reality is meaningfully distinct from logical or scientific reality. The need for ultimate meaning—for base-level meaning that justifies itself and need not be further justified—seems to be a near-universal human characteristic. It makes up one quarter of Baumeister’s four-part descriptive model of meaning, outlined in the previous chapter, and it is the ultimate of meaning that people will seek out if it is not culturally provided. Frequently, the Ultimate End is an imagined state of future bliss. Examples of Ultimate Ends include Heaven in Christianity and other religions, everlasting romantic love in cultures such as our own that feature love matches in marriage, and amorphous personal “success” in the modern careerist cult of the self. Ultimate Ends can also be deities or concepts (work, “rock and roll,” political equality, existence itself) that feel valuable in and of themselves to faithful adherents, and that do not subjectively seem to require any further justification. In an objective sense, however, it is hard to see an end to justification. Believers in Ultimate Ends seem to be guilty of a sneaky dualism, of imposing a meaning layer upon objectively verifiable reality and then treating the meaning layer as if it were objectively, and not merely socially, real. In many cases, the Ultimate End is demonstrably pretend, not even a real thing. In other cases, the Ultimate End is a real concept, and it is only the idea that it is the base value that justifies everything that is not demonstrable. Experience Machines vary along the dimensions of being effective (producing desirable, meaningful experiences and preventing or at least domesticating negative experiences), honest (not hiding the fact that they are cultural artifacts designed to produce experiences), and voluntary (rather than forced upon adherents). These traits are not necessarily independent; I suspect the most effective Experience Machines that have evolved in human societies are probably some of the least honest and least voluntary, and I’d expect honesty and voluntariness to generally correlate negatively with effectiveness. The least voluntary Experience Machines are the jealous ones, described by William Burroughs as the One God Universe (though a jealous Experience Machine might just as well be polytheistic or atheistic). These Experience Machines claim not to be Experience Machines at all, but to just be actual objective reality. They frequently require the rejection (and even destruction) of competing Experience Machines, and sometimes even the destruction of their adherents for good measure. They are the sneakiest dualists, for they do not even admit to their nature as a meaning layer on top of objective reality. But such denial is obviously a good evolutionary strategy, and probably even makes them more effective in presenting a believable system to adherents. Voluntariness and honesty correlate with each other in Experience Machines, as in the case of much modern use of psychedelic drugs. To meaningfully choose to utilize an Experience Machine, one must be aware one is doing so; it would be hard for a dishonest experience machine to be voluntary. Similarly, it would be incredible if an involuntarily imposed Experience Machine were honest about its nature—to try to do so would violate, I think, strong and widely-shared (though rarely articulated) intuitions about what mere experiences, as opposed to Ultimate Ends, may justify. The Co-Evolution of Humans and Their Experience Machines The biological phenomenon of the supernormal stimulus (superstimulus) has a great deal in common with the Experience Machine. An Experience Machine is, in fact, a type of supernormal stimulus. In biology, some bees are tricked into fertilizing flowers because the flower triggers the mating instinct of bees more than even a female bee. The flower is experienced by the bee as better than nature; it is a superstimulus. Of course, a superstimulus, like a parasite, ought not to get too good, such that it disrupts the survival and reproductive patterns of the organism it depends on. An ideal Experience Machine like Nozick imagines would allow the user to jump in and forego survival needs and mating opportunities. Natural Experience Machines, aesthetics and religions, generally exact a much milder a drag on their hosts’ evolutionary goals than this ideal Experience Machine. In nature, superstimuli, just like parasites and naturally evolving Experience Machines, must achieve an equilibrium in which the host species expends enough energy to support its own needs while also expending plenty of energy supporting the reproduction of the parasite, superstimulus provider, or Experience Machine. (The reproductive needs of the Experience Machine can be substantial; it must not only reproduce by being passed to each successive generation, but must also be defended from new or invasive Experience Machines.) And so our co-evolved Experience Machines are demanding, but mild. The most effective, intense Experience Machines would likely interfere with our survival and reproductive processes so much that they would no more exist stably in nature than an extremely virulent parasitic organism. If we are willing to enter these new, powerful, addictive (however hypothetical) Experience Machines, we must be willing to abandon the “evolutionary goals” of survival, organism-level status, and reproduction—to declare them not our own goals. Effective Experience Machines may mean the end of our species, as better and better Experience Machines begin to out-compete other humans (including possible offspring) for human attention. However, this need not be the case. A society that could continue to reproduce itself despite the availability of every kind of experience imaginable for its members could come very close to being a just society. Whether or not it leads to extinction, this is the kindest path for humanity. The Protection of an Aesthetic Humans may be taken advantage of by sneaky competitors, both biological and memetic. However, some co-evolving memetic structures, especially aesthetics, might actually protect humans from exploitation. Human aesthetics can grow very subtle, assuming many layers beyond naive sensory impressions such as salty and sweet, melodic and upbeat. A subtle aesthetic can be a valuable cultural tool for evaluating the quality of necessary physical and cultural items. An old cattleman possesses an aesthetic of cattle that cannot be communicated in a checklist; he will not be cheated easily. Tribes with sensitive aesthetics will not be bought off with glass beads for long.30 In modern life, our aesthetics commonly protect us from threatening information. When we tune out or turn off a stream of information, we often do so in disgust. Pleasurable streams of information attract our attention instead. And what renders information streams pleasurable or disgusting is the aesthetic we have absorbed and created. Aesthetics, as memetically evolving items, are not “interested” in protecting us especially; they are interested in protecting themselves. They are old cognitive tools, and they are very useful, but at the same time, they tend to be conservative and to defend themselves from memetic threats. Ourselves as Experience Machines Humans do not exist alone. We are only constrained toward consciousness by other human beings. In relationships, each person has both the character of an experiencer and of an experience provider. In interactions with each other, we are always experiencing the other and being an Experience Machine for the other. This is the core of humanity. According to Roy Baumeister, it is the reason consciousness evolved. This is particularly important in sexual relationships. There is an immediately observable divide in the nature of experiences desired in a sexual relationship between men and women. This can be seen in the variety of pornography consumed by each gender, regardless of sexual orientation. For men, the pornography consumed tends to be explicit visual imagery of sex with attractive, young women or men—a substitute first-person experience of sex. That is not what women seek out and buy; what sells to women are romance novels, explicit or not, and rather than providing a first-person experience of sex, they provide a vicarious experience of being an extremely high-value female. “Valuedness” is the pornographic heart of women’s romance literature; the male lover is important to the extent that he demonstrates and supports the value of the heroine. So men desire first-person experiences with high-value women, and women desire experiences of valuedness. (Of course, the reverse is true as well, but not nearly to the same extent, as revealed in consumption patterns and as predicted by mating strategy theory.) We might say that in terms of sexuality, women are primarily Experience Machines, experiencing even ourselves as such, whereas men are primarily experiencers. Intense sexual selection has perhaps made us something like a creepy autonomous RealDoll with a womb. However, outside of sexuality, the sexes may be reversed; women, as the choosing and limiting sex, are the primary experiencers, and men are expected to provide experiences for them upon which to make their decisions. Men produce more instances of humor than women, for instance. In all relationships, sexual or not, each person has a dual nature: experiencer and experience provider. Each of these aspects, on each person, acts as a “selection site”—in both Darwinian and memetic senses. There are, on the one hand, experiences that humans avoid or seek out; on the other hand, there are experiences that one provides others or protects others from. Each of these has selection effects for reproductive fitness. Both one’s preference for certain experiences, and one’s ability to deliver certain experiences, are relevant to one’s social and mating success. To the extent that cultural items give us experiences and help us produce experiences in others, these dual natures also affect the evolution of cultural items. As an example, the book How to Win Friends and Influence People is a cultural item that demonstrates how to be a better Experience Machine for others. In friendships as well as mating, we will be accepted or get the high-status experiences we want to a greater degree if we can give those experiences to others. This cultural item (the book) has been successful at getting itself reproduced to the extent that it helps individuals create and have the experiences that they desire from and for each other. Another example involves the behavior of neonates. Infants are extremely dependent upon parental care, and vulnerable to parental rejection (especially in past societies, but even in our own). They have evolved to send signals (create experiences) almost immediately after birth that encourage parental care and discourage rejection (infanticide). They immediately signal vigor by crying, producing non-social smiles, and making eye contact within a few weeks of birth. Both aspects of our dual nature allow us to exercise some (bounded) control, and to have some limited effect on them. We can, to some degree, choose what we experience; again, to a limited degree, we can choose what we cause others to experience. However, the distance between what we try to cause others to experience and what they actually experience is frequently a dark chasm of longing and misery. *** The things that make life seem meaningful often depend on illusion and selective perception to maintain themselves. Social groups support religions and aesthetics that help us believe that certain things outside ourselves are meaningful. Not only items of culture, but even our own brains can be seen as miniature Experience Machines, letting us perceive and remember only a limited and modified aspect of external reality. Like other miniature Experience Machines, the brain is a product of evolutionary processes, serving reproductive goals orthogonal to the well-being of individual minds. Creating life in the real human world has much in common with creating life in a simulated environment. The experiences of individuals is what matters in either case, and values that give the appearance of mattering in and of themselves can frequently be demonstrated to be illusions designed to create just that experience. If it is meaning that justifies the suffering of life then meaning has a high burden of proof to demonstrate its inherent, non-instrumental value, and the frequent use of illusion in this domain invites skepticism. If it is the experience of meaning that justifies life’s hardships, then we are really back to a hedonic calculus based on experiences—and have little claim to govern individuals’ choice of experiences. The Reverse Experience Machine improves on Nozick’s experiment by removing the status quo bias. We might consider a variant on the question of whether to create a human life that removes the sacredness associated with this domain. Rather, consider creating a new, conscious character within an Experience Machine. How good would the Experience Machine have to be? What features would it require? If human life were a video game, would anyone choose to play it?",
      "chapter_number": 10,
      "section_number": null,
      "word_count": 5993,
      "file_path": "index_split_010.html",
      "spine_order": 11
    },
    {
      "title": "Chapter Five: Moral Foundations Analysis of Suicide and Childbearing",
      "content": "Chapter Five: Moral Foundations Analysis of Suicide and Childbearing The first part of this book investigated a modern worldview in which human moral beliefs are not the product of a rational utilitarian calculus, but rather of evolved heuristics that function to solve coordinated action problems and bind groups together. These include sacredness, loyalty, and authority as well as harm, fairness, and freedom. Human cultures are not rationally chosen sets of institutions, but messy, evolved collections of cultural items. We participate in them not because they give us accurate representations of reality, but because they meet our social and psychological needs. We now proceed to analyze the two specific subjects of this inquiry—suicide and childbearing—from this perspective. Suicide and Moral Foundations A. The harm of suicide Harm/care is a very rational model for moral intuition, and likely fails to account for most moral cognition surrounding suicide. This is the foundation, however, to which most philosophical arguments regarding suicide have been addressed (and indeed to which non-specialists willing to discuss their beliefs often instinctively appeal). What are the harms of suicide—and the harms of its prohibition? By what right might these harms be inflicted? 1. Harm to survivors—friends, relatives, and others Suicide opponents often call suicide a form of murder —self-murder. The suicide is viewed as improperly taking himself away from his friends and relatives earlier than they expected, frustrating their expectations. It is natural to assign a dysphemism to a hated practice that violates sacredness, but of course suicide is distinct from murder. People who commit suicide are not “victims” in the sense that people who are murdered are. Consent is a powerful element, transforming rape into consensual sex, slavery into work, kidnapping into a vacation. A suicide’s survivors are not victims, I will argue, because the type of harm that they suffer is a type of harm that the suicide himself, and not a murderer, has a right to inflict as a double effect of refusing to live. And it cannot be that the harm to survivors is the only—or even the major—reason that murder is wrong. The murder of a lonely person with no relatives is surely no less horrible (or not much less horrible) than the murder of a person with many relatives. Evolutionary psychologists Martin Daly and Margo Wilson31 point out that “tribal people may explain a particular act of seemingly unprovoked homicide to an appalled missionary or anthropologist by pointing out that the victim had no relatives”—that is, there was no danger of retaliation—but to a modern mind, this is hardly a moral defense. How much of the harm to survivors is due not to the suicide itself but to the suicide prohibition? A writer on the Internet suicide group alt.suicide.bus.stop, writing as “EverDawn,” asserts that a great deal of the harm to survivors of suicide—in particular, the perception of suicide as “tragic”—is an artifact of the policy of suicide prevention and its attendant doctrines: Perceiving an event as tragic makes it difficult to come to terms with, in contrast to an event which is just sad. If a sad event couldn’t have and shouldn’t have been prevented, then there is no blame to be placed, and nobody to be angry at. But a tragic event raises the questions: how could it be prevented, who should have prevented it. This leads to anger (when blaming others) and despair (when blaming self). The questions linger on, unanswered, making it far more difficult to come to terms with the event. We have been led to believe that suicide should be prevented because suicide is tragic, when in fact, the reason why suicide is tragic is because society has chosen a policy of suicide prevention. Suicide is a sad event, however, the perception of suicide as tragic is a result of the choice society has made—a choice which society is responsible for. Ultimately, society is to blame for the negative consequences of this choice. The harm of suicide is distinct from the harm of murder, and—a theme that will be highlighted throughout this book —the suicide prohibition itself is responsible for much of the harm that suicide does cause. Let us now specifically examine the harms that suicide causes to those left behind. a. Loss of company, support, and other expected goods The most commonly cited harm inflicted by suicide is the harm to the surviving friends and relatives. What, exactly, does that harm consist of? Certainly, it is not merely the fact that the person has died. Everyone dies eventually; suicides are not unique in this. Our surviving family and friends must eventually come to terms with all of our deaths. The only special harm attributable to the suicide is that he has died early, depriving the survivors of an expected period of his company and support—specifically, that period between the time of suicide and the time he would have otherwise died. During that time, the lover or spouse no longer enjoys the affection of the suicide; the relative no longer enjoys his visits and presents and sidewalk-shoveling; the friend no longer enjoys his opinions and companionship; the parent may no longer hope for grandchildren. The problem is that little of this “company and support” (and reproductive capacity) is morally obligatory. A person may, without committing a moral wrong by modern standards, leave his spouse due to irreconcilable differences or move away from his friends and relatives to pursue a career or refuse to have children. Providing our company is a voluntary act, and we are under no moral obligation to do so. The company and support of a person is best viewed as a privilege, not a right—with the important exception of a person’s voluntarily conceived children (there is a moral duty to care for one’s children that renders the suicide of a parent of dependent children, rebuttably, wrong). The losses inherent in a suicide are real, but unlike the losses inherent in a murder, they may be inflicted in the exercise of a moral right. At the very least, we are generally permitted to inflict those losses in other contexts. If suicide is prohibited because of the harm to our mothers, should we also be legally forbidden to move away from our mothers? b. Knowledge of permanent loss A loss of companionship and support is upsetting, but perhaps a suicide is worse than moving away because it creates the knowledge in the minds of survivors that the loss is permanent. It removes hope of an eventual return and reconciliation. Is this harm blameworthy? Do people have a right to this (often irrational) hope? Move-away losses and other estrangements are frequently permanent. While the knowledge of the permanence of a loss may be painful, it is also valuable to know the truth. The survivor of a suicide may in this way be better off than the person left behind in an estrangement he stubbornly refuses to admit is permanent. While both the loss of the company of the decedent and the knowledge that his departure is permanent are harms that survivors of a suicide suffer, it is important to recognize that these harms conflict with the liberty interests of the suicidal person (freedom/oppression foundation) and with a fairness analysis (fairness/cheating) of the act and its harms. c. Discovering and disposing of the body A distinctly visceral harm must be suffered by someone in any suicide in our prohibition society: the discovery and disposal of the body. Where the discoverer is a relative or close associate, the shock must be even greater. While discovering the body of one’s spouse or friend or child must necessarily be awful, it is an artifact of the suicide prohibition that this must happen. Legal suicide (allowing for chosen death and market mechanisms to accomplish it comfortably) would allow suicides to say goodbye before dying, to die in the presence of loved ones, or to discreetly provide for the professional disposal of their bodies. The shock of discovering the body of a suicide must be weighed against another harm that is also a consequence of prohibition: since he must hide his act in order to get away with it, a suicide may be “missing” for days or weeks (or more) prior to discovery. Given the suicide prohibition, privacy and a controlled environment are essential to a suicide’s success; his own home is often the only place where these are possible. Legal, preplanned suicide, perhaps taking place in a hospital, would eliminate this harm. Frequently in our prohibition society, another must suffer the great harm of being the unwilling agent of death for the suicide (as with suicides who jump in front of trains). This is unfortunate, and I see such suicides as particularly morally questionable. However, this harm (in fact, this type of suicide) is also an artifact of the suicide prohibition and would largely disappear if reliable suicide methods that did not cause harm to bystanders were commonly available. Everyone dies of something. And we can’t bury ourselves. This means that for every human being who has ever lived, someone must discover and dispose of the body. It is mistaken to attribute this harm only to suicides. It is part of our humanity that we—suicides and non-suicides alike—must inflict this harm on others. Once we have been given the dubious gift of life, we are destined to burden someone with the disposal of our dead body. 2. Harm to the Suicide Himself Those who are comfortable with paternalism often argue that suicide must be prevented—indeed, that it displays a lack of compassion to allow it—because of the harm to the suicide himself. a. Loss of future experiences Frequently the victim under consideration for the harm/ care foundation is the suicidal person—who is to be protected from himself. How can one harm oneself? The harm inflicted by the suicide upon himself must be the deprivation of possible future experiences (keep in mind that sacred harms, such as religious harm, belong under different moral foundations). However, by committing suicide, a person affirms that, in his evaluation, the expected future gains from living are not worth the expected costs. Many people intuitively support this line of thinking when it comes to people dying of a terminal illness. But why would people dying of a terminal illness be the only people miserable enough to rationally want to die? Hope is not necessarily rational. Prohibiting suicide amounts to substituting one’s own (poorly informed) judgment for the suicide’s own (immeasurably better informed) judgment of the degree to which his life is worth living. I have argued elsewhere that suicide is not, as many believe, the irrational product of mental illness. But what about suicide committed on impulse? Perhaps a person’s “self” evaluates the situation at time t and decides that suicide is preferable, but later, at time t plus 24 hours, he might decide he was mistaken, and dearly wish to keep living. One problem with this theory is that suicide does not, in fact, appear to be an impulsive act,32 but generally involves a plan. And given the existing barriers to suicide, a suicide that appears “impulsive” may actually reflect the genuine rational desires of the suicide. The person who rationally prefers to die may be unfairly prevented from doing so by legal and practical barriers; he may need an “impulse” to push him over the edge and enact his rational desire. Confronted with evidence that suicidality is not impulsive and fleeting, paternalists often point to statistics showing that only a small percentage of people who are caught before completing a suicide attempt go on to commit suicide, but this is a poor line of evidence. We live in a society that prohibits suicide and expends vast resources to prevent and punish it. Being forcibly prevented from exiting life by the medical and legal institutions of our culture is a devastating experience, encouraging a sense of learned helplessness and despair. Imagine you lived in one of the many countries that criminalizes abortion. In your country, it is the case that women who attempt abortion but are caught before they succeed rarely go on to actually get an abortion. Proponents of prohibition claim this is evidence that few women actually want abortions. Is this line of reasoning suspicious? (In both cases, prohibition increases the difficulty of achieving the desired result—abortion in one case, death in the other.) Even if we could be certain that a would-be suicide would be glad to be rescued (we can’t), this would not be a strong moral reason to prohibit suicide. The victim’s being “glad it happened” after the fact does not render interference morally justifiable. b. Harm from an unsuccessful suicide attempt Harm inflicted by an unsuccessful suicide attempt is entirely an artifact of the suicide prohibition, not a harm inherent in suicide. Every year, thousands of people are rendered permanently disabled by being forcibly rescued from suicide attempts; as noted earlier, this is one of many ways in which prohibition increases the cost of suicide—in this case, by increasing its potential for harm suffered by the suicidal person. c. Failed signaling It is commonly believed that a suicide attempt should be universally interpreted as a “cry for help.” A successful suicide may be seen, then, as a failed signal for help. But this attitude benefits neither serious suicides, nor would-be signalers. Again, the idea of “failed signaling” is an artifact of the suicide prohibition. In order for a person to send a reliable signal, the suicide attempt must appear lethal while not actually being lethal. If comfortable, reliable suicide were legally and practically available, there would be very little value in choosing any other method, and any other method would be less lethal than the medical option. This would interfere with the appearance of lethality communicated by a suicide attempt, thereby decreasing the motivation to make a “signal” attempt in the first place. What an insincere suicide attempter—a “signaler”—really wants is to be rescued. That is, he wants to be forcibly prevented from committing suicide, because he does not really want to commit suicide. Remove the possibility for rescue, and you remove this insincere suicide’s motivation to make the potentially harmful attempt in the first place. It is the suicide prohibition, and not suicide itself, that causes this harm to the would-be signaler. B. Loyalty When the topic of suicide is raised in a moral context, it becomes increasingly likely that someone with a personal connection to a suicide will bring up that connection. This is perfectly understandable, but it locates the harm of suicide in near others (in-group members especially) rather than diffusely among the populace. Someone with a near connection to a suicide may find that he is able to shift the discussion toward his preferred theory. If he takes a position in favor of government intervention and brings up a deceased family member who committed suicide (even though this is technically a non sequitur), the interlocutor taking an opposite position may be reframed as attacking the family member rather than a position. The interlocutor’s moral argument may thus be perceived, especially by him, as a loyalty violation toward his own in-group. It is natural, both psychologically and rhetorically, to emphasize an in-group connection to a phenomenon like suicide. There is nothing wrong with this. Faced with this natural tendency, opponents of prohibition must depersonalize arguments before engaging. One strategy is to emphasize loyalty toward the class of people who want to die through acknowledging their freedom to exit. This is further addressed below, in my discussion of “Liberty.” C. Fairness, Cheating, Selfishness, and Suicide Closely related to judgments of loyalty are judgments of fairness. What is to be expected of a person in our society? It is very common for proponents of prohibition to emphasize that suicide is “selfish,” generally relying on the visceral connotations of this term for effect rather than defining it precisely. Rather than accepting the idea that suicide is selfish, we must investigate what is meant by this statement and place our concerns in context according to the moral faculties swayed by such concerns. What is the standard by which reciprocity is judged? To say that suicide is selfish is to imply that the suicidal person has not lived up to a duty to his fellow man, a duty to go on living no matter the cost in personal misery. But what is the basis for this duty? Is it fair to expect someone to live out his natural life? What would make it fair or unfair? The length of a natural life varies, as do the circumstances in which it must be lived. The basis of fairness can’t be consent to life—consent occurs neither at the beginning (no one consents to being born) nor at the end (a suicidal person explicitly does not consent to being alive). Certainly social expectations are violated by suicide, if not stipulated contractual ones; though there was no express agreement to live up to, we might imagine a contract implied by certain actions, at whose heart is the promise to live out one’s natural life no matter what. What behaviors would indicate acceptance of such an implied contract? Perhaps merely staying alive indicates ongoing consent for life, but as I argued in the first chapter, an action without the genuine freedom to do the opposite cannot indicate consent. Perhaps forming serious relationships indicates consent, but how is a life to be made even potentially worth living without the formation of strong relationships of mutual reliance? Must a person choose a track for himself early on—suicide and solitude, or strong relationships and severe restriction on the moral right of suicide? Intuitively and in practice, attempts at social integration are rarely seen as violations by a suicidal person, and social withdrawal is not seen as a moral duty. D. Authority Supreme Court Justice Antonin Scalia,33 in refusing to recognize a right of citizens to refuse medical care that would prolong their lives, offers the defense that suicide was a felony at common law—which is to say that historically, in England for hundreds of years, the penalty for trying to kill yourself was hanging. Scalia grounds an authority-based argument against suicide in this early prohibition: because suicide was a felony, he argues, modern governments need not recognize a suffering person’s right to end his life. The authority foundation has not found much persuasive power within the context of suicide. Arguments like the above seem self-evident to those, like Scalia, who are moved by authority, but read as clumsy otherwise. However, a major force for the acceptance of the suicide prohibition has been the expanding authority of medicine in our society. Medicine, and the medical model of suicide, is as much a product of the authority framework as of the harm/care foundation. Medicine pretends to an almost exclusively harm/care orientation; however, it has acquired a halo of sacredness since its great successes in the last century with vaccines and antibiotics. And it has used this sacredness to cultivate an aura of authority. As detailed in the first chapter, the greater portion of the suicide prohibition is not legal, exactly, but medical. Doctors, as part of a hospital system, have the authority to imprison people on locked wards for displaying signs of mental illness that are presumed to indicate a danger to self or others. In practice, this means that even a rational suicidal person may be imprisoned. The authority to imprison, to medicate, to bully and coerce patients into compliance with treatment plans, goes along with expanding medical authority in a variety of contexts once thought to be the domain of the family or the individual. Hospital staff frequently remove children from parents judged to be a danger to the children—and, in many cases, the only danger is the disagreement with doctors as to the diagnosis and its appropriate treatment. Doctors have referred to this procedure as a “parent-ectomy,”34 as in surgical removal of the parents. That medical experts should have such authority is a very modern development. Another result of the expanded authority of medical practitioners is doctors assisting police by performing invasive cavity searches of suspects.35 The expanding authority of medicine is worrying. There are no checks or balances built into our system to counteract the authority of doctors, and experiments with socialized medicine mean that government is more involved with health care than ever. E. Suicide and Sanctity Among those who oppose suicide and approve of its prohibition, sanctity, not harm, appears to be the foremost reason. In laboratory experiments,36 the harm/care foundation was activated with regard to homicide, but did not substantially affect judgments of suicide. Instead, concern with the tainting of souls and moral disgust appeared to be the most powerful operative foundations. In the previous chapter, it was noted that a characteristic of sacred beliefs is that symbols tend to be confused with referents; images of cigarette smoking and discussion of rape may be seen as violations in addition to the underlying behaviors themselves. Thus it is with suicide: even conversations about suicide, whether artistic or mundane, have the power to trigger strong reaction, and this reaction often takes the form of censorship (discussed at length in a later chapter). The supposed suicide contagion is often brought up as a rational basis for such censorship, but the fact that suicide is open for contagion analysis, when other acts (such as interpersonal violence) are generally not, must be explained. And it is precisely the purity violation inherent in suicide and discussions of suicide that allows for contagion analysis: impurity is contagious, and moral degradation is seen to spread like an infection, whereas ordinary harm is not. If ordinary violence were seen to be contagious, its moral condemnation and retributive responses would be imperiled; but suicide, as a sanctified domain and a special sacredness violation, is frequently the subject of contagion framing. F. Liberty The liberty foundation is that which is most conducive to eliminating the suicide prohibition. Thomas Szasz and other libertarian writers have advocated for a right to die as part of a broader right of self-determination that includes the right to refuse psychiatric treatment. Responses to the pro-choice position that strive to maintain the liberty frame tend to balance future liberty interests of the person with present liberty interests, breaking a person into multiple selves over time and presenting the different selves’ interests as in conflict. The position that prioritizes future interests over present interests is in accordance with the suicide prohibition; paternalism often refuses to admit that it is paternalism, instead insisting that it is merely representing the true, genuine “freedoms” of a future person. In other contexts, restricting the actions of a future self is seen as an important freedom. All contracts, for instance, have this feature, as did the institution of marriage before modern no-fault interventions. In the suicide context, however, the decision of the present self to commit suicide is often stigmatized as disordered, insane, or impulsive; that it may be a rational and integrated decision makes the case for restricting it based on future interests more difficult. Childbearing and Moral Foundations The morality of suicide is distinct from the question of the morality of childbearing, as illustrated in the first chapter. But the two issues are connected, especially along the harm/ care, fairness, and loyalty foundations. Childbearing is especially sacralized in our culture; as with suicide, the sacredness foundation bears a great deal of the weight of moral cognition on childbearing, if often invisibly. Freedom, as applied to childbearing, is generally limited to analysis of the rights of parents—the right to bear children, and the right to prevent or abort children. Rarely are the liberty, harm, or fairness interests of the children seriously considered. A. Childbearing and Harm That being alive entails suffering has been acknowledged at least since the time of the Buddha. Even the best lives are frequently painful and boring, punctuated by unsatisfied longing, loneliness, fear, shame, hunger, anger, and grief. All humans age and die—and to make matters worse, they become aware early on that they will inevitably die. A naive view from the hedonic perspective, in which only pleasure and pain matter, was explored in the first chapter where I considered Bryan Caplan’s argument that since most people stay alive, rather than jump off of tall buildings, the pleasures of life must outweigh its many harms. A more nuanced view must allow that this is frequently not the case: that the harm of life frequently seems to outweigh any benefit it may be said to provide to the living person. The one million suicides per year, globally, put a lower bound on this condition, but it is difficult to know how many people suffer so much that life is, on net, a harm to them. This analysis is made more complicated by the fact that symbolic and social meaning, rather than a robotic pleasure/pain trade off, is in fact what seems to motivate human action. Not many people commit suicide, but many people act as if their lives are not very valuable to them. They risk actual death or social death by gambling their present circumstances on a small chance of future payoff, in a manner that is not actuarially sound. They choose, with their economic decisions, to believe in a counterfactual world, indicating dissatisfaction with the real world. They palliate present suffering in a manner that harms future prospects. This gamble/ palliate behavior is examined in detail in a later chapter; it indicates that, rather than valuing life as a precious gift, people frequently treat life as having zero or negative value with their actual actions. The suffering occasioned by life is great and undeniable, indicating that childbearing, at least in this aspect, does major harm to those brought into the world. Is there something that makes up for this harm, such that something causing so much misery might properly be regarded as a gift? This “balancing factor” might be meaning—either universal meaning, or subjective meaning found and elaborated by individuals; this is addressed in an earlier chapter. Another possibility is the proposition that, on balance, the pleasure and good experiences of life make up for the suffering it occasions. Rather than eschewing all suffering, individuals frequently accept some degree of suffering in pursuit of other rewards—either in the form of meaning, or in the form of pleasure. The mountain climber or medical student affirmatively chooses to suffer for the purpose of future experiences, pleasurable or meaningful. Others, looking back on times of suffering, say they are glad to have had such experiences. When making decisions for ourselves, there is no moral problem with trading off suffering for pleasure or meaning; it appears to be a social fact that people do not minimize suffering in their own lives. What about when we act upon others—especially strangers, whose preferences we know nothing about? Can we permissibly cause them serious harm in order to give them a benefit, and without their permission? This question, fundamental to the modern philosophic question of antinatalism, will be addressed in a later section, but it is important to root it in the “harm/care” moral foundation, and to notice what other moral foundations affect thinking about childbearing. B. Fairness, Cheating, and Reciprocity The fairness and reciprocity orientation regarding childbearing is prominent in many cultures. Life (and perhaps care, feeding, and rearing) is regarded as a gift that parents give their children. This is regarded as creating a debt owed by the child to the parents, which may be repaid with some form of filial piety. To see life as a gift is to accept that one is born owing a debt. It is a very prosocial world view, encouraging good behavior, care of parents, and perhaps even the production of grandchildren as a means of fulfilling the debt. The benefits that children supposedly provide, such as support in old age and grandchildren, are frequently mentioned in support of having children. And the absence of these benefits, or of children themselves, is commonly expressed in terms of fear—the fear of dying alone. Emphasis of the fairness foundation elides notice of the significant parent-offspring competition present in humans. Neither the evolutionary nor subjective interests of parents and offspring align perfectly; often they are very badly mismatched. (As a mild example, consider the differences between the suitor a young lady might choose for herself, and the one her parents might choose for her. A less mild example might take notice of real, modern arranged marriages between prepubescent girls and much older men, often relatives.) The fairness frame, among other things, uses the thought of the horror of nonexistence to coax filial piety out of children and give parents more power in parent-offspring competition. As noted above, this is likely a civilization-preserving cultural idea, encouraging action in accord with longer time horizons. It achieves this at the expense of coercion toward children. In agrarian societies, children have significant economic value; the cost of bearing, feeding, and caring for them is more than offset by the value of work they perform. In our society, however, children have negative economic value.37 How do parents in the modern world deal with the fact that children are, in economic terms, a “bad bargain”? One strategy is for parents to attribute more non-economic value to children38 when reminded of the economic loss they are taking, “exaggerating” their parental joy in response to the salience of the costliness of children. This will be explored below in the section on sanctity, but there is fairness and reciprocity at work here as well: if children cannot provide economic value in return for their economic cost, they are said to provide other kinds of value. The high cost of children is driven not just by their declining economic value, but by the increasing cost of giving a child socially appropriate resources. Spending on children is determined in part by the spending of those in the community. A status arms race drives up spending, not just on clothes and toys but also on education, extracurricular activities, and medicine. High-status parents may feel the need to distance their children, through spending, from the children of poor people (who at any rate have more children than wealthy, educated people). Since children impose such a high cost, those who opt out of childbearing are sometimes accused of “free riding,” of being lazy or selfish. In other words, childless people are seen as cheating on a supposedly reciprocal obligation — either with their own parents, or with others in society who have an interest in the genetic future of their race or species. No doubt the cost and burden of childbearing is a factor for many decisions not to reproduce, but it is incorrect to see parents as especially self-sacrificing in this regard. While the economic and well-being costs of having children are high, most of the “cost” of existence is borne by the children themselves, not by the parents in raising them. Parenting involves not just volunteering for the job of parent, but volunteering innocent children for the job of being people. C. Sanctity In the laboratory, when manipulated by researchers to think about the high economic cost of having children, parents tend to focus on and elaborate another kind of value that children have—their emotional and spiritual meaning, the value of the special connection between parent and child. In one experimental study, parents manipulated to think about the high cost of childrearing said they planned to spend more time with their children during the upcoming weekend than parents who had not been so manipulated.39 Outside the laboratory, elaborating new kinds of value for children seems to have been a widespread response to the changing economic value of children—and of women. The consequences of this new source of sanctity have not always been good for children. We need not go as far as Philippe Ariès (Centuries of Childhood) in positing that childhood was only recently invented and that parents five hundred years ago did not form strong, protective bonds with their children. The absence of such bonds, in a species requiring so much parental investment and care for survival, seems incredible, if only on evolutionary grounds. However, there have been drastic, visible changes in the typical treatment of children since the Industrial Revolution changed their economic meaning. In Meanings of Life Roy Baumeister summarizes the changing economic and social value of women during the industrial revolution: For centuries…women’s work had held a secure place in the social environment. It was inferior in prestige to men’s work, but it was no less vital. The family economy, even the family’s survival, was clearly and multiply dependent on the woman’s contribution. Work is a powerful source of purpose (goals) and efficacy in life, and so women’s lives certainly did not lack for meaning in these respects. The woman’s work was vital to the family, and everyone knew it. Then a remarkable thing happened. The Industrial Revolution took over women’s tasks one by one. First, the textile mills soon could produce cloth more cheaply and efficiently than more weaving. Then other tasks, ranging from candle-making to food processing, shifted out of the home and into the factory. The woman’s contribution to the family dwindled from vital and central to minor. To put it crudely, from an economic standpoint, women became obsolete. …The importance of these economic shifts cannot be underestimated for understanding the history of women… The “Woman Question” that vexed the 19th century was based on a profound uncertainty about what women were useful for. Such a question would have been unthinkable in previous eras, for women’s contribution to everyone’s daily life was palpable and vital, even when the treatment of women was a mixture of contempt and exploitation. An economically useless womanhood was a new and troubling phenomenon. [Emphasis mine; citations omitted.] The answer to the “Woman Question” that was elaborated in the nineteenth century is still a major source of sacredness today: the innovation of the “cult of motherhood.” The last remaining source of value that women had—childbearing and childrearing—was made into “a more comprehensive, fulfilling purpose”: The first step was the elevation of motherhood into an important, fulfilling life-task. A “cult” of motherhood appeared early in the 19th century. Speeches, sermons, and publications started to describe the importance of motherhood for the nation. It was mothers, they said, who determined the nation’s future, for mothers determined the character traits of the next generation. Around 1820, there began a rapid proliferation of books and pamphlets on how best to rear a child. It was addressed to mothers, who were not (for pretty much the first time in history) considered more important than fathers to their child’s upbringing. By mid-century, the glorification of the mother’s role had reached the point where the father’s role was all but forgotten, and it seemed that mothers alone could transform their innocent babies into productive, virtuous citizens of the Republic. Child care, which had previously been regarded as a minor and unprestigious job, now loomed as a sacred and difficult responsibility of mothers. …Writers and speakers began to refer to the ecstasies and raptures that supposedly characterized motherhood. To read these passages, many of which were written by men, one would think that taking care of children was a source of uninterrupted bliss. [Emphasis in original; citations omitted.] But women were not the only ones whose economic value had eroded: the economic value of children plummeted as the industrial revolution progressed. Both women and children were given new and different value through the glorification of motherhood. The consequences of this new arrangement for women, children, and society have been mixed. Victorian concern for the well-being of children as a special, protected class is associated with the passage of laws regulating child labor and criminalizing abuse. Women gained status both from their newly-important role as mothers and from their new alliance with the church; they became guardians of virtue, and translated this into political power for child welfare causes. Concern for the well-being of children, and recognition of women’s role in promoting it, contributed to other “women’s” causes, including temperance and female suffrage. However, once women attained equal legal and social status to that of men—in part because of their connection with religion and childbearing—the allure of childrearing as a sole source of meaning seems to have faded. The women’s liberation movement, the normalization of divorce, and the massive increase in women’s participation in college and work since the 1960s indicate that the cult of motherhood was not adequate to meet the needs of modern women for meaning. But the sacredness of motherhood (and of childhood) is alive and well. Only a few generations ago, children were allowed to roam on their own around cities and countryside. Today, for a child to be allowed outside his own yard without adult supervision is a legal scandal. Children’s freedom to roam and to socialize informally has been severely curtailed; their school environment has become more prisonlike, their physical safety protected at the expense of their education, development, and fun. The loss of children’s freedom to roam may be regarded as an unfortunate late stage in the sacralization of childrearing. Abuse panics, whether focused on satanic cults or neighborhood pedophiles, reflect the sacred status of children—and also the deep discomfort mothers have with sending them to be cared for by strangers while they work. That motherhood is sacred may be illustrated by the pattern of products and causes seeking to identify themselves with motherhood. Representing a mother rather than, say, a puppy or cartoon bear lends a consumer product advertisement a certain gravity. “Mothers Against Drunk Driving” is only one of dozens of groups that link their causes with the sacredness of the maternal bond. Sex workers, in lobbying for status and sometimes for the legalization of their profession, put the fact that they are mothers front and center, implying that motherhood “rubs off ” sacredness even on those whose moral behavior is most questionable. The sacredness of childbearing, as with other forms of sacredness, is often visible in its violation. Most obviously, the sacredness of children is applied to embryos and fetuses, informing opposition to abortion. This is not to say that abortion proponents like myself are immune from sacredness; the right to choose has become somewhat sacred, and the women’s body itself is a locus of sacredness vulnerable to violation by regulation. Controls on reproduction themselves violate sacredness: eugenics is metonymically associated with Nazis, and reproduction is considered a “fundamental right” in the United States. Even very mild and sensible controls on reproduction are rejected by courts. The freedom to reproduce—or not to reproduce—is discussed below, but it’s important to note that it straddles the line between the freedom foundation and the sacredness foundation. It is, in other words, a sacred right. D. Loyalty As mentioned above, those who do not reproduce are often viewed as lazy, “free-riding” on the efforts of others to promote the future of the species. Loyalty—whether to one’s kin, or to the species in general—is a moral foundation relevant to childbearing. Having children is now very costly, which suggests a new role for childbearing: as a costly signal of group commitment. Many religious groups (Catholics, Mormons, Orthodox Jews) strongly suggest or even mandate that followers have many children, and this prescription probably assists coordination between co-religionists. Religious communes that impose heavy costs on their members40 (in the form of prohibitions and requirements) tend to survive longer than less demanding cults; costly signals, whether observing dietary restrictions or having large families, make cooperation more reliable. E. Freedom The liberty of parents to procreate is now so deeply enshrined in American law and culture that it has come to function as a sacred right. Less than a hundred years ago, procreation was not the sacred right that it is now; popular family manuals and works of sociology extolled birth control in progressive terms not primarily as an individual right but as a means of controlling and improving the quality of human populations. Today, even in extreme cases, restrictions on childbearing are almost never tolerated. The forcible sterilization of people likely to have children with bad lives is hardly conceivable to moderns, and any suggestion that individual choice is not the ideal determinant of procreation is dismissed as eugenics. It is politically and socially permissible to sincerely argue for restrictions on abortion, but not for restrictions on reproduction. The right to have children, like many other modern rights, is not mentioned in the Constitution, but is interpreted as being protected by an implied right to privacy. It is now, as I have said, a sacred right that may not be violated even in the most extreme cases. Mothers who starve their children to death41 and fathers who make no effort to support their many children42 may not be restricted in their “fundamental right” to have as many children as they can. It is extremely rare, however, to consider the child’s liberty interests. Opponents of abortion maintain that the child has a “right to life,” but it is very strange to talk about a “right not to be born”—even a limited right not to be born under very bad circumstances. Life, of course, is the ultimate freedom, a human existence being the prerequisite for having any meaningful freedoms at all. But life is also a burden. That childbearing has been turned into a freedom, rather than something that just happens, is why discussions like this are possible. Birth control and abortion make it undeniable that having children is a choice. As childbearing has become more economically costly and more voluntary, the social meaning of children has changed.",
      "chapter_number": 12,
      "section_number": null,
      "word_count": 6952,
      "file_path": "index_split_012.html",
      "spine_order": 13
    },
    {
      "title": "Chapter Six:What Really Causes Suicide",
      "content": "Chapter Six:What Really Causes Suicide Despite decades of clinical research into the causes of suicide, including robust and well-supported models, scientific explanations for suicide have been ignored in popular understanding. A 2013 article43 in the New York Times on the rise of suicide in middle-aged people provides the following mistaken explanation by Ileana Arias, Principal Deputy Director of the Centers for Disease Control (and someone who should know better): Dr. Arias noted that the higher suicide rates might be due to a series of life and financial circumstances that are unique to the baby boomer generation. Men and women in that age group are often coping with the stress of caring for aging parents while still providing financial and emotional support to adult children. “Their lives are configured a little differently than it has been in the past for that age group,” Dr. Arias said. “It may not be that they are more sensitive or that they have a predisposition to suicide, but that they may be dealing with more.” The most robust, empirically supported model in modern suicidology is that provided by Thomas Joiner, who summarizes his findings in the book Why People Die By Suicide. According to Joiner, there are three main factors that influence the decision to commit suicide: the feeling of being a burden on others, a failure of social belonging, and acquired competence in one’s suicide method. The idea the people commit suicide because they are “dealing with more,” that they are driven to suicide by being asked to provide too much “financial and emotional support” and the “stress of caring” for others, is in fact the opposite of the truth: it is not being over-burdened that causes suicide, but rather being a burden on others. Failed Social Belonging The single largest factor in predicting suicide, both at the individual and the national level, is the failure to belong in relationships with the opposite sex, family members, and society. A broad array of sources supports this conclusion. Not just any pain, but the pain of social rejection and failed belonging, causes suicide. While chronic pain44 causes only a modest increase in suicide rates, or none at all for most types of pain, the psychological pain of failed belonging is a major risk factor. Divorce rates consistently predict suicide rates in countries all over the world at the national level; within countries, divorce significantly predicts suicide at the individual level, especially for men. Breakups of cohabitation relationships are significantly associated with suicide, too. Pregnant women have among the lowest rates of suicide of any group. The rate of suicide for pregnant women is only about one third45 to one sixth46 the rate for non-pregnant women; pregnancy is a major protective factor. Having dependent small children (especially under the age of two47) is also protective. However, women who experience a stillbirth have an elevated risk of suicide48 relative to women who experience live births. Marriage and parental relationships are the strongest relationships most people experience; social belonging at this intimate level is very protective against suicide, whereas losing this source of belonging is a major risk factor. But wider community belonging is also relevant. Religiosity is protective against suicide, but it is church attendance49 that explains this effect as much as religious beliefs about the morality of suicide. Churches provide a community in which to belong; the absence of a social community puts people at risk. Similarly, loss of employment is a significant predictor of suicide when unemployment is of long duration,50 and when it is part of a mass lay-off indicating a reduced likelihood of finding comparable employment. At the national level, suicide rates tend to increase in economic downturns. The loss in social position—not absolute wealth status—is the explanatory factor. The threat of social death—of disgrace, of exile from the community—often seems to make death look appealing in comparison. Suicides that are most widely reported in the media follow a common pattern: a person of very high status experiences a disgrace (moral, financial, or both) and commits suicide. Though the person’s status would have remained high relative to the average person even after the disgrace, the impending loss of social status and relationships looks from his perspective like social death. A large metastudy on risk factors for suicide in prison,51 using data covering over four thousand prison suicides, revealed interactions that support the failed social belonging risk factor for suicide. Even though in the general population, being married and employed is protective against suicide, among prisoners, being married or employed was associated with a higher risk of suicide. Why should this be? Married prisoners and those with jobs outside prison faced a loss of previous belonging, a social death. Unmarried, unemployed prisoners, on the other hand, might view prison as a normal part of life, a continuation of previous belonging experiences. Being housed in a single cell was also associated with higher risk of suicide; a cellmate may provide a greater sense of belonging. Being white was associated with a higher risk of suicide and being black with a decreased risk, but that is true of non-imprisoned populations as well. Race may have effects on the level of belonging in prison,52 as it does on sexual victimization rates, with white inmates being much more likely to be victimized. Gay people are more likely to commit suicide53 than straight people. This is often attributed to bullying and homophobia, but it may in part be explained by failed belonging relative to peers, parents and family, and in relationships. Failed belonging may explain an apparent puzzle about suicide and intelligence. At the individual level IQ is negatively associated with suicide, but although smarter people are generally less likely to kill themselves the rule does not hold for those at the very top (“Terman’s Termites”54) or at the very bottom (the mentally retarded55) of the intelligence distribution. The exception of those with very low IQ from the overall negative association of IQ with suicide may be a result of a cognitive “floor” for suicide—the abstract thought, planning, and competence necessary to commit suicide may be missing among these individuals. The increased suicide risk among very high IQ individuals may result from gifted individuals having high expectations for social status and belonging that are thwarted, or from having a mind that is very different from others, making it difficult to form relationships. With the exceptions of many suicides in a small sample of extremely gifted individuals and rare suicides among those with intellects far below the level of normal functioning, in general low IQ is a risk factor for suicide.56 (Having well-educated parents57 and a low IQ score has been associated with particularly high risk, perhaps because failing to live up to the standards of one’s parents and community is a form of social death.) However, despite the negative relationship at the individual level, when aggregate data are viewed on the national level (and even at the regional level, in many cases), there is a actually positive association between mean IQ and the suicide rate; countries with higher mean IQs58 experience more suicides (but fewer homicides). How can these seemingly contradictory observations be resolved? One confounding factor is that latitude (distance from the equator) is also highly correlated with suicide rates, both on the national and regional level, and IQ is also highly correlated to distance from the equator. However, since the suicide rates of immigrant populations are closer to those of their countries of origin than to those of their host countries (as with blacks in the United States and whites in South Africa), the population IQ effect is likely independent of latitude. One explanation for the discrepancy is that high-IQ populations create complex societies in which it is easy to fall through the cracks and experience social death. Where mean intelligence is high, expectations are high. Those who can’t handle such complexity face the risk of social exclusion. In populations with lower intelligence, life is simpler, fertility (a protective factor) is higher, and social bonds are not as fleeting or fragile. Burdensomeness Another broad risk factor for suicide, somewhat related to social belonging, is perceived burdensomeness—the feeling that one is a burden on others. Many sources of evidence point to perceptions of burdensomeness as a risk factor. Even though younger people are more violent than older people, older people commit suicide much more often than younger people. Suicide is positively associated with age in both men and women. The perception of burdensomeness is likely to increase with age and infirmity. Indeed, when terminally ill patients ask their doctors to assist them with suicide they frequently cite concerns59 of being a burden on others, losing control, being dependent on others for physical care, and loss of dignity; physical pain does not seem to be nearly as important a motivation. Among elderly people, factors that influence burdensomeness (including disability preventing them from activities of daily living, visual impairment, and institutionalization) are associated with suicidal ideation.60 In a study of the contents of suicide notes61 that compared the notes of attempters who did not complete suicide with the notes of completed suicides themes of burdensomeness predicted the lethality of a suicide attempt better than the “desire to control one’s own feelings, desire to control others, emotional pain, and hopelessness,” none of which independently predicted lethality. It should be noted that some studies of suicide notes62 have failed to find thwarted belonging and burdensomeness present in the majority of suicide notes, but both of these themes do frequently occur in genuine suicide notes, at rates of 42.5% and 15.5% respectively. Most suicides do not leave notes, and analysis of the content of notes is at best suggestive of the motivation of those who do. The presence of thwarted belonging and burdensomeness themes in the suicide notes of completed suicides is suggestive of motivation. While not as strong a predictor of suicide as thwarted belonging, burdensomeness appears to be a strong predictor of suicide. Both of these factors are relevant to the evolutionary analysis of suicide, which is addressed below. Competence The final factor with a major effect on suicide is competence—a measure of the suicidal person’s developed capability to harm himself using the chosen method. Competence is obtained through familiarity with the chosen method and through the practice of increasingly provocative self-harm, by which process individuals break down their natural resistance to harming themselves. Suicidal individuals are often very dependent on a particular method. Another way to express this is that the demand for suicide demonstrates low elasticity with respect to method. Suicide barriers are often erected on bridges that are suicide “hot spots,” places known in the community to be the site of previous successful suicides. When these barriers are erected, surprisingly, suicides at nearby bridges often do not increase, as would be expected if suicides simply substituted comparable methods. In Australia, when tightened emissions standards for motor vehicle exhaust reduced the lethality of suicide attempts using this method, and overall suicide rates declined as a result.63 It appears that Australians who were predisposed to die in this manner did not simply switch to more lethal methods. Indeed, information about the lethality of suicide methods is not widely available, and when the lethality of a method changes drastically, this change will likely not factor into method decisions until it is too late. Similarly, the suicide rate in the United Kingdom fell in the period after 196364 when household gas was detoxified, rendering this previously reliable method non-lethal. Again, people did not substitute a new, lethal method for many years after the detoxification; if they had, the suicide rate would have remained constant or increased (as predicted by economic troubles at the time). Using a “tried and true” method that has been demonstrated in the past to work, whether a bridge or motor vehicle exhaust, appears to be important to many suicides. As noted in an earlier section, humans have a natural resistance to physically harming themselves. Joiner notes that suicides frequently go through a process of engaging in increasingly provocative acts of self harm before committing suicide; they may engage in non-lethal self harm, such as cutting, or make potentially lethal suicide attempts. The single biggest predictor of completed suicide is a history of a suicide attempt;65 individuals may “practice” suicide until they get it right. Certain professions have higher suicide rates than the baseline, and often choose methods that their occupations have trained them to use. Doctors, as well as nurses, dentists, and scientists66 experience elevated suicide rates even when controlling for demographic factors, and they tend to choose drug overdoses. (Mathematicians and artists also experience elevated rates of suicide, but factors other than acquired competence likely account for these.) Some but not all studies worldwide show an elevated suicide rate for police officers that is not explained by demographic factors, e.g. being mostly male.67 Method preferences also appear to differ by gender. Both male and female physicians experience an elevated rate of suicide, but the rate for female physicians is much more elevated against the baseline female population68 compared to that of men. This could be explained by a female preference for drug overdose rather than firearms. Firearms are more popular among men. Men are more likely to develop familiarity and competence with firearms than women, and when men use firearms to attempt suicide, they are more likely to complete suicide69 than women who use firearms. There is evidence that women prefer poisoning in general; in areas in which lethal chemicals are widely available, such as India and China, female suicides account for a much higher percentage of total suicides. In China, which accounts for a quarter of suicides worldwide, women are significantly more likely70 to commit suicide than men. Indeed, a majority of suicides in China utilize the method of poisoning by lethal pesticides;71 this also accounts for the greater risk of suicide among rural Chinese. Taken together, thwarted belonging, perceived burdensomeness, and acquired competence parsimoniously account for a huge portion of the variation in suicide rates. What Doesn’t Cause Suicide Some factors are commonly associated with suicide, but have little demonstrable, independent effect on suicide apart from the previously named factors. Depression, for instance, accounts for a very mild increase in suicide risk, mostly in males.72 It would be shocking if there were not some effect, as suicide and suicidal ideation are themselves diagnostic factors in major depressive disorder. But the claim that “the number one cause of suicide is untreated depression,” as asserted in popular sources such as suicide.org and even the Department of Health and Human Services’ website, has no basis in fact. It would be much more accurate to say that maleness is the leading cause of suicide. Depression occurs most often in women and young people; suicide, by contrast, occurs mostly in older people and men. Some mental illnesses other than depression, however, do drastically increase the risk of suicide. Importantly, while maintaining that mental illness is relevant to suicide, Joiner does not implicate mental illness in causing suicide—rather, his model explains the highly elevated suicide levels in people with disorders like bipolar I and II and borderline personality disorder by the fact that such disorders (a) facilitate comfort with increasingly lethal self-harm, (b) increase feelings of (and perhaps actual) burdensomeness, and (c) decrease the ability to belong. Evolutionary Considerations Is suicide an adaptive phenomenon? Why do our brains, themselves the product of millions of years of evolution, occasionally allow us to kill ourselves and destroy any hope of future reproduction? Denys deCatanzaro has been researching the evolutionary biology of human suicide since the early 1980s.73 He outlines both adaptive and non-adaptive possibilities of the behavior of suicide. In considering the possibilities, keep in mind that the phenomenon of suicide may not have a single explanation; some suicides (or suicide attempts) may be better explained as adaptive behavior, others as maladaptive. For instance, in terms of being the product of adaptation, the suicides of the elderly might be in an entirely different category74 from those of adolescents. Here are the possibilities, broadly. First, suicide might not be an adaptation at all. It might be a logical decision made rationally by the individual, and not specifically influenced by inherited traits. The positive relationship between suicide and IQ on the national level, as well as the decreased risk of suicide seen in mentally retarded individuals, as noted in above, both make this hypothesis more likely; if suicide requires a certain minimum IQ in order to occur, then it must be a relatively new phenomenon in the development of human beings, with not much time for adaptations to occur. While lower animals sometimes engage in behavior that is lethal to themselves for kin-altruistic reasons, there is no true analogue to the human phenomenon of suicide among other animals. If Dan Everett is correct that suicide is completely absent among the Pirahã people,75 those humans whose culture most discourages abstract thought, then this is even more evidence that the level of abstraction required to commit suicide has only recently been reached by humans. However, since suicide seems to account for a significant proportion of deaths in virtually every human group ever studied,76 it is likely that populations have had some time to develop adaptations to this eventuality. But there is another possibility, according to deCatanzaro: the adaptations that lead to suicide in the modern world did not lead to suicide in past environments of evolutionary adaptation. That is, there is a mismatch between human nature and the modern environments in which we find ourselves, and this mismatch is the cause of suicide. The most intriguing possibility is that suicide is itself an adaptive behavior, under certain circumstances. How could this be so, given that suicide ends one’s survival and destroys any future chance at reproduction, the two most crucial factors for selection? The answer lies in kin selection. Genes are not carried by the individual only, but shared with relatives; offspring are not the only chance for reproductive success. Parents, siblings, nieces and nephews also carry one’s genes. And future children are not the only path to evolutionary success; investment in previously-born children (and their reproductive success) also advances genetic interests. One gets “inclusive fitness”—an increase in the chance of one’s genes being passed on—from promoting the survival and reproduction of close kin as well as by promoting one’s own survival and reproduction. deCatanzaro proposes a mathematical model77 of “adaptive suicide” in which individuals monitor their “inclusive fitness”—the likelihood of having future surviving offspring, plus the ability to contribute to the survival and reproduction of existing relatives in proportion to their relatedness. Under certain conditions, one’s expected contribution to one’s own genetic fitness (likelihood of reproduction, likelihood of the survival of one’s future offspring to reproduce, effectiveness at materially supporting one’s offspring and other relatives) may fall to virtually nothing. However, as long as one survives under these circumstances, an individual not only contributes nothing to his own genetic fitness, but also likely drains the resources of his genetic relatives. His internal meter of his inclusive fitness would read a negative value, meaning that his continued survival is contrary to his genetic interests. Therefore, suicide, in this limited situation, must be said to be adaptive. This adaptation would require that humans have a kind of “inclusive fitness monitor,” noticing factors such as future fertility, ability to contribute, and burdensomeness on close kin. It would require that the brain have a mechanism for causing suicide (or mechanisms for inhibiting suicide that it could cease to inhibit), and this suicide mechanism would have to be triggered by a negative reading on the inclusive fitness meter. Also, for this adaptation to have come into existence, situations in which people were a significant burden on the genetic interests of their kin must have been so common in human history as to be a selective force. In our modern world, it would be callous and cruel to think of a sick, elderly relative as a burden who would be better off dead. And that is not the message of an inclusive fitness model—its message is merely that, in the recent past during which modern humans were evolving, a heritable trait that functioned to tell a human something like “die if you’re a net burden on your genetic kin, otherwise stay alive” may have carried benefits in terms of selection. Unfortunately, Thomas Joiner cannot get past the (admittedly substantial) emotional load of the adaptive model of suicide, and rejects it on what are essentially aesthetic grounds: …I do not much like this adaptive suicide view; my own dad died by suicide and the idea that he was an actual burden is offensive. My view is that self-sacrifice is adaptive in some animal species. It may have been adaptive under certain conditions in the course of human evolution, but we will never really know. Most important, it does not really matter now. What matters now is that perceived burdensomeness—and, to the extent that it exists, actual burdensomeness—are remediable through perception- and skill-based psychotherapies. Death is no longer adaptive, if it ever was.78 This is a strange statement for a scientist. Although Joiner is writing a book called Why People Die By Suicide, he asserts that the essential “why” of his research does not matter— especially to the extent that it might be “offensive.” In this, I think he misunderstands the nature of the adaptive view. It is not to say that suicide is good or bad, or that Joiner’s dad really was a burden to Joiner or his family; it is simply that, in the human environment of evolutionary adaptedness, the ability and predilection to commit suicide under certain conditions may have conferred a benefit. Joiner also wrongly asserts that “we will never really know” about the adaptive theory, when he should know that the evolutionary psychology model is perfectly capable of generating testable hypotheses, and has done so in the past with robust results.79 Joiner repeatedly impresses upon readers the notion that it is perceived burdensomeness—not actual burdensomeness—that facilitates suicide. However, this may be more nice than true: suicidal persons’ perceptions of their own burdensomeness may in fact be highly accurate. Just before he dismisses the adaptive theory of suicide, Joiner summarizes a study supporting the view that suicides really are a burden: “when researchers interviewed the significant others of eighty-one people who had recently attempted suicide, a majority of significant others reported that their support of the patient represented a burden to them.” The adaptive model leads to different predictions (and, in turn, possibly different risk assessments and treatment models) from Joiner’s model. For instance, in Joiner’s model, “belongingness” is all that matters. But an adaptive model would predict that some forms of belongingness would be more protective against suicide than others—specifically, contributing to the welfare of one’s genetic relatives (or perhaps surrogates for genetic relatives) would be more protective than other forms of belonging. Relationships (especially heterosexual) with spouses and children would matter more than relationships with friends in an adaptive model (as they seem to do), but not in Joiner’s model. Similarly, in Joiner’s model all that matters is “burdensomeness”—no matter who is burdened. An adaptive model might predict that burdensomeness on genetic relatives in particular (or their surrogates) would trigger suicidal behavior, rather than burdensomeness on non-relatives. In fact, suicidal ideation is predicted by feelings of burdensomeness on kin,80 in particular among the elderly and other high-risk groups. The fact that marriage, pregnancy, and the presence of small dependent children are all protective against suicide is suggestive; not just any belongingness prevents suicide, but especially those types most closely associated with genetic fitness. Sex differences in suicide and suicidal behavior are also better explained by an adaptive model than a purely nonadaptive model. Around the world, men commit the vast majority of suicides; women attempt suicide more frequently than men, but account for fewer completed suicides. Joiner’s model accounts for sex differences between the suicide rates of men and women in two ways: first, in terms of competence, men are more likely to be exposed to provocative stimulation (all kinds of violence and more) that break down one’s fear of death over time; second, in terms of desire for death, men are more likely to be disconnected and more likely than women to feel they are burdensome. This is probably true—but, again, why should this be? Why should men be more prone to risky, painful, violent, or as Joiner terms it, “provocative” behavior? The answer, again, lies in evolutionary biology. Men are not merely “socialized” to be more violent—there are good evolutionary reasons for their greater violence and risktaking in all areas. A great deal of this is due to what Daly and Wilson81 term the “effective polygyny” of human beings (at least in our Environments of Evolutionary Adaptedness, or EEAs)—that is, that the fertility variance among men is much higher than among women. Many more men than women have a high number of children, and many more men than women have zero children. This leads to the sad phenomenon of male disposability. While a woman is “valuable,” with a certain, nearly guaranteed level of reproductive success, a man may have no reproductive success at all—but may, by engaging in risky behavior (e.g., successful killing in wars or honor battles), increase his reproductive success to well beyond what a woman might have. A human male is, sadly, invited by his genetic heritage to gamble his life on the chance of a big payoff in reproductive success. What is driving differential violence in general may also drive differential suicides—even independently from the greater access to fear-reducing, provocative experiences. Note that in this case suicide may, but need not be, adaptive in itself; the loss from an occasional suicide may be outweighed by better performance by surviving males who also engage in provocative behavior. More specifically, Joiner’s model does not explain why, in addition to varying between genders and across age groups, the time pattern in suicides across age groups is different between men and women. Men’s suicide rates are a linear function of age: the older the male, the higher the suicide rate. Women’s suicide rates vary with time differently, however. While in some countries, the pattern for women matches that for men, in other countries the pattern is very different. In Canada, rather than rising linearly with age, suicide among women peaks during the 35–44 age range; in the United States, the Netherlands, and Sweden, it peaks during the 45–54 age range; and in Australia, Denmark, and Poland, female suicides peak in the 55–64 age range.82 While belonging and burdensomeness are probably implicated, the fact that these are the age ranges of menopause and postmenopause in women seems to lend support to the adaptive view as to why burdensomeness and thwarted belonging would come into play at those times: future reproductive fitness zeroes out, making the possibility of a negative contribution value (burdensomeness) salient. While Joiner’s three-factor model is compelling, I think there is persuasive evidence that an adaptive model should be considered. At the very least, such a hypothesis should not be rejected on merely aesthetic grounds. To do so is irresponsible and unscientific. An accurate analysis of the etiology of suicide affects both assessment of the risk of suicide and treatment for the suffering that causes suicide. Attempted Suicide as an Adaptive Behavior: Suicide Gambles Suicide itself may be adaptive in circumstances in which one’s inclusive fitness is negative; however, even if inclusive fitness is positive, a suicide attempt may be adaptive if the expected benefits from possibly surviving exceed the expected loss from death. An apparently lethal but ultimately unsuccessful suicide attempt may be not only adaptive, but economically beneficial—provided one does not die in the attempt. In a 2003 article in the Southern Economic Journal, Dave Marcotte presented data that suicide attempters experience an increase in income after the attempt that is proportional to the lethality of the attempt. Charles Duhigg summarizes83 in his Slate article, provocatively subtitled “Why trying to kill yourself may be a smart business decision”: Marcotte’s study found that after people attempt suicide and fail, their incomes increase by an average of 20.6 percent compared to peers who seriously contemplate suicide but never make an attempt. In fact, the more serious the attempt, the larger the boost—“hard-suicide” attempts, in which luck is the only reason the attempts fail, are associated with a 36.3 percent increase in income. (The presence of nonattempters as a control group suggests the suicide effort is the root cause of the boost.) Marcotte’s data suggest that a suicide attempt, particularly an apparently lethal one, acts as a signal that the individual needs help—and, as it is a signal that entails significant cost (the risk of death), it is a particularly believable signal. This signal seems to act to make resources “cheaper”—a suicide attempter may get access to resources that he did not have access to before the attempt. Suicide attempts can represent a kind of gamble for people in very difficult situations. Indeed, Marcotte found that the increase in income was proportional to the lethality of the attempt, an indication of the cost—hence reliability—of the signal sent by the attempt. If a suicide attempt is a (perhaps wholly unconscious) gambling strategy for increased investment from others, then suicide attempts may be adaptive even when one’s own death decreases one’s inclusive fitness (as with a healthy young person), if the expected value of extra fitness from “winning” the gamble makes up for it. If young girls, for instance, frequently make attempts of low lethality, this may reflect that their internal “inclusive fitness meters” are still giving positive values, but that they are willing to take a slight risk of self-harm in exchange for an increase in attention (and potentially fitness). As noted above, our species’ moderate effective polygyny—the fact that male fitness has higher variance than female fitness—means that a male is more likely to die childless than a woman. His inclusive fitness is more likely to be negative, but in addition, he has less to lose and more to gain from a more serious suicide attempt. If he dies, from his genes’ perspective, it might not be much loss compared to the benefits of “winning” the gamble and surviving the attempt. Recall that women commit suicide much more often when lethal poisons are available (e.g., Chinese rural women, women physicians). This is a method unlikely to be lethal in our environments of evolutionary adaptedness; its relatively low lethality might be the deeper reason that women feel comfortable using it, even though modern chemicals in some cases make it reliably lethal. Also, the period during which a person “acquires competence” by engaging in increasingly provocative behaviors may provide the opportunity for group members to intervene and offer support; women are likely to be arrested earlier in this process than men, in part due to their more secure reproductive value compared to male “disposability.” These hypothesized adaptive processes are not necessarily conscious, if they exist; many people who make serious suicide attempts do sincerely intend to die. From the genes’ perspective, it is enough to get the organism to perform the adaptive behavior (in this case, attempting suicide when the expected gain from surviving exceeds the expected loss in fitness from dying)—the strategy, if it exists, is genetically encoded, not rationally calculated. Of course, even if nonconscious, an adaptation may still respond to economic incentives. If it is capable of choosing an appropriately lethal means of suicide, it is capable of responding to a change in the likelihood of rescue. If rescue is forbidden, for example, the likelihood of survival is close to zero for many methods. Again, Joiner is ideologically opposed to this line of thinking, and again, it’s for aesthetic, not scientific, reasons. Joiner’s complaints are two: the economic “viewpoint” is dangerous, in that it may encourage lethal-seeming suicide attempts; and it is callous, in that it denies the reality of the suffering experienced by the suicidal individual. Both of these complaints are without merit. As to the “danger” of the economic model, Joiner says: The danger of viewpoints like this should be pointed out. Any analysis that encourages suicidal behavior in any way—particularly in ways that romanticize or glorify it, or make it seem easy and normative—has potential negative consequences for public health. But it is hardly the viewpoint that is dangerous—it’s the existing incentive structure in our society that encourages apparently lethal suicide attempts in people who often don’t really want to die. I have argued that if the suicide prohibition were ended, this dangerous incentive structure—the “fantasy of rescue”—would also end. Analyses are not dangerous. Problems are dangerous. Analyses identify the problems and point the way to solutions. By suggesting that the economic analysis is dangerous, Joiner is contributing to the taboo against speaking about suicide. Joiner also argues that the economic hypothesis denies the reality of the suffering of suicide attempters. He believes that the economic idea is part of a kind of “deconstructionist” philosophy in the school of Jacques Derrida: “What is left for the deconstructionist, then, is a constant questioning of the very existence of reality and meaning—including the reality of emotional pain. Try telling that to a suicidal person.” This objection is misguided. Joiner thinks that the economic model does not account for the pain suffered by those who attempt suicide. But the economic model suggests no such thing! Duhigg’s unfortunate opening example in his popular summary of the Marcotte study reports that right before the depressed, suicidal Kirk Jones jumped over the guardrail at Niagara Falls and survived, he had bragged to friends that he would “make some money” if he went over the Falls and lived. Despite this unfortunate and likely unrepresentative example, the core hypothesis is not that people coldly calculate that they will get a benefit from an apparently lethal suicide attempt. Rather, suffering people are motivated by that awful, extremely real suffering to do something awful—to essentially gamble their lives on a chance at making the suffering stop. An economic explanation, especially an adaptive one, need not imply cold, conscious processing and weighing of “expected values” at all. In a later chapter I will revisit the subject of “suicide gambles” in a broader sense, including behaviors apparently unrelated to suicide.",
      "chapter_number": 13,
      "section_number": null,
      "word_count": 5725,
      "file_path": "index_split_013.html",
      "spine_order": 14
    },
    {
      "title": "Chapter Seven: On Contagion",
      "content": "Chapter Seven: On Contagion Behavioral Contagion Infectious diseases spread through contagion; one person infected with the flu can infect dozens of others. The specific microorganisms that cause each disease can be identified, and patterns of transmission can be discerned using epidemiological methods. Wells infected with cholera can be identified and sealed off. Many human behaviors are transmitted in patterns that mimic disease contagion. Pathological homesickness, apotemnophilia, multiple personality disorder, and even Ursuline convents in seventeenth-century France have all been posited to spread by sociogenic contagion. Just as cultural items such as computer viruses spread through direct contagion of software, our minds may be similarly vulnerable to contagious ideas and behaviors, viruses on the informational level rather than the microbiological level. Cultural contagion is even an explicit goal: an essay or a video “goes viral” when it succeeds in getting itself replicated on computers all over the world. Behaviors are not, for the most part, transmitted by germs; they must be transmitted culturally. The metaphorical “germs” by which behavioral contagion occurs are abstract and vague compared to real germs. If we find the contagion metaphor useful for thinking about behavioral change, we must keep in mind the ways in which the metaphor is incomplete, for here there is no tidy, legible mechanism of transmission. Ethical Perspectives on Suicide Contagion Is suicide contagious? Could it be like a computer virus, infecting the software of the mind itself? Here the analogy to biological science has taken on moral proportions. On the one hand, if suicide can be contagious, the agency of a person committing suicide is called into question; as with the disease model of addiction, the outcome seems to be less his fault when viewed as partly the product of contagion. On the other hand, if suicide is contagious in the sense that one suicide might meaningfully cause many others, then there may be a special ethical duty to refrain from committing suicide in order to avoid having a causative effect on others. This is, of course, assuming suicide is always a bad outcome, to be prevented no matter how much suffering and ignorance is required to do so. This latter perspective—that there is a moral duty not to commit suicide, grounded in large part in the possible contagious effects of a suicide—is taken by Jennifer Michael Hecht in her recent popular book Stay: A History of Suicide and the Philosophies Against It.84 During the twentieth century, moral public discourse on suicide was largely replaced with medical discourse; psychologists reframed suicide as being necessarily the result of mental illness, undermining the agency and moral responsibility attributable to suicides. Contemporary philosophers85 have struggled to articulate arguments for the intuition that suicide is wrong without reference to religion. Hecht takes up the challenge to provide a secular account of the case against suicide, and she motivates the duty not to commit suicide, in large part, by reference to the alleged contagious effects of suicide. Examining the phenomenon of contagion can help sort out the moral implications of this new basis for the wrongness of suicide. The Science of Suicide Contagion Swabs and microscopes will not reveal the secrets of behavioral contagion, but what about epidemiological analysis? Dozens of studies have investigated the phenomenon of suicide contagion, using statistical analysis to attempt to identify clusters of suicides in space and time. So is there such a thing as suicide contagion, or not? In a 2003 paper entitled “Media Contagion and Suicide Among the Young”86 Madelyn Gould and co-authors assert that there is “ample evidence from the literature on suicide clusters and the impact of the media to support the contention that suicide is ‘contagious.’” In contrast, Thomas Joiner, a suicide researcher mentioned in previous chapters, calls the evidence for large-scale clusters “equivocal.”87 In a 1999 paper on suicide contagion, Joiner goes on to say that contagion “has not been conceptually well developed nor empirically well supported as an explanation for suicide clusters.” Writing in 2009, a team led by Michael Westerlund elaborately qualify their claim as follows: “Although disputed, most researchers in the field of suicide and mass media agree that the studies carried out to date have substantiated the existence, under certain circumstances, of genuine suicidal ‘contagion’ from suicide reports in the media.”88 Why the discrepancy between researchers writing on the same subject at approximately the same time? To understand the dissonant claims, we must first figure out what, exactly, the phenomenon of contagion precisely is. The purported phenomenon of suicide contagion happens as follows: A person commits suicide; Another person learns of the suicide, through media or otherwise; and Learning about the suicide causes the second person to also commit suicide. The slipperiest part of the above definition is the word “cause,” which might be interpreted in a number of ways—in context, it might reasonably mean anything from necessary “but-for” causation to a subtle influence, or something as abstract as a condition of possibility. The word “cause” here stands in for the mechanism of suicide contagion akin to biological germs, discussed above. Moral Contagion or Informational Contagion? There are really two types of “cause” that we care about, two distinct aspects of the message presumably conveyed by a suicide to any imitators. First, there is the implied moral message that suicide is acceptable. When a vulnerable person is considering suicide, the theory goes, a news report of a celebrity suicide functions as “social proof” that suicide is an acceptable solution to serious problems. The moral licensing effect is posited to be strong enough to push a suicidal person over the edge. This is the message stressed in the “social learning theory” model of suicide contagion.89 It is also the message emphasized by Hecht in her moral argument based on contagion: “don’t kill yourself, because it teaches other people that suicide is okay.” But the second aspect of the message conveyed by a suicide is purely informational. Instead of (or in addition to) its moral message, a successful act of suicide provides cold, hard facts—especially regarding the specifics of the method used. Useful information making its way through a population follows the same patterns of dissemination as a disease infecting a population. Information about how to commit suicide successfully is difficult to find; a single, salient case study providing careful description of the not-too-horrible sounding method is better-quality information than may otherwise be available. People who have never been seriously suicidal generally underestimate the practical difficulty of successfully committing suicide; a part of this difficulty is the lack of reliable information about method. A single successful suicide would only be valuable information among people starved for quality information about suicide, and our suicide prohibition ensures that we are so starved. In this aspect, the suicide’s crime against society, if he commits one, is epistemic. The moral claim grounded in this type of contagion would sound more like this: “don’t kill yourself, because it teaches other people that suicide is possible.” There seems to be less moral weight in this duty than in the earlier phrasing; the violation amounts to passing forbidden information, perhaps even inadvertently. Within suicide contagion research, no effort is made to distinguish information-heavy “contagion” from moral licensing “contagion.” In a meta-analysis of papers investigating suicide contagion, Steven Stack90 reviews what he calls “perhaps the most dramatic illustration of an imitative effect”—the publication of the suicide self-help book Final Exit in 1991. Suicides by asphyxiation, a method recommended in the book, reportedly increased by 313% in the year after the book’s publication, and over a quarter of these suicides had a copy of the book present at the death scene.91 Of course, the publication of the book Final Exit is very different from a celebrity suicide—the deceased, in suffocating themselves, were presumably using information they had sought out in the book, and it is strange that Stack characterizes this as an “imitative effect.” While there are descriptions of actual assisted suicides in Final Exit, it would likewise be strange to characterize the cluster suicides as “imitating” them—or of imitating anyone. The sense in which the book “caused” the suicides is limited; as Stack notes, the overall rate of suicide did not rise. Rather, people who wanted to commit suicide did research and were able to use a comfortable, reliable method. This is not a case of contagion, but of research. Studies do not attempt to distinguish the informational from the moral component of contagion. This is unfortunate. As I will explain, it appears to me that the information component of suicides dominates observed contagion effects, surpassing the effects, if any, of moral licensing. Where contagion is most apparent, the information component of the original suicide will be apparent as well. Mass Clusters and Point Clusters There are two types of suicide clusters, according to Joiner (1999) and Mesoudi (2009).92 A mass cluster is an episode of suicide contagion on a national scale, without spatial clustering. An example is the suicide of Marilyn Monroe, discussed below, with effects detectable in national suicide statistics. The other type is a point cluster, a local cluster of suicides often confined to one school, prison, or hospital. Again, the evidence for the existence of mass clusters is “equivocal,” according to Joiner. In the rare cases in which contagion patterns are clearly detectable, we will see that the suicides in question were high in information content. For local-level suicide clustering there is a great deal of evidence—but, as Joiner points out, there is little evidence that this clustering is caused by contagion. In fact, computer models testing Joiner’s (1999) hypothesis93 suggest that either contagion or geographic sorting of similar people (homophily) could explain the degree to which suicides appear to cluster. The cause of suicides is difficult to sort out even when contagion is assumed to be present; but clustering may be present even in the absence of any contagion whatsoever, because people tend to live near people similar to them. In a related study,94 assortative relating—self-sorting by trait—accounted for patterns of suicidality in pairs of college roommates. Suicide clusters in Scotland have been found to be adequately explained by spatial concentrations of economic deprivation.95 Whether a mass cluster or a point cluster is under study, statistical analysis of the numerical data determines whether there is a significant result. Researchers must use discretion in specifying how cluster-like is cluster-like enough. Estimates of the proportion of suicides accounted for by clusters vary widely, from less than 1% to 13% or more.96 A recent quantitative review of 419 findings across 55 studies investigating media suicide contagion97 concluded that only 35% of the findings under study supported the existence of clustering or contagion; the vast majority of findings were negative. (If publication bias applies here, and positive findings are preferentially reported, then the evidence appears even worse.) In contrast to what Stack characterizes as “narrative” literature reviews, which, like Gould’s 2003 study, often conclude that contagion unquestionably exists, Stack notes that in this quantitative review, “the weight of the evidence is, in fact, against an imitative effect. Indeed, 269/419 findings or 64.2% reported the absence of an imitative effect.” The evidence for suicide contagion is equivocal, and its peculiarities subtle. To cut through the mathematical abstractions, let’s take a look at one of the most dramatic suicide mass clusters in American history—that following the suicide of Marilyn Monroe. The Death of Marilyn Monroe On August 5, 1962, Marilyn Monroe committed suicide by an overdose of the barbiturate Nembutal. Examining national suicide data from the years surrounding her death, a “copycat” cluster clearly suggests itself even without the application of statistical analysis tools. David Phillips reported that there were 197 suicides in the week after the death of Marilyn Monroe,98 a 12% increase over the expected number. But the increase is perceptible at the monthly and yearly level as well. The apparent copycat effect is most pronounced among women, and highly localized to the specific method used by Marilyn Monroe. Between the years of 1958 and 1971 in the United States, the number of suicides rose gradually with the population; the rate of suicide did not change substantially during that time period (see Figure 1). The rate of suicides by poisoning, however, increased, and the rate of poisoning by barbiturates specifically doubled.99 Figure 1. Suicide rate and poisoning suicide rate, 1958–1971 Poisoning suicides, and especially barbiturate overdoses, had been increasing for years before Marilyn Monroe’s suicide (see Figure 2). A gradually increasing trend was established between 1958, when there were 912 barbiturate overdoses, and 1961, when there were 1,341. In 1962, however, the gradual trend was suddenly replaced with an even steeper increase (see Figure 2). In 1962, there were 1,739 barbiturate overdose suicides; 1963 saw even more, with 1,997 such deaths. The sudden increase is then followed by a gradual decrease, even falling below the trend line predicted by the initial 1958–1961 increase. Figure 2. Barbiturate suicide rate, overall and by sex, 1958–1971 Barbiturate overdoses during this period follow a clear pattern: there tend to be about twice as many women as men committing suicide by barbiturate overdose. This is remarkable since men are about four times as likely to commit suicide as women, and this holds true for most suicide methods. When it comes to suicide by poison, though, and especially by barbiturate overdose, women are twice as represented as men. Viewing the graphs of male and female overdoses separately (Figure 2), there is an increase in male suicides of this type following Marilyn Monroe’s death, but most of the “extra” barbiturate suicides appear to be women. The sudden uptick in suicides is also detectable at the monthly level. From January 1958 until July 1962, the monthly number of suicides bounces from 1,300 to 1,800. Monthly poisoning suicide numbers range from the high 200s to the low 400s, with a secular increasing trend. In August 1962, the number of suicides is up a little, but the number of poisoning suicides is up a lot (Figure 3). In 1961, there had been 1,620 suicides in July and 1,579 in August; in 1962, there were 1,659 suicides in July and 1,838 in August. Again in 1961, there were 390 poisoning deaths in July and 367 in August; in 1962, there were 370 poisoning deaths in July and 543 in August, the first time during the study period (and perhaps ever) that the figure exceeded 500. Figure 3Figure 3. Monthly suicides and poisoning suicides, 1962 It is possible that the rise in suicide during the week and month of Marilyn Monroe’s death, and the acceleration of deaths by poisoning and especially barbiturate overdose by women in the months and years after her death, are the product of coincidence, not causally related to her suicide at all. It is also possible that some third factor caused both Monroe’s suicide and the other female poisoning suicides. However, the evidence is strongly suggestive of a causal connection, even in the absence of statistical analysis. Marilyn Monroe’s death was a high-information suicide; the New York Mirror even specified the number of pills she had taken on its front page (Figure 4). Barbiturate sleeping pills were commonly prescribed at the time, and even available on the black market. (Today, much less lethal benzodiazepines have replaced barbiturates on both the prescription market and the black market; however, barbiturates are still the drug typically prescribed for assisted suicide in the United States.) Monroe’s suicide presented an extremely useful piece of information for those considering suicide: 40 Nembutal taken by mouth are lethal to a small woman. Figure 4. Cover of the New York Mirror, August 6, 1962 The death of Marilyn Monroe provides an unusually clear example of an apparent mass suicide cluster. Most correlations are much weaker; recall that the majority of findings of suicide contagion studies reviewed in Stack’s 2005 analysis were negative. Often no correlation can be found at all. Certain features of studies make them more or less likely to have a negative or positive result.100 One is femaleness: researchers looking at suicide rates of women specifically are more likely to detect contagion than researchers looking at men’s or overall suicide rates. Another is the celebrity status of the original suicide, particularly entertainment or political celebrity status, which is positively correlated with finding a contagion effect compared to studies examining non-celebrity suicides. If researchers study a suicide that is portrayed negatively in the media, they are much less likely to find a contagion pattern than researchers who are not studying suicides they deem to have been portrayed negatively in the media. Studies looking at youth suicide rates have also been less likely to find a contagion effect than studies of the general population,101 casting doubt on the theory that youth are particularly susceptible to suicide contagion. Detecting a suicide cluster using statistical analysis, even when the numbers are very suggestive of causation, can say nothing about the mechanism by which causation might occur. If media reports of suicides are contagious and importantly causative of future suicides—if they are truly a risk factor for suicide—then we would expect survivors of nearly-lethal suicide attempts to be more likely to have recently been exposed to reports of a suicide than non-suicidal matched controls. If, on the other hand, serious suicide attempters do not differ significantly from non-suicidal matched controls in terms of exposure to media reports of suicide, then it is less likely this kind of media exposure is importantly causative of suicide. Absence of correlation (between suicide attempter status and suicide media exposure), in this case, would likely indicate absence of causation. This was the experimental design of a 2001 study by James Mercy et al.,102 “Is Suicide Contagious? A Study of the Relation between Exposure to the Suicidal Behavior of Others and Nearly Lethal Suicide Attempts.” 153 young people, ages 13–34, who had recently been hospitalized for a nearly-lethal suicide attempt, along with 513 non-suicidal matched controls, were interviewed about their exposure to media accounts of suicide, as well as suicidal behavior on the part of parents, relatives, or friends. Exposure to the suicidal behavior of parents and relatives was not significantly different between the groups—but more non-suicidal controls than suicide attempters had been exposed to media reports of suicide and to the suicidal behavior of friends. Contrary to expectation, and again based on this one study, suicide media and suicidal behavior by friends appears to have a protective effect against suicide. If our world happens to work according to the principles of this study, then suicide exhibits a moral de-licensing effect, the opposite of the moral contagion of social learning theory; and if this is true, committing suicide yourself makes your friends less likely to commit suicide. Gould et al. (2003) criticize the findings of the Mercy et al. (2001) study on the grounds that around half of the subjects were adults between the ages of 25 and 34. Groups this old are not known to exhibit suicide contagion, says Gould. Stack (2005) contradicts this statement with the finding that studies of youth were less likely to find a contagion effect than studies of the entire population. He notes that the misperception that youth are prone to suicide contagion is the result of a few studies with “atypical research design and/or samples,” such as counting only suicides by a particular method rather than the entire population’s suicide rates. In addition, many studies around the world have identified suicide clusters in non-teenage populations. Perhaps Gould et al. reject these studies and their conclusions as well, if it is so clear that suicide contagion is undetectable outside of a teenage population. Jennifer Michael Hecht103 attempts to make a moral case against suicide without appealing to God or to religious injunctions—and turns instead to science to support the moral obligation. The Mercy study serves as a kind of reversal test, to see if the facts of suicide contagion matter to the moral outcome in Hecht’s case. If suicide, encountered in both personal and public life, could be shown to modestly decrease future suicides, would that make suicide not wrong (or at least not as wrong)? Based on my reading of Hecht, I suspect that she would insist that suicide remains completely wrong, even if Mercy et al.’s findings had been replicated dozens of times. Suicide contagion is not weight-bearing; no part of the anti-suicide argument hinges on its truth or falsity. Hecht uses suicide contagion more like a decoration than as support for the case against suicide; nothing turns on it, and none of her conclusions would change if she came to agree that “suicide contagion” is exaggerated and misleading, and more about information than moral licensing. I suspect that the “information payload” of a suicide is strongly predictive of whether that suicide will cause contagion-like effects. Marilyn Monroe’s suicide carried a dense information payload, and produced a detectable wave of suicides. Final Exit is nothing but information payload—and even though no suicide was associated with it, it produced a “contagion” effect stronger than any real suicide. Another well-supported suicide cluster occurred after the suicide of Quebecois journalist Gaetan Girouard. Girouard committed suicide by hanging; this may not seem like a major information payload, but it actually is. Hanging is around 70% lethal,104 which is actually slightly higher than the lethality level of suicidal gunshot wounds for women. Hanging is not as violent or traumatic as other methods, and it is easily achievable with common materials. And it is this information payload, rather than the moral licensing payload, that primarily drives the apparent contagiousness of suicide. Why Women? According to Stack (2005), studies investigating female suicide rates are almost five times more likely to find a contagion effect than studies investigating suicide rates in men or in the population as a whole. The Marilyn Monroe suicide cluster is perceptibly driven by female suicides. Why should women be especially subject to contagion? Women are more likely to experience psychosomatic illness in general, and to display physical symptoms from social suggestion (as in mass hysteria) than men. Suicide contagion might function similar to a socially-transmitted hysterical illness. There is a simpler explanation, though: women are pickier about method than men. Female suicide rates are around a quarter of men’s suicide rates overall, and the statistics for most suicide methods reflect this sex difference. But as noted earlier in the chapter, women are twice as likely to die by barbiturate overdose as men—but few women use firearms to commit suicide compared to men. Women in China commit suicide more often than men; lethal poisons (such as agricultural pesticides) are legal and available in China that are not available in the United States, and most Chinese women who commit suicide do so by ingesting poison. The physician suicide rate is elevated for both men and women, but the suicide rate for female doctors is relatively more elevated than that for male doctors. Access to lethal drugs or poisons appears to be more of a determining factor in female than male suicides; males are more flexible with regard to method. Government suicide prevention policies include drug prohibition, restrictions on gun purchases, barriers on bridges and high places, and even emissions standards on car exhaust. (Australia’s suicide rate dropped as car exhaust systems became more efficient and therefore less lethal.) These prohibitions burden both men and women, but the drug prohibition falls particularly hard on women. As a result, suicidal women in our society are likely to be experiencing an information gap compared to suicidal men—having the will to commit suicide, but lacking an acceptable method to accomplish it. The information provided by the event of a celebrity suicide and the method used—prescription drugs, hanging, or asphyxiation, by plastic bag or charcoal burning—would therefore be more likely to be collected and used by a woman than a man. In summary, the association of femaleness with suicide contagion is likely a function of women’s greater sensitivity to method, including women’s preference for less violent methods, especially poison. Other Factors in Contagion: Negative Definition of Suicide The evidence for suicide clusters—much less contagion— is more suggestive than compelling. Most findings are null. But one study feature in particular is particularly likely to guarantee a null result (that is, no contagion): a story that portrays suicide in a negative light, providing “negative definitions” for the suicide and its effects. In Stack (2005), researchers investigating “negative light” portrayals of suicide were 99% less likely to find a positive result than those not investigating a self-described negative portrayal (odds ratio 0.01). Keeping the sketchiness of the entire domain in mind, this finding might be a fluke. Whether a given story involved a “negative portrayal” was, according to Stack, defined by the authors of the studies themselves; it may not be measuring any feature of reality that is reliable across observers. Those (few) studies that sought to examine suicides receiving negative portrayals may have many things in common with each other besides the negative portrayal, including low information content. Examples of “negative definition” stories provided by Stack (2005) include the mass suicide of the People’s Temple cult members in Jonestown and the suicide of Nirvana singer Kurt Cobain; the “negative definition” hypothesis seems arbitrary enough to risk being a fully general excuse for why a particular suicide did not result in a contagion cluster. Take another look at Figure 4; one might easily characterize its sordid emphasis on Monroe’s nudity as a negative portrayal of a suicide—despite the dozens of imitators. However, it is also possible that suicide contagion does regularly occur, and that the negative portrayal of suicide somehow halts the ordinary process of transmission. If the negative portrayal of suicide in the media has the capacity to shut down suicide contagion effects from suicides, then the role of the media is more important than the role of the original suicide in meaningfully causing the contagious suicides. Touching back to Hecht yet again, if contagion were really a basis for assigning blame to suicide, then this finding would put most of the blame on media outlets and hardly any on individuals. I doubt whether Hecht would let individuals off that easily. Rather, the individual duty to live, no matter how much one is suffering and wants to die, does not seem to be affected by consequential arguments about suicide contagion. Ultimately, suicide contagion is superfluous to her argument. Unfortunately, there is not much left when you take the over-hyped science away. Suicide contagion is used by Hecht to motivate a secular moral duty against suicide. The evidence for suicide contagion is mixed and frequently self-contradictory, but even if Hecht discovered it to be wholly imaginary, it would probably not affect her analysis of the duty not to commit suicide. Suicide contagion is a prop that looks good with the argument, rather than a genuinely relevant proposition that might have real-world effects. Suicide contagion is also the chief justification for the censorship of reports of suicide. The next chapter will examine the censorship of suicide, as well as the censorship or failure to censor other behaviors that may contribute to contagion.",
      "chapter_number": 14,
      "section_number": null,
      "word_count": 4510,
      "file_path": "index_split_014.html",
      "spine_order": 15
    },
    {
      "title": "Chapter Eight: The Censorship of Suicide",
      "content": "Chapter Eight: The Censorship of Suicide Sex and violence are ubiquitous in high and low art today, but artwork depicting suicide remains in danger of censorship merely because of its subject. In London, Paul Day’s compelling, emotionally dense frieze was pulled from a rail station because it depicted a skeleton driving a train and a commuter “wobbling precariously” close to the tracks—alluding to suicide by train. The Pepsi corporation apologized for and retracted ads (published in a German magazine) that depicted a “lonely single calorie” committing suicide. Chris Abraham, the self-appointed censor who received the apology indicated that electronic communication will help him carry out his inquisition into commercial art: “The lesson here,” Abraham declared, “is that social media has eyes everywhere and the network to make sure that advertisers can no longer hide stuff in niche markets.” Art, advertisements, and video games that deal with suicide—entry points for conversations about suicide among ordinary people—are unjustly criticized, censored, and destroyed. There is only one appropriate way to speak of suicide, one appropriate attitude toward it, and all others are quickly suppressed. This is not the case for other controversial topics—murder, race, gender, drug use—nor should it be. Suicide is tabooed in a unique and unfortunate way. Joan Wickersham, author of The Suicide Index and daughter of a suicide, thinks that more conversation about suicide would be a good thing: I think there is a kind of shame and a kind of taboo attached to suicide…We would prefer to think it doesn’t happen. I think we have to acknowledge it does happen. We have to acknowledge that it’s a mystery, that we don’t understand it very well. I just wanted to give a sense of what it is really like to go through this.105 Wickersham says there is a reluctance to talk about suicide, adding, “I would love to see more honest conversation about it.”106 Contrary to Wickersham’s goal, “honest conversation” about suicide is suppressed in the media when a suicide occurs. This suppression is often based on well-intentioned but flawed “media guidelines” published by anti-suicide groups. In addition to the fact that these guidelines promote the ethical position that suicide is wrong, I see two major problems with these guidelines: one, they promote myths about suicide as if they were facts; two, they increase the guilt of survivors by portraying suicide as preventable. The “Media Guidelines for Suicide” on suicide.org advise reporters as follows: • Emphasize the number one cause for suicide: • The number one cause for suicide is untreated depression. • And then indicate that depression is treatable, and thus anyone suffering from depression needs to receive IMMEDIATE help. This, as we have seen, is contrary to the scientific studies, which show that depression only slightly increases the risk for suicide—a fact which in itself carries little weight, since suicidality is one of the possible criteria for diagnosing depression. According to Thomas Joiner,107 borderline personality disorder and anorexia nervosa are far more predictive of suicide than depression. (BPD is associated with a 10% lifetime risk of suicide and a 50% lifetime rate of at least one very severe suicide attempt.) Even given a slight correlation between depression and suicide, it’s overstating the case to say that depression causes suicide. It would be more accurate, but less satisfying, to say that the desire to die, coupled with the acquired ability to die, is the leading cause of suicide. The suicide.org guidelines also recommend using the “fact” that “Over 90% of the people who die by suicide have clinical depression or a similar mental illness when they die.” I have repeatedly attempted to debunk this statistic, but the comfortable idea that suicide is caused by mental illness is hard to dislodge and unlikely to be questioned too closely. Other “media guidelines” offered by suicide.org range from silly to intrusive to Orwellian: • Do not begin a television newscast with a suicide story. • Do not place suicide stories on the cover of newspapers or magazines. • Never portray suicides as heroic. • Never say that a suicide “ended pain” or “ended suffering.” Suicide CAUSES excruciating pain for suicide survivors. • Also, people need to be alive to feel relief from pain. Suicide CAUSES pain. • Do not use the terms “successful suicide” or “committed suicide.” Use the term “died by suicide” instead. • The term “committed suicide” is NOT accurate and is VERY hurtful to those who have attempted suicide and to suicide survivors. Say “died by suicide.” The media guidelines proposed by suicide.org strictly fit my definition of “politically correct bullshit”: they express majority opinion in a manner unconcerned with truth, and have the function of a moral taboo to protect an important cultural narrative from negation. The guidelines promulgated by the National Institutes of Mental Health are much more harmful, however, in that they function to increase the pain and guilt experienced by people close to a person who committed suicide. The message promoted by the NIMH guidelines is that suicide is always preventable, and there are always warning signs. The guidelines advise reporters that: Studies of suicide based on in-depth interviews with those close to the victim indicate that, in their first, shocked reaction, friends and family members may find a loved one’s death by suicide inexplicable or they may deny that there were warning signs. Accounts based on these initial reactions are often unreliable.108 That is, there are always warning signs; push family remembers until they “remember” the politically correct story. Reporters are advised to ask survivors questions such as: • Had the victim ever received treatment for depression or any other mental disorder? • Did the victim have a problem with substance abuse? The message is that there were warning signs that, had the family cared enough to look, would have revealed the suicide’s intentions so that the suicide could have been prevented. Unfortunately, this serves to increase the guilt of survivors, legitimize increasingly coercive suicide prevention tactics, and increase the survivors’ sense that the suicide was a tragedy because it was “preventable.” The problems I identify—promoting false information and unnecessarily increasing survivors’ guilt and pain—are in addition to the harm to the marketplace of ideas that is done in the name of curbing the controversial phenomenon of suicide contagion. A single ethical idea is given precedence over all others, and false facts are repeated in the name of protecting it, and of protecting the institutions that depend on it (“Mention that Suicide.org is available 24 hours a day for anyone who is suicidal,” advises suicide.org). Censorship of Suicide versus Censorship of Violence In the previous chapter, I examined the evidence for the claim that censorship of suicide is necessary because suicide is contagious. But why censor reports of suicide and not reports of other contagious behaviors—such as violence? The evidence for violence contagion is much stronger than that for suicide contagion. But whereas suicide censorship is widely accepted, censorship of other-directed violence in media stories is rare. Violence contagion is demonstrated by the same type of ecological study as suicide contagion,109 and there is a body of laboratory evidence—not found in the suicide research— suggesting that exposure to violent stimuli increases aggressive behavior. However, despite both sources of evidence, the theory that media reports of violence “cause” real-life violence is not at all universally accepted.110 Despite greater evidence for a causal link in the case of violence, the idea that the media should voluntarily self-censor with regard to reports of violence is much less widely accepted than the corresponding idea applied to reports of suicide. Contagion and Moral Responsibility The insistence that suicide is media-contagious, but violence is not, is not rational. It is better understood, I believe, as a consequence of the differential attributions of moral responsibility in cases of suicide versus other-directed violence. Suicide is seen as an irrational act; the actor, as the story goes, is not in control of himself, certainly not sane, and is therefore vulnerable to external effects. On the other hand, the idea that violent acts like homicides are attributable to media suggestion is generally seen as a pathetic excuse. Perpetrators of violence are perceived as much more morally responsible for their acts than suicides. Despite evidence to the contrary, idea contagion is thus psychologically ruled out as a cause of violence, but not of suicides. Is political corruption contagious? How about adultery? Prostitution? Riots? Drug abuse? Such questions are rarely even studied. Obesity certainly appears to be contagious. If so, should we censor reports of these topics to avoid a contagion effect? To do so would seem ludicrous and counterproductive, not to mention contrary to our political ideals. But the censorship of suicide goes unchallenged. Moral Responsibility and Willingness to Censor The more an actor is seen as the agent of his actions, the less outside influences are seen as affecting his actions. In cases where moral responsibility is strongly attributed to an actor, it follows that outside influences are unlikely to be taken seriously as a cause of his actions—and, therefore, it is not necessary to censor these “outside influences” (such as media reports). It is my belief that the widespread voluntary censorship of reports of suicide—from use of politically correct language to pervasive norms of message content—are the result of the modern trend to exculpate suicides from moral responsibility and to redefine suicide as an act of insanity. There is, however, little evidence that suicides are any less morally responsible for their actions than murderers. Certainly, many other behaviors are media-contagious—but they are not censored, nor are many of them even studied. I think that one possible explanation is that, at a deep level, people understand that suicide is just not that bad compared to actual acts of violence—despite hysterical language describing suicide as “self-murder.” We want to exculpate people from acts to which we are sympathetic. While we often refuse to define acts outside of societal norms as “not wrong,” we may nonetheless refuse to attribute full moral responsibility to these acts. But this sort of sympathy backfires in our society. People who are “not responsible for their actions” must be “protected,” often in painful and dehumanizing ways; and society is responsible for their “protection,” often to the detriment of freedom.",
      "chapter_number": 15,
      "section_number": null,
      "word_count": 1708,
      "file_path": "index_split_015.html",
      "spine_order": 16
    },
    {
      "title": "Chapter Nine: Procreative Responsibility: A Road Map",
      "content": "Chapter Nine: Procreative Responsibility: A Road Map Is it good to make people? Rather than construct a traditional argument, the present chapter will map out the branches of this question, its possible meanings, modes of investigation, and evidences. It is my intention here to clarify the space of argument so that the reader can see how the pieces fit together, rather than to persuade along the single axis of antinatalism. The first branch we encounter is the source of “good” in “is it good to make people?” Descriptively, we are looking for the “sake” that is at the foundation of meaning and value itself, an ultimate value that needs no further justification. Values contending to fill this role may be external or abstract—God is a common ultimate value, though newer values such as “intelligence itself,” or “the present and future existence of humans in our universe” have become popular abstract values in the absence of otherwise reified religious faith. The other sort of “sake” is people themselves—things are good or not to the extent that they are good or not for particular people, both already-existing people and people not yet (and possibly never to be) born. Most antinatalist theory focuses on this branch. Although David Benatar presents many religious arguments in his antinatalist treatise Better Never to Have Been, his (and my) main focus has been on whether it is good for people themselves to be born. Even where religious or abstract values are very strong, significant harm to particular people makes the moral determination difficult; not all Abrahams put in a position to sacrifice their Isaacs are willing to do so. Even where sacred values dominate, the harm/care and fairness foundations can still be powerful motivations. Liberty Being created is a necessary condition for having any sort of experience. While one cannot choose to be created, being created is necessary for having any freedom to make choices at all. But is liberty always a gift? In “A Right of Self-Termination?”111 J. David Velleman shows that there are many situations in which getting a choice makes us worse off than if we did not have that choice. This is true not in the paternalist sense that we might make the wrong decisions if given a choice, as even an optimal decision maker can be harmed by being offered certain choices. For instance, if you are invited to a boring dinner party you might prefer never to have been asked rather than face the decision to suffer through the party or refuse the invitation and risk offending the host. A convenience store clerk would prefer not to have the option to open the safe, because having that option makes her a target for robbers. And, Velleman argues, some people may prefer not to have the option to die; some people would rather stay alive, but not bear the moral responsibility for staying alive (and perhaps draining their family’s resources for medical care). Life is often the same kind of freedom: an unwanted one that makes people worse off than if they didn’t have it. The fact that it is the basis for other freedoms does not demonstrate that it is a desirable thing to get. Harm and Measurement: Preferentist and Non-Preferentist Approaches Being born necessarily entails many bad experiences, not the least of which is death. But many (not all) people also have many good experiences. Causing a person to be born causes them to have all the experiences they end up having. How are we to know whether the positive aspects of life are strong and numerous enough to outweigh the harms? Approaches to this question can be divided into two categories: preferentist and non-preferentist. Preferentist approaches assume that people’s preferences are good evidence of what is actually good for them. Non-preferentist approaches take a more abstract perspective, and do not assume that people’s preferences—stated or otherwise inferred—are strong evidence of what is good for them. Preferentist Approaches and Evidence Preferentism is perhaps the most natural mode of ethical analysis. A preferentist might answer the question “is it good for people to be born?” with the suggestion to just ask people whether they are happy to have been born. Preferentists might in addition ask what decisions would be made by people in ideal circumstances with complete information.112 Thought experiments and careful attention to biases may be helpful in teasing out underlying preferences, but the only evidence available, by definition, concerns real people in real, non-ideal circumstances, with limited information. Free Disposal and the Imaginary Survey The casual antinatalist in the wild is certain to encounter two preferentist bodies of evidence regarding the value of life: “why don’t you just kill yourself?” and the Imaginary Survey. The former body of evidence is of the same class as the “free disposal” argument, treated in the first chapter of this book: since only a small percentage of people commit suicide (and the antinatalist interlocutor himself is by definition not among them), this is evidence for the preferentist case that people are generally happy to be born. However, fear of death is not love of life. There are many factors that cause rational people to prefer life to suicide even if their lives are not worth living. There is the pain, uncertainty, and risk of a suicide attempt under prohibition. There is the wish to avoid causing pain to family and friends. There is the instinctual horror of death itself. Even given these and many other obstacles, many people do commit suicide—about a million people a year, worldwide. Millions more attempt suicide but are unsuccessful. Some classes of people have a much higher suicide rate than others—men, white people and Asians, those with certain mental illnesses such as bipolar disorder, and gay and transgendered people. According to the preferentist “free disposal” case, certain classes of people may be ethically forbidden from reproducing based merely on the suicide statistics of similarly situated people. But I have never heard preferentists express a percentage likelihood of suicide that makes reproduction ethically wrong, except to anchor at 50% without explanation—as if a 50% chance of having a hellish life is a morally neutral thing to cause. Bipolar disorder, for example, is highly heritable and likely has a strong genetic component. If one monozygotic (“identical”) twin has bipolar disorder, the other twin has a 40–70% chance of having the disorder too.113 Only about 1% of the population has bipolar disorder, but if a parent has bipolar disorder, the risk goes up to 5–10%—up to ten times the risk. Between 10% and 15% of people with bipolar disorder commit suicide,114 and up to 56% of sufferers make a serious suicide attempt. While the outcome is not determinable by simple multiplication, a preferentist pronatalist who sticks with the likelihood of suicide as a measure of preference for life must at least grant that a bipolar individual takes a very serious risk of harm by bringing offspring into the world. Unfortunately, it is impossible to be aware of all the risk factors in one’s genome that might contribute to the misery of one’s children. The very uncertainty of one’s offspring being in the miserable class is addressed below in the section on uncertainty. The second most common preferentist body of evidence, as presented in the wild, is the Imaginary Survey. The nature of this evidence is that it feels obvious to interlocutors that everyone is very glad to have been born, and they are expected to say so if asked. They perform an “imaginary survey” of people worldwide, and the results are clear: people prefer to be alive. How realistic is this Imaginary Survey? In 1932, sociologist Ruth Shonle Cavan published a paper detailing the responses of 7,852 children from diverse geographic, economic, and racial backgrounds.115 Each child was asked if he had experienced having the wish to never have been born. Around 30% of children indeed reported having had this wish. What caused children to wish they had never been born? The biggest predictor was what was then called neuroticism —81% of highly neurotic children expressed the wish to never have been born, whereas only 7% of well-adjusted, non-neurotic children reported so wishing. Poverty and family trouble, such as being from a broken home and having a poor relationship with parents, was correlated somewhat with girls, but not boys, wishing they had never been born. Perhaps the most disturbing finding was that the wish to never have been born was spread fairly evenly among all children, urban and rural, white, black, and Mexican, rich and poor, from happy or broken homes. Girls were more likely to express the wish to never have been born than boys, even though men commit suicide more often than women. Based on this sample, it appears that the wish to never have been born is a poor predictor of suicide later in life. Since suicide and the wish to never have been born appear poorly correlated, they cannot both be strong evidence for the likely subjective value of life. Revealed Preference in Non-Suicidal Behavior There is another line of evidence that is important to take note of for preferentists: the revelation of preference (the subjective valuing of life) in people’s behaviors aside from suicide. I explore this line of evidence at length in the next chapter (“The Mathematics of Misery”), but will outline the evidence here. If life is subjectively very valuable to people, we would expect them at a minimum to behave as if this is so—for instance, to rarely engage in life-risking behavior unless there is a very strong reason to do so, and to minimize risk to life when it is easy to do so. We might also expect them to avoid actuarially unfair gambles and to display low time preference, making decisions that favor long-term security and well being. The behaviors we would most expect from individuals who do not value their lives would be risking their lives in dangerous situations, engaging in gambles whose expected value is negative (such as joining a street gang, buying lottery tickets, and going to law school), and palliating their misery in ways that harm their long-term prospects (as with drugs, alcohol, or casual sex). These behaviors are in fact widespread, affecting many times more people than suicide. A detailed portrait of the high time preference state of mind is provided by Richard T. Wright and Scott H. Decker in their criminology book Armed Robbers in Action: Stickups and Street Culture.116 They term this state of mind “desperate partying”: A majority of the offenders in our sample spent much of the money they obtained through armed robbery to pursue what was for them an open-ended quest for excitement and sensory stimulation. Forty of the fifty-nine offenders who told us what they did with the proceeds of their stickups said they used most of the cash to initiate or sustain various forms of illicit action, including gambling, drug use, and heavy drinking. While the offenders often referred to such activities as partying, there is a danger in accepting this definition of the situation uncritically; the activities were pursued with an intensity and grim determination that suggest something far more serious was at stake. For those in our sample, participation in illicit street action was no party, at least not in the conventional sense of the term. They appeared to find it anything but relaxing and showed little or no inclination to exercise the personal restraint that characterizes suburban cocktail parties. Rather, they gambled, used drugs, and drank alcohol heedless of any consequences. In the process, many of them began to contemplate their next stickup. …The offenders are easily seduced by street culture at least in part because they view their future prospects as bleak and see little point in long-range planning. The behavior of “desperate partying” is not only seen among poor people in the worst circumstances; it is widespread across many classes. The pursuit of drug-induced euphoria and intense experiences will be familiar to many people who have suffered long-term anxiety or depression. Palliating with drugs or intense experiences that have serious long-term risks and harms suggests that, subjectively, the present is so bad that it’s worth trading off quality of life in the future to make the present tolerable. Similarly, making a gamble with a low likelihood of success and a high likelihood of very bad consequences suggests that one’s present situation is not worth preserving by behaving cautiously. These behaviors, and not just suicide, are evidence that life is not a universally valued commodity. People are not, of course, perfectly rational beings. Behavioral economists argue that humans are at best partially rational, and generally exhibit major departures from rationality. Therefore their behavior may not reflect their genuine preferences. When a person exhibits high time preference, rather than placing a low value on his life, he may just be stupid. To the extent that this criticism is accepted as weighing against the evidentiary value of these “desperate partying” palliation behaviors and gambling behaviors, however, it must also weigh against accepting the suicide data as evidence of life’s value. To the extent that it means something that people rarely commit suicide, it must also mean something that they often act as if their lives are a burden to them. This latter argument will be elaborated in the next chapter. Non-Preferentist Approaches Non-preferentist approaches to the question of making people do not assume that people’s self reports or behavior reveals what is best for them. Rather, they attempt to answer the question from a broader perspective (while still treating subjective experience as real and crucially important). The most important non-preferentist approach to the question of making new people is David Benatar’s, presented in his 2006 book Better Never to Have Been. The core of this non-preferentist argument lies in what he terms “the asymmetry”—a difference in valuing good and bad experiences depending on whether the person experiencing them has been created, or not. Naive Weighing From a naive perspective, we might expect to weigh the harms of life against the benefits of life as we expect the yet-to-be-created person to experience them. If the benefits somehow outweigh the harms, then creating the life, from this perspective, is permissible. There are arguments— Benatar himself examines this line of thought—that the harms of life do outweigh the positive aspects, even when the “positive aspects” are conceived broadly and not just limited to a purely hedonic analysis. Loneliness and boredom, discomfort and pain, aging and death affect everyone who is born (unless, in the case of aging, they die in childhood). To make matters worse, there is evidence that bad experiences affect people more intensely than good experiences. In Baumeister et al.’s paper “Bad Is Stronger Than Good”117 the authors present evidence for the universal psychological principle that bad experiences produce a stronger psychological effect than good experiences. For instance, the authors revisit the 1978 study conducted by Brickman et al., “Lottery winners and accident victims: Is happiness relative?”118 In that study Brickman and co-authors interviewed people who had won the lottery and people who had been paralyzed in a serious accident (with either event having occurred about one year prior to the interview), as well as a control group. The lottery winners were no happier than the other two groups: The euphoria over the lottery win did not last, and the winners’ happiness levels quickly returned to what they had been before the lottery win. Ironically, perhaps, the only lasting effect of winning the lottery appeared to be the bad ones, such as a reduction in enjoyment of ordinary pleasures. The accident victims, on the other hand, had not returned to their previous level of happiness one year after the accident. On the contrary, they often thought about how much better life was before the accident. People do not appear to bounce back from bad experiences to nearly the degree to which they get over good experiences. “Loss aversion” is the economic term for this human psychological peculiarity (otherwise known as “adaptation level theory” or “prospect theory”)—people would much rather avoid loss than pursue gain. The possibility of losing a thousand dollars is not made up for by an equal possibility of gaining a thousand dollars. Because bad is stronger than good in human psychology, in order to make up for the bad experiences, good experiences must not merely outnumber, but vastly outnumber, bad experiences. Benatar’s Asymmetry Benatar’s asymmetry proposes that this naive weighing from the previous section is ethically inappropriate. This is because the good and bad experiences of possible future beings are not mirror images of each other (symmetrical), but are rather completely different. The popular mystic poet Khalil Gibran said, “Do not the spirits in the aether envy us our pains?” The answer the asymmetry gives to this whimsical line is a simple “no.” Pain, broadly conceived, is bad. Here we are not talking about the pain of eating spicy food or exercising to soreness, but rather the pain of loneliness, hopelessness, boredom, grief, illness, aging, and death. Suffering is terrible, no matter whom it is happening to. This is especially true of the large subset of suffering that leads not to growth or awakening, but only to misery. It is unfortunate that anyone suffers—people or animals. The prevention of suffering is simply good. On the other hand, people being happy (again, broadly construed) is good. It is good that people have good experiences and find ways to connect to one another and alleviate each other’s suffering. But what about those spirits in the aether—possible future people? Gibran’s spirits are having subjective experiences (envy). Actual possible people have no subjective experiences. If nothing good happens to them because they are never born, they are not missing anything. Giving possible future people good experiences is simply not as strong an ethical motivator as preventing future people from having bad experiences. A bad experience happening to anyone is bad; preventing bad experiences (even by preventing experiencers from existing) is good. But a good experience NOT happening to someone is only bad if the person already exists such that he can be deprived of the experience. Imagine for a moment that the asymmetry is false. Then providing possible people with good experiences is a strong ethical reason to create new people. If this is the case, we each have a strong moral duty to have as many children as possible, and to expand the human population to its maximum, so long as lives are barely worth living.119 Every sperm that does not fertilize an egg represents a tragedy. These moral intuitions implied by denying the asymmetry are alien (Derek Parfit’s “Repugnant Conclusion” is so named for a reason). If accepting the asymmetry seems alien, consider the implications of its opposite. Shiffrin’s Asymmetries To summarize the previous section, David Benatar argues that bringing someone into existence is always a harm, and grounds his argument in a particular asymmetry—the “goodness” of absent pain, versus the mere neutrality of absent pleasure where no one is thereby deprived. Seana Shiffrin, on the other hand, doesn’t argue that procreation is always a harm, but does refuse to characterize procreation as a “morally innocent endeavor.” She argues for a more equivocal view of bringing people into existence. While procreation is not necessarily always a harm, according to Shiffrin, it is often a harm, and procreators should bear moral responsibility for the harm they do.120 Shiffrin defends her view with a different asymmetry— that, while it is fine to harm someone in order to prevent a greater harm to him (even without his consent, such as in the case of rescue), it is not fine to harm a person without his consent merely to provide him a benefit. Her core example involves a wealthy recluse (“Wealthy”) whose only means of helping others is by dropping five-million-dollar cubes of gold from the air on a neighboring island. Many lucky islanders receive Wealthy’s presents with no complications, but one recipient (“Unlucky”) is hit with the cube and breaks his arm. While the Unlucky might, after the fact, be glad to have been hit with the gold cube, and consider the broken arm worth it, intuition suggests that dropping five million-dollar gold cubes on people is wrong: Unlucky admits that all-things-considered, he is better off for receiving the $5 million, despite the injury. In some way he is glad that this happened to him, although he is unsure whether he would have consented to being subjected to the risk of a broken arm (and worse fates) if he had been asked in advance; he regards his conjectured ex-ante hesitation as reasonable. Given the shock of the event and the severity of the pain and disability associated with the broken arm, he is not certain whether he would consent to undergo the same experience again. Shiffrin also points out a “related asymmetry,” proposed by Thomas Scanlon,121 between the harm that is morally correct to inflict on another, and the “harm” that a person may inflict on himself. In Shiffrin’s words (summarizing Scanlon), One may reasonably put much greater weight on a project from the first-person perspective than would reasonably be accorded to it from a third-party’s viewpoint. A person may reasonably value her religion’s mission over her health, but the state may reasonably direct its welfare efforts toward her nutrition needs rather than to funding her religious endeavors. This “related asymmetry” is concerned with both the problem of consent and, indirectly, with the kind of value that may be acted on for another person’s “own good.” A person may consent to “harm” for any reason whatever, agent-relative or otherwise; but in order to inflict harm on another without consent, we must either (a) have such a good model of the person’s values that we can infer hypothetical consent based on the person’s own values, or (b) act in furtherance of values that any possible person would share. The logic of these three asymmetries is further explored in a later chapter, “Hurting People and Doing Good.” Uncertainty Finally, even if we agree on the standard for measuring whether a life is good, the extreme uncertainty in predicting whether a given life will in fact be good counsels against reproduction. This is the approach taken by Jason Marsh in his 2014 paper “Quality of Life Assessments, Cognitive Reliability, and Procreative Responsibility.”122 While the author does not agree with Benatar that no life is good, he proposes that we should take very seriously the lack of certainty we have that a particular life will be good. This uncertainty includes not only predicting future events, but uncertainty as to whether we are, ourselves, reliable evaluators of our own quality of life. The sufferings that make lives seem not worth living are hard to predict; some of them may be hiding in our genomes; others are events yet to occur. Even if we performed our ideal Imaginary Survey and almost every respondent replied that he was glad to be alive, there remains uncertainty as to how much we can trust that these embodied selfreports are accurate reflections of reality. The principle of caution, respecting the gravity of human suffering, weighs against procreating to the extent that it is unpredictable whether the person created will have a good life.",
      "chapter_number": 17,
      "section_number": null,
      "word_count": 3883,
      "file_path": "index_split_017.html",
      "spine_order": 18
    },
    {
      "title": "Chapter Ten: The Mathematics of Misery",
      "content": "Chapter Ten: The Mathematics of Misery Is life a precious gift, or is it a costly burden? Are we impossibly lucky to be alive—or impossibly unlucky? In the previous chapter, I noted that preferentist theories of procreative responsibility would seek to determine what people’s behavior reveals about how much they value their lives. This chapter examines an approach to measuring nonsuicidal behaviors that indicate a negative assessment of the value of one’s own life. Truncated Utility Functions and the Value of Life “Utility” is an economic concept similar to happiness, but broader. It is the ultimate emotional evaluation of whether things are good or bad. The concept of utility does not rest on a purely hedonistic model of life; economics recognizes that utility may be gotten from a variety of transactions and experiences, springing from motives self-interested, altruistic, and everything in between. Generally speaking, utility is a function of “income”— again, very broadly defined. Income in this sense need not be monetary income in dollars, as from a job or investments, but may include items that are not even available directly on any market, such as affection from other humans and self-respect. I will address below the question of what real human utility functions are actually a function of. (I reserve the right to switch willy-nilly and with no warning between speaking of utility functions that are functions of monetary income and those that are functions of other things, depending upon context to clarify which I mean.) As Gary Becker and Richard Posner note in their important (but unpublished) 2004 paper, “Suicide: An Economic Approach,”123 economists studying how utility responds to changes in income have primarily focused on middle-class individuals—people who own houses, earn money from investments, and buy fire, health, and automobile insurance. This has led to the conclusions of economics occasionally not being true observations of general human nature, as they often purport to be, but rather observations of middleclass human nature. One of these suspect observations is that utility functions are concave. This is a typical representation of a concave utility function: What this means is that a person gains a lot of utility from the first dollar he gets—even the first thousand or ten thousand dollars—but he doesn’t get nearly as much utility from the 40,000th dollar, and gets even less from the millionth dollar. (Modern American utility functions of income apparently top out at around $75,000 per year.) What this, in turn, means is that, dollar for dollar, gains are less valuable to the average suburbanite than losses are painful. He would rather pay $1000 a year in car insurance, say, than take a one-in-ten chance at a $10,000 loss during that year. This phenomenon—that makes the insurance industry viable and makes utility functions concave—is called risk aversion. Many people behave in ways that are not consistent with risk aversion. They make “bad” bets—bets where the expected payoff (probability of success times magnitude of win) is less than the cost of the bet. They take risks seemingly without regard for possible bad consequences. They appear focused on the present and immediate future, at the expense of the far future (they are “extreme future discounters”). Miserable people and poor people are particularly likely to fit these criteria. Negative Utility and the Death Wish Economy In a paper entitled “Behavioral Economics and Perverse Effects of the Welfare State,”124 Bryan Caplan and Scott Beaulier present a possible solution: irrationality and akrasia. The bad choices made by poor people are a result of their inability to forecast the future effects of their actions, combined with laziness. Welfare and other social programs, rather than making the poor better off, paradoxically make them worse off, say Caplan and Beaulier, because their irrational, akratic minds cannot handle the extra choices.125 Becker and Posner offer a different solution: miserable and poor people don’t “properly” consider the future because their lives are so painful that they are effectively suicidal. Poor people look around and rationally weigh the costs and benefits of different courses of action, but choose to gamble on long shots precisely because their current situations are not worth living in. They would just as soon die as remain in their current situations, so they gamble what little they have on the hope of a meaningful life. Don’t just think gangs and lotteries and crime and crack. Think about people pursuing acting or singing careers, or going to law school or business school, or marrying in haste, or even, perhaps, having children. Think of people who bet everything—including their futures—on winning a particular gamble, even if it’s not a fair gamble and the likelihood of payoff doesn’t make up for the losses necessarily incurred when the chips are down. The utility function pictured above has a lot of space beneath it and above the x axis, even at the origin. This reflects a judgment that even at zero income, a person takes great value from being alive. This may or may not fit the facts. The actual points at which actual human utility functions intersect the x axis may be far to the right of the y axis, as with this utility function for a person who only begins to get positive utility at income Id. For all incomes below Id, the person experiences negative utility—that is, he suffers. This utility function is a model illustrating the phenomenon that many people (myself included) do not seem to derive much utility at all from incomes (broadly conceived) much greater than zero. Many people are so miserable that they do not want to enter the future at all. Their whole future projected life is worthless to them. In technical terms, their utility over all future time intervals, appropriately discounted, is less than zero. Also, their current utility (present circumstance) is zero or negative (otherwise they’d stick around a bit longer to pick up extra utility). Suicide is one option for such people. But there are two other options, according to Becker & Posner (terminology is mine): Take what you have and “bet” it on a chance at something that would make life worth living. If it fails, you can always kill yourself. (Gamble) Since there is an element of uncertainty to the future, take what you have and use it to make the present livable so you can postpone suicide. Something to make life worth living might be just around the corner. If not, you can always kill yourself. (Palliate & Wait) The utility function above for inefficient utility producers (like myself), where the utility function dips below the x axis, means that the person modeled must fear losing income below this point, because having income below Id means he will suffer. But a would-be suicide need not suffer. He has an ace up his sleeve: all suffering is the same as death to him, for he can use death to escape any suffering. His utility function is effectively truncated. It looks like this: Instead of dipping below the x axis, his utility function continues along the x axis all the way to the y axis (and beyond, if you allow for negative income). Now there is a portion of the utility function that is convex—the signature of risk preference, the opposite of risk aversion described above. Any income below the critical level Id is worth nothing to the effectively suicidal person. This means that it will not make sense for him to expend any effort in securing income below this level. Like a depressed person who has lost the sense of the value of things, he is not motivated to get up in the morning, to work hard, to be responsible, if all it means is income below Id. It’s the same as death to him. How can we tell who is effectively suicidal? Nonsuicidal people still often rationally accept gambles, even gambles with a risk of death. The main way to tell the difference between effectively suicidal people (with a truncated utility function, as above) and nonsuicidal people is that suicidal people are insensitive to the potential for great losses, and are only motivated by the possibility of a big win; effectively suicidal people accept actuarially unfair gambles which do not properly compensate them for risk of loss (including risk of death). Nonsuicidal people demand to be compensated for risks of loss, including risk of death. To the extent that people display risk preference and extreme future discounting of losses but not large gains—to the extent that they are willing to accept unfair gambles with a high probability of loss (Gamble) or improve their short term well-being at potentially great cost to their future selves (Palliate & Wait)—the hypothesis of effective suicidality must be considered. Only by considering and rejecting this hypothesis, based on data and/or reasons, could we meaningfully attribute these features to departures from the rational actor model, as Beaulier and Caplan do prematurely. Beaulier and Caplan essentially argue against “welfare floors” because by cushioning the bad consequences of a gamble, they make antisocial gambles more attractive. But they ignore that there is a built-in welfare floor in any human society, welfare state or not: suicide. It is inconsistent to maintain that, on the one hand, a welfare floor is undesirable because negative utilities are necessary as motivators for action, and on the other hand, that utility is rarely negative and hence procreation is morally innocent. This model does not, however, predict mass suicides at any point, and the fact that suicide remains rare does not mean that many people do not have effectively suicidal, truncated utility functions. All this theory claims is that people act as if they don’t value their lives. Unsuccessful gambles may or may not be followed up with actual suicide; the costs of suicide are often greater than a pre-suicidal person realized when contemplating life paths, and are artificially elevated by the de facto suicide prohibition. Also, cheap palliation is widely available, allowing many would-be suicides (such as myself) to postpone this costly decision. Policy Implications The most important policy implication of the “mathematics of misery” I have outlined here—of the fact that many people appear to attach zero value to their lives—is that procreation becomes much more of a suspect enterprise. If people’s behavior reveals that they do not highly value their lives, then it is not “obvious,” as Bryan Caplan would have us believe, that human beings are benefitted by being brought into existence. A life that produces zero utility in the immediate present, and zero or negative utility for the foreseeable future, is hardly the kind of precious gift that would justify procreation, yet from this model it is likely that a substantial portion of the population of the world lives just this kind of life. Someone whose utility function is negative for all time intervals would have been better off not having been born. Many people are in this situation through no fault of their own. Once this much is understood, a second policy implication is a move toward greater compassion in providing “palliative care” to people whose present utility and expected future utility are negative and whose only incentive to remain alive is uncertainty. As a society, we are willing to allow “palliative care” for terminally ill persons, but our middle-class model of risk aversion and the value of life prevents us from recognizing the need for palliative care in “healthy” people as well. There are further implications for harm reduction, regardless of one’s position about the value of life. Viewing utility functions (and hence human motivation) in this light, we can see that a suffering person chooses from available gambles and palliation methods. Outlawing a particular type of gamble or palliation method will likely divert demand to other types of gambles or palliation, and hence will not reduce overall levels of harm unless substitution happens to be toward less harmful activities. Recognition of this “demand for risk” should guide policy decisions regarding dangerous activities. What Real Human Utility Functions Are Functions Of The utility function appears to be a function of income in the strict sense that, within a country, wealthier people tend to be less miserable. But it is also a function of one’s past incomes; receiving a higher income increases utility in the short run, but in the long run it sets a new baseline for utility (the “hedonic treadmill”). Utility is also a function of the incomes of near others, or of one’s within-group status. This is why more direct income-utility correlation is found within-country than between countries. More than anything, however, a human utility function is a function of social belonging. That’s the ultimate point not only of income, but of intelligence, beauty, and many other material and non-material goods: they may be traded for social belonging. The ability to provide others with what they want is the opposite of burdensomeness, a pillar factor of suicide risk in Thomas Joiner’s model (the other pillars are social belonging as such, and competence in carrying out the act of suicide). We want income because we want to be able to get the attention of others. We want a safe social place, primarily—and, of course, we want a better social place than the one we currently occupy. The primary good, for humans, is group belonging. There is only so far up or down you can go in a social group, only so much room for status manipulation before you have to find a whole new social group. Within a group or class, we like to go up, but we absolutely hate to go down. Each person sees a huge drop-off in utility when considering the loss of his present group belonging, no matter whether his present group is high or low in status relative to the greater society. This has very little to do with absolute material welfare. This is why the guy choosing television and phones over food is making the right choice.126 Group belonging really is more important than short-term well-being. He is even displaying risk aversion, as is the poor black parent who gives her child a name that strongly signals group belonging at the expense of belonging in other groups or classes. It’s extremely difficult to join a whole new social group. Everyone faces a utility drop-off, a chasm, at the prospect of losing social belonging—a process sometimes described as social death. People behave as if losing one’s social group and status is worse than death. This is strong evidence that social death really is worse than death. Poor Baby or Rich Baby: Which is Worse? Data about crime, drug use, and other forms of risk preference and palliation seem to indicate that poor people are more likely than rich people to display the kind of truncated, effectively suicidal utility function I have been discussing. This could support the claim that it is more wrong for a poor person to have a child than for a rich person. But when we realize that social belonging trumps everything, we see that what really determines the value of life is the opportunity to be part of a social group. Middle class people have different relevant social groups from poor people, and the very wealthy have different social groups altogether. A child born into one of these groups must establish a place for himself; if few places are available, downward mobility (social death) is indicated. A person born into a very wealthy social group that has few opportunities for belonging may thus be in a worse position than a person born into poverty but with many opportunities for belonging. As Becker and Posner note, the nature of the “Gamble” you can afford depends on your present income; higher present incomes buy better gambles, with a higher probability of success. Therefore, wealthier people may succeed in their suicide gambles more often than poor people, so their gambles are more socially invisible than those of the poor— but they are still making them. However, the social belonging hypothesis that I have been advancing here (that social belonging is the primary determinant of utility) implies that the income at which life becomes worth living, Id, varies with one’s existing social situation, hence with initial income. Wealthy effectively-suicidal people start out with more initial income—they have more to gamble with—but they have a higher mark to reach for their gambles to be successful. It is not clear which effect predominates. The Economics of Palliation and Bullshit This model outlined above applies not only to serious gambles with significant downsides as well as significant, potentially permanent upsides (suicide gambles, like joining a street gang or going to law school), but also applies on a smaller scale to measures that temporarily reduce the pain experienced by the actor, though with potential future costs (palliation, like smoking cigarettes or playing World of Warcraft). Palliative remedies may have significant present and future costs, but at least they are generally effective at alleviating pain temporarily. However, looking around at the transactions taking place in the world economy, one cannot help but notice the market share of bullshit. Huge numbers of consumers prove willing to spend money on products and services that measurably don’t do what they promise to do. These products and services may or may not be particularly harmful, but they all have monetary cost, and they all have a very low likelihood of solving the problem they purport to solve. The market in expensive placebos is massive. Here are exemplary lists of both Palliation phenomena and Expensive Placebo phenomena, so that the reader will have a better idea of what I’m talking about: Palliation Expensive Placebo Budweiser Cheleda weight loss potion heroin face de-wrinkling potion World of Warcraft breast augmentation potion cigarettes penis growth and erection potion The McRib multi-level marketing wealth potion 7th Heaven psychic services lactation porn Jesus video poker nice Russian women looking for a good husband who need your credit card number In both cases, consumers seem blind to the downside. In the Palliation case there is a significant downside, but it’s made up for by the reliable temporary relief from pain. In the Expensive Placebo case, the downside is limited to the cost of the product or service, but the upside is measurably nil. The line between Palliation and Expensive Placebo may be fuzzy; for instance, a lonely person may get real social pleasure from interacting with a psychic consultant (and effective scammers, like all salesmen, tend to be pleasant people). An alcohol advertisement often includes implicit promises of social belonging, which if interpreted literally would make it more of an Expensive Placebo Belonging Serum than a genuine palliation tool. But the distinguishing characteristic is that in the case of what I call Expensive Placebos, the benefit that is bargained for is wholly imaginary, whereas with Palliation the essence of the promised benefit is, in fact, provided. Since the value of Expensive Placebos arises from pure fiction, ordinary measures of quality are not available; if acknowledged and utilized, real measures of quality would destroy the entire market. From this, we can distinguish Expensive Placebos from Palliation in terms of the effect of price. The price of an Expensive Placebo is a measure of social proof it carries—a more expensive placebo gets you better fantasies. A two-dollar penis enlargement pill probably doesn’t work, but one that costs $2,000 is a much more effective fantasy projection device. Price has to take on more epistemic weight in the evaluation of Expensive Placebos, because no other indicia of reliability are relevant. This is so because every indication of reliability, except price, would show the value to be zero. In order to maintain the fantasy, we must look at price instead of real quality indicators. To the degree that an intervention is Palliation, consumers would seek out the most palliation for the cost—these are ordinary goods where price is negatively correlated with demand. But to the degree that an intervention is an Expensive Placebo, price should behave much more weirdly, perhaps even correlating positively with demand, as with Veblen goods. It’s not just that the consumer of an Expensive Placebo makes himself blind to the downside of the purchase; the downside becomes the upside. (Here we may recall the similar phenomenon in which parents report getting more meaning and joy from child-rearing activities—and plan to spend more time with their children over a coming weekend—when they are reminded of the downside, but not the upside, of having kids.) There are some things that people will pay for even an imaginary chance at having. Youth, love, sex, wealth, and status are so deeply and painfully desired that people are willing to suspend their disbelief for the privilege of imagining that they might be obtainable. The need for social belonging trumps all other needs, and even trumps our own rationality. Being old, fat, poor, or impotent means being in social pain. Just as the desperate, terminally ill cancer patient often turns to expensive placebos for an imaginary chance at more life, desperate, terminally alive sad people turn to expensive placebos for a chance to imagine a decent life.",
      "chapter_number": 18,
      "section_number": null,
      "word_count": 3521,
      "file_path": "index_split_018.html",
      "spine_order": 19
    },
    {
      "title": "Chapter Eleven: The Burden of Life",
      "content": "Chapter Eleven: The Burden of Life That being born is a good thing is treated as axiomatic by the majority of thinkers who consider the issue. The philosopher Thomas Nagel, for instance, states that “All of us, I believe, are fortunate to have been born,” even while affirming that not having been born is no misfortune.127 Bryan Caplan, even as he disdains to address substantive antinatalist objections to his devoutly pronatalist views, is fond of emphasizing the “obviousness” of his belief that being born is an unequivocal good for the person who is brought into being. In defending in vitro fertilization, for example, Caplan writes, “How can I neglect the welfare of the children created by artificial means? I’m not ‘neglecting’ children’s welfare. I just find it painfully obvious that being alive is good for them.”128 There are two elements to this kind of thinking. First, it represents a judgment that life is, on the whole, worth getting and having; but second, all the talk of “obviousness” also implies that there is something wrong with even asking the question. I want to address how quantitative methods, rather than intuition and assumption, might be used to measure the downside of existence. There is, I want to argue, a need to analyze quantitatively the obligations that we are all born with, if only to arrive at a better understanding of the inherent and uninvited pain of life. From this vantage, I want to deny the “obvious” by posing a simple question: if our lives are to be worth having on the whole, mustn’t such pain, at a minimum, be made up for with valuable experiences? Work and Leisure We might characterize the central unpleasant obligation in our lives as the obligation to “work” (broadly construed) in order to meet the salient and potentially misery-inducing needs we are born with or naturally develop. These needs include not only food, clothing, shelter, and medical care, but also status, love, sex, attention, and company.129 We can even quantify these needs by quantifying work done to satisfy them, for which we have a great deal of data. Some of these needs, of course, may actually be satisfied by working—the need to belong, to feel valuable, to not be a burden. At the same time, however, some of these needs are actually increased by working—that is, work may create disutility as well as utility. How can you tell the difference between what people do to merely to ease the pain and discomfort of existence, and what people actually want to be doing? Many economists have addressed the question of the difference between work and leisure, and how we may quantify and measure them. One crude-but-tempting measure of the value of leisure time is merely a person’s wage. But as economists Douglas Larson and Sabina Shaikh have explained,130 this is much too crude to get at the true nature of work and leisure: Assuming the average wage is the appropriate opportunity cost of time presumes that the individual faces no constraints on hours worked, derives no utility or disutility from work, and has a linear wage function…This is unlikely to be true for many people…an individual’s average wage does not necessarily reveal anything about the shadow value of discretionary leisure time, either as an upper or lower bound. The question of the value of leisure time is intimately related to the question of quantifying the unpleasant obligations placed on us by virtue of existence, so that we may have a starting point for a meaningful comparison of life’s costs and life’s benefits. How do we characterize “work”? What is the difference between “work” and “leisure”? Intuitively, we know the difference—or at least, there exist clear cases of “work” and clear cases of “leisure.” Operating a cash register is work. Washing dishes is work. Doing bong rips is leisure. Reading novels is leisure. Watching television and having sex are generally leisure (unless you’re in advertising or a prostitute). For most people, child care and lawn care qualify as work—whether paid or unpaid—but for some people, these same activities may qualify as leisure some of the time. These examples suggest that leisure is that which is done for the sake of the experience itself, whereas work is done with some goal in mind other than the experience itself, and is done only in service of that goal. Running ten miles is leisure for me, because I do it for the pleasure of the experience; running those same ten miles might be work for someone else, because he does it to lose weight, not for the pleasure of running. A third person might run for both reasons, in which case the action has aspects of both leisure and work. We should not necessarily expect that every action and every hour can be neatly categorized as “work” or “leisure,” even for a particular individual. This should give us pause when considering the appraisal of “leisure” preferred by Mark Aguiar and Erik Hurst in their 2007 paper “Measuring Trends in Leisure: The Allocation of Time Over Five Decades.”131 Aguiar and Hurst rely on an hour-by-hour tally of time not spent in market or nonmarket work (e.g., at work, or doing unpaid work around the house or around town), but in reality a single hour may have substantial aspects of both work and leisure. Aguiar and Hurst also remark on a potentially definitional characteristic of leisure: the degree to which market inputs (e.g., money, technology, etc.) are consumed to reduce the amount of time spent in the activity. They say: …one definition of whether an activity is “leisure” may be the degree of substitutability between the market input and the time input in the production of the commodity. That is, the leisure content of an activity is a function of technology rather than preferences. In the examples above, one can use the market to reduce time spent cooking (by getting a microwave or ordering takeout food) but cannot use the market to reduce the time input into watching television (although innovations like VCRs and Tivo allow some substitution). Let me give a definition of my own, to fit my question: Work is any action (or omission, perhaps) that we undertake in order to prevent or remedy some unpleasant state, and that we would not undertake if the unpleasant potential state were not a factor. An activity has a strong work component if technology is demanded by individuals to reduce the amount of time they spend in the activity. In other words, work is what you do only because you have to eat, and you spend as little time doing it as is possible to satisfy your (present and projected future) needs. Many studies since the 1980s have found that physicians’ demand for leisure directly affects the prevalence of cesarean sections.132 Cesarean sections are highly correlated to time variables associated with doctors wanting to get the hell out of there, although (further strengthening the theory) this correlation is dependent on the type of insurance covering the patient. Instead of relying on the Imaginary Survey justification to “prove” that coming into existence is a good thing, economists and ethicists could use more creative, quantitative methods to examine the question of how bad (and how good) life is. Specifically, we need to figure out how to tell the difference between suffering people attempting to remedy their shitty situation, and happy people chilling out —both of which may describe any of us at different times in our life, or even our day. “Are you glad you were born?” is unsubtle, an all-or-nothing approach that relies heavily on people knowing the answer to questions they may have only limited capacity to understand. Analyzing behavior in smaller chunks would give us a better idea of just how happy people are to be here. Poverty and Pain Behavioral economics is a strong tool for understanding ourselves and each other. However, many behavioral economists, consciously or unconsciously, rely heavily on the Imaginary Survey justification, and no economist, to my knowledge, has attempted to use behavioral economics methods to figure out how bad, or how good, life is to individuals. Let’s return to Bryan Caplan’s “Behavioral Economics and Perverse Effects of the Welfare State.” It’s a fascinating and even audacious paper. Caplan argues that giving the poor more life choices through charitable assistance seems to actually harm them because they are irrational and fail to choose the best option for themselves. From his abstract: Critics often argue that government poverty programs perversely make the poor worse off by encouraging unemployment, out-of-wedlock births, and other “social pathologies.” However, basic microeconomic theory tells us that you cannot make an agent worse off by expanding his choice set. The current paper argues that familiar findings in behavioral economics can be used to resolve this paradox. Insofar as the standard rational actor model is wrong, additional choices can make agents worse off. More importantly, existing empirical evidence suggests that the poor deviate from the rational actor model to an unusually large degree. The paper then considers the policy implications of our alternative perspective. The option Caplan fails to consider is this: the lives of the poor are unacceptably bad without charitable aid. We don’t think it irrational, exactly, when a person in extreme pain does something to relieve his pain that may have negative future consequences. A shrieking, sweating patient in horrible pain might be perfectly aware of the potential for developing a long-term addiction to opiates, but we do not consider his decision to take opiate medication to be irrational. His pain is so bad that we think it makes sense for him to use any means to stop it, even if such means harm his future interests. Connecting to my discussion of work vs. leisure, I think it a valid hypothesis that poverty is actually dreadfully painful —not only physically, but emotionally and socially. There is only so much pain we can expect a being to endure before his attempts to relieve it through future-damaging means become perfectly understandable and, in fact, rational. The Demand for Pain Relief An economic theory of rationality, to be in touch with human ethical reality, must include an account of pain. We must attempt to define and study pain (in the broad sense) in a behavioral economics context, rather than to define it away, as Caplan attempts to do. The economist Karl Smith notes133 that studies consistently show that consumers do not seem to take into account mortality data when choosing between health care providers, even when very good mortality data is widely available in a user-friendly format. Perhaps the demand for life is not as high as we might think. People seem willing to spend money on health care, but not to care about outcome. One approach suggested by this finding would be to study the revealed preferences of consumers’ willingness to pay for death risk reduction and broadly defined pain relief respectively, in different contexts and populations. Is Loss Aversion Irrational? Recent laboratory research134 demonstrates that tufted capuchin monkeys exhibit what behavioral economists consider to be a typical human departure from rationality— “loss aversion.” That is, monkeys trained to use metal discs as money preferred to buy fruit from a graduate student who would give them a smaller food reward but sometimes add a few grapes, rather than from a graduate student who would give them a larger food reward but then maybe remove a few grapes. The monkeys weren’t maximizing the number of grapes they got; they specifically exhibited a preference to have things added, rather than have things taken away. I don’t think this necessarily illustrates irrationality in the capuchins; it illustrates that they are utility maximizers, not grape maximizers. Monkeys experience a loss of utility from losing grapes that is greater than the utility produced by those grapes. Losing grapes, we might say, is painful. Doing the resource-maximizing thing does not necessarily equate with doing the utility-maximizing thing. A Place for Quantitative Methods Caplan’s conclusion is that we must not treat the poor as rational actors, because they deviate so heavily (compared to the wealthy) from being long-term best-interest maximizers. Therefore, he says, we should not expect to solve their problems by giving them money or other charitable aid. An equally supported conclusion would be that being poor is so awful it is unendurable, like severe physical pain. Taking this into account, the seemingly poor choices of poor people are actually quite rational, serving an overriding and immediate need to alleviate pain. Caplan also gives us a hint at what might be an indicator of painfulness: the degree to which the actor deviates from resource maximization. He says, The behavioral literature has documented that the average person frequently violates neoclassical assumptions. But it rarely investigates variation in the tendency to violate neoclassical assumptions. Casual empiricism and limited formal evidence suggest that the poor do deviate more. A great deal more could be learned at low cost if new behavioral studies collected information on participants’ income and education to test for heterogeneity. Analyzing many factors—not just income, but also education, and intelligence—for correlation to deviation from resource-maximization rationality could help us understand the circumstances under which life is so painful that we act “irrationally.”",
      "chapter_number": 19,
      "section_number": null,
      "word_count": 2209,
      "file_path": "index_split_019.html",
      "spine_order": 20
    },
    {
      "title": "Chapter Twelve: Hurting People and Doing Good",
      "content": "Chapter Twelve: Hurting People and Doing Good A 2008 report from the United Kingdom’s Home Office Advisory Council on the Misuse of Drugs concluded that ecstasy (at least, MDMA) is not nearly as dangerous as was previously thought, either in terms of lethality or long-term health consequences. The Council even recommended changing the classification of MDMA from its present status as Class A substance (heroin, crack, and amphetamines prepared for injection are Class A) to the less-dangerous Class B (which includes marijuana and Ritalin). The recommendation was, of course, rejected. A February 2009 editorial in New Scientist135 took the logic a step further: Imagine you are seated at a table with two bowls in front of you. One contains peanuts, the other tablets of the illegal recreational drug MDMA (ecstasy). A stranger joins you, and you have to decide whether to give them a peanut or a pill. Which is safest? You should give them ecstasy, of course. A much larger percentage of people suffer a fatal acute reaction to peanuts than to MDMA. The implication is that, when acting upon a stranger, we should minimize his risk of death. (We might also consider our own willingness to endure, on the one hand, a stranger’s slight peanut breath, and on the other, a stranger clinging to our leg like a baby macaque for three hours, but that is a separate calculus.) The blogger Caledonian136 has a slightly different take: we should focus on the relative likelihood of harm, he says, rather than the relative likelihood of death. Both of these goals—acting to minimize the risk of death to a stranger, and acting to minimize his risk of harm—are laudable and widely shared. But there’s a glaring aspect of the utilitarian calculus that almost no one seriously considers in making the decision to administer a peanut or a dose of ecstasy. This is the differential positive utility to be gained by the stranger in each case. A peanut is marginally sustaining, but unless it’s been boiled with star anise and Sichuan peppercorns, it’s not particularly enjoyable. Ecstasy, on the other hand, is fucking awesome. Why doesn’t anybody consider the relative benefit to the stranger along with the relative harm? While many of us would certainly consider the pleasure of ecstasy in deciding whether to eat the pill or the peanut ourselves, it’s proper and coherent not to consider the pleasurable effects of a potentially harmful action when it will be inflicted upon a non-consenting stranger whose values we do not know. This illustrates Seana Shiffrin’s principal that, while it’s morally acceptable to harm a stranger without his consent in order to prevent worse harm (e.g., to administer ecstasy in order to avoid administering a peanut or to break someone’s arm in order to pull him from a burning car), it’s not morally acceptable to harm a stranger without his consent in order to provide a pure benefit. But the ecstasy example supports a stronger inference: when evaluating actions that will harm a non-consenting stranger, his potential pleasure doesn’t count. When we’re acting toward someone whose values we do not know, we should not think in terms of maximizing his utility, but in terms of minimizing our harm to him. The distinction between acting toward a non-consenting stranger whose values we do not know, and acting toward ourselves (or toward someone whose values we know), is one that is ignored by S.D. Baum in his article “Better to exist: a reply to Benatar.”137 Baum’s “reply” (to David Benatar’s position that it is always better not to bring people into existence) is, in relevant part, as follows: The benefits/harms asymmetry is commonly manifested (including in Benatar’s writing) in the claim that no amount of benefit, however large, can make up for any amount of harm, however small. This claim comes from an intuition that while we have a duty to reduce harm, we have no duty to increase benefit. The corresponding ethical framework is often called “negative utilitarianism.” Negative utilitarianism resembles maximin in its resolute focus on the worst off—as long as some of those worst off are in a state of harm, instead of just in a state of low benefit. Like maximin, negative utilitarianism can recommend that no one be brought into existence—and that all existing people be euthanised. I find negative utilitarianism decidedly unreasonable: our willingness to accept some harm in order to enjoy the benefits of another day seems praiseworthy, not mistaken. I thus urge the rejection of this manifestation of the benefits/harms asymmetry. Our own willingness to accept suffering in the interest of pleasure (or any other value) is no reason to think that it is right to inflict that same suffering on a non-consenting stranger. Negative utilitarianism may not be the proper course to take in our own lives, but thought experiments like this one suggest that negative utilitarianism is the proper course to take toward the lives of others who do not consent to our interference. Baum also assumes, contrary to Benatar’s express position, that death is not a harm to already-existing people. In fact, Benatar’s claims do not rest on any simplistic pleasure/pain conception of value; Benatar argues that death is a harm, even a painless death. It is, in fact, one of the great harms of life—every person born will suffer the harm of death. Most people think it’s morally acceptable to have babies. Most people think this despite the fact that the babies will certainly suffer a great deal during their lifetimes and may suffer an exceptional amount. Pronatalists generally want to point out the good things in life—the pleasant effects of puppies and sunsets—and to balance them against life’s harms. But bringing a child into the world necessarily entails harming a stranger (for one doesn’t know the values of one’s child prior to procreation).138 It is no different from dosing a stranger with ecstasy for no reason, except that the harms of life massively exceed the harms of ecstasy, and the pleasure of life, for many, is much less. Considering the non-consenting stranger’s pleasure in the ecstasy/peanut case is unthinkable; procreation advocates need to explain why considering his pleasure in coming into existence is just fine.139",
      "chapter_number": 20,
      "section_number": null,
      "word_count": 1034,
      "file_path": "index_split_020.html",
      "spine_order": 21
    },
    {
      "title": "Chapter Thirteen: The World of Nature of Which We Are a Part",
      "content": "Chapter Thirteen: The World of Nature of Which We Are a Part The extent of the suffering of wild animals is literally unimaginable.140 We have a function in our minds for imagining suffering—remembering a dog bite, perhaps, or another nasty injury. And we have an abstract multiplication function in our minds as well. But this doesn’t get us even close to understanding the amount of suffering that occurs in nature in a single minute. What would it feel like to land on the surface of the sun? Answer: not like anything. You can’t even approach the surface of the sun; even millions of miles out, shielded by a spacecraft, a human body would disintegrate. We are physically incapable of perceiving how bad the surface of the sun would feel. Thus it is with the amount of suffering in the natural world (and, incidentally, its subset, the human world). 1. On The Ways In Which Nature Makes Andrea Yates Look Like June Cleaver Eurasian coots, a species of migratory water bird, may hatch up to nine chicks. But under normal circumstances, food is in short supply. The parent birds feed the baby birds tiny shrimp for the first three days after hatching. Then, mama coot turns into Mommy Dearest. A baby bird begs for food, as usual—but, with no warning, the parents “punish” it, biting the chick hard on its tiny head. The parents do this to all the chicks in turn. Eventually, one chick is singled out for special torture, and abused until it stops begging for food and starves to death. This process is repeated until only two or three chicks survive. Pelicans hatch three chicks, but under normal circumstances, only one survives. Instead of the parent birds doling out death, it’s the siblings—the two larger birds pluck at the smallest with their sharp beaks and knock it out of the nest. Then the conspirators turn on each other until only one chick is left. Sir David Attenborough141 himself acknowledges that this might be a bit cruel, by human standards. But, he assures us, it’s all for the best—in especially good years, a pelican or coot can raise an extra chick or two. So torturing baby birds to death serves the purpose of increasing the genetic fitness of the parents by a little bit. Does that really make it okay? 2. The Incoherence of Species-Relative Morality We are taught as children not to apply human standards of morality to animal behavior. We do not expect macaques to be egalitarian, nor male lions to refrain from killing cubs sired by other males. We should not, this theory goes, expect animals to raise the babies they produce to adulthood; we should not be dismayed if they, in fact, torture their young to death when it is advantageous for them to do so. Most people of our era have a strong, visceral inclination against cruelty to animals, just as we do against cruelty to human children. We judge animal suffering to be bad. Watching a nature documentary, we hope the impala can evade the lion, yet we also hope the lion cubs get fed somehow. But watch what your mind does when considering these two contradictory hopes. Does it come to a coherent resolution of the problem? Or does it just shrug its shoulders and spackle the problem over with some bullshit about the circle of life? Life must go on . . . end of thought. Is it okay that the impala gets eaten? That the cub dies? What about an old lion slowly dying in the hot sun? How about that little chick pictured above, getting abused and starved to death by its parents? Genesis 1:21 (KJV) says: And God created great whales, and every living creature that moveth, which the waters brought forth abundantly, after their kind, and every winged fowl after his kind: and God saw that it was good.” According the Judeo-Christian God, torturing baby coots to death is not just okay, but good. “God” gave us that whopper to swallow; can you swallow it? Human morality, some may argue, applies only to human actions—not to the actions of animals. I agree with this. For the most part, animals are not agents, but merely robots— machines executing programs created by natural selection. However, morality must certainly apply to human inaction, and especially our inaction in preventing harm, suffering, and awfulness. What is the moral justification for the “hands off ” dogma regarding nature? We often interfere with nature for the good of humans and human industry. Why not for the good of individual animals? Bloody Nature is a machine for pushing genes into the future. Does it really “know best”? 3. Respect for Species? Nature exists. We try to “conserve” ecosystems in their “natural” state (scare quotes because ecosystems evolve and change over time in response to environmental pressures, including those from other species). But who is this good for? Is it good for the animals themselves? Thomas Nagel considers the difficulty of this question in his essay “Birth, Death, and the Meaning of Life,” in his important book The View from Nowhere (from which my blog, which many of you are familiar with, took its title).142 While teaching at Princeton in the 70s, Professor Nagel noticed a sad little spider living in a urinal in the men’s bathroom. The spider appeared to Professor Nagel to have a crappy life, constantly getting peed on; “he didn’t seem to like it,” notes Nagel: Gradually our encounters began to oppress me. Of course it might be his natural habitat, but because he was trapped by the smooth porcelain overhang, there was no way for him to get out even if he wanted to, and no way to tell whether he wanted to…So one day toward the end of the term I took a paper towel from the wall dispenser and extended it to him. His legs grasped the end of the towel and I lifted him out and deposited him on the tile floor. He just sat there, not moving a muscle. I nudged him slightly with the towel, but nothing happened…I left, but when I came back two hours later he hadn’t moved. The next day I found him in the same place, his legs shriveled in that way characteristic of dead spiders. His corpse stayed there for a week, until they finally swept the floor. Professor Nagel acted with empathy toward the spider— treating the spider how he imagined the spider would want to be treated. But did he do the spider any good? Would non-interference by Professor Nagel have done the spider any good? The spider might have lived longer, scrambling away from piss streams a hundred times a day, and may have eventually made more spiders. Would that be a good thing? What do spiders want? Is there such a thing as a meaningful life for a spider? Does a spider’s life do the spider any good? There is a popular idea, born, I think, from applying the principles of liberalism where they do not belong—the idea that non-interference indicates respect for a species or animal, as if it were a person. (Where interference is allowed, it is to remedy some previous human interference.) This is also (idiotically) applied to human cultural systems, not just biological systems; in the human context, it is known as cultural relativism. And it is just as incoherent applied to animals as applied to folks slicing off the clitorises of babies. Let us for a moment suppose that we will treat individual animals as persons whose pleasures, pains, and desires we can identify and respect. In that case, empirically speaking, non-interference is a poor policy. We could do more to make animals suffer less by intervention than by complete non-intervention. On the other hand, perhaps it is the species that is our “person”—we should try to respect a species, or, perhaps, a whole complex ecosystem. But since species and ecosystems are not percipient beings capable of pleasure and suffering, by assigning them respect, we open up the question of the purpose of doing so. Who are ecosystems good for? Or are they perhaps mystically intrinsically good, as Jehovah would have us believe? 4. Use Nature As We Please? To some degree, nature au naturel is good for humans. We need trees and algae and fish in order to live. Genetic diversity, developed over millions of years, ensures the longevity of our biosphere. Being near green plants and animals makes us happy. We frequently violate our supposed policy of non-intervention with the natural world when doing so benefits humans, in some cases actively seeking the extinction of certain organisms (like smallpox). I don’t think this is wrong at all, because (a) smallpox doesn’t do anyone, including itself, any good by existing; and (b) smallpox causes untold suffering. But why draw the line at smallpox? It is my contention that not just smallpox, but all creatures, do not do themselves any good by existing—from piss-dodging spiders to coyotes to humans. Not only do we breathe oxygen and eat food produced by biological systems, we also appreciate the beauty of complex systems. Can we justify the suffering of baby coots because we think their ecosystem is interesting? Earlier generations of humans liked to torture animals for their own pleasure (and some people still do). We now judge this to be evil. But is standing by while animals torture each other in “natural” ways, when we have the power to stop it, any better than actively torturing animals? Responsible people spay or neuter their pets. Why not spay Nature Herself? We don’t even have to harm or kill animals in order to stop Nature from doing her evil deeds. We could simply prevent their reproduction, or even merely cease our current “conservation efforts” that involve breeding animals. Breeding wild animals and releasing them into the wild is doing the ugly work of Genesis all over again—and cruelly claiming that it’s “good.” 5. Is Being Human-Like Better? We are touched by human-like (or ideal-human-like) characteristics in animals—nurturing young, monogamy, neighborliness, cooperation. Humans, although we commit parental infanticide at a rate higher than any other great ape (as would be expected from our relative immaturity at birth), at least attempt to raise most of our young to adulthood. But is “human” really more “humane”? Compare the pelicans and coots to the rosella parrot. These parents feed “fairly”—that is, all chicks are fed equally, although they hatch at different times, so some chicks are larger than others. Large, older baby parrots even share their food with their smaller siblings! Aw. Sound good? Nice parrots. However, they are merely postponing the point at which the red teeth and claws come into the picture. These parrot parents produce more than two offspring. What do you think happens to most of them? They go off and found happy egalitarian parrot families of their own? Maybe for a little while. But a species can’t expand indefinitely. Most of these new parrots will get eaten or starve to death. The lucky few will go on to put dozens of new parrots into the world, for natural selection to claw apart and eat alive. r is evil, but K is not so great either. Antibiotics were not invented until World War II. Prior to that, any human parent faced the very real possibility of losing some or all of his children before they reached adulthood. Humans were visibly under the same selection pressures as the rest of the animals. However, for a couple of generations, we have managed to pretend that nearly all our offspring can survive to adulthood and bear children of their own. We must look to nature to remind ourselves that this is a temporary fantasy.",
      "chapter_number": 21,
      "section_number": null,
      "word_count": 1966,
      "file_path": "index_split_021.html",
      "spine_order": 22
    },
    {
      "title": "Appendix: Living in the Epilogue: Social Policy as Palliative Care",
      "content": "Appendix: Living in the Epilogue: Social Policy as Palliative Care A self is a machine for making you concerned about your organism. —Antonio Damasio The Story as a Cognitive Bias The essence of consciousness, says Antonio Damasio, is the internal narrative—the story one tells oneself about oneself.143 The ability to create this narrative—to conceive of oneself, to project oneself into the past and the future, to connect events meaningfully—has proven to be a very effective evolutionary strategy to ensure that an organism acts to promote its own ends. Our evolutionary history ensures that we think in stories. Stories are so central to our thinking that it is hard to think about them. An old fish said to a couple of young fish, “Morning, boys! The water’s fine today!” and swam off. One young fish turned to the other young fish and asked, “What’s water?” Thus it is with humans and stories. Stories are extremely useful; as information-hungry, social creatures, we are as pleased to hear stories as dogs are to sniff the pee stains of other dogs. We love stories. We are stories. We think and remember in the form of stories. As Roger Schank puts it (in Tell Me a Story: A New Look at Real and Artificial Memory), “In the end all we have, machine or human, are stories and methods of finding and using those stories.” But stories are not real. They are constructs that we apply to the universe, but there is no story out in the universe. There is no “gist” or “point” to the universe, as stories have gists and points. We construct meaning to serve our evolutionarily-determined ends, and this is, I think, the most central of all the cognitive biases.",
      "chapter_number": 22,
      "section_number": null,
      "word_count": 288,
      "file_path": "index_split_022.html",
      "spine_order": 23
    },
    {
      "title": "Living in the Epilogue",
      "content": "Living in the Epilogue A few years ago, I wanted to die all the time, every minute. I suffered intensely, and the main project of my life was to get through time. I researched suicide methods, made repeated attempts, but always failed, and was left with the conviction that suicide is extremely difficult. At some point, I changed my focus from trying to end my life to trying to make what years I am forced to endure less miserable. In the language of illness, I put myself in hospice and gave myself palliative care. I tried many therapies, including a six-month attempt at alcoholism. Many of my experimental palliative care therapies (including this) failed, but a few (including distance running and marriage) were extremely successful at making me not suffer all the time. Marriage is a kind of heaven, and I suspect that I am now happier than most people in the world. Life remains an irritation, but for me it is not the constant grind of pain and humiliation that it must be for millions of people. In many ways, my pro-death orientation makes life more pleasant, since I utterly lack the fear of death and all the cringing urgency that fear engenders. But there is something missing. Here is the problem, if it is a problem: I am not in a story. Living outside of any story—living without hope for the future, without the belief that one is part of a narrative—is confusing. It’s hard to get anything done when nothing has a point. For any not-immediately-pleasurable action (or inaction) I contemplate—getting up in the morning, vacuuming, answering the phone—there is no readily-available answer to the ever-present question in my mind: “why?” At least, there is no long-term “why.” Do I wish I were in a story again? Ultimately, no. Even if it were possible to imagine myself as a character in some narrative about to unfold, I don’t really want to. This would be sacrificing truth for comfort—and questionable comfort at that. I spoke about this with my closest friend years ago, and he suggested that I have had a story, and now I’m living in the “ever after” part. I am, for all relevant purposes, living in my own epilogue. This is also, I think, the status of people with terminal illness who are about to die: their story is essentially over. This is even true if you believe in an afterlife (including the transhumanist kind). There Are No Stories In Heaven There are no stories in heaven; heaven is all epilogue. It functions as a bookend on our stories; we may even call it the “hereafter,” as in “happily ever after.” There can be no conflict in heaven, so there can be no stories, either. Aristotle scholar Martha Nussbaum explores how grim it is for humans to live outside of a story, even in heaven. In her essay “Transcending Humanity,” she considers Odysseus’ choice to give up eternal youth and pleasure with Calypso in order to return to his wife and the certainty of inevitable death. She says, What, in the face of the recognized human attachment to transcendence, could justify such a choice? Odysseus has little to say. But what he does say makes it perfectly clear that the key is not any surpassing beauty in Penelope herself. He freely grants that from this point of view Calypso will be found superior. And he points to no superiority in Penelope that could counterbalance Calypso’s divine excellence. So he is not, it seems, choosing a glorious prize in spite of the fact that he has to face death to get it; that is not at all how he sees the issue. He is choosing the whole human package: mortal life, dangerous voyage, imperfect mortal aging woman. He is choosing, quite simply, what is his: his own history, the form of a human life and the possibilities of excellence, love, and achievement that inhabit that form. What, then, can he say to make that choice intelligible, once the alternative of divinity and agelessness is on the scene? And yet, to readers of the poem from ancient to modern times, Odysseus’ choice does seem intelligible, and also admirable—the only choice we would have our hero make. Odysseus’ choice is perfectly understandable because the alternative is so…boring. Without the possibility of loss, nothing is interesting. Without limitation, there is no possibility for excellence, which is, in the Aristotelian view at least, the purpose of a human being: We don’t quite know what it would be for this hero, known for his courage, craft, resourcefulness, and loyal love to enter into a life in which courage would atrophy, in which cunning and resourcefulness would have little point, since the risks with which they grapple would be removed, and in which love, insofar as it appears at all, would be very different in shape from the love that connects man to wife and child in the human world of the poem. And: The Greeks, no less than contemporary Americans, praise outstanding athletic performance as a wonderful instance of human excellence…But clearly, such achievement has point and value only relatively to the context of the human body, which imposes certain species-specific limits and creates certain possibilities of movement rather than others…But if this means that even races or contests between different animal species will usually seem pointless and odd, it means all the more that there will be no athletic excellence at all, and no meaningful concept of athletic excellence, in the life of a being that is, by nature, capable of anything and physically unlimited…What would such achievement be, in a being for whom it is all easy? What would be the rules of the game? But the real appeal of Penelope, and of the mortal world, compared to heaven, is the possibility of stories. We root for Odysseus to choose Penelope over immortality, says Nussbaum, because of this more general uneasiness about the shapelessness of the life Calypso offers: pleasure and kindliness and on and on, with no risks, no possibility of sacrifice, no grief, no children. All we need to do to see this is to compare accounts of lovemaking. Odysseus and Calypso “withdrew, and in a recess of the arching cavern they took their pleasure in love, and did not leave one another’s side.” That’s the end of that; the poet can say no more; for they have nothing to talk about, since they have done nothing and nothing has happened to them. As for the human husband and wife: The two in their room enjoyed the delights of love, then pleased one another with recounting what had befallen each. The queen told how much she had suffered in these halls, seeing always there the pernicious multitude of suitors who in wooing her had slaughtered so many beasts, fat sheep and oxen, and drawn so much wine from the great jars. The king told of the harm he had done to others and the misery he had endured himself. Penelope listened to him enraptured, and sleep did not fall upon her eyelids till he had told his tale to the end.144 It’s perfectly plain that the human pair are, at least from the viewpoint of the human reader, more interesting and more erotic. A sexuality divorced from conversation, from storytelling, from risk and adventure and the sharing of risk and adventure, seems extremely boring; and we feel that it is a great tribute to the goddess’s beauty that Odysseus retains his interest in her, after so much time. Life is quite unbearable for a human without the “risk and adventure” of a story-bound life. What we are looking for when we look for the “meaning of life” is the greater story. The unfortunate truth, suggested by science and vehemently denied by religion, is that there is no greater story. We may make up stories and allow them to shape our perceptions, but ultimately there is no story. We are all living in the epilogue of reality, or rather worse, because there never was a story. For many of us, our personal stories have run out— and it’s extremely difficult to push oneself into a new story once you see that all stories are vanity. It is like the difficulty of staying in a dream once one realizes one is dreaming. The Cheery and the Damned Why are drugs, prostitution, gambling and suicide illegal, when they clearly give so much relief to suffering people? I think it is because, at a societal level, we are deluded into thinking that happiness is possible, maybe even easy or likely, without these things. I have called this “cheery social policy.” The fundamental problem with this sort of cheeriness is the assumption that a good life—a pleasant life—is relatively easy to achieve. Cheery people are able to hold such a belief because they are able to ignore—and perhaps can’t even conceive of—the suffering of a significant minority of the population. A good life is not easily achieved for many of us. There is a majority belief that we need not use extraordinary means to achieve a happy and meaningful life. Behaviors that deviants engage in, perhaps in pursuit of a tolerable life—weird sex with lots of people, say, or using steroids or marijuana or LSD or benzodiazepines—strike cheery people as perplexing and frightening. For a cheery person, these behaviors are wholly unnecessary. Life is perfectly tolerable without them. And they increase the risk of harm! Who wants harm? What the cheery cannot imagine is the importance, the function of these behaviors, and others like them—the pursuit of the interesting, and the temporary suspension of the intolerability of existence, which intolerability (for many) the cheery do not even perceive, and therefore do not properly weight as a problem. In a blog post titled “Explanations for drug war”145 Jason Roy makes this point with respect to the drug prohibition. He quotes John Gray’s Straw Dogs: Drug use is a tacit admission of a forbidden truth. For most people happiness is beyond reach. Fulfillment is found not in daily life but escaping from it. Since happiness is unavailable, the mass of mankind seeks pleasure. Religious cultures could admit that earthly life was hard, for they promised another in which all tears would be wiped away. Their humanist successors affirm something still more incredible—that in future, even the near future, everyone can be happy. Societies founded on a faith in progress cannot admit the normal unhappiness of human life. As a result, they are bound to wage war on those who seek an artificial happiness in drugs. But it is not necessarily the case that prohibitionists think that life is great. It’s that they think it is meaningful—that we are in a story, and it’s worth participating in, win or lose. The idea that life is inherently worthwhile, and happiness easy to achieve, underlies many social policies, including prohibitions (legal or moral) on suicide, abortion, nonmarital sex, drugs, gambling, and even eating fatty food. On the other hand, if life were not inherently worthwhile, suicide would be understandable, and bringing a new life into the world would not be an unqualified good, but an uneasy question mark. Sex, drugs, and fun would be appropriate ways to treat oneself for the unwanted condition of life.",
      "chapter_number": 23,
      "section_number": null,
      "word_count": 1888,
      "file_path": "index_split_023.html",
      "spine_order": 24
    },
    {
      "title": "Palliative Care: A Double Standard for People in the Epilogue",
      "content": "Palliative Care: A Double Standard for People in the Epilogue The terminally ill are at the end of their story. If you’re going to die anyway, what does it matter what you do? Take ecstasy. Go skydiving. Fuck a prostitute. Kill yourself. Who cares? There is a sense that, once you’re terminally ill and an official short-timer in life, what you do ceases to really matter. This is, I think, at the heart of the double standard our society imposes with regard to suicide and the other activities mentioned above. If you’re young and healthy, you have an obligation to stay alive and be sober and responsible. But if you’re toast anyway, anything goes. For the dying, we can conceive of allowing them pleasure as mercy. But we are not so eager to offer mercy to healthy people. That is because we mistakenly believe in the concept of health. Toward Social Policy as Palliative Care We are all terminally ill. Not one of us is going to survive. And our stories are delusions. Each one of us lives in The Matrix—a story-dream created by our minds. Happiness is not easy; meaning is elusive. Young, healthy people who find themselves miserable, or find that they no longer inhabit a story, have even more need of the kind of “palliative care” that we offer to terminally ill people, simply because young people have so much more time to get through. Eighty years! Ninety years! A hundred years of epilogue ahead of us? It’s crushingly boring to ponder. As Martha Nussbaum says, When Calypso speaks of “calm possession of this domain,” our hearts sink; for there’s no story in that… Stories have shaped and continue to shape the readers’ desires, giving them a preference for onward movement over stasis, for risk over self-sufficiency, for the human form of time over divine timelessness. They play upon and nourish the emotions—fear, anticipation, grief, hope—that presuppose the form of life of a being both needy and resourceful, both active and finite—and that seem to have their point and function only within the context of such a life. Regarding antinatalism, someone recently asked me if it was my belief that the bad outweighed the good, or whether I thought they weren’t even comparable. I believe the latter. Ray Brassier, in his introduction to Thomas Ligotti’s excellent The Conspiracy against the Human Race, puts it thus: The optimist fixes the exchange rate between joy and woe, thereby determining the value of life. The pessimist, who refuses the principle of exchange and the injunction to keep investing in the future no matter how worthless life’s currency in the present, is stigmatized as an unreliable investor. This is the view from hell. Hell is not the state of experiencing a great deal of suffering with no pleasure to “balance it out.” Hell is popping out of the notion of meaning altogether. And this Hell is the meta-condition that we are all in, whether we perceive it or not.",
      "chapter_number": 24,
      "section_number": null,
      "word_count": 498,
      "file_path": "index_split_024.html",
      "spine_order": 25
    },
    {
      "title": "Acknowledgments",
      "content": "Acknowledgments I would like to thank Chip Smith of Nine-Banded Books for bringing this book into existence over the past four years, for suggesting that I write it, and for encouragement, technical assistance, and friendship along the way. Thanks to everyone who has read early versions of this book and provided helpful criticism and editing assistance—Thomas Ligotti, Ann Sterzinger, Jim Crawford, Anita Dalton, Samuel Crowell and Sam Frank, among others. Thanks to Rob Sica for his philosophy scholarship and librarian assistance, and to readers and commenters of my blog. Thanks to my family, Nona Perry, Dan Perry, Nona Baker, Michelle Perry, Gleta and George Perry, and Kris and George Perry; and to my husband, Andrew Breese, for supporting my work and exploring ideas with me; and to my friends Sarah Lennon, Megan Robb, Phil Ogston, and C. Thi Nguyen. I would like to thank the late Dr. Jack Kevorkian for permission to use his evocative painting as cover art. Finally, I would like to thank Unaffiliated Smartypants Twitter for engaging with crazy ideas with me over the past few years (which acknowledgment is not meant to suggest that such a thing as Unaffiliated Smartypants Twitter exists).",
      "chapter_number": 25,
      "section_number": null,
      "word_count": 196,
      "file_path": "index_split_025.html",
      "spine_order": 26
    },
    {
      "title": "Chapter 156",
      "content": "[←126] “We asked [a poor rural Moroccan farm worker] what he would do if he had more money. He said he would buy more food. Then we asked him what he would do if he had even more money. He said he would buy better-tasting food. We were starting to feel very bad for him and his family, when we noticed the TV and other high-tech gadgets. Why had he bought all these things if he felt the family did not have enough to eat? He laughed, and said, “Oh, but television is more important than food!’” Quoted in: Banerjee, Abhijit, and Esther Duflo. 2011, April 25. More than one billion people are hungry in the world. Foreign Policy.",
      "chapter_number": 154,
      "section_number": null,
      "word_count": 119,
      "file_path": "index_split_154.html",
      "spine_order": 155
    },
    {
      "title": "Chapter 165",
      "content": "[←135] Actually, the New Scientist is oversimplifying; there are two risks of death in each case. The first kind of risk is the risk that the stranger S has particular characteristics which will make any peanut, or any MDMA, lethal for him. The second kind of risk is that a particular ecstasy tablet or peanut will be lethal for any given stranger (e.g., the tablet purporting to be E is really, say, buprenophine, or the peanut is somehow infected with lethal levels of salmonella). The latter type of risk probably isn’t that significant, though. UK studies don’t seem to be finding lethal chemicals in street ecstasy. In Australia, the most common “fake ecstasy” is methamphetamine, which is not particularly lethal. As for peanuts, the CDC reports that the death rate from nontyphoidal Salmonella like the S. typhimurium that recently caused peanut recalls is about 00.78%. Editorial: Drugs drive politicians out of their mind. 2009, February 11. New Scientist.",
      "chapter_number": 163,
      "section_number": null,
      "word_count": 158,
      "file_path": "index_split_163.html",
      "spine_order": 164
    }
  ],
  "chunks": [
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch2",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "chapter",
      "title": "Chapter 4",
      "content": "Table of Contents Preface Introduction: Breaking the Ring of Motivated Ignorance PART I: A Worldview of Worldviews Chapter One: Free Disposal and the Burden of Life The Suicide Prohibition The Cost of Disposal The Land of Free Disposal The Burden of Life Chapter Two: The Empirical Nature of the Meaning of Life The Needs for Meaning Value Social belonging Purpose Efficacy Self-worth or status How Meaning Operates: Methods and Illusions Meaning infection False permanence Suffering measures meaning Illusion of control The Story Non-fungibility of meaning Chapter Three: The Modern Sacredness and Moral Foundations Morphology of the Sacred A Window into Sacredness: The Violation Sacredness Negotiations Moral Foundations Sacrednesses Old and New A Necessary Danger Chapter Four: Experience Machines and Their Ratification The True Gifts of the Good People: How Experience Machines Help Us Escape Uncertainty Friendly Neighborhood Experience Machines: Where Do They Come From? Aesthetics and Religions: A Minor Distinction A Sneaky Dualism The Co-Evolution of Humans and Their Experience Machines The Protection of an Aesthetic Ourselves as Experience Machines PART II: The Ethics of Suicide and the Suicide Prohibition Chapter Five: Moral Foundations Analysis of Suicide and Childbearing Suicide and Moral Foundations Childbearing and Moral Foundations Chapter Six:What Really Causes Suicide Failed Social Belonging Burdensomeness Competence What Doesn’t Cause Suicide Evolutionary Considerations Attempted Suicide as an Adaptive Behavior: Suicide Gambles Chapter Seven: On Contagion Behavioral Contagion Ethical Perspectives on Suicide Contagion The Science of Suicide Contagion Moral Contagion or Informational Contagion? Mass Clusters and Point Clusters The Death of Marilyn Monroe Why Women? Other Factors in Contagion: Negative Definition of Suicide Chapter Eight: The Censorship of Suicide Censorship of Suicide versus Censorship of Violence Contagion and Moral Responsibility Moral Responsibility and Willingness to Censor PART III: The Ethics of Procreation Chapter Nine: Procreative Responsibility: A Road Map Liberty Harm and Measurement: Preferentist and Non-Preferentist Approaches Preferentist Approaches and Evidence Free Disposal and the Imaginary Survey Revealed Preference in Non-Suicidal Behavior Non-Preferentist Approaches Naive Weighing Benatar’s Asymmetry Shiffrin’s Asymmetries Uncertainty Chapter Ten: The Mathematics of Misery Truncated Utility Functions and the Value of Life Negative Utility and the Death Wish Economy Policy Implications What Real Human Utility Functions Are Functions Of Poor Baby or Rich Baby: Which is Worse? The Economics of Palliation and Bullshit Chapter Eleven: The Burden of Life Work and Leisure Poverty and Pain The Demand for Pain Relief Is Loss Aversion Irrational? A Place for Quantitative Methods Chapter Twelve: Hurting People and Doing Good Chapter Thirteen: The World of Nature of Which We Are a Part 1. On The Ways In Which Nature Makes Andrea Yates Look Like June Cleaver 2. The Incoherence of Species-Relative Morality 3. Respect for Species? 4. Use Nature As We Please? 5. Is Being Human-Like Better? Appendix: Living in the Epilogue: Social Policy as Palliative Care The Story as a Cognitive Bias Living in the Epilogue There Are No Stories In Heaven The Cheery and the Damned Palliative Care: A Double Standard for People in the Epilogue Toward Social Policy as Palliative Care Acknowledgments",
      "word_count": 503,
      "character_count": 3464,
      "chapter_number": 2,
      "section_number": null,
      "paragraph_number": null,
      "start_position": 0,
      "end_position": 3464,
      "parent_chunk_id": null
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch2_p1",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "paragraph",
      "title": "Paragraph 1",
      "content": "Table of Contents Preface Introduction: Breaking the Ring of Motivated Ignorance PART I: A Worldview of Worldviews Chapter One: Free Disposal and the Burden of Life The Suicide Prohibition The Cost of Disposal The Land of Free Disposal The Burden of Life Chapter Two: The Empirical Nature of the Meaning of Life The Needs for Meaning Value Social belonging Purpose Efficacy Self-worth or status How Meaning Operates: Methods and Illusions Meaning infection False permanence Suffering measures meaning Illusion of control The Story Non-fungibility of meaning Chapter Three: The Modern Sacredness and Moral Foundations Morphology of the Sacred A Window into Sacredness: The Violation Sacredness Negotiations Moral Foundations Sacrednesses Old and New A Necessary Danger Chapter Four: Experience Machines and Their Ratification The True Gifts of the Good People: How Experience Machines Help Us Escape Uncertainty Friendly Neighborhood Experience Machines: Where Do They Come From? Aesthetics and Religions: A Minor Distinction A Sneaky Dualism The Co-Evolution of Humans and Their Experience Machines The Protection of an Aesthetic Ourselves as Experience Machines PART II: The Ethics of Suicide and the Suicide Prohibition Chapter Five: Moral Foundations Analysis of Suicide and Childbearing Suicide and Moral Foundations Childbearing and Moral Foundations Chapter Six:What Really Causes Suicide Failed Social Belonging Burdensomeness Competence What Doesn’t Cause Suicide Evolutionary Considerations Attempted Suicide as an Adaptive Behavior: Suicide Gambles Chapter Seven: On Contagion Behavioral Contagion Ethical Perspectives on Suicide Contagion The Science of Suicide Contagion Moral Contagion or Informational Contagion? Mass Clusters and Point Clusters The Death of Marilyn Monroe Why Women? Other Factors in Contagion: Negative Definition of Suicide Chapter Eight: The Censorship of Suicide Censorship of Suicide versus Censorship of Violence Contagion and Moral Responsibility Moral Responsibility and Willingness to Censor PART III: The Ethics of Procreation Chapter Nine: Procreative Responsibility: A Road Map Liberty Harm and Measurement: Preferentist and Non-Preferentist Approaches Preferentist Approaches and Evidence Free Disposal and the Imaginary Survey Revealed Preference in Non-Suicidal Behavior Non-Preferentist Approaches Naive Weighing Benatar’s Asymmetry Shiffrin’s Asymmetries Uncertainty Chapter Ten: The Mathematics of Misery Truncated Utility Functions and the Value of Life Negative Utility and the Death Wish Economy Policy Implications What Real Human Utility Functions Are Functions Of Poor Baby or Rich Baby: Which is Worse? The Economics of Palliation and Bullshit Chapter Eleven: The Burden of Life Work and Leisure Poverty and Pain The Demand for Pain Relief Is Loss Aversion Irrational? A Place for Quantitative Methods Chapter Twelve: Hurting People and Doing Good Chapter Thirteen: The World of Nature of Which We Are a Part 1. On The Ways In Which Nature Makes Andrea Yates Look Like June Cleaver 2. The Incoherence of Species-Relative Morality 3. Respect for Species? 4. Use Nature As We Please? 5. Is Being Human-Like Better? Appendix: Living in the Epilogue: Social Policy as Palliative Care The Story as a Cognitive Bias Living in the Epilogue There Are No Stories In Heaven The Cheery and the Damned Palliative Care: A Double Standard for People in the Epilogue Toward Social Policy as Palliative Care Acknowledgments",
      "word_count": 503,
      "character_count": 3464,
      "chapter_number": 2,
      "section_number": null,
      "paragraph_number": 1,
      "start_position": 0,
      "end_position": 3464,
      "parent_chunk_id": "sarah_perryevery_cra_unknown_ch2"
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch4",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "chapter",
      "title": "Preface",
      "content": "Preface This is a book about ethics. People don’t often change their minds about ethics. When they do, it is generally for social reasons, not because they are exposed to reasoned argument. Reasoned arguments more often allow people to cement their existing opinions. Ethical beliefs are, in any case, extremely limited in their ability to influence actions. I will advocate several ethical positions that are counterintuitive, and that some people would describe as evil. These ethical positions include the view that life—not just human life, but all life capable of having experiences—is very bad. It is very immoral, I will argue, to have babies or to otherwise create aware beings. I will also argue that suicide is not wrong or a product of mental illness, but an ethically privileged, rational response to the badness of life. You might imagine these to be positions held by a comic book villain bent on destroying all life in the universe for its own good. That’s fine with me. In fact, it’s a good place to start. Because in presenting what I hope is a reasoned and factually supported ethical argument advocating such extreme ideas, I do not expect to persuade. It is more likely that I will be mentally categorized by the reader as such a cartoon villain (assuming the reader is not one of those few to whom these cartoon villain ideas seem obviously right). And to the extent that the reader holds contrary, prolife, anti-suicide beliefs, I understand that exposure to my unorthodox views may only reinforce those beliefs. Believe it or not, that seems pretty rational to me. To respond to crazy-sounding out-group beliefs with increased faith in the in-group beliefs validated by known and trusted authority—is a smart strategy. From the trenches of interpersonal communication, I don’t think “ad hominem” is even much of a fallacy. On the contrary, consciousness—and all knowledge—is social in nature; and most of our knowledge comes not from direct experience or through reasoning, but from trusted sources. Though some of our beliefs about the physical world come from direct experience, we mostly rely on the trusted testimony of teachers, scientists, and friends to understand such things that we have no direct experience of, or of which our direct experience is understood to be limited or mistaken. The Earth appears to be flat, and the sun, which looks like it is smaller than the Earth, appears to be moving around the earth. We know better only because we are reliably advised that our initial sensory impressions are incorrect. In a similar way, we get some of our ethical beliefs from direct intuitive perception, but we also rely on the ethical beliefs of those around us to shape our own beliefs and actions. We are much more likely to be vegetarians if our friends are vegetarians. We are much less likely to support gun control if our friends are gun enthusiasts. Many readers will find it natural to think of the self as the ultimate arbiter of ethical questions, but this is based on a modern and distinctly Western conception of the self. And even self-heavy moderns will sometimes admit to confusion as to what is the right thing to do in a morally unclear situation. Who, then, is to be consulted and trusted on issues of moral relevance? And what should be the result if one disagrees with a trusted friend on a moral matter? There are some people—crazy people, evil people, people who have taken large amounts of methamphetamines for days on end—whose disagreements with our opinions on ethical matters would not cause us to have any doubts as to the correctness of our own opinions (possibly the opposite, as noted above). But any socially well-adjusted human being is likely from time to time to encounter a person whose contrary opinions are less easily dismissed. When we engage with such a person—who is so trusted, whose mental apparatus has been so verified to work well, and whose motives are so clearly earnest—we may come away less certain about the correctness of our own views. I like the term “epistemic peer” for a person so trusted, brain-wise and team-wise, that his opinion will be taken very seriously when it disagrees with our own. I am more interested in establishing myself as an epistemic peer of the reader than in autistically presenting a logical argument for the correctness of my views. When you find yourself coming to an unusual conclusion and you can’t find a flaw in your own reasoning, the epistemically proper path, I think, is to show your brain and show your work. You display the way your mind (your laboratory apparatus) approaches the problem, and you present your argument (your laboratory protocol) in a clear way so that others may examine it. As I would rather participate in social reasoning than table-pound in my corner, I will not only present the extreme forms of my arguments (many of which I think are correct); I will also attempt to present the continuum for each position, many points along which are uncontroversially reasonable. More important, I will show that such continua exist. I consider many people reasonable who do not go full cartoon villain and agree with me that all life is unfortunate and nobody should ever have babies. What makes such people seem reasonable to me is that they recognize the possibility that a given life could go very badly, and that the joys of life might not outweigh the suffering. At the very least, they recognize that the interests of an aware being are very hard to predict before that being is created. What I would like readers of this book to come away with is not the urge to bomb IVF clinics or dismantle suicide barriers on bridges. I would prefer that readers simply and sincerely consider the question of whether existence is a blessing or a burden, and I hope to encourage the understanding that for many people, it is a useless burden. I would like the reader to think of parenthood as a moral decision affecting a new human being, rather than an event that merely happens to oneself. I would like the reader to consider that it may be both more important and more possible to prevent harm than to do active good in the world. I would like readers to consider the mental states of aware beings as being a very important, if not terminal, locus of ethical value in the universe. Finally, I would like readers to dig further into the nature of their own values, especially the primitive values of survival and longevity. If these points are communicated, I will have done my duty to the late Dr. Jack Kevorkian, who suffered much in his life for the good of others and who, before his death, kindly gave me permission to use one of his paintings on the cover of my book. The prevailing views on birth and suicide, I will argue, are very misguided. But they are misguided in characteristically human and evolutionarily adaptive ways. In order to reject them, we must approach what David Eubanks has called the Frontier of Occam—the highest intelligence achievable by a civilization before it figures out better ways to achieve its ends than by continuing to pursue the goals of its alien creator, evolution. I suspect that I have made more converts to the cause of questioning life’s value simply by being an adorable housewife who makes a killer chanterelle risotto than by any particular argument I’ve constructed. Since I can’t make you risotto, I have tried to present my arguments in a calm and reasoned manner, with abiding respect for the humanity that we all share. Perhaps I will come across as the sort of cartoon villain you should accept as an epistemic peer. But whether or not you allow me to influence you with my dangerous ideas, I hope you will believe me when I tell you that I am very much on your side. You are, after all, an aware being having experiences. This is true whether or not you have had or will have children, and this is true whether you want to live or want to die. Thank you for reading my book.",
      "word_count": 1379,
      "character_count": 7969,
      "chapter_number": 4,
      "section_number": null,
      "paragraph_number": null,
      "start_position": 0,
      "end_position": 7969,
      "parent_chunk_id": null
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch4_p1",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "paragraph",
      "title": "Paragraph 1",
      "content": "Preface This is a book about ethics. People don’t often change their minds about ethics. When they do, it is generally for social reasons, not because they are exposed to reasoned argument. Reasoned arguments more often allow people to cement their existing opinions. Ethical beliefs are, in any case, extremely limited in their ability to influence actions. I will advocate several ethical positions that are counterintuitive, and that some people would describe as evil. These ethical positions include the view that life—not just human life, but all life capable of having experiences—is very bad. It is very immoral, I will argue, to have babies or to otherwise create aware beings. I will also argue that suicide is not wrong or a product of mental illness, but an ethically privileged, rational response to the badness of life. You might imagine these to be positions held by a comic book villain bent on destroying all life in the universe for its own good. That’s fine with me. In fact, it’s a good place to start. Because in presenting what I hope is a reasoned and factually supported ethical argument advocating such extreme ideas, I do not expect to persuade. It is more likely that I will be mentally categorized by the reader as such a cartoon villain (assuming the reader is not one of those few to whom these cartoon villain ideas seem obviously right). And to the extent that the reader holds contrary, prolife, anti-suicide beliefs, I understand that exposure to my unorthodox views may only reinforce those beliefs. Believe it or not, that seems pretty rational to me. To respond to crazy-sounding out-group beliefs with increased faith in the in-group beliefs validated by known and trusted authority—is a smart strategy. From the trenches of interpersonal communication, I don’t think “ad hominem” is even much of a fallacy. On the contrary, consciousness—and all knowledge—is social in nature; and most of our knowledge comes not from direct experience or through reasoning, but from trusted sources. Though some of our beliefs about the physical world come from direct experience, we mostly rely on the trusted testimony of teachers, scientists, and friends to understand such things that we have no direct experience of, or of which our direct experience is understood to be limited or mistaken. The Earth appears to be flat, and the sun, which looks like it is smaller than the Earth, appears to be moving around the earth. We know better only because we are reliably advised that our initial sensory impressions are incorrect. In a similar way, we get some of our ethical beliefs from direct intuitive perception, but we also rely on the ethical beliefs of those around us to shape our own beliefs and actions. We are much more likely to be vegetarians if our friends are vegetarians. We are much less likely to support gun control if our friends are gun enthusiasts. Many readers will find it natural to think of the self as the ultimate arbiter of ethical questions, but this is based on a modern and distinctly Western conception of the self. And even self-heavy moderns will sometimes admit to confusion as to what is the right thing to do in a morally unclear situation. Who, then, is to be consulted and trusted on issues of moral relevance? And what should be the result if one disagrees with a trusted friend on a moral matter? There are some people—crazy people, evil people, people who have taken large amounts of methamphetamines for days on end—whose disagreements with our opinions on ethical matters would not cause us to have any doubts as to the correctness of our own opinions (possibly the opposite, as noted above). But any socially well-adjusted human being is likely from time to time to encounter a person whose contrary opinions are less easily dismissed. When we engage with such a person—who is so trusted, whose mental apparatus has been so verified to work well, and whose motives are so clearly earnest—we may come away less certain about the correctness of our own views. I like the term “epistemic peer” for a person so trusted, brain-wise and team-wise, that his opinion will be taken very seriously when it disagrees with our own. I am more interested in establishing myself as an epistemic peer of the reader than in autistically presenting a logical argument for the correctness of my views. When you find yourself coming to an unusual conclusion and you can’t find a flaw in your own reasoning, the epistemically proper path, I think, is to show your brain and show your work. You display the way your mind (your laboratory apparatus) approaches the problem, and you present your argument (your laboratory protocol) in a clear way so that others may examine it. As I would rather participate in social reasoning than table-pound in my corner, I will not only present the extreme forms of my arguments (many of which I think are correct); I will also attempt to present the continuum for each position, many points along which are uncontroversially reasonable. More important, I will show that such continua exist. I consider many people reasonable who do not go full cartoon villain and agree with me that all life is unfortunate and nobody should ever have babies. What makes such people seem reasonable to me is that they recognize the possibility that a given life could go very badly, and that the joys of life might not outweigh the suffering. At the very least, they recognize that the interests of an aware being are very hard to predict before that being is created. What I would like readers of this book to come away with is not the urge to bomb IVF clinics or dismantle suicide barriers on bridges. I would prefer that readers simply and sincerely consider the question of whether existence is a blessing or a burden, and I hope to encourage the understanding that for many people, it is a useless burden. I would like the reader to think of parenthood as a moral decision affecting a new human being, rather than an event that merely happens to oneself. I would like the reader to consider that it may be both more important and more possible to prevent harm than to do active good in the world. I would like readers to consider the mental states of aware beings as being a very important, if not terminal, locus of ethical value in the universe. Finally, I would like readers to dig further into the nature of their own values, especially the primitive values of survival and longevity. If these points are communicated, I will have done my duty to the late Dr. Jack Kevorkian, who suffered much in his life for the good of others and who, before his death, kindly gave me permission to use one of his paintings on the cover of my book. The prevailing views on birth and suicide, I will argue, are very misguided. But they are misguided in characteristically human and evolutionarily adaptive ways. In order to reject them, we must approach what David Eubanks has called the Frontier of Occam—the highest intelligence achievable by a civilization before it figures out better ways to achieve its ends than by continuing to pursue the goals of its alien creator, evolution. I suspect that I have made more converts to the cause of questioning life’s value simply by being an adorable housewife who makes a killer chanterelle risotto than by any particular argument I’ve constructed. Since I can’t make you risotto, I have tried to present my arguments in a calm and reasoned manner, with abiding respect for the humanity that we all share. Perhaps I will come across as the sort of cartoon villain you should accept as an epistemic peer. But whether or not you allow me to influence you with my dangerous ideas, I hope you will believe me when I tell you that I am very much on your side. You are, after all, an aware being having experiences. This is true whether or not you have had or will have children, and this is true whether you want to live or want to die. Thank you for reading my book.",
      "word_count": 1379,
      "character_count": 7969,
      "chapter_number": 4,
      "section_number": null,
      "paragraph_number": 1,
      "start_position": 0,
      "end_position": 7969,
      "parent_chunk_id": "sarah_perryevery_cra_unknown_ch4"
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch5",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "chapter",
      "title": "Introduction: Breaking the Ring of Motivated Ignorance",
      "content": "Introduction: Breaking the Ring of Motivated Ignorance Human cognition is a mixture of the rational and the magical. Religious thinking is even more important than rational thinking for people deciding how to behave, and this is the case even for people who do not consider themselves religious. The rationality of analytic philosophy is a powerful tool for understanding the world, but the world of human cognition cannot be comprehended without attention to the religious, the magical, and the sacred. The first part of this book deals with the irrational side of human cognition, exploring our need for meaning and our attribution of meaning and sacredness. The second and third parts of this book engage with rationality. Here is an overview of the central thread connecting the parts: People have innate needs for meaning—needs for some ultimate, foundational value that justifies all other values; for purpose in life; for a sense of efficacy and control; and for a sense of self-worth. The meanings that people find in the world are generally illusory—for instance, promised future states of fulfillment that never occur. Since meaning is both necessary AND illusory, people must protect their valuable sources of meaning from disparagement with the armor of sacredness. One of the most sacred and meaning-giving beliefs is the idea that life is a desirable, precious thing to have and to give to others. This sacredness prevents us from thinking clearly about suicide and birth. It is the most poignant example of Jonathan Haidt’s “ring of motivated ignorance” that surrounds the sacred. However, for the most intrepid explorers, challenging the essential sacredness of life—one of the most powerful shared sources of meaning in our sacredness-deprived culture—may mean crossing a frontier into new and unexpected insights and new ways of conceiving of humanity and compassion, especially with respect to suicide and procreation. *** This book engages with analytic philosophy, particularly in its approach to antinatalism and suicide rights. But it also engages with the responses of non-philosophers, whose approaches are probably more representative of ordinary human thought than are more sophisticated treatments found in the literature of analytic philosophy. Chapter 1 engages with Bryan Caplan’s self-described “cursory rejection” of antinatalism, grounded in the claim that if life is so bad you can always commit suicide (in my experience, an overwhelmingly common first response to antinatalism). This chapter introduces antinatalism and explains the connection between antinatalism and suicide. Chapter 2 is about meaning—what kinds of meaning we require as humans, and how we find that meaning in the world. The connection between meaning and suffering is explored. Chapter 3 introduces Jonathan Haidt’s “moral foundations” approach, illustrating how sacredness and purity, care for others, fairness concerns, and loyalty influence our beliefs. Chapter 4 elaborates on Robert Nozick’s famous “Experience Machine” thought experiment, motivating a radical perspective in which mental states are the only objects of moral consideration. Ethical issues are explored from this perspective. Part II focuses on suicide. Chapter 5 analyzes suicide and childbearing from a moral foundations perspective. Chapter 6 examines the causes of suicide, including an exploration of the evolutionary biology of suicide. Chapter 7 engages with the work of Jennifer Michael Hecht, whose popular philosophy book argues that we have a duty to not kill ourselves because doing so gives moral license to others to also commit suicide. This chapter examines the phenomenon of suicide contagion, presenting evidence that it is not moral license but rather the transmission of much-desired information that is responsible for the rare phenomenon of suicide “contagion.” The phenomenon of suicide contagion is also cited in favor of censoring media reports of suicide as well as the depiction of suicide in art and discussion; Chapter 8 examines the censorship of suicide. Part III is about procreation. Chapter 9 provides a roadmap to the ethical arguments involved, both preferentist (believing that people know what is good for them) and non-preferentist (believing that people do not necessarily know what is good for them). Chapters 10 and 11 explore preferentist arguments, demonstrating that people frequently act as if life is a burden rather than a precious gift. Chapter 12 presents non-preferentist arguments against procreation. Chapter 13 connects the human predicament to that of the rest of the creatures in the world and in our evolutionary history. Finally, I include as an appendix a personal essay about the lack of narrative meaning.",
      "word_count": 726,
      "character_count": 4746,
      "chapter_number": 5,
      "section_number": null,
      "paragraph_number": null,
      "start_position": 0,
      "end_position": 4746,
      "parent_chunk_id": null
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch5_p1",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "paragraph",
      "title": "Paragraph 1",
      "content": "Introduction: Breaking the Ring of Motivated Ignorance Human cognition is a mixture of the rational and the magical. Religious thinking is even more important than rational thinking for people deciding how to behave, and this is the case even for people who do not consider themselves religious. The rationality of analytic philosophy is a powerful tool for understanding the world, but the world of human cognition cannot be comprehended without attention to the religious, the magical, and the sacred. The first part of this book deals with the irrational side of human cognition, exploring our need for meaning and our attribution of meaning and sacredness. The second and third parts of this book engage with rationality. Here is an overview of the central thread connecting the parts: People have innate needs for meaning—needs for some ultimate, foundational value that justifies all other values; for purpose in life; for a sense of efficacy and control; and for a sense of self-worth. The meanings that people find in the world are generally illusory—for instance, promised future states of fulfillment that never occur. Since meaning is both necessary AND illusory, people must protect their valuable sources of meaning from disparagement with the armor of sacredness. One of the most sacred and meaning-giving beliefs is the idea that life is a desirable, precious thing to have and to give to others. This sacredness prevents us from thinking clearly about suicide and birth. It is the most poignant example of Jonathan Haidt’s “ring of motivated ignorance” that surrounds the sacred. However, for the most intrepid explorers, challenging the essential sacredness of life—one of the most powerful shared sources of meaning in our sacredness-deprived culture—may mean crossing a frontier into new and unexpected insights and new ways of conceiving of humanity and compassion, especially with respect to suicide and procreation. *** This book engages with analytic philosophy, particularly in its approach to antinatalism and suicide rights. But it also engages with the responses of non-philosophers, whose approaches are probably more representative of ordinary human thought than are more sophisticated treatments found in the literature of analytic philosophy. Chapter 1 engages with Bryan Caplan’s self-described “cursory rejection” of antinatalism, grounded in the claim that if life is so bad you can always commit suicide (in my experience, an overwhelmingly common first response to antinatalism). This chapter introduces antinatalism and explains the connection between antinatalism and suicide. Chapter 2 is about meaning—what kinds of meaning we require as humans, and how we find that meaning in the world. The connection between meaning and suffering is explored. Chapter 3 introduces Jonathan Haidt’s “moral foundations” approach, illustrating how sacredness and purity, care for others, fairness concerns, and loyalty influence our beliefs. Chapter 4 elaborates on Robert Nozick’s famous “Experience Machine” thought experiment, motivating a radical perspective in which mental states are the only objects of moral consideration. Ethical issues are explored from this perspective. Part II focuses on suicide. Chapter 5 analyzes suicide and childbearing from a moral foundations perspective. Chapter 6 examines the causes of suicide, including an exploration of the evolutionary biology of suicide. Chapter 7 engages with the work of Jennifer Michael Hecht, whose popular philosophy book argues that we have a duty to not kill ourselves because doing so gives moral license to others to also commit suicide. This chapter examines the phenomenon of suicide contagion, presenting evidence that it is not moral license but rather the transmission of much-desired information that is responsible for the rare phenomenon of suicide “contagion.” The phenomenon of suicide contagion is also cited in favor of censoring media reports of suicide as well as the depiction of suicide in art and discussion; Chapter 8 examines the censorship of suicide. Part III is about procreation. Chapter 9 provides a roadmap to the ethical arguments involved, both preferentist (believing that people know what is good for them) and non-preferentist (believing that people do not necessarily know what is good for them). Chapters 10 and 11 explore preferentist arguments, demonstrating that people frequently act as if life is a burden rather than a precious gift. Chapter 12 presents non-preferentist arguments against procreation. Chapter 13 connects the human predicament to that of the rest of the creatures in the world and in our evolutionary history. Finally, I include as an appendix a personal essay about the lack of narrative meaning.",
      "word_count": 726,
      "character_count": 4746,
      "chapter_number": 5,
      "section_number": null,
      "paragraph_number": 1,
      "start_position": 0,
      "end_position": 4746,
      "parent_chunk_id": "sarah_perryevery_cra_unknown_ch5"
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch7",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "chapter",
      "title": "Chapter One: Free Disposal and the Burden of Life",
      "content": "Chapter One: Free Disposal and the Burden of Life When people are considering whether to have a child, is it appropriate for them to consider whether the child might be harmed just by being created? Should they think about whether life for this child might be a great burden, rather than a gift? In a blog post entitled “Free Disposal,” economist Bryan Caplan says that it is not appropriate to consider such things.1 We can see that life is always a blessing and never a burden, he says, because people may freely dispose of their lives if they wish, but few take advantage of this opportunity. By revealed preference—an economic term for a person’s actions revealing his true desires—it is clear that people overwhelmingly find their lives to be of positive value. Caplan writes: Actually, this may well be the easiest utility inference in the world. We know that people almost universally prefer existing to not existing because there are so many cheap and easy ways to stop existing. As intro econ teachers might say, life is a good with free (or nearly free) disposal. To bolster his position, Caplan cites the following passage by Epicurus: Yet much worse still is the man who says it is good not to be born, but “once born make haste to pass the gates of Death.” [Theognis, 427] For if he says this from conviction why does he not pass away out of life? For it is open to him to do so, if he had firmly made up his mind to this. But if he speaks in jest, his words are idle among men who cannot receive them. In another blog post entitled “A Cursory Rejection of Antinatalism,”2 Caplan makes a similar claim: Almost everyone’s behavior confirms that they’re glad to be alive. After all, no mobile adult needs to be miserable for long. Tall buildings and other routes to painless suicide are all around us; in economic jargon, life is a good with virtually ‘free disposal.’ Yet suicide is incredibly rare nonetheless. Bryan Caplan believes that we live in the Land of Free Disposal. We do not. While legal in a narrow sense, suicide is still very much the subject of prohibition. The costs of making a serious suicide attempt are actually very high, and prohibition increases these costs. In this chapter, we will explore the suicide prohibition and the costs of suicide, and then imagine a world very different from our own—the Land of Free Disposal, where suicide is not meaningfully prohibited and the costs of making a serious suicide attempt are actually minimized. It might not be a nice place to visit, but it is certainly not the world we live in. The Suicide Prohibition In the United States, a person is not guilty of a crime for attempting to kill himself. This is the only sense in which suicide is legal in the modern Western world. The first sense in which suicide is prohibited is that a person may be imprisoned against his will in a hospital for attempting suicide. If a person is judged to pose a danger to himself, such as by attempting suicide or even expressing the desire to commit suicide, he may be held against his will on the locked ward of a psychiatric hospital. The length of the legal period of incarceration varies by jurisdiction. Once on the locked ward, the patient is not free to leave; guards, alarmed doors, and other measures are in place to prevent him from “eloping.” If he has attempted suicide, or is suspected of harboring suicidal thoughts, he may be obliged to remove his jewelry and clothing and be forced to wear paper clothing instead (paper clothing poses less of a hanging risk). Staff may watch him while he sleeps, through a suicide watch window. He will be monitored while he shaves, if he is allowed to shave. Freedom is an imprecise term. But when the government authorizes the imprisonment of a person for attempting or even seriously discussing a particular action, it seems natural to conclude that he is not free to do that action. The person contemplating suicide has more to fear from the hospital than from incarceration. If he survives his suicide attempt or is discovered before he has died, then a progression of paramedics, nurses, doctors, and perhaps even surgeons will attempt to foil his plans by saving his life. Even people who choose very lethal methods by which to exit the world, such as a jump from heights or a gunshot to the head, frequently fail to end their lives, in large part due to modern medicine. Across the United States, four billion dollars are spent annually on emergency room and hospital treatment for people who attempted suicide but were caught before they could die. A person is not “free” to do something that he must either get away with in secret or be forcibly prevented from doing if caught. It gets worse. Those brought back from the brink of death often suffer debilitating injuries that significantly decrease quality of life—below a baseline that was already not worth living. One such patient was the focus of a 2007 single-patient study in the Annals of Neurology.3 The patient, a 48-year-old woman, had at that time been kept alive for over two years in a state of akinetic mutism—she was conscious, but could not move or speak. She experienced severe brain damage from a suicide attempt and was kept alive for years while scientists performed experiments on her. She may be alive still. Life may not be disposed of freely if those who attempt to dispose of it are routinely “rescued” and brought back to life. The policy makes successful disposal less likely, and the risk of being preserved alive in a maimed condition increases the cost of a suicide attempt. And those tall buildings that are supposed to provide for the free disposal of life do not work very reliably. Even the jump from the 64-meter Bosphorus Bridge in Istanbul fails to result in death around 3% of the time. A gunshot to the head is similarly risky, and methods like slashing arteries, hanging, or suffocation by automobile exhaust are even more likely to fail. More important, these methods are horrible; the need to endure the experience makes the cost of the attempt very high. Aversion to heights and body envelope violation are installed by evolution and difficult to overcome, even for people who truly desire death. An observation an economist might make is that methods of suicide are not good substitutes for each other. When a popular method of suicide is made illegal or more difficult, the overall suicide rate often goes down; people do not simply substitute a different method of suicide. After Australia tightened motor vehicle exhaust restrictions, making suicide by carbon monoxide poisoning more difficult, the regional suicide rate decreased. Suicide attempts using this method remained popular but became less lethal, resulting in fewer suicides. More impressively, a few studies of suicide barriers on bridges have found that installing a suicide barrier on a bridge does not increase suicides from nearby bridges. Gun ownership increases the risk of suicide; the availability of a method that is fairly reliably lethal confers such a reduction in the cost of suicide that merely owning a gun makes one more likely to commit suicide. One of the most universal findings about suicide is that men successfully commit suicide about four times more often than women; but where methods preferred by women are available, such as the lethal poisons that may be ingested by mouth that are available in China and India, the female suicide rate sometimes exceeds that of men! People do not seem to freely substitute one method for another. Low rates of substitution indicate that for disposal to be free, desirable methods must not be restricted. And there is a clear, best method. It is reliable, reasonably free from pain, and does not require the suicide to endure a frightening body envelope violation or similar trauma. In those jurisdictions in which suicide is legal under limited circumstances for humane reasons, this is the method used. This is the method preferred by doctors, nurses, veterinarians, and others with relevant knowledge and the ability to acquire the means. This method is, of course, a drug overdose, either by barbiturates or by a synthetic opiate like Fentanyl. The drug prohibition (or drug war) means that barbiturates and Fentanyl are not legally available to people who wish to use the best method to commit suicide. If the best method of disposal requires committing a crime, even though it hurts no one, then disposal is hardly free. In our interconnected market society, it is difficult to do anything alone, with no one’s help. Suicide is a particularly difficult task, and the resources, information, and assistance provided by another person might make the difference between success and failure. Such assistance is illegal. Helping another person to commit suicide is prosecuted as a crime in all but the most limited situations in the few states that allow physician-assisted suicide. Suicide is the only act that is not itself a crime, but which assisting another person to commit is a crime. Even trying to die together may be interpreted as assistance for prosecutorial purposes; the survivor of a suicide pact has sometimes been prosecuted for the death of his luckier comrade. To forbid assistance makes the act less free. The suicidal person is not only prevented from enlisting friendly volunteers to help him, he is denied the ability to freely use markets to achieve his ends. This is a severe handicap indeed, because of both the power of the market and the impotence of the disconnected individual. And so we might amend Bryan Caplan’s confident assertion thus: Disposal is free—except that you will be locked up in a hospital if you are caught trying to exercise this freedom; except that your unwanted life will be returned to you if possible, perhaps in worse condition than before; except that you may not use the most painless, reliable method that puts no bystanders at risk, but must take your chances with painful, violent methods. And no one may help you. If disposal is not “free” in the sense that it is legally permissible, it is also not “free” in terms of costs. We will now look at some of the costs facing a person considering a suicide attempt. The Cost of Disposal So far, we have seen that a major downside to a suicide attempt is the risk that it will fail or be discovered before it is complete. The risk of ending up on a locked ward of a psychiatric hospital, perhaps grievously and permanently injured, is one kind of cost of disposal. But there are many. From the gene’s-eye perspective of evolution, it is very dangerous for an organism to have the capacity to realize that it can escape all of its pain and sorrow by ending its own life. If an organism is given this capacity, either it must be kept content enough that it never wishes to commit suicide, or it must be inhibited from committing suicide, physically or psychologically.4 Many of the costs of a suicide attempt stem from these built-in inhibitions. The terror that a person feels, standing on a bridge or on top of a high building, desperately wishing for death and trying to summon the courage to jump, is an example of the psychological inhibition against suicide. The universal disgust response to body envelope violations is another; it is psychologically trying for a person to cut through all the skin, muscles, and tendons necessary to access his arteries. Passing out from low oxygen and vomiting when poisoned are examples of built-in physical barriers that sometimes effectively inhibit suicide. But people do not exist as individual units separate from human relationships and groups. A great deal of the cost of committing suicide faced by a person wanting to die is social and empathetic: it is resonant in the loneliness and grief that his death will cause, or at least hasten, among parents, children, siblings, a spouse, or friends. As social creatures, we begin forming bonds at least as soon as we are born; these bonds, while often no more voluntarily chosen than our own births, are powerful motivations. Those with whom we have formed social bonds rely on us, imposing a significant cost on suicide even for a miserable person who genuinely wishes to die. The person who successfully ends his life deprives his relatives and his friends of his continued company and support. Everyone dies eventually—the grief and deprivation that death entails are inescapable—but the suicide hastens death, and so appears responsible for it in the eyes of his community. And it is not just the loss of company and support. The suicide of a close associate is usually regarded as much more painful than the event of such a person moving across the country and losing touch, even though the deprivation is similar in either case. Some social costs are artifacts of the prohibition. The suicide must act in secret, sneaking and hiding to avoid detection and unwanted rescue. But who will discover his dead body? It will be especially traumatic for a relative or close friend to happen upon the dead body of a suicide. But often the other option is to risk not being discovered for a long period of time, during which those close relatives will need to endure the fear and uncertainty of “missing person” status. And because of the prohibition, the person determined to commit suicide cannot calmly discuss his intention with his close associates. He cannot say goodbye, or he will likely be locked up in a hospital. Part of what makes suicide seem devastating for those left behind is that it is framed as a tragic, preventable loss rather than the lucky escape of a miserable person. The presence or absence of strong social bonds is actually more determinative of suicide than misery or suffering. Thomas Joiner, in his influential study of suicide,5 found that failed social belonging—and, to a lesser extent, a sense of burdensomeness rather than helpfulness—is a better predictor of suicide than any other kind of unhappiness or misery. The only other strong predictor of suicide in his model is the competence necessary to use one’s chosen method, i.e. access to drugs, knowledge of guns, etc. Unhappy countries do not experience more suicide than happy countries. A major study recently found that countries with higher levels of happiness actually have higher suicide rates than less happy countries.6 (This finding was replicated at the level of individual states of the United States.7) Simple misery does not seem to reliably cause suicide, the way it would in Bryan Caplan’s naive model; rather, people seem to commit suicide when they are freed from, or perhaps rather deprived of, the social bonds that were keeping them alive. There are significant costs associated with suicide apart from the loss of one’s life, and when these costs are removed (whether by weakening social bonds or making desirable methods available), suicide is made more likely. It does not seem to be the case that people are avoiding suicide simply because they are happy to be alive. The Land of Free Disposal Bryan Caplan’s assertion that creating lives can never be wrong because we live in a world with many tall buildings to jump off of (yet only a small proportion of humans actually utilize these free disposal services) is based on a faulty understanding of reality. But what would Caplan’s ideal Land of Free Disposal look like? We turn now to imagining such a land in which suicide is really free—in which legal barriers to suicide are removed, and in which people are permitted to subvert the natural (but unwanted) barriers to suicide. This imaginary land does not necessarily represent my policy prescriptions (for instance, I think parents lose their moral right to commit suicide when they take on the responsibility for a child), and we will find it is not a utopia. The thought experiment is meant to illustrate the high cost our own world places on “disposal,” and how this cost is related to the burden of having been born. In the Land of Free Disposal, the main guiding intention is that it is easy to commit suicide. When a person makes a suicide attempt, he is not sent to a hospital prison; instead, if he has followed proper procedures for signaling his intention, he dies. The most lethal, comfortable methods are widely available, and since suicide is fine, a competitive market arises to provide the most appealing methods. The power of the market is brought to bear on the problem of finding desirable ways to die. Not just “Ask your doctor if Obliviall is right for you,” but also death arcades. The technological burdens of suicide are taken care of in the Land of Free Disposal. The market is a powerful instrument, and allowing it to solve the problems of suicide makes disposal relatively comfortable and efficient. No one has to cut his arteries or shoot himself fourteen times with a .22. Only rarely does someone jump off of a tall building. Suicide is easy, painless, and guaranteed. Technology can go a long way toward undermining our unchosen, Nature-programmed, often irrational fixation on our own continued existence. Of course, it is unlikely to completely free a human being of the biological costs of disposal, but in the Land of Free Disposal these costs are at least minimized. But the technology is not everything. The guarantee of death is very important, perhaps more important than the technological aspect. Even a small possibility of surviving a suicide attempt, in maimed and helpless condition, is rationally a major concern. If one is at all tempted toward a Many Worlds8 analogy for probability, after a good, strong suicide attempt, most of the future selves are gone—but a few, the only conscious ones, are trapped in a hospital incommunicado for decades. Even if the probability is very tiny, the potential consequences are so bad that it may not be worth the gamble. But no one needs to worry about this in the Land of Free Disposal. So everyone who wants to die may die. But to ensure that disposal is truly free, other costs must be removed from the suicide as well. Suicide has no stigma in the Land of Free Disposal. In kindergarten your kid’s teacher has each student draw a picture on the topic of “When Would I Kill Myself?” What has he drawn there? It is very sad when children commit suicide—and many of them do, even in our world—but preventing them from doing so is not free disposal. Many people do not want to die alone. As in our world, people sometimes post pictures of their last moments to Facebook, but in the Land of Free Disposal the pictures are taken automatically at the death arcades and resemble on-ride photography at Disneyland. In this way and in many other ways, the path to death is made easier by the possibility of social connection. Unlike in our world, people in the Land of Free Disposal may sit with a dying suicide to comfort and even assist him without fear of imprisonment. The desire for some kind of connection to the future after one’s death—a kind of immortality—is recognized as a strong psychological motivation, and provided for in the public policy allowing suicides to donate their organs at a hospital. There is no organ shortage in the Land of Free Disposal, and since suicide isn’t creepy at all, everybody wins. There have been changes in lending and credit, and in contract law in general, in the Land of Free Disposal, but institutions have adjusted. Standard clauses have been drafted to amend insurance policies and other formal agreements. Of course, the loneliness of family and friends must be considered a cost of suicide not likely to be attenuated by social interventions. We may not wish to reduce these bonds—to do so might create a very undesirable society— but they form a cost of suicide that may make a person suffer through a miserable, unwanted life for the good of others. The Land of Free Disposal might experiment with weakening social bonds through alternative methods of childrearing, as with kibbutzim, or alternative relationship structures, such as arm’s-length polyamory rather than mutually dependent monogamy. Policies designed to reduce interdependence between humans might make suicide easier for those who desire it, but to the extent they are successful, they would also likely reduce the aggregate quality of life experienced by everyone. A social species like ours is unlikely to achieve truly Free Disposal, except perhaps among our most isolated members. But other interventions could at least partially balance the burdens that social bonds place on the person desiring to be rid of his existence. A posthumous tax credit for suicides, for example, might decrease the socially-imposed cost of suicide for a miserable person. And rather than spending tens of millions on suicide prevention efforts (as our government does through the National Institutes of Health, the military, and other agencies), the governing body of the Land of Free Disposal spends money on campaigns to promote the right to suicide. In the Land of Free Disposal, billboards, television, and the Internet carry the message that suicide is a sacred right, rather than the message that suicide is wrong and a sign of illness. PSAs remind people that “No One Owns You—Suicide is Your Right!” On the chance that suicide “contagion” is real and social proof removes a major cost of suicide, fictional and nonfictional accounts of successful suicides are broadcast widely in approving terms. Curricula in schools emphasize personal autonomy, vilify interpersonal possessiveness, and treat suicide as a positive life choice to be seriously considered. “Do You Love Her Enough to Let Her Go?” The Burden of Life The distance between the Land of Free Disposal and our own world is a measure of the burden of life placed on anyone born into our society. In our world, only about a million people a year successfully commit suicide; in the absence of restrictions and costs, this number would be much higher. Bryan Caplan’s “easiest utility inference in the world” is, as we have seen, incorrect. Creating a person places a burden on him that he may be obliged to bear against his genuine desire to be rid of it. Creating children in a cavalier and thoughtless manner is not a morally responsible option. We must look deeper to determine whether creating a particular child is in that child’s best interests.",
      "word_count": 3795,
      "character_count": 22353,
      "chapter_number": 7,
      "section_number": null,
      "paragraph_number": null,
      "start_position": 0,
      "end_position": 22353,
      "parent_chunk_id": null
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch7_p1",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "paragraph",
      "title": "Paragraph 1",
      "content": "Chapter One: Free Disposal and the Burden of Life When people are considering whether to have a child, is it appropriate for them to consider whether the child might be harmed just by being created? Should they think about whether life for this child might be a great burden, rather than a gift? In a blog post entitled “Free Disposal,” economist Bryan Caplan says that it is not appropriate to consider such things.1 We can see that life is always a blessing and never a burden, he says, because people may freely dispose of their lives if they wish, but few take advantage of this opportunity. By revealed preference—an economic term for a person’s actions revealing his true desires—it is clear that people overwhelmingly find their lives to be of positive value. Caplan writes: Actually, this may well be the easiest utility inference in the world. We know that people almost universally prefer existing to not existing because there are so many cheap and easy ways to stop existing. As intro econ teachers might say, life is a good with free (or nearly free) disposal. To bolster his position, Caplan cites the following passage by Epicurus: Yet much worse still is the man who says it is good not to be born, but “once born make haste to pass the gates of Death.” [Theognis, 427] For if he says this from conviction why does he not pass away out of life? For it is open to him to do so, if he had firmly made up his mind to this. But if he speaks in jest, his words are idle among men who cannot receive them. In another blog post entitled “A Cursory Rejection of Antinatalism,”2 Caplan makes a similar claim: Almost everyone’s behavior confirms that they’re glad to be alive. After all, no mobile adult needs to be miserable for long. Tall buildings and other routes to painless suicide are all around us; in economic jargon, life is a good with virtually ‘free disposal.’ Yet suicide is incredibly rare nonetheless. Bryan Caplan believes that we live in the Land of Free Disposal. We do not. While legal in a narrow sense, suicide is still very much the subject of prohibition. The costs of making a serious suicide attempt are actually very high, and prohibition increases these costs. In this chapter, we will explore the suicide prohibition and the costs of suicide, and then imagine a world very different from our own—the Land of Free Disposal, where suicide is not meaningfully prohibited and the costs of making a serious suicide attempt are actually minimized. It might not be a nice place to visit, but it is certainly not the world we live in. The Suicide Prohibition In the United States, a person is not guilty of a crime for attempting to kill himself. This is the only sense in which suicide is legal in the modern Western world. The first sense in which suicide is prohibited is that a person may be imprisoned against his will in a hospital for attempting suicide. If a person is judged to pose a danger to himself, such as by attempting suicide or even expressing the desire to commit suicide, he may be held against his will on the locked ward of a psychiatric hospital. The length of the legal period of incarceration varies by jurisdiction. Once on the locked ward, the patient is not free to leave; guards, alarmed doors, and other measures are in place to prevent him from “eloping.” If he has attempted suicide, or is suspected of harboring suicidal thoughts, he may be obliged to remove his jewelry and clothing and be forced to wear paper clothing instead (paper clothing poses less of a hanging risk). Staff may watch him while he sleeps, through a suicide watch window. He will be monitored while he shaves, if he is allowed to shave. Freedom is an imprecise term. But when the government authorizes the imprisonment of a person for attempting or even seriously discussing a particular action, it seems natural to conclude that he is not free to do that action. The person contemplating suicide has more to fear from the hospital than from incarceration. If he survives his suicide attempt or is discovered before he has died, then a progression of paramedics, nurses, doctors, and perhaps even surgeons will attempt to foil his plans by saving his life. Even people who choose very lethal methods by which to exit the world, such as a jump from heights or a gunshot to the head, frequently fail to end their lives, in large part due to modern medicine. Across the United States, four billion dollars are spent annually on emergency room and hospital treatment for people who attempted suicide but were caught before they could die. A person is not “free” to do something that he must either get away with in secret or be forcibly prevented from doing if caught. It gets worse. Those brought back from the brink of death often suffer debilitating injuries that significantly decrease quality of life—below a baseline that was already not worth living. One such patient was the focus of a 2007 single-patient study in the Annals of Neurology.3 The patient, a 48-year-old woman, had at that time been kept alive for over two years in a state of akinetic mutism—she was conscious, but could not move or speak. She experienced severe brain damage from a suicide attempt and was kept alive for years while scientists performed experiments on her. She may be alive still. Life may not be disposed of freely if those who attempt to dispose of it are routinely “rescued” and brought back to life. The policy makes successful disposal less likely, and the risk of being preserved alive in a maimed condition increases the cost of a suicide attempt. And those tall buildings that are supposed to provide for the free disposal of life do not work very reliably. Even the jump from the 64-meter Bosphorus Bridge in Istanbul fails to result in death around 3% of the time. A gunshot to the head is similarly risky, and methods like slashing arteries, hanging, or suffocation by automobile exhaust are even more likely to fail. More important, these methods are horrible; the need to endure the experience makes the cost of the attempt very high. Aversion to heights and body envelope violation are installed by evolution and difficult to overcome, even for people who truly desire death. An observation an economist might make is that methods of suicide are not good substitutes for each other. When a popular method of suicide is made illegal or more difficult, the overall suicide rate often goes down; people do not simply substitute a different method of suicide. After Australia tightened motor vehicle exhaust restrictions, making suicide by carbon monoxide poisoning more difficult, the regional suicide rate decreased. Suicide attempts using this method remained popular but became less lethal, resulting in fewer suicides. More impressively, a few studies of suicide barriers on bridges have found that installing a suicide barrier on a bridge does not increase suicides from nearby bridges. Gun ownership increases the risk of suicide; the availability of a method that is fairly reliably lethal confers such a reduction in the cost of suicide that merely owning a gun makes one more likely to commit suicide. One of the most universal findings about suicide is that men successfully commit suicide about four times more often than women; but where methods preferred by women are available, such as the lethal poisons that may be ingested by mouth that are available in China and India, the female suicide rate sometimes exceeds that of men! People do not seem to freely substitute one method for another. Low rates of substitution indicate that for disposal to be free, desirable methods must not be restricted. And there is a clear, best method. It is reliable, reasonably free from pain, and does not require the suicide to endure a frightening body envelope violation or similar trauma. In those jurisdictions in which suicide is legal under limited circumstances for humane reasons, this is the method used. This is the method preferred by doctors, nurses, veterinarians, and others with relevant knowledge and the ability to acquire the means. This method is, of course, a drug overdose, either by barbiturates or by a synthetic opiate like Fentanyl. The drug prohibition (or drug war) means that barbiturates and Fentanyl are not legally available to people who wish to use the best method to commit suicide. If the best method of disposal requires committing a crime, even though it hurts no one, then disposal is hardly free. In our interconnected market society, it is difficult to do anything alone, with no one’s help. Suicide is a particularly difficult task, and the resources, information, and assistance provided by another person might make the difference between success and failure. Such assistance is illegal. Helping another person to commit suicide is prosecuted as a crime in all but the most limited situations in the few states that allow physician-assisted suicide. Suicide is the only act that is not itself a crime, but which assisting another person to commit is a crime. Even trying to die together may be interpreted as assistance for prosecutorial purposes; the survivor of a suicide pact has sometimes been prosecuted for the death of his luckier comrade. To forbid assistance makes the act less free. The suicidal person is not only prevented from enlisting friendly volunteers to help him, he is denied the ability to freely use markets to achieve his ends. This is a severe handicap indeed, because of both the power of the market and the impotence of the disconnected individual. And so we might amend Bryan Caplan’s confident assertion thus: Disposal is free—except that you will be locked up in a hospital if you are caught trying to exercise this freedom; except that your unwanted life will be returned to you if possible, perhaps in worse condition than before; except that you may not use the most painless, reliable method that puts no bystanders at risk, but must take your chances with painful, violent methods. And no one may help you. If disposal is not “free” in the sense that it is legally permissible, it is also not “free” in terms of costs. We will now look at some of the costs facing a person considering a suicide attempt. The Cost of Disposal So far, we have seen that a major downside to a suicide attempt is the risk that it will fail or be discovered before it is complete. The risk of ending up on a locked ward of a psychiatric hospital, perhaps grievously and permanently injured, is one kind of cost of disposal. But there are many. From the gene’s-eye perspective of evolution, it is very dangerous for an organism to have the capacity to realize that it can escape all of its pain and sorrow by ending its own life. If an organism is given this capacity, either it must be kept content enough that it never wishes to commit suicide, or it must be inhibited from committing suicide, physically or psychologically.4 Many of the costs of a suicide attempt stem from these built-in inhibitions. The terror that a person feels, standing on a bridge or on top of a high building, desperately wishing for death and trying to summon the courage to jump, is an example of the psychological inhibition against suicide. The universal disgust response to body envelope violations is another; it is psychologically trying for a person to cut through all the skin, muscles, and tendons necessary to access his arteries. Passing out from low oxygen and vomiting when poisoned are examples of built-in physical barriers that sometimes effectively inhibit suicide. But people do not exist as individual units separate from human relationships and groups. A great deal of the cost of committing suicide faced by a person wanting to die is social and empathetic: it is resonant in the loneliness and grief that his death will cause, or at least hasten, among parents, children, siblings, a spouse, or friends. As social creatures, we begin forming bonds at least as soon as we are born; these bonds, while often no more voluntarily chosen than our own births, are powerful motivations. Those with whom we have formed social bonds rely on us, imposing a significant cost on suicide even for a miserable person who genuinely wishes to die. The person who successfully ends his life deprives his relatives and his friends of his continued company and support. Everyone dies eventually—the grief and deprivation that death entails are inescapable—but the suicide hastens death, and so appears responsible for it in the eyes of his community. And it is not just the loss of company and support. The suicide of a close associate is usually regarded as much more painful than the event of such a person moving across the country and losing touch, even though the deprivation is similar in either case. Some social costs are artifacts of the prohibition. The suicide must act in secret, sneaking and hiding to avoid detection and unwanted rescue. But who will discover his dead body? It will be especially traumatic for a relative or close friend to happen upon the dead body of a suicide. But often the other option is to risk not being discovered for a long period of time, during which those close relatives will need to endure the fear and uncertainty of “missing person” status. And because of the prohibition, the person determined to commit suicide cannot calmly discuss his intention with his close associates. He cannot say goodbye, or he will likely be locked up in a hospital. Part of what makes suicide seem devastating for those left behind is that it is framed as a tragic, preventable loss rather than the lucky escape of a miserable person. The presence or absence of strong social bonds is actually more determinative of suicide than misery or suffering. Thomas Joiner, in his influential study of suicide,5 found that failed social belonging—and, to a lesser extent, a sense of burdensomeness rather than helpfulness—is a better predictor of suicide than any other kind of unhappiness or misery. The only other strong predictor of suicide in his model is the competence necessary to use one’s chosen method, i.e. access to drugs, knowledge of guns, etc. Unhappy countries do not experience more suicide than happy countries. A major study recently found that countries with higher levels of happiness actually have higher suicide rates than less happy countries.6 (This finding was replicated at the level of individual states of the United States.7) Simple misery does not seem to reliably cause suicide, the way it would in Bryan Caplan’s naive model; rather, people seem to commit suicide when they are freed from, or perhaps rather deprived of, the social bonds that were keeping them alive. There are significant costs associated with suicide apart from the loss of one’s life, and when these costs are removed (whether by weakening social bonds or making desirable methods available), suicide is made more likely. It does not seem to be the case that people are avoiding suicide simply because they are happy to be alive. The Land of Free Disposal Bryan Caplan’s assertion that creating lives can never be wrong because we live in a world with many tall buildings to jump off of (yet only a small proportion of humans actually utilize these free disposal services) is based on a faulty understanding of reality. But what would Caplan’s ideal Land of Free Disposal look like? We turn now to imagining such a land in which suicide is really free—in which legal barriers to suicide are removed, and in which people are permitted to subvert the natural (but unwanted) barriers to suicide. This imaginary land does not necessarily represent my policy prescriptions (for instance, I think parents lose their moral right to commit suicide when they take on the responsibility for a child), and we will find it is not a utopia. The thought experiment is meant to illustrate the high cost our own world places on “disposal,” and how this cost is related to the burden of having been born. In the Land of Free Disposal, the main guiding intention is that it is easy to commit suicide. When a person makes a suicide attempt, he is not sent to a hospital prison; instead, if he has followed proper procedures for signaling his intention, he dies. The most lethal, comfortable methods are widely available, and since suicide is fine, a competitive market arises to provide the most appealing methods. The power of the market is brought to bear on the problem of finding desirable ways to die. Not just “Ask your doctor if Obliviall is right for you,” but also death arcades. The technological burdens of suicide are taken care of in the Land of Free Disposal. The market is a powerful instrument, and allowing it to solve the problems of suicide makes disposal relatively comfortable and efficient. No one has to cut his arteries or shoot himself fourteen times with a .22. Only rarely does someone jump off of a tall building. Suicide is easy, painless, and guaranteed. Technology can go a long way toward undermining our unchosen, Nature-programmed, often irrational fixation on our own continued existence. Of course, it is unlikely to completely free a human being of the biological costs of disposal, but in the Land of Free Disposal these costs are at least minimized. But the technology is not everything. The guarantee of death is very important, perhaps more important than the technological aspect. Even a small possibility of surviving a suicide attempt, in maimed and helpless condition, is rationally a major concern. If one is at all tempted toward a Many Worlds8 analogy for probability, after a good, strong suicide attempt, most of the future selves are gone—but a few, the only conscious ones, are trapped in a hospital incommunicado for decades. Even if the probability is very tiny, the potential consequences are so bad that it may not be worth the gamble. But no one needs to worry about this in the Land of Free Disposal. So everyone who wants to die may die. But to ensure that disposal is truly free, other costs must be removed from the suicide as well. Suicide has no stigma in the Land of Free Disposal. In kindergarten your kid’s teacher has each student draw a picture on the topic of “When Would I Kill Myself?” What has he drawn there? It is very sad when children commit suicide—and many of them do, even in our world—but preventing them from doing so is not free disposal. Many people do not want to die alone. As in our world, people sometimes post pictures of their last moments to Facebook, but in the Land of Free Disposal the pictures are taken automatically at the death arcades and resemble on-ride photography at Disneyland. In this way and in many other ways, the path to death is made easier by the possibility of social connection. Unlike in our world, people in the Land of Free Disposal may sit with a dying suicide to comfort and even assist him without fear of imprisonment. The desire for some kind of connection to the future after one’s death—a kind of immortality—is recognized as a strong psychological motivation, and provided for in the public policy allowing suicides to donate their organs at a hospital. There is no organ shortage in the Land of Free Disposal, and since suicide isn’t creepy at all, everybody wins. There have been changes in lending and credit, and in contract law in general, in the Land of Free Disposal, but institutions have adjusted. Standard clauses have been drafted to amend insurance policies and other formal agreements. Of course, the loneliness of family and friends must be considered a cost of suicide not likely to be attenuated by social interventions. We may not wish to reduce these bonds—to do so might create a very undesirable society— but they form a cost of suicide that may make a person suffer through a miserable, unwanted life for the good of others. The Land of Free Disposal might experiment with weakening social bonds through alternative methods of childrearing, as with kibbutzim, or alternative relationship structures, such as arm’s-length polyamory rather than mutually dependent monogamy. Policies designed to reduce interdependence between humans might make suicide easier for those who desire it, but to the extent they are successful, they would also likely reduce the aggregate quality of life experienced by everyone. A social species like ours is unlikely to achieve truly Free Disposal, except perhaps among our most isolated members. But other interventions could at least partially balance the burdens that social bonds place on the person desiring to be rid of his existence. A posthumous tax credit for suicides, for example, might decrease the socially-imposed cost of suicide for a miserable person. And rather than spending tens of millions on suicide prevention efforts (as our government does through the National Institutes of Health, the military, and other agencies), the governing body of the Land of Free Disposal spends money on campaigns to promote the right to suicide. In the Land of Free Disposal, billboards, television, and the Internet carry the message that suicide is a sacred right, rather than the message that suicide is wrong and a sign of illness. PSAs remind people that “No One Owns You—Suicide is Your Right!” On the chance that suicide “contagion” is real and social proof removes a major cost of suicide, fictional and nonfictional accounts of successful suicides are broadcast widely in approving terms. Curricula in schools emphasize personal autonomy, vilify interpersonal possessiveness, and treat suicide as a positive life choice to be seriously considered. “Do You Love Her Enough to Let Her Go?” The Burden of Life The distance between the Land of Free Disposal and our own world is a measure of the burden of life placed on anyone born into our society. In our world, only about a million people a year successfully commit suicide; in the absence of restrictions and costs, this number would be much higher. Bryan Caplan’s “easiest utility inference in the world” is, as we have seen, incorrect. Creating a person places a burden on him that he may be obliged to bear against his genuine desire to be rid of it. Creating children in a cavalier and thoughtless manner is not a morally responsible option. We must look deeper to determine whether creating a particular child is in that child’s best interests.",
      "word_count": 3795,
      "character_count": 22353,
      "chapter_number": 7,
      "section_number": null,
      "paragraph_number": 1,
      "start_position": 0,
      "end_position": 22353,
      "parent_chunk_id": "sarah_perryevery_cra_unknown_ch7"
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch8",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "chapter",
      "title": "Chapter Two: The Empirical Nature of the Meaning of Life",
      "content": "Chapter Two: The Empirical Nature of the Meaning of Life Even the best human lives include substantial suffering. A typical person experiences considerable pain, loneliness, and boredom in his lifetime, together with aging and the inevitability of death. What is it that justifies the human species in reproducing itself despite all the suffering? One possible answer is the happiness and pleasure that life is expected to provide, and this happiness-and-pleasure hypothesis will be treated seriously in later chapters. But happiness is not the reason most people feel that life is valuable despite all the suffering; rather, it is meaning. The feeling that life is meaningful is the real reason that people think human lives are worth making. The conviction of meaning functions as an intuitive justification for creating the lives of others; whether or not this justification is valid, it does seem to be true that finding a sense of meaning eases the experience of suffering in actual lives. Subjectively, the feeling that life is meaningful—that there are ultimate values, that life has a purpose—tends to point to a source of meaning, something higher than and external to the mere feeling or intuition of meaning. While sources of meaning vary greatly (and often contradict each other), the sense and expectation of meaning itself is surprisingly universal—so universal that the intuition is almost never challenged. This very universality should motivate us to be cautious about taking meaning’s claims at face value. One should be suspicious of any claim that is defended for contradictory reasons, and most people who agree that life is meaningful disagree as to what makes it so. The belief that life is meaningful tends to take the form of a strong feeling rather than a reasoned conclusion; indeed, one of the functions of meaning is to shield a person from the harmful effects of reasoning by providing a value that is justified for its own sake, a foundational rock for cognition below which no “whys” need be answered. It is this feeling of meaning that may be profitably investigated. We will examine the needs that motivate people to seek meaning, then explain the methods used by various sources of meaning to meet those needs. Along the way, we will look at some of the trends in meaning in the rapidly changing modern world from a cultural evolution perspective. The Needs for Meaning The social psychologist Roy Baumeister has been studying how people experience meaning in their lives for decades, and continues to publish on the topic to this day. His 1991 book Meanings of Life proposed four needs that must be filled with sources of meaning: a need for an ultimate value base a need for personal purpose a need for self-worth or status a need for efficacy or control Both Baumeister’s later work and the work of psychologist Thomas Joiner indicate that a fifth need is also critical for human well-being: the need for social belonging. The satisfaction of this need is crucial for the sense of meaning. Thwarted belonging (through, for example, divorce, job loss, or social rejection) is painful and so destructive of meaning that Thomas Joiner found it to be a major predictor of suicide. It is the social group that maintains sources of meaning most effectively; people are rarely successful at supplying meaning for themselves without outside assistance. Even the ultimate value of the self is most effective when reinforced by the social group. Value Human cognition is characterized by asking “why?”—explicitly as a child, internally as an adult. If an action is difficult or undesirable, it must be justified. More general principles justify specific cases. Stop at intersections because it is part of one’s duty to drive carefully; drive carefully to avoid hitting people; avoid hitting people because injuring others through carelessness is wrong. To avoid infinite regression (and all the cognitive trouble that would go along with it), there must be some end to this process of justification: humans need values that are valuable for their own sake, ultimate values not relying on anything else for justification. A value is an end, as opposed to a means to an end, and offers an end to thinking uncomfortable thoughts that have no answer. Ultimate values may be positive (for example, space exploration, or “the show must go on” in theater) or negative (for example, eschewing racism or adultery as purity violations). They are often experienced as sacred—self-evident, not to be traded off against non-sacred values, and perhaps even surrounded by a protective zone of “motivated ignorance,” as Jonathan Haidt puts it.9 Sacred values may be lost if not protected, and are difficult to recreate once lost. Social belonging Successful social belonging has been a prerequisite for survival and reproduction in the human line for millions of years. It is a need on par with the need for food. Indeed, humans in dire poverty often choose to spend money on social belonging rather than on more food. Even minor threats of social rejection cause anxiety and insecurity; one line of research suggests that social rejection hurts like physical pain. Philippe Rochat, in his book Others in Mind,10 calls social rejection the mother of all fears, the driving force behind most higher-order human psychology, particularly the exacerbated human care about reputation and the control of public presentation of the self. He continues: I propose that the need to affiliate and its counterpart, the fear of social rejection, together form the bottom line of what underlies the experience of shame, embarrassment, contempt, empathy, hubris, or guilt. This underlies all the powerful and often devastating self-conscious emotions that are presumably unique to our species. Social groups, rather than individuals, are the units that maintain sacred values. People generally adjust toward accepting the meaning sources of their near peers. Religious people who leave their community have difficulty maintaining old beliefs while surrounded by people with alien values and meaning structures. On the other hand, people with extreme religious beliefs report more happiness than less religious or non-religious people; the religious community provides both a reliable social belonging experience and a solid, clear basis for value whose self-evident truth is made easier to see by interaction with fellow believers. Isolation is profoundly disturbing, as prisoners detained in solitary confinement learn. Thwarted social belonging predicts suicide, as noted above. People faced with the loss of social belonging (especially stemming from the loss of a job or a romantic partner) are more likely to commit suicide. Those with sources of social belonging, such as a spouse or small children, are less likely to kill themselves. An important exception that proves this particular rule involves married prisoners. Research has shown that prisoners who were married or employed at the time they were incarcerated are actually more likely to commit suicide than unmarried, unemployed prisoners.11 In this case, the married, employed men experienced prison as a loss of a high level of social belonging in the outside world; unmarried and unemployed prisoners experienced less of a drop in social belonging, and may have even viewed prison as a continuation of previous belonging experiences, such as through participation in gangs. We rely on each other for belonging, and we rely on each other to maintain the collective sources of meaning. We cannot do these things for ourselves. Purpose The need for purpose is the need for a present idea of something in the future that motivates present action. All the sources of meaning provide ways to spread the self out over time, to consider the past and the future when weighing what to do now. Purposes provide reasons to make costly sacrifices in the present in order to improve the future. Baumeister12 divides purposes into two types: goals and fulfillments. Goals are short-term future plans that are likely to actually be achieved; once a goal is completed, a new one must be found. Fulfillments, on the other hand, are fantasies about an idealized far future. Eternal life in heaven is an example of a fulfillment, but many fulfillments are not religious in nature. Any goal that seems to offer, in one’s own mind, a permanent state of sustained positive affect, is likely to be a fulfillment rather than a normal goal. These might include fame’s promise of eternal bliss or “making it” in a high-status career, or more mundane matters like marrying or having children, or even the fantasy of “dropping out” and raising organic goat cheese on a farm. In each case, if we cared to look, we would observe that currently famous people, high-status careerists, spouses, parents, and goat farmers are not ecstatically happy all the time—they have goals and fulfillments of their own. In an important way, this is not the point: fulfillments do the job of motivating present behavior as long as they are plausible. Every aspect of meaning is characterized by illusion. The present self is fooled in order to coordinate its actions. In a later section we will consider who is doing the fooling. Efficacy People need to feel that they have control over the world around them, that they have the ability to reach goals or realize values. Efficacy means the capability to help others as well as oneself. Baumeister et al. (2013) found that a greater sense of meaning was associated with doing things for others, even though in many cases happiness was reduced even as meaning was enhanced.13 Loss of efficacy happens naturally with aging. Over time, the faculties and capabilities used to define the self erode. Similarly, disease or paralysis can harm one’s sense of efficacy. Without efficacy, it’s hard not to be a burden on others; the sense of burdensomeness, along with thwarted belonging, are among Joiner’s three predictive factors for suicide. Suicide itself may be pursued in order to restore some amount of efficacy with the act of death. Self-worth or status The need for self-worth is the need to feel that one is valuable and important relative to others. This kind of status is comparative, and is often realized by comparing oneself to those lower in status. Hierarchies provide self-worth of this kind to everyone except those at the very bottom, who must find alternative bases for self-worth. In societies without clear status hierarchies, there is less certainty about social position, hence more worry. In societies whose social system is in upheaval, for example by political or technological revolution, values of each type may be lost. It may be best to have many sources of meaning to rely on, each acting as insurance against the others’ disappearance. The old sources of meaning are cultural items—items of information that reproduce themselves using humans, in a symbiotic rather than parasitic relationship. The cultural package of religion, morals, dietary rules, and heroic stories is the result of hundreds or thousands of years of environmentally attuned replication and refinement. Old sources of meaning have a deserved prestige: they have been proven to work in the environments in which they appear for as long as they’ve been around. They represent the social capital investments made by the group’s ancestors over generations. But when the environment is changing quickly, old values may no longer fit the new conditions; conservative value-maintenance processes may not be enough to control the decline of old sources of meaning. How can you recover lost values? Deep, effective value justifications are rare, and if lost, may not be replaced. Generally, when faced with the loss of a value, people act very conservatively; rather than seeking radically new kinds of value, they seek to elaborate on an existing value. In recent decades, faced with the loss of old sources of meaning such as religion, consensus morality, and neighborhood belonging, and lacking a value justification, the existing value of self-worth began to play a greater role in carrying meaning. Prior to the nineteenth century, the self had been commonly regarded as a very bad thing, the enemy of God and of the interests of the group. But gradually, as the foundational bases for value crumbled during the twentieth century, the self, rehabilitated, took on the role of value justification and became the seat of self-worth. The heavy modern self has a hard task: it must do for itself what human religion and community did in the past. It must provide itself with meaning. Individual selves have been appointed to authorize morality after consensus morality lost its power to coordinate groups. Marriages began to be expected to be a source of personal fulfillment to the individuals involved. Opinions on divorce changed drastically during the 1960s and 70s; what started as an unthinkable act under all but the worst circumstances became a common practice, understood to be sometimes necessary in order to be true to oneself. Millennials, the most recent generation to come of age in America, have grown up attempting to define meaning for themselves in this strange post-value world. Not surprisingly, opinion polls find them to be selfish and obsessed with fame. Having grown up with only the self to look to for guidance, they have elaborated the only source of value they know. How Meaning Operates: Methods and Illusions Meaning takes many forms and operates in counterintuitive ways. Rather than exploring entirely new domains from which to derive meaning, people tend to stick with what they know, elaborating or reinforcing old sources of meaning. Mothers in prison for killing their children are a particularly meaning-deprived group.14 They have lost a great degree of social belonging. Their self-worth is very low, especially when measured against the role of “mother.” Their efficacy is limited, and they cannot find a justification for their actions. In one survey of such women, nearly every one preferred the same path toward a reunion with meaning, at least in her own mind: almost every mother wanted to have another child as soon as she got out of prison, so that she could prove (especially to herself) that she could raise a child properly and regain her self-worth as a good mother. People tend not to seek out radical new sources of meaning; when meaning is lost, they attempt to restore old sources of meaning, no matter how much this risks encountering the same harm that occurred before. Genuinely new sources of meaning do appear from time to time, with varying success at providing for people’s needs. Science and space exploration are new sources of meaning, sacralized decades ago but still closely protected in online social networks. Science is especially seen as a sacred value of liberalism in America, although certain aspects of science (such as psychometric research) conflict with other, more sacred values. Medicine is a new sacred value, especially since the invention of antibiotics gave doctors a genuinely effective tool in the 1940s. Medicine is implicitly based on another sacred value, science. Health is an acceptable value for a modern who is excessively dependent on the self for value; focusing on health provides goals or even fulfillments (the imagined endless elation when a weight-loss goal is attained) and efficacy, while preserving the self as both a value base and a seat of self-worth. The heavy modern self, expected to provide its own meaning, seeks to escape meaning when messages about the self are painful. Yet another popular new method of obtaining meaning is to identify with, or loyally fight on the side of, people who are in some manner oppressed. Old oppressed groups are mostly still around (except for the satanic ritual abuse victims, who finally had to leave), and more importantly, new oppressed groups are constantly being discovered. These groups often turn out to have value bases in and of themselves, offering ultimate value, social belonging, efficacy, and self-worth. Meaning infection Meaning in all the forms above is socially transmissible. The social group itself is powerful; group expectations can prompt behavior that an individual cannot perform on his own. In her book on religious glossolalia, Speaking in Tongues,15 Felicitas Goodman notes that her subjects could only enter a glossolalic trance in the presence of others, and the bigger and more committed the group, the more powerful the effect. You can’t make yourself speak in tongues, but being among others who believe you will speak in tongues can induce that experience. The group’s familiar presence induces a powerful disinhibition unavailable to a lone person. Meaning operates in a similar manner: as a form of social cognition. A person integrating into a new group will absorb many of the new group’s meanings and values. Group membership affects individual values and has for all time; modern geographic mobility means that individual values have recently begun to affect group membership as well. A moral: be careful whom you accept as an in-group member, as you will almost certainly absorb some of his values. False permanence Sources of meaning display false permanence. They appear to be stable, unchanging, and permanent, but this is one of many illusions involving meaning. In reality, the scrappy source of meaning must adapt and change to survive, or risk disappearing; both its stability and its permanence are illusions. Fulfillments are especially burdened by false permanence, promising eternal positive affect and endlessly satisfying high status. The stability of value bases is often exaggerated, such as with modern marriage relationships. Modern young people are starved for meaning and crave to attach it to themselves permanently, but tattoos and expensive weddings, sadly, can’t put back together what no-fault divorce has torn apart. Suffering measures meaning Happiness and meaning are correlated.16 Meaning does seem to contribute to happiness and ease suffering. There are many factors, however, that are correlated to meaning but not to happiness. Experiencing many bad events, for instance, predicts a sense of meaning but also unhappiness. Anxiety is also positively correlated with meaning but negatively correlated with happiness. Meaning increases with certain kinds of suffering; the meaningfulness of a particular group or experience is proportional to the suffering incurred to join. More intense initiation or hazing rituals create more meaningful bonds within the group. More demanding or more religious utopian communes tend to last longer than their more easy-going or secular brethren. The experience of meaning in proportion to negative experiences is somewhat malleable. When people are reminded of the costly, negative aspects of a source of meaning, such as the high economic cost of children,17 their evaluation of the source of meaning becomes more positive and more meaningful in comparison with people who are given a more positive spin on childrearing. Meaning appears in proportion to the suffering that occasions it, and meaning can quickly smooth over uncomfortable inconsistencies revealed in one’s worldview. From the outside, it appears to be an illusion; from the inside, it is experienced as powerful and profound. Illusion of control Some sources of meaning provide actual control over the world and one’s circumstances. Some only provide the illusion of control,18 which may be just as good. In 1969, researchers tested stress responses to loud noises. Subjects who were blasted with loud noise found the experience very distressing. In one group, however, each participant was given a button; this button, they were told, would turn off the noise if it got too bad. None of these subjects used their button (which wasn’t plugged in anyway), but they mostly felt a lot better about the noise. Shamans, witches, and even medical doctors often provide an illusion of control to suffering people. A love spell or a bottle of cholesterol pills probably won’t have much real-world effect, but such props can provide a much-needed sense of control to a suffering person. Life, perhaps, would be more enjoyable and less miserable if it were not mandatory. The Story When meaning takes the form of a narrative, this is another illusion, though again perhaps a benevolent one. Narratives help us organize the past according to the needs of a present self. The stories we tell ourselves about ourselves also help us plan for the future, as with goals and fulfillments. There is one particular story that is among our most resilient pieces of cultural information. It arises spontaneously on all continents at various times, and quickly spreads. Depending on its specifics and its messenger, this story can facilitate a revolution or it can protect the status quo. The story is the one about bad people doing bad things, and how they are responsible for the problems in the world. These bad people must be rooted out and stopped for the sake of the country and—often quite literally—the children. A folklore term for this kind of story is a “subversion myth.” Historical examples abound; here are a few from Jeffrey S. Victor’s paper19 “Satanic Cult Rumors as Contemporary Legend”: In Ancient Rome, the stories commonly claimed that Christians were kidnapping Roman children for use in secret ritual sacrifices. Later, during the Middle Ages, the stories claimed that Christian children were being kidnapped by Jews, again for use in secret ritual sacrifices…In France, just before the French Revolution, similar stories accused aristocrats of kidnapping the children of the poor, for use of their blood in medical baths. [Citations omitted.] Police in modern Saudi Arabia routinely hunt, arrest, prosecute, and execute witches. In the early 1980s, Christian religious programming on state-run television in Benin, Nigeria, generally condemned Western influence and blamed the country’s problems on corruption and witchcraft.20 The Benin example highlights that the vilified class need not exist in reality for the story to be effective, as with the satanic cult ritual abuse panics of the 1980s and to some extent the modern wars on terror and bigotry. What makes the story of bad guys so popular? Mainly, it provides a universally applicable justification for why things are not going well. In human societies, things are generally not going well in a variety of ways, at least from the perspective of individual members. But subversion myths arise in times of special trouble; as Victor puts it, they “usually arise at times when a society is undergoing a deep cultural crisis of values, after a period of very rapid social change has caused much disorganization and widespread social stress.” This justification for things not going well satisfies people’s need for an explanation. A story that vilifies those in power may precede (and perhaps precipitate) a revolution, as in France. Revolutions are particularly likely to occur when things are really, really not going well in a society in the first place, hence there is a great perceived need for an explanation. A story that vilifies others, however, is useful once the revolutionaries have seized power and become the government, with an interest in maintaining the status quo. When religious movements like Islamism, democracy, Christianity, and communism first come into power, things are generally pretty bad; the new government has something like regression to the mean on its side. Unfortunately, political societies are delicate, carefully evolved systems and it’s amazing that they limp along at all; attempts at reform, like mutations in DNA, usually make things worse. Yet the story offers hope. Millions of scapegoats have been executed by governments in service of this story. Despite its flaws, the story is certainly more comfortable than suddenly accepting that large human societies just can’t be very good or wise or fair or free, and that attempts to manipulate the intricate yet lumbering social ecosystem, no matter how well-meaning and carefully researched, usually make things worse. Non-fungibility of meaning A final illusion that meaning creates is one of particular specialness with regard to the source of meaning. People get attached to sources of meaning and regard them as irreplaceable. Actually, it does not seem to matter what source of meaning appears, as long as one is found.",
      "word_count": 3942,
      "character_count": 24544,
      "chapter_number": 8,
      "section_number": null,
      "paragraph_number": null,
      "start_position": 0,
      "end_position": 24544,
      "parent_chunk_id": null
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch8_p1",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "paragraph",
      "title": "Paragraph 1",
      "content": "Chapter Two: The Empirical Nature of the Meaning of Life Even the best human lives include substantial suffering. A typical person experiences considerable pain, loneliness, and boredom in his lifetime, together with aging and the inevitability of death. What is it that justifies the human species in reproducing itself despite all the suffering? One possible answer is the happiness and pleasure that life is expected to provide, and this happiness-and-pleasure hypothesis will be treated seriously in later chapters. But happiness is not the reason most people feel that life is valuable despite all the suffering; rather, it is meaning. The feeling that life is meaningful is the real reason that people think human lives are worth making. The conviction of meaning functions as an intuitive justification for creating the lives of others; whether or not this justification is valid, it does seem to be true that finding a sense of meaning eases the experience of suffering in actual lives. Subjectively, the feeling that life is meaningful—that there are ultimate values, that life has a purpose—tends to point to a source of meaning, something higher than and external to the mere feeling or intuition of meaning. While sources of meaning vary greatly (and often contradict each other), the sense and expectation of meaning itself is surprisingly universal—so universal that the intuition is almost never challenged. This very universality should motivate us to be cautious about taking meaning’s claims at face value. One should be suspicious of any claim that is defended for contradictory reasons, and most people who agree that life is meaningful disagree as to what makes it so. The belief that life is meaningful tends to take the form of a strong feeling rather than a reasoned conclusion; indeed, one of the functions of meaning is to shield a person from the harmful effects of reasoning by providing a value that is justified for its own sake, a foundational rock for cognition below which no “whys” need be answered. It is this feeling of meaning that may be profitably investigated. We will examine the needs that motivate people to seek meaning, then explain the methods used by various sources of meaning to meet those needs. Along the way, we will look at some of the trends in meaning in the rapidly changing modern world from a cultural evolution perspective. The Needs for Meaning The social psychologist Roy Baumeister has been studying how people experience meaning in their lives for decades, and continues to publish on the topic to this day. His 1991 book Meanings of Life proposed four needs that must be filled with sources of meaning: a need for an ultimate value base a need for personal purpose a need for self-worth or status a need for efficacy or control Both Baumeister’s later work and the work of psychologist Thomas Joiner indicate that a fifth need is also critical for human well-being: the need for social belonging. The satisfaction of this need is crucial for the sense of meaning. Thwarted belonging (through, for example, divorce, job loss, or social rejection) is painful and so destructive of meaning that Thomas Joiner found it to be a major predictor of suicide. It is the social group that maintains sources of meaning most effectively; people are rarely successful at supplying meaning for themselves without outside assistance. Even the ultimate value of the self is most effective when reinforced by the social group. Value Human cognition is characterized by asking “why?”—explicitly as a child, internally as an adult. If an action is difficult or undesirable, it must be justified. More general principles justify specific cases. Stop at intersections because it is part of one’s duty to drive carefully; drive carefully to avoid hitting people; avoid hitting people because injuring others through carelessness is wrong. To avoid infinite regression (and all the cognitive trouble that would go along with it), there must be some end to this process of justification: humans need values that are valuable for their own sake, ultimate values not relying on anything else for justification. A value is an end, as opposed to a means to an end, and offers an end to thinking uncomfortable thoughts that have no answer. Ultimate values may be positive (for example, space exploration, or “the show must go on” in theater) or negative (for example, eschewing racism or adultery as purity violations). They are often experienced as sacred—self-evident, not to be traded off against non-sacred values, and perhaps even surrounded by a protective zone of “motivated ignorance,” as Jonathan Haidt puts it.9 Sacred values may be lost if not protected, and are difficult to recreate once lost. Social belonging Successful social belonging has been a prerequisite for survival and reproduction in the human line for millions of years. It is a need on par with the need for food. Indeed, humans in dire poverty often choose to spend money on social belonging rather than on more food. Even minor threats of social rejection cause anxiety and insecurity; one line of research suggests that social rejection hurts like physical pain. Philippe Rochat, in his book Others in Mind,10 calls social rejection the mother of all fears, the driving force behind most higher-order human psychology, particularly the exacerbated human care about reputation and the control of public presentation of the self. He continues: I propose that the need to affiliate and its counterpart, the fear of social rejection, together form the bottom line of what underlies the experience of shame, embarrassment, contempt, empathy, hubris, or guilt. This underlies all the powerful and often devastating self-conscious emotions that are presumably unique to our species. Social groups, rather than individuals, are the units that maintain sacred values. People generally adjust toward accepting the meaning sources of their near peers. Religious people who leave their community have difficulty maintaining old beliefs while surrounded by people with alien values and meaning structures. On the other hand, people with extreme religious beliefs report more happiness than less religious or non-religious people; the religious community provides both a reliable social belonging experience and a solid, clear basis for value whose self-evident truth is made easier to see by interaction with fellow believers. Isolation is profoundly disturbing, as prisoners detained in solitary confinement learn. Thwarted social belonging predicts suicide, as noted above. People faced with the loss of social belonging (especially stemming from the loss of a job or a romantic partner) are more likely to commit suicide. Those with sources of social belonging, such as a spouse or small children, are less likely to kill themselves. An important exception that proves this particular rule involves married prisoners. Research has shown that prisoners who were married or employed at the time they were incarcerated are actually more likely to commit suicide than unmarried, unemployed prisoners.11 In this case, the married, employed men experienced prison as a loss of a high level of social belonging in the outside world; unmarried and unemployed prisoners experienced less of a drop in social belonging, and may have even viewed prison as a continuation of previous belonging experiences, such as through participation in gangs. We rely on each other for belonging, and we rely on each other to maintain the collective sources of meaning. We cannot do these things for ourselves. Purpose The need for purpose is the need for a present idea of something in the future that motivates present action. All the sources of meaning provide ways to spread the self out over time, to consider the past and the future when weighing what to do now. Purposes provide reasons to make costly sacrifices in the present in order to improve the future. Baumeister12 divides purposes into two types: goals and fulfillments. Goals are short-term future plans that are likely to actually be achieved; once a goal is completed, a new one must be found. Fulfillments, on the other hand, are fantasies about an idealized far future. Eternal life in heaven is an example of a fulfillment, but many fulfillments are not religious in nature. Any goal that seems to offer, in one’s own mind, a permanent state of sustained positive affect, is likely to be a fulfillment rather than a normal goal. These might include fame’s promise of eternal bliss or “making it” in a high-status career, or more mundane matters like marrying or having children, or even the fantasy of “dropping out” and raising organic goat cheese on a farm. In each case, if we cared to look, we would observe that currently famous people, high-status careerists, spouses, parents, and goat farmers are not ecstatically happy all the time—they have goals and fulfillments of their own. In an important way, this is not the point: fulfillments do the job of motivating present behavior as long as they are plausible. Every aspect of meaning is characterized by illusion. The present self is fooled in order to coordinate its actions. In a later section we will consider who is doing the fooling. Efficacy People need to feel that they have control over the world around them, that they have the ability to reach goals or realize values. Efficacy means the capability to help others as well as oneself. Baumeister et al. (2013) found that a greater sense of meaning was associated with doing things for others, even though in many cases happiness was reduced even as meaning was enhanced.13 Loss of efficacy happens naturally with aging. Over time, the faculties and capabilities used to define the self erode. Similarly, disease or paralysis can harm one’s sense of efficacy. Without efficacy, it’s hard not to be a burden on others; the sense of burdensomeness, along with thwarted belonging, are among Joiner’s three predictive factors for suicide. Suicide itself may be pursued in order to restore some amount of efficacy with the act of death. Self-worth or status The need for self-worth is the need to feel that one is valuable and important relative to others. This kind of status is comparative, and is often realized by comparing oneself to those lower in status. Hierarchies provide self-worth of this kind to everyone except those at the very bottom, who must find alternative bases for self-worth. In societies without clear status hierarchies, there is less certainty about social position, hence more worry. In societies whose social system is in upheaval, for example by political or technological revolution, values of each type may be lost. It may be best to have many sources of meaning to rely on, each acting as insurance against the others’ disappearance. The old sources of meaning are cultural items—items of information that reproduce themselves using humans, in a symbiotic rather than parasitic relationship. The cultural package of religion, morals, dietary rules, and heroic stories is the result of hundreds or thousands of years of environmentally attuned replication and refinement. Old sources of meaning have a deserved prestige: they have been proven to work in the environments in which they appear for as long as they’ve been around. They represent the social capital investments made by the group’s ancestors over generations. But when the environment is changing quickly, old values may no longer fit the new conditions; conservative value-maintenance processes may not be enough to control the decline of old sources of meaning. How can you recover lost values? Deep, effective value justifications are rare, and if lost, may not be replaced. Generally, when faced with the loss of a value, people act very conservatively; rather than seeking radically new kinds of value, they seek to elaborate on an existing value. In recent decades, faced with the loss of old sources of meaning such as religion, consensus morality, and neighborhood belonging, and lacking a value justification, the existing value of self-worth began to play a greater role in carrying meaning. Prior to the nineteenth century, the self had been commonly regarded as a very bad thing, the enemy of God and of the interests of the group. But gradually, as the foundational bases for value crumbled during the twentieth century, the self, rehabilitated, took on the role of value justification and became the seat of self-worth. The heavy modern self has a hard task: it must do for itself what human religion and community did in the past. It must provide itself with meaning. Individual selves have been appointed to authorize morality after consensus morality lost its power to coordinate groups. Marriages began to be expected to be a source of personal fulfillment to the individuals involved. Opinions on divorce changed drastically during the 1960s and 70s; what started as an unthinkable act under all but the worst circumstances became a common practice, understood to be sometimes necessary in order to be true to oneself. Millennials, the most recent generation to come of age in America, have grown up attempting to define meaning for themselves in this strange post-value world. Not surprisingly, opinion polls find them to be selfish and obsessed with fame. Having grown up with only the self to look to for guidance, they have elaborated the only source of value they know. How Meaning Operates: Methods and Illusions Meaning takes many forms and operates in counterintuitive ways. Rather than exploring entirely new domains from which to derive meaning, people tend to stick with what they know, elaborating or reinforcing old sources of meaning. Mothers in prison for killing their children are a particularly meaning-deprived group.14 They have lost a great degree of social belonging. Their self-worth is very low, especially when measured against the role of “mother.” Their efficacy is limited, and they cannot find a justification for their actions. In one survey of such women, nearly every one preferred the same path toward a reunion with meaning, at least in her own mind: almost every mother wanted to have another child as soon as she got out of prison, so that she could prove (especially to herself) that she could raise a child properly and regain her self-worth as a good mother. People tend not to seek out radical new sources of meaning; when meaning is lost, they attempt to restore old sources of meaning, no matter how much this risks encountering the same harm that occurred before. Genuinely new sources of meaning do appear from time to time, with varying success at providing for people’s needs. Science and space exploration are new sources of meaning, sacralized decades ago but still closely protected in online social networks. Science is especially seen as a sacred value of liberalism in America, although certain aspects of science (such as psychometric research) conflict with other, more sacred values. Medicine is a new sacred value, especially since the invention of antibiotics gave doctors a genuinely effective tool in the 1940s. Medicine is implicitly based on another sacred value, science. Health is an acceptable value for a modern who is excessively dependent on the self for value; focusing on health provides goals or even fulfillments (the imagined endless elation when a weight-loss goal is attained) and efficacy, while preserving the self as both a value base and a seat of self-worth. The heavy modern self, expected to provide its own meaning, seeks to escape meaning when messages about the self are painful. Yet another popular new method of obtaining meaning is to identify with, or loyally fight on the side of, people who are in some manner oppressed. Old oppressed groups are mostly still around (except for the satanic ritual abuse victims, who finally had to leave), and more importantly, new oppressed groups are constantly being discovered. These groups often turn out to have value bases in and of themselves, offering ultimate value, social belonging, efficacy, and self-worth. Meaning infection Meaning in all the forms above is socially transmissible. The social group itself is powerful; group expectations can prompt behavior that an individual cannot perform on his own. In her book on religious glossolalia, Speaking in Tongues,15 Felicitas Goodman notes that her subjects could only enter a glossolalic trance in the presence of others, and the bigger and more committed the group, the more powerful the effect. You can’t make yourself speak in tongues, but being among others who believe you will speak in tongues can induce that experience. The group’s familiar presence induces a powerful disinhibition unavailable to a lone person. Meaning operates in a similar manner: as a form of social cognition. A person integrating into a new group will absorb many of the new group’s meanings and values. Group membership affects individual values and has for all time; modern geographic mobility means that individual values have recently begun to affect group membership as well. A moral: be careful whom you accept as an in-group member, as you will almost certainly absorb some of his values. False permanence Sources of meaning display false permanence. They appear to be stable, unchanging, and permanent, but this is one of many illusions involving meaning. In reality, the scrappy source of meaning must adapt and change to survive, or risk disappearing; both its stability and its permanence are illusions. Fulfillments are especially burdened by false permanence, promising eternal positive affect and endlessly satisfying high status. The stability of value bases is often exaggerated, such as with modern marriage relationships. Modern young people are starved for meaning and crave to attach it to themselves permanently, but tattoos and expensive weddings, sadly, can’t put back together what no-fault divorce has torn apart. Suffering measures meaning Happiness and meaning are correlated.16 Meaning does seem to contribute to happiness and ease suffering. There are many factors, however, that are correlated to meaning but not to happiness. Experiencing many bad events, for instance, predicts a sense of meaning but also unhappiness. Anxiety is also positively correlated with meaning but negatively correlated with happiness. Meaning increases with certain kinds of suffering; the meaningfulness of a particular group or experience is proportional to the suffering incurred to join. More intense initiation or hazing rituals create more meaningful bonds within the group. More demanding or more religious utopian communes tend to last longer than their more easy-going or secular brethren. The experience of meaning in proportion to negative experiences is somewhat malleable. When people are reminded of the costly, negative aspects of a source of meaning, such as the high economic cost of children,17 their evaluation of the source of meaning becomes more positive and more meaningful in comparison with people who are given a more positive spin on childrearing. Meaning appears in proportion to the suffering that occasions it, and meaning can quickly smooth over uncomfortable inconsistencies revealed in one’s worldview. From the outside, it appears to be an illusion; from the inside, it is experienced as powerful and profound. Illusion of control Some sources of meaning provide actual control over the world and one’s circumstances. Some only provide the illusion of control,18 which may be just as good. In 1969, researchers tested stress responses to loud noises. Subjects who were blasted with loud noise found the experience very distressing. In one group, however, each participant was given a button; this button, they were told, would turn off the noise if it got too bad. None of these subjects used their button (which wasn’t plugged in anyway), but they mostly felt a lot better about the noise. Shamans, witches, and even medical doctors often provide an illusion of control to suffering people. A love spell or a bottle of cholesterol pills probably won’t have much real-world effect, but such props can provide a much-needed sense of control to a suffering person. Life, perhaps, would be more enjoyable and less miserable if it were not mandatory. The Story When meaning takes the form of a narrative, this is another illusion, though again perhaps a benevolent one. Narratives help us organize the past according to the needs of a present self. The stories we tell ourselves about ourselves also help us plan for the future, as with goals and fulfillments. There is one particular story that is among our most resilient pieces of cultural information. It arises spontaneously on all continents at various times, and quickly spreads. Depending on its specifics and its messenger, this story can facilitate a revolution or it can protect the status quo. The story is the one about bad people doing bad things, and how they are responsible for the problems in the world. These bad people must be rooted out and stopped for the sake of the country and—often quite literally—the children. A folklore term for this kind of story is a “subversion myth.” Historical examples abound; here are a few from Jeffrey S. Victor’s paper19 “Satanic Cult Rumors as Contemporary Legend”: In Ancient Rome, the stories commonly claimed that Christians were kidnapping Roman children for use in secret ritual sacrifices. Later, during the Middle Ages, the stories claimed that Christian children were being kidnapped by Jews, again for use in secret ritual sacrifices…In France, just before the French Revolution, similar stories accused aristocrats of kidnapping the children of the poor, for use of their blood in medical baths. [Citations omitted.] Police in modern Saudi Arabia routinely hunt, arrest, prosecute, and execute witches. In the early 1980s, Christian religious programming on state-run television in Benin, Nigeria, generally condemned Western influence and blamed the country’s problems on corruption and witchcraft.20 The Benin example highlights that the vilified class need not exist in reality for the story to be effective, as with the satanic cult ritual abuse panics of the 1980s and to some extent the modern wars on terror and bigotry. What makes the story of bad guys so popular? Mainly, it provides a universally applicable justification for why things are not going well. In human societies, things are generally not going well in a variety of ways, at least from the perspective of individual members. But subversion myths arise in times of special trouble; as Victor puts it, they “usually arise at times when a society is undergoing a deep cultural crisis of values, after a period of very rapid social change has caused much disorganization and widespread social stress.” This justification for things not going well satisfies people’s need for an explanation. A story that vilifies those in power may precede (and perhaps precipitate) a revolution, as in France. Revolutions are particularly likely to occur when things are really, really not going well in a society in the first place, hence there is a great perceived need for an explanation. A story that vilifies others, however, is useful once the revolutionaries have seized power and become the government, with an interest in maintaining the status quo. When religious movements like Islamism, democracy, Christianity, and communism first come into power, things are generally pretty bad; the new government has something like regression to the mean on its side. Unfortunately, political societies are delicate, carefully evolved systems and it’s amazing that they limp along at all; attempts at reform, like mutations in DNA, usually make things worse. Yet the story offers hope. Millions of scapegoats have been executed by governments in service of this story. Despite its flaws, the story is certainly more comfortable than suddenly accepting that large human societies just can’t be very good or wise or fair or free, and that attempts to manipulate the intricate yet lumbering social ecosystem, no matter how well-meaning and carefully researched, usually make things worse. Non-fungibility of meaning A final illusion that meaning creates is one of particular specialness with regard to the source of meaning. People get attached to sources of meaning and regard them as irreplaceable. Actually, it does not seem to matter what source of meaning appears, as long as one is found.",
      "word_count": 3942,
      "character_count": 24544,
      "chapter_number": 8,
      "section_number": null,
      "paragraph_number": 1,
      "start_position": 0,
      "end_position": 24544,
      "parent_chunk_id": "sarah_perryevery_cra_unknown_ch8"
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch9",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "chapter",
      "title": "Chapter Three: The Modern Sacredness and Moral Foundations",
      "content": "Chapter Three: The Modern Sacredness and Moral Foundations Sacredness is a universal human phenomenon. Emile Durkheim proposed that religion operates in all human societies, whether visibly or not: wherever there is a moral community, it will display particular beliefs and practices for the veneration and maintenance of its sacred objects. Sacredness is often invisible from the inside, but we can see its nature when it changes rapidly over a short period of time. The trajectory of smoking in American culture from the 1980s to the present is a case study in the formation of a modern sacredness. Smoking was common during the middle of the last century—in restaurants, in offices, even on airplanes. But public focus began to be drawn to the harms of smoking, especially cancer. Tobacco companies were vilified for selling deadly products and for hiding their deadly nature; cigarettes themselves absorbed some of this moral indignation. Not only the act of smoking but also images of cigarettes were regulated and prohibited. The proportion of smokers in the United States plummeted over a few decades. Cigarettes became not just harmful, but ritually impure, a sacredness violation. The prohibition’s magical, religious nature can be seen in the way that cigarettes ritually contaminate activities similar to smoking, but without any of the harm that justified the marginalization of cigarette smoking. Nicotine inhalers have gained popularity in the United States, offering nicotine delivery in a manner functionally similar to smoking, but without any of the carcinogens released by burning tobacco. This practice has been the subject of bans and strict regulation in many states, cities, and private companies. What has happened is that the impure, profane act of cigarette smoking has rubbed off its residue of moral degradation onto the behaviorally similar act of using a nicotine inhaler. Breastfeeding in the United States has undergone an opposite trajectory. A few decades ago, breastfeeding was an act performed in private, and only in desacralized areas. (My own mother remembers not being allowed to breastfeed in the Mormon church when I was a baby, over thirty years ago.) Public breastfeeding was an unspoken violation, and as such would have been disturbing to witness. However, activist pro-breastfeeding groups such as La Leche League formed networks of new mothers, transmitting pro-breastfeeding ideas from woman to woman, insisting that they conceive of breastfeeding as natural, not sexualized, and not shameful. These ideas are now widely held, even somewhat sacralized, and public breastfeeding is much more common. Employers must accommodate the breastfeeding schedules of their workers. Even the Mormon church now encourages and supports the practice. Criticism of or threats to breastfeeding are now seen as sacredness violations, whereas decades earlier public breastfeeding would have been the shocking violation. Sacredness illuminates a practice or an object with a halo of righteousness, or casts onto it an aura of contemptibility. It functions to limit the discussion that is permissible surrounding the sacred object, including the nature of its depiction in art and culture. The cognitive phenomenon of sacredness even limits the thoughts that are comfortable for an individual to have regarding the sacred object. Morphology of the Sacred What is the sacred? What does it look like, and how does it behave? Jonathan Haidt, investigator and popularizer of moral foundations theory, gives the following hint about the sacred: “The fundamental rule of political analysis from the point of psychology is, follow the sacredness, and around it is a ring of motivated ignorance.” This epistemic feature— that sacredness protects itself by tabooing the wrong kinds of thought near its foundations—is exploited in the foundational legends of a culture, origin stories that are often sources of sacredness. Folklorist Linda Dégh might be regarded as an expert on the folkloric legend (as distinct from märchen, magic stories that English speakers would refer to as “fairy tales”). The main difference is that the legend is a personal story that invites genuine disbelief (think “urban legend”), whereas märchen are impersonal stories that are clearly not intended to be believed. But sacred, foundational narratives are not ordinary legends, she says. In discussing the definition of the legend, Dégh says that there are some stories that she excludes from the label “legend”: Arguing for the disputability factor as crucial, I excluded legend-like narratives that enforce belief and that deny the right of disbelief or doubt, narratives that express majority opinion and are safeguarded by moral taboos from negation and, what is more, from deviation.21 Dégh’s examples are “religious (Christian, hagiographic, or saint’s) legends,” and the “patriotic (heroic) legends dispensed through school education by governments, confirming citizens in civil religiosity.” Not only churches may form moral communities that function as religions, but ostensibly secular societies as well. We may not really question the harmfulness of tobacco or the benefits of breastfeeding and remain truly polite. Sacred beliefs are those that are held by consensus within the moral community. It is useful for groups to share sacred beliefs—indeed, even outlandish beliefs—as these are costly signals of commitment to the group that enhance trust and cooperation within the religious community. Cognitive and social mechanisms reduce expression of ideas that threaten the sacred belief or object, and these social mechanisms have the function of a moral taboo to protect sacred truths from negation, or sacred purity from violation. As a result, people are indignant at the suggestion of trading off sacred values for ordinary values—and the more nakedly obvious the trade-off is made, the more indignant they will be. Sacred beliefs are so powerful that outlandish beliefs are often maintained—even strengthened—in the face of strong disconfirmatory evidence. In their now-classic study,22 Festinger et al. give an account of a UFO cult whose leader predicted the destruction of the earth on December 20, 1954. The leader claimed that a spaceship would come before the destruction to rescue the faithful believers, but when the spaceship did not arrive as predicted and the world was not destroyed, the group faced a serious threat to its underlying sacred beliefs for which the members had sacrificed a great deal. Yet the group did not dissolve in shame. They were receptive to a new message received by their leader, to the effect that their faithfulness had spared the world from destruction. The group is reportedly still active today. The group-maintained sacred belief was so strong that even the most damaging possible evidence was not enough to undermine it. So much for the UFO crazies. But it was only a couple of decades ago in the United States that it was widely believed that satanic cults were abusing and murdering vast numbers of children. The McMartin Preschool trial allowed prosecutors to spin a tale of the perfect sacredness violation: an evil conspiracy by entrusted adults to sexually abuse vulnerable children. As unprecedented numbers of women entered the workforce in the 1980s the expanded use of daycare increased guilt and uncertainty associated with leaving children under the supervision of unrelated caregivers, setting the stage for the perfect sacredness violation to become a moral panic. No convictions resulted from the McMartin Preschool trial, but over the course of the three-year trial the lives of the accused were irreparably damaged. Similar accusations would soon lead to the erroneous prosecution, conviction and imprisonment of many unfortunate scapegoats.23 The Arkansas teens known as the “West Memphis Three,” for example, were convicted of ritually murdering three children toward the end of the moral panic in 1994,24 despite the fact that no forensic evidence tied any of them to the crimes; they were released in 2011 after spending over eighteen years in prison. The connection between sacredness and victimhood can be understood from such examples. Innocent children left in the care of strangers provided the most vulnerable possible victims, and better yet for memetic transmissibility, this victim status was up for grabs. Recovered memory therapists sought clients with the message that anyone might be a victim of satanic ritual abuse and not know it. The offer of status and attention for “recovering” memories of abuse found many takers. It is often the case that when a sacred belief assigns special status to victims of particular holiness, the number of these extra-holy victims grows. A Window into Sacredness: The Violation Sacredness is most clearly revealed in its violation, especially in the modern world in which conflicting worldviews often collide. The violation of sacredness triggers the social mechanisms that protect the sacred object from attack. The sacredness system may be viewed as having two components: first, the individual human capacity to perceive and respond to sacredness; and second, the cultural items that are held to be sacred. There is great variety in the nature of things held to be sacred, though these follow regular patterns, generally representing collective group interests. Fashions in sacredness travel quickly, as illustrated in the introductory examples. The human capacity to perceive sacredness—sacredness susceptibility—varies within human populations and likely between populations, though probably more in magnitude than in the nature of the underlying psychological processes. The window into the workings of sacredness is especially wide in the modern world, in which members of different moral communities with conflicting sacrednesses frequently interact. In an established, insular community in which everyone understands the same sacredness and wishes to avoid giving offense (thus risking rejection from the community), sacredness violations are likely much rarer. Sacred beliefs can only be maintained by the community, but they are stored in the minds and bodies of community members as part of their individual and group identities. To a believer in a particular sacredness, an attack on that sacredness is an attack on himself. Sacredness violations are perceived as aggressions, and produce similar physiological states of arousal; the poor person experiencing an attack on his sacred foundation has no choice whether to feel this psychological pain. Relying on a particular sacredness leaves us vulnerable to violations—and our responses to this violation protect the sacred object. We must choose our sacrednesses wisely; circling the totems of our community is an excellent strategy. Thanks to the candor of Internet communications, we know something about the physiological effects of suffering a sacredness violation. When confronted with a threatening worldview, sufferers report a variety of physical symptoms, such as heart pounding, shaking, and vision changes; some think they will “black out” from rage. These symptoms line up well with a “fight or flight” arousal response to aggressive threats. Indeed, in this state, the victim of the sacredness violation wishes violence (and even a violent end) on the violator with disturbing frequency, even when the sacredness violation was not violent in nature.25 Sacredness violations threaten all four types of meaning detailed in Chapter 2. First, our sacred objects are frequently identical with our value bases or terminal values; the threat to the sacred is a threat to the foundation of all else. Second, sacredness violations may threaten the plausibility of fulfillment states, the (largely imaginary) future states of perfect happiness and justice that we are all supposed to be working toward and making it easier for each other to believe in. Third, sacredness violations that relate to identity and self-worth are particularly painful; the modern self carries a heavy burden of meaning, and even very mild and realistic reminders of one’s own ordinariness or mediocrity can be devastating. When one has attached a sacred meaning to an aspect of his identity, the threat to this sacred meaning is perceived the same as a threat to his physical person. Finally, sacredness violations threaten efficacy, making us feel powerless in the face of attack; it is common for individuals so threatened to attempt to form a coalition of sacredness violation victims with which to confront the violator. It is important to understand that sacredness violations actually do subjectively hurt the person experiencing the violation, and that he has little or no control over this process. Empathy demands attention to sacredness, and sacredness is maintained and standardized within the community as much by the desire to avoid hurting others as by the desire to avoid being exiled from the group for insufficient piety. This process means that what is held sacred by people within a moral community will tend to converge on a consensus, even if they start out with a variety of notions of the sacred. In sum, when a sacredness violation occurs the victim whose sacredness is threatened perceives an aggression and enters a state of fight-or-flight arousal. When the reaction is threatening enough the victim will seek to form a coalition condemning the sacredness violation. (Incidentally, this has the effect of spreading the offending violation to more eyes and ears; some publicity strategies specialize in triggering a sacredness reaction in the hope that it will lead to sharing as part of coalition building.) Finally, if a powerful enough coalition forms, the violator will be sanctioned, either with threats or actual harm, up to and including the loss of his social position. Sacredness Negotiations This “converging on consensus” describes the negotiations for sacredness within a group. These negotiations are vulnerable to being turned to the benefit of savvy individuals at the expense of the group; sacredness, like honesty, is as much an exploit as a feature. Honesty is a valuable quality in a cooperation partner, hence a valuable quality to signal; a display of genuine honesty may often be the most effective way to signal trustworthiness and thereby secure cooperation. Similarly, those who are susceptible to sacredness are valuable as sincere cooperation partners since they are unlikely to defect. Signaling that one is susceptible to sacredness is therefore valuable, and actually being susceptible to sacredness might be the best way to do this. Experiencing sacredness together—mutually acknowledging invisible but tacitly understood objects—enables human coordination at a high level of complexity. When groups are in conflict, sacrednesses battle rather than being negotiated; each side holds more firmly to its sacred beliefs even when—especially when—presented with threatening evidence. Within groups that reproduce cultural items, some of which are sacred, these cultural items undergo evolutionary processes. They mutate and change if not held in check, and they do so in particular patterns. Since sacredness is ultimately a kind of signal, it may become the central instrument in a process similar to that hypothesized to burden some animals with fitness-detracting sex characteristics in “runaway” sexual selection. Both humans themselves and their sacred objects evolve together; this is multi-level selection. At the level of cultural evolution, symbols acquire their own reality. Sacredness draws resources toward symbolic complexity and away from the underlying foundational reality. Old cultures achieved equilibrium with their human hosts, or disappeared; new cultures in an environment of rapid technological change mutate beyond anything seen before. Moral Foundations Jonathan Haidt’s moral foundations model describes human moral reasoning as the product of several cognitive processes, which are mostly intuitive and non-rational. The top candidates for “rational” moral foundations are the harm/care foundation (caring for others and not harming them) and the fairness/cheating foundation (regarding norms of fairness and desert). Haidt has argued that political liberals use only these two moral foundations in moral decision making, whereas conservatives have three more capacities: loyalty (the preference of the in-group over the out-group), authority (respect for hierarchy and role), and sanctity or purity (which is at the heart of this chapter on sacredness). However, Haidt recognizes that even political liberals maintain a “zone of motivated ignorance” around their sacred concepts and beliefs. Recently, Haidt has endorsed a sixth category of moral foundation, liberty/oppression, or preferring freedom to coercion; this is the moral foundation that most characterizes libertarians. It is likely that moral communities of all political varieties use all moral foundations; it is just harder to see the sacred moral foundations of the dominant moral community, as even the investigation into whether something is sacred may be seen as a sacredness violation. Haidt points out that while the students involved in the Weather Underground bombing were firmly grounded in the harm/care foundation, they were able to engage in harm—bombing—because they sacralized the victims (e.g., Native Americans) of their enemy. Many conflicts become apparent when we try to imagine that modern liberal political reasoning is immune to loyalty, authority, or sanctity. First, liberals as much as conservatives tend to confuse a sacred symbol with its referent, lending an aura of sanctity to what might otherwise be a pure harm/care consideration. Not only was smoking cigarettes restricted and prohibited, but also representations of smoking (so as not to send the wrong messages to children) and eventually smoking’s largely harmless cousin, the nicotine vaporizer. To engage with a more emotionally charged example, consider rape. Few people would deny that rape is a serious harm, but even the insufficiently pious discussion of rape may be perceived as a sacredness violation. Second, sacred beliefs that are naturally defended out of harm/care or fairness concerns (and hence presumably up for utilitarian calculus) are not, in fact, analyzed for overall harm or fairness. Anti-discrimination policies (as against women, racial groups, people with disabilities, and gay people) are enacted without provision to measure their realworld effects. To even suggest that these policies, based on sacred beliefs, have bad outcomes for the very people they were ostensibly designed to help, is treated as a sacredness violation. Health care is viewed as a clear case of harm/care, but as with anti-discrimination laws, outcome measures are often lacking compared with a refusal to “trade off ” the sacred value of health against other values that also affect quality of life. Expressions of shock over the prospect of “rationing” medical treatments or over “death panels” exemplify the sacralization of health care. Third, loyalty in the modern liberal way of thinking is imagined to be spread amongst all humanity, not limited to a petty in-group. However, in practice, modern liberals do seem to recognize a political out-group against whom calls for violence are permitted and even encouraged. Emphasis on the low social status of political enemies is a milder tactic that nevertheless illustrates the working of the loyalty foundation. Fourth, the fairness foundation would seem to be in conflict with an ideology that enshrines the “Just World Fallacy” as doctrine in its ethic of education for all, to solve all problems. This logic works out in a manner that will be familiar to theologians: on the one hand, legal policies are changed to ensure that educational opportunities are widely available to disadvantaged groups, from Head Start to college. On the other hand, these policies do not seem to lead to equality the way they should (according to the committed beliefs of political liberals). But rather than challenge the sacred beliefs underlying the conflict, an enemy is posited to explain away the apparent discord: entrenched oppression and discrimination must still be present, despite the best efforts of reformers, and true believers must renew their commitment to eradicating it. This process is reminiscent of the way many Christians resolve the Problem of Evil, or the contradiction between a loving, powerful God and the misery apparent in the world: they posit an enemy, the Devil, who is responsible for evil. Both forms of evil—discrimination and the Devil—serve the function of supporting a sacred belief system and avoiding dissonance. Sacrednesses Old and New Emile Durkheim described the death of gods as the failure of groups to maintain the sacred objects (gods) as “social technology” in the face of a rapidly changing world. He noticed the emergence of a Cult of the Individual that he hoped might take the place of gods in providing sacredness. Baumeister documented the tensions and failure modes of the self-as-source-of-meaning strategy (see Chapter 2), resulting in the unnaturally stressed modern self and the suffering it endures (and often tries to escape). Durkheim also noted the emergence of a new, modern religion whose sacred objects, rather than gods, were equality, justice, and individual freedom. Indeed, these are sacred values today, and violations that threaten them often trigger the fight-or-flight responses described earlier. A “ring of motivated ignorance” surrounds these values, protecting them from rigorous examination. Unfortunately, these sacred value bases have shown themselves to be fragile; they are more vulnerable than the old gods to exploitation by status seekers, and they are more susceptible to churn and change that leads to the destruction of social capital. Equality is the foremost sacred value of the secular religion of the West. Equality before the law is connotationally extended, in the logic of sacred things, to imply equality of important inherent characteristics. To threaten the sacred idea of racial equality is a transgression particularly likely to result in sanctions against the violator. Gender equality (and, more recently, equality across sexual orientation and gender identity) is another especially sacred value. The sacred value of women is complex and contradictory; the modern religion axiomatically defines women as equal to men, ascribing any differences to sexist rearing and social expectations, but women are also treated as special victims in need of protection. The sacralization of rape (that is, viewing rape as a special sacredness violation whose mere symbolic representation has the power to harm) harnesses this contradiction. The work ethic, Baumeister argues, is not the age-old sacred moral foundation it once pretended to be; rather, it is a novel, modern invention that filled, for a time, the value gap created by rapid industrialization. The work ethic relied on contradictions that made it ultimately unstable. “The work ethic failed because it increasingly became incompatible with actual human experience,” Baumeister says.26 Workers were expected to see work as a source of long-term reward and social mobility, but these promises were quickly seen to be bogus. Work was at once seen as having intrinsic value (work for work’s sake) and extrinsic value (for money and status). These values proved difficult to reconcile psychologically, and an ethic that demanded self-denial was at odds with a culture that increasingly promoted consumption and self-expression. And, of course, work was getting more and more boring all the time. In our time, the education ethic has replaced the work ethic. As a modern sacred value, education provides a fulfillment state both in the personal and the societal sense. In the personal sense, education promises a future state of high status and advancement, all deserved through one’s own work and skills. In a societal sense, education is extolled as a basis for advancement that can be distinguished from inherited intelligence—an idea comfortably compatible with the premise of basic equality. However, in the foundation of the education ethic one can detect cracks similar to those that were the undoing of the work ethic. High expectations of fulfillment states are met with mediocre job prospects. Analyzed economically, education appears to offer more opportunity for signaling inborn intelligence than for actually increasing intelligence, productivity, or status. Women in particular are tempted to spend years educating themselves in the hope of making a higher status match, but are often disappointed; years of aging while in school generally reduce their mating value more than the education acquired increases it. The view that education equals intelligence—that environment is everything and that genes matter not at all in important matters—is highly compatible with the sacred value of equality. Higher education—indeed, even the prison-like primary and secondary education required of young citizens—functions as a sacred and very costly ritual to ensure high status and group belonging. The costs are internalized by the young people who gamble on their culture’s sacred beliefs—and through this process the ravenous culture comes to own their future productivity, while rarely delivering on its promises. The profligate dumping of money into education can be understood as a case of runaway signaling; more and more resources are devoted to an exercise that has less and less contact with non-symbolic reality. Old sources of sacredness have survived but are now encountered in a new way. Children probably always provided a source of ultimate meaning and sacredness, but now they are more sacred than ever, and in different ways. Children, now being very costly to raise, no longer provide a financial benefit to their parents. So children must instead provide meaning to make up for the missing material benefits. Having children is also, for the first time in human experience, genuinely a choice rather than a matter of course or providence. This choice must be justified, as it did not have to be in the past. Sacredness may be detected in its violation, but it is also a positive phenomenon. The sacredness of motherhood (another old sacredness) can be detected in that marginal groups emphasize their connection to maternity in order to assert legitimacy. Sex workers emphasize that they are mothers in order to justify their stigmatized career path. “Stay-at-home-mom” has become an approved euphemism for the older term “housewife,” which is now considered embarrassing without the boost of sacralization from motherhood. A Necessary Danger Sacredness is necessary for the coordination of human action, for politics, for orderly human life. It is essentially a valuable illusion created cooperatively by the social unit, often over a long time at great cost, and then maintained and defended against mutations and competing sacredness structures. Sacredness secretly informs all of our judgments, even those that seem to be purely related to harm or fairness— indeed, even those that don’t seem to have a moral dimension. Old sacredness structures that coevolved with our ancestors over generations have crumbled in the face of rapid social and technological change. Will our new sources of sacredness provide the basis for a flourishing, stable society? Or will they too crumble—or spin off into forms of increasing complexity and fragility? It is possible that the swift mutation and spread of sacred ideologies may prove destabilizing and destructive. Like invasive species, newly coined values are untested within our rapidly changing ecosystem. Sacredness organizes human behavior and helps groups ease individual suffering by providing a sense of meaning. But sacredness is also a source of suffering and misery, with the potential for rapid, destructive sweeps. Removing the sacredness from human life is not a goal that is likely to be achieved, nor even a very desirable one. Our responsibility is to examine our own cognition as best as we are able, including that part of our cognition that perceives and responds to sacredness. By watching ourselves and others as we experience sacredness and its violation under many circumstances, we lay a foundation to be able to judge—and perhaps engineer— sacred objects.",
      "word_count": 4392,
      "character_count": 28547,
      "chapter_number": 9,
      "section_number": null,
      "paragraph_number": null,
      "start_position": 0,
      "end_position": 28547,
      "parent_chunk_id": null
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch9_p1",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "paragraph",
      "title": "Paragraph 1",
      "content": "Chapter Three: The Modern Sacredness and Moral Foundations Sacredness is a universal human phenomenon. Emile Durkheim proposed that religion operates in all human societies, whether visibly or not: wherever there is a moral community, it will display particular beliefs and practices for the veneration and maintenance of its sacred objects. Sacredness is often invisible from the inside, but we can see its nature when it changes rapidly over a short period of time. The trajectory of smoking in American culture from the 1980s to the present is a case study in the formation of a modern sacredness. Smoking was common during the middle of the last century—in restaurants, in offices, even on airplanes. But public focus began to be drawn to the harms of smoking, especially cancer. Tobacco companies were vilified for selling deadly products and for hiding their deadly nature; cigarettes themselves absorbed some of this moral indignation. Not only the act of smoking but also images of cigarettes were regulated and prohibited. The proportion of smokers in the United States plummeted over a few decades. Cigarettes became not just harmful, but ritually impure, a sacredness violation. The prohibition’s magical, religious nature can be seen in the way that cigarettes ritually contaminate activities similar to smoking, but without any of the harm that justified the marginalization of cigarette smoking. Nicotine inhalers have gained popularity in the United States, offering nicotine delivery in a manner functionally similar to smoking, but without any of the carcinogens released by burning tobacco. This practice has been the subject of bans and strict regulation in many states, cities, and private companies. What has happened is that the impure, profane act of cigarette smoking has rubbed off its residue of moral degradation onto the behaviorally similar act of using a nicotine inhaler. Breastfeeding in the United States has undergone an opposite trajectory. A few decades ago, breastfeeding was an act performed in private, and only in desacralized areas. (My own mother remembers not being allowed to breastfeed in the Mormon church when I was a baby, over thirty years ago.) Public breastfeeding was an unspoken violation, and as such would have been disturbing to witness. However, activist pro-breastfeeding groups such as La Leche League formed networks of new mothers, transmitting pro-breastfeeding ideas from woman to woman, insisting that they conceive of breastfeeding as natural, not sexualized, and not shameful. These ideas are now widely held, even somewhat sacralized, and public breastfeeding is much more common. Employers must accommodate the breastfeeding schedules of their workers. Even the Mormon church now encourages and supports the practice. Criticism of or threats to breastfeeding are now seen as sacredness violations, whereas decades earlier public breastfeeding would have been the shocking violation. Sacredness illuminates a practice or an object with a halo of righteousness, or casts onto it an aura of contemptibility. It functions to limit the discussion that is permissible surrounding the sacred object, including the nature of its depiction in art and culture. The cognitive phenomenon of sacredness even limits the thoughts that are comfortable for an individual to have regarding the sacred object. Morphology of the Sacred What is the sacred? What does it look like, and how does it behave? Jonathan Haidt, investigator and popularizer of moral foundations theory, gives the following hint about the sacred: “The fundamental rule of political analysis from the point of psychology is, follow the sacredness, and around it is a ring of motivated ignorance.” This epistemic feature— that sacredness protects itself by tabooing the wrong kinds of thought near its foundations—is exploited in the foundational legends of a culture, origin stories that are often sources of sacredness. Folklorist Linda Dégh might be regarded as an expert on the folkloric legend (as distinct from märchen, magic stories that English speakers would refer to as “fairy tales”). The main difference is that the legend is a personal story that invites genuine disbelief (think “urban legend”), whereas märchen are impersonal stories that are clearly not intended to be believed. But sacred, foundational narratives are not ordinary legends, she says. In discussing the definition of the legend, Dégh says that there are some stories that she excludes from the label “legend”: Arguing for the disputability factor as crucial, I excluded legend-like narratives that enforce belief and that deny the right of disbelief or doubt, narratives that express majority opinion and are safeguarded by moral taboos from negation and, what is more, from deviation.21 Dégh’s examples are “religious (Christian, hagiographic, or saint’s) legends,” and the “patriotic (heroic) legends dispensed through school education by governments, confirming citizens in civil religiosity.” Not only churches may form moral communities that function as religions, but ostensibly secular societies as well. We may not really question the harmfulness of tobacco or the benefits of breastfeeding and remain truly polite. Sacred beliefs are those that are held by consensus within the moral community. It is useful for groups to share sacred beliefs—indeed, even outlandish beliefs—as these are costly signals of commitment to the group that enhance trust and cooperation within the religious community. Cognitive and social mechanisms reduce expression of ideas that threaten the sacred belief or object, and these social mechanisms have the function of a moral taboo to protect sacred truths from negation, or sacred purity from violation. As a result, people are indignant at the suggestion of trading off sacred values for ordinary values—and the more nakedly obvious the trade-off is made, the more indignant they will be. Sacred beliefs are so powerful that outlandish beliefs are often maintained—even strengthened—in the face of strong disconfirmatory evidence. In their now-classic study,22 Festinger et al. give an account of a UFO cult whose leader predicted the destruction of the earth on December 20, 1954. The leader claimed that a spaceship would come before the destruction to rescue the faithful believers, but when the spaceship did not arrive as predicted and the world was not destroyed, the group faced a serious threat to its underlying sacred beliefs for which the members had sacrificed a great deal. Yet the group did not dissolve in shame. They were receptive to a new message received by their leader, to the effect that their faithfulness had spared the world from destruction. The group is reportedly still active today. The group-maintained sacred belief was so strong that even the most damaging possible evidence was not enough to undermine it. So much for the UFO crazies. But it was only a couple of decades ago in the United States that it was widely believed that satanic cults were abusing and murdering vast numbers of children. The McMartin Preschool trial allowed prosecutors to spin a tale of the perfect sacredness violation: an evil conspiracy by entrusted adults to sexually abuse vulnerable children. As unprecedented numbers of women entered the workforce in the 1980s the expanded use of daycare increased guilt and uncertainty associated with leaving children under the supervision of unrelated caregivers, setting the stage for the perfect sacredness violation to become a moral panic. No convictions resulted from the McMartin Preschool trial, but over the course of the three-year trial the lives of the accused were irreparably damaged. Similar accusations would soon lead to the erroneous prosecution, conviction and imprisonment of many unfortunate scapegoats.23 The Arkansas teens known as the “West Memphis Three,” for example, were convicted of ritually murdering three children toward the end of the moral panic in 1994,24 despite the fact that no forensic evidence tied any of them to the crimes; they were released in 2011 after spending over eighteen years in prison. The connection between sacredness and victimhood can be understood from such examples. Innocent children left in the care of strangers provided the most vulnerable possible victims, and better yet for memetic transmissibility, this victim status was up for grabs. Recovered memory therapists sought clients with the message that anyone might be a victim of satanic ritual abuse and not know it. The offer of status and attention for “recovering” memories of abuse found many takers. It is often the case that when a sacred belief assigns special status to victims of particular holiness, the number of these extra-holy victims grows. A Window into Sacredness: The Violation Sacredness is most clearly revealed in its violation, especially in the modern world in which conflicting worldviews often collide. The violation of sacredness triggers the social mechanisms that protect the sacred object from attack. The sacredness system may be viewed as having two components: first, the individual human capacity to perceive and respond to sacredness; and second, the cultural items that are held to be sacred. There is great variety in the nature of things held to be sacred, though these follow regular patterns, generally representing collective group interests. Fashions in sacredness travel quickly, as illustrated in the introductory examples. The human capacity to perceive sacredness—sacredness susceptibility—varies within human populations and likely between populations, though probably more in magnitude than in the nature of the underlying psychological processes. The window into the workings of sacredness is especially wide in the modern world, in which members of different moral communities with conflicting sacrednesses frequently interact. In an established, insular community in which everyone understands the same sacredness and wishes to avoid giving offense (thus risking rejection from the community), sacredness violations are likely much rarer. Sacred beliefs can only be maintained by the community, but they are stored in the minds and bodies of community members as part of their individual and group identities. To a believer in a particular sacredness, an attack on that sacredness is an attack on himself. Sacredness violations are perceived as aggressions, and produce similar physiological states of arousal; the poor person experiencing an attack on his sacred foundation has no choice whether to feel this psychological pain. Relying on a particular sacredness leaves us vulnerable to violations—and our responses to this violation protect the sacred object. We must choose our sacrednesses wisely; circling the totems of our community is an excellent strategy. Thanks to the candor of Internet communications, we know something about the physiological effects of suffering a sacredness violation. When confronted with a threatening worldview, sufferers report a variety of physical symptoms, such as heart pounding, shaking, and vision changes; some think they will “black out” from rage. These symptoms line up well with a “fight or flight” arousal response to aggressive threats. Indeed, in this state, the victim of the sacredness violation wishes violence (and even a violent end) on the violator with disturbing frequency, even when the sacredness violation was not violent in nature.25 Sacredness violations threaten all four types of meaning detailed in Chapter 2. First, our sacred objects are frequently identical with our value bases or terminal values; the threat to the sacred is a threat to the foundation of all else. Second, sacredness violations may threaten the plausibility of fulfillment states, the (largely imaginary) future states of perfect happiness and justice that we are all supposed to be working toward and making it easier for each other to believe in. Third, sacredness violations that relate to identity and self-worth are particularly painful; the modern self carries a heavy burden of meaning, and even very mild and realistic reminders of one’s own ordinariness or mediocrity can be devastating. When one has attached a sacred meaning to an aspect of his identity, the threat to this sacred meaning is perceived the same as a threat to his physical person. Finally, sacredness violations threaten efficacy, making us feel powerless in the face of attack; it is common for individuals so threatened to attempt to form a coalition of sacredness violation victims with which to confront the violator. It is important to understand that sacredness violations actually do subjectively hurt the person experiencing the violation, and that he has little or no control over this process. Empathy demands attention to sacredness, and sacredness is maintained and standardized within the community as much by the desire to avoid hurting others as by the desire to avoid being exiled from the group for insufficient piety. This process means that what is held sacred by people within a moral community will tend to converge on a consensus, even if they start out with a variety of notions of the sacred. In sum, when a sacredness violation occurs the victim whose sacredness is threatened perceives an aggression and enters a state of fight-or-flight arousal. When the reaction is threatening enough the victim will seek to form a coalition condemning the sacredness violation. (Incidentally, this has the effect of spreading the offending violation to more eyes and ears; some publicity strategies specialize in triggering a sacredness reaction in the hope that it will lead to sharing as part of coalition building.) Finally, if a powerful enough coalition forms, the violator will be sanctioned, either with threats or actual harm, up to and including the loss of his social position. Sacredness Negotiations This “converging on consensus” describes the negotiations for sacredness within a group. These negotiations are vulnerable to being turned to the benefit of savvy individuals at the expense of the group; sacredness, like honesty, is as much an exploit as a feature. Honesty is a valuable quality in a cooperation partner, hence a valuable quality to signal; a display of genuine honesty may often be the most effective way to signal trustworthiness and thereby secure cooperation. Similarly, those who are susceptible to sacredness are valuable as sincere cooperation partners since they are unlikely to defect. Signaling that one is susceptible to sacredness is therefore valuable, and actually being susceptible to sacredness might be the best way to do this. Experiencing sacredness together—mutually acknowledging invisible but tacitly understood objects—enables human coordination at a high level of complexity. When groups are in conflict, sacrednesses battle rather than being negotiated; each side holds more firmly to its sacred beliefs even when—especially when—presented with threatening evidence. Within groups that reproduce cultural items, some of which are sacred, these cultural items undergo evolutionary processes. They mutate and change if not held in check, and they do so in particular patterns. Since sacredness is ultimately a kind of signal, it may become the central instrument in a process similar to that hypothesized to burden some animals with fitness-detracting sex characteristics in “runaway” sexual selection. Both humans themselves and their sacred objects evolve together; this is multi-level selection. At the level of cultural evolution, symbols acquire their own reality. Sacredness draws resources toward symbolic complexity and away from the underlying foundational reality. Old cultures achieved equilibrium with their human hosts, or disappeared; new cultures in an environment of rapid technological change mutate beyond anything seen before. Moral Foundations Jonathan Haidt’s moral foundations model describes human moral reasoning as the product of several cognitive processes, which are mostly intuitive and non-rational. The top candidates for “rational” moral foundations are the harm/care foundation (caring for others and not harming them) and the fairness/cheating foundation (regarding norms of fairness and desert). Haidt has argued that political liberals use only these two moral foundations in moral decision making, whereas conservatives have three more capacities: loyalty (the preference of the in-group over the out-group), authority (respect for hierarchy and role), and sanctity or purity (which is at the heart of this chapter on sacredness). However, Haidt recognizes that even political liberals maintain a “zone of motivated ignorance” around their sacred concepts and beliefs. Recently, Haidt has endorsed a sixth category of moral foundation, liberty/oppression, or preferring freedom to coercion; this is the moral foundation that most characterizes libertarians. It is likely that moral communities of all political varieties use all moral foundations; it is just harder to see the sacred moral foundations of the dominant moral community, as even the investigation into whether something is sacred may be seen as a sacredness violation. Haidt points out that while the students involved in the Weather Underground bombing were firmly grounded in the harm/care foundation, they were able to engage in harm—bombing—because they sacralized the victims (e.g., Native Americans) of their enemy. Many conflicts become apparent when we try to imagine that modern liberal political reasoning is immune to loyalty, authority, or sanctity. First, liberals as much as conservatives tend to confuse a sacred symbol with its referent, lending an aura of sanctity to what might otherwise be a pure harm/care consideration. Not only was smoking cigarettes restricted and prohibited, but also representations of smoking (so as not to send the wrong messages to children) and eventually smoking’s largely harmless cousin, the nicotine vaporizer. To engage with a more emotionally charged example, consider rape. Few people would deny that rape is a serious harm, but even the insufficiently pious discussion of rape may be perceived as a sacredness violation. Second, sacred beliefs that are naturally defended out of harm/care or fairness concerns (and hence presumably up for utilitarian calculus) are not, in fact, analyzed for overall harm or fairness. Anti-discrimination policies (as against women, racial groups, people with disabilities, and gay people) are enacted without provision to measure their realworld effects. To even suggest that these policies, based on sacred beliefs, have bad outcomes for the very people they were ostensibly designed to help, is treated as a sacredness violation. Health care is viewed as a clear case of harm/care, but as with anti-discrimination laws, outcome measures are often lacking compared with a refusal to “trade off ” the sacred value of health against other values that also affect quality of life. Expressions of shock over the prospect of “rationing” medical treatments or over “death panels” exemplify the sacralization of health care. Third, loyalty in the modern liberal way of thinking is imagined to be spread amongst all humanity, not limited to a petty in-group. However, in practice, modern liberals do seem to recognize a political out-group against whom calls for violence are permitted and even encouraged. Emphasis on the low social status of political enemies is a milder tactic that nevertheless illustrates the working of the loyalty foundation. Fourth, the fairness foundation would seem to be in conflict with an ideology that enshrines the “Just World Fallacy” as doctrine in its ethic of education for all, to solve all problems. This logic works out in a manner that will be familiar to theologians: on the one hand, legal policies are changed to ensure that educational opportunities are widely available to disadvantaged groups, from Head Start to college. On the other hand, these policies do not seem to lead to equality the way they should (according to the committed beliefs of political liberals). But rather than challenge the sacred beliefs underlying the conflict, an enemy is posited to explain away the apparent discord: entrenched oppression and discrimination must still be present, despite the best efforts of reformers, and true believers must renew their commitment to eradicating it. This process is reminiscent of the way many Christians resolve the Problem of Evil, or the contradiction between a loving, powerful God and the misery apparent in the world: they posit an enemy, the Devil, who is responsible for evil. Both forms of evil—discrimination and the Devil—serve the function of supporting a sacred belief system and avoiding dissonance. Sacrednesses Old and New Emile Durkheim described the death of gods as the failure of groups to maintain the sacred objects (gods) as “social technology” in the face of a rapidly changing world. He noticed the emergence of a Cult of the Individual that he hoped might take the place of gods in providing sacredness. Baumeister documented the tensions and failure modes of the self-as-source-of-meaning strategy (see Chapter 2), resulting in the unnaturally stressed modern self and the suffering it endures (and often tries to escape). Durkheim also noted the emergence of a new, modern religion whose sacred objects, rather than gods, were equality, justice, and individual freedom. Indeed, these are sacred values today, and violations that threaten them often trigger the fight-or-flight responses described earlier. A “ring of motivated ignorance” surrounds these values, protecting them from rigorous examination. Unfortunately, these sacred value bases have shown themselves to be fragile; they are more vulnerable than the old gods to exploitation by status seekers, and they are more susceptible to churn and change that leads to the destruction of social capital. Equality is the foremost sacred value of the secular religion of the West. Equality before the law is connotationally extended, in the logic of sacred things, to imply equality of important inherent characteristics. To threaten the sacred idea of racial equality is a transgression particularly likely to result in sanctions against the violator. Gender equality (and, more recently, equality across sexual orientation and gender identity) is another especially sacred value. The sacred value of women is complex and contradictory; the modern religion axiomatically defines women as equal to men, ascribing any differences to sexist rearing and social expectations, but women are also treated as special victims in need of protection. The sacralization of rape (that is, viewing rape as a special sacredness violation whose mere symbolic representation has the power to harm) harnesses this contradiction. The work ethic, Baumeister argues, is not the age-old sacred moral foundation it once pretended to be; rather, it is a novel, modern invention that filled, for a time, the value gap created by rapid industrialization. The work ethic relied on contradictions that made it ultimately unstable. “The work ethic failed because it increasingly became incompatible with actual human experience,” Baumeister says.26 Workers were expected to see work as a source of long-term reward and social mobility, but these promises were quickly seen to be bogus. Work was at once seen as having intrinsic value (work for work’s sake) and extrinsic value (for money and status). These values proved difficult to reconcile psychologically, and an ethic that demanded self-denial was at odds with a culture that increasingly promoted consumption and self-expression. And, of course, work was getting more and more boring all the time. In our time, the education ethic has replaced the work ethic. As a modern sacred value, education provides a fulfillment state both in the personal and the societal sense. In the personal sense, education promises a future state of high status and advancement, all deserved through one’s own work and skills. In a societal sense, education is extolled as a basis for advancement that can be distinguished from inherited intelligence—an idea comfortably compatible with the premise of basic equality. However, in the foundation of the education ethic one can detect cracks similar to those that were the undoing of the work ethic. High expectations of fulfillment states are met with mediocre job prospects. Analyzed economically, education appears to offer more opportunity for signaling inborn intelligence than for actually increasing intelligence, productivity, or status. Women in particular are tempted to spend years educating themselves in the hope of making a higher status match, but are often disappointed; years of aging while in school generally reduce their mating value more than the education acquired increases it. The view that education equals intelligence—that environment is everything and that genes matter not at all in important matters—is highly compatible with the sacred value of equality. Higher education—indeed, even the prison-like primary and secondary education required of young citizens—functions as a sacred and very costly ritual to ensure high status and group belonging. The costs are internalized by the young people who gamble on their culture’s sacred beliefs—and through this process the ravenous culture comes to own their future productivity, while rarely delivering on its promises. The profligate dumping of money into education can be understood as a case of runaway signaling; more and more resources are devoted to an exercise that has less and less contact with non-symbolic reality. Old sources of sacredness have survived but are now encountered in a new way. Children probably always provided a source of ultimate meaning and sacredness, but now they are more sacred than ever, and in different ways. Children, now being very costly to raise, no longer provide a financial benefit to their parents. So children must instead provide meaning to make up for the missing material benefits. Having children is also, for the first time in human experience, genuinely a choice rather than a matter of course or providence. This choice must be justified, as it did not have to be in the past. Sacredness may be detected in its violation, but it is also a positive phenomenon. The sacredness of motherhood (another old sacredness) can be detected in that marginal groups emphasize their connection to maternity in order to assert legitimacy. Sex workers emphasize that they are mothers in order to justify their stigmatized career path. “Stay-at-home-mom” has become an approved euphemism for the older term “housewife,” which is now considered embarrassing without the boost of sacralization from motherhood. A Necessary Danger Sacredness is necessary for the coordination of human action, for politics, for orderly human life. It is essentially a valuable illusion created cooperatively by the social unit, often over a long time at great cost, and then maintained and defended against mutations and competing sacredness structures. Sacredness secretly informs all of our judgments, even those that seem to be purely related to harm or fairness— indeed, even those that don’t seem to have a moral dimension. Old sacredness structures that coevolved with our ancestors over generations have crumbled in the face of rapid social and technological change. Will our new sources of sacredness provide the basis for a flourishing, stable society? Or will they too crumble—or spin off into forms of increasing complexity and fragility? It is possible that the swift mutation and spread of sacred ideologies may prove destabilizing and destructive. Like invasive species, newly coined values are untested within our rapidly changing ecosystem. Sacredness organizes human behavior and helps groups ease individual suffering by providing a sense of meaning. But sacredness is also a source of suffering and misery, with the potential for rapid, destructive sweeps. Removing the sacredness from human life is not a goal that is likely to be achieved, nor even a very desirable one. Our responsibility is to examine our own cognition as best as we are able, including that part of our cognition that perceives and responds to sacredness. By watching ourselves and others as we experience sacredness and its violation under many circumstances, we lay a foundation to be able to judge—and perhaps engineer— sacred objects.",
      "word_count": 4392,
      "character_count": 28547,
      "chapter_number": 9,
      "section_number": null,
      "paragraph_number": 1,
      "start_position": 0,
      "end_position": 28547,
      "parent_chunk_id": "sarah_perryevery_cra_unknown_ch9"
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch10",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "chapter",
      "title": "Chapter Four: Experience Machines and Their Ratification",
      "content": "Chapter Four: Experience Machines and Their Ratification Suppose there were an experience machine that would give you any experience you desired. Superduper neuropsychologists could stimulate your brain so that you would think and feel you were writing a great novel, or making a friend, or reading an interesting book. All the time you would be floating in a tank, with electrodes attached to your brain. Should you plug into this machine for life, preprogramming your life’s experiences? —Robert Nozick, Anarchy, State, and Utopia I believe that we should be very cautious about creating conscious beings, and I believe that the ideal number of conscious beings (and perhaps even living beings) in the universe is probably zero, for the good of those beings themselves. Since suffering and misery are inescapable parts of life, if we are to justify creating life there must be something that outweighs suffering and misery within the space of universal judgments. Candidates generally fall into two categories. The first category is essentially hedonist: pleasure or good experiences are said to outnumber or outweigh bad experiences. This is the objection Bryan Caplan is making with his Free Disposal argument, discussed in the first chapter; assuming preferentism (that people choose what is good for them), and assuming that people have free choice in the relevant arenas, people would merely commit suicide if it were not true that the pleasure of life outweighs the suffering. And since only a million people per year commit suicide, creating life is obviously the right choice. A more subtle variation of this argument does not rely on suicide, but on a sort of imaginary survey: most people would probably report that their lives are worth living, that the good outweighs the bad, and therefore it must. The second category of responses is that there is something valuable and meaningful about life that makes it worth living even if the bad vastly outweighs the good. In the previous chapter, we explored and categorized some of the things that people find meaningful, noting how these change according to circumstance and over time. One of the most salient features of the things that make life seem meaningful is that they frequently rely on illusion: the illusion of unchanging permanence, of a future state of happiness, of one’s ability to affect the world. It is my view that the sense of meaningfulness is itself an illusion, a cognitive phenomenon that is very adaptive for individuals and groups. This illusion is maintained by communities in order to organize the behavior of individuals, in part by easing their suffering. One response to this is to counter that meaning is not an illusion—that there is real value in the world beyond what is experienced by living beings. Unfortunately, the proposed real and true meanings are often difficult to express in words to others who do not sense their truth. The feeling that life is meaningful is a pre-rational sensory perception that is widely shared. However, the specific meanings that people find satisfying and convincing are disparate and often contradictory. These underlying realities should make us question whether the sense that life is meaningful—or that some specific meaning can be found in life—is a true observation, or merely an illusion. The very adaptiveness of this belief, even if it were not true, must also make us suspect its veracity. The meaning realist has the further problem that no specific meaning is held by a majority of humanity; if there is one true meaning, then whatever it is, the majority of people’s lives go very badly because they do not perceive it. Another response is that while meanings vary, it is enough that almost everyone finds some meaning in life. In other words, the sense that life is meaningful is enough to justify life, and the myriad meanings found and elaborated by individuals are all, in fact, the meaning of life. This seems to be the most common position articulated in modern post-Christian Western societies: if a person finds his life to be meaningful, then it is meaningful—even if different people find contradictory meanings in life. One person might find a sense of meaning in fighting for equality, another in ethno-nationalism, and they are both right. This second response is actually a variation on hedonism, in that the experience of meaning, rather than the experience of pleasure, provides value. According to this view, a life of overwhelming suffering but with a deep experience of meaning might be better than a life of joy and pleasure that is internally felt to be meaningless. But ultimately, divorced from the meaning realism of the first response, this grounds meaning in subjective experiences; the sense of meaning becomes another form of pleasure. The modern idea that it is up to each individual to find meaning in life, and that this meaning justifies life, means accepting a meaning-based Experience Machine. The things that we find to be meaningful are, in fact, miniature Experience Machines. They rely on illusion and filter the information that reaches us so that we may continue to feel that life is meaningful, or continue to search for meaning in life if it is missing. They are very useful; they help us organize our behavior, coordinate with others, and manage our emotions. In a practical sense they often make the suffering of life bearable; but, once they are recognized to be illusions, they cannot justify suffering in an abstract sense any more than pleasure can. We need not jump into a Nozickian Experience Machine to get pleasure and a sense of meaning from intricate illusions. The Reverse Experience Machine experiment is close to the situation we find ourselves in—if we found out we were in an Experience Machine already, would we choose to leave it for the real world? Institutions, religions, social communities, and even individual people function as Experience Machines, creating and maintaining illusions that help us feel that life is worthwhile. A meaning realist would reject the Experience Machine, but to be consistent he must also reject those aspects of life that use illusion or information filters to provide meaning. A meaning subjectivist has little ground to reject the Experience Machine. This has implications for the justification of life’s misery based on meaningfulness. The True Gifts of the Good People: How Experience Machines Help Us Escape Uncertainty By necessity, each person must form a theory of the world that is abstracted from, and less detailed than, the territory of the world itself. There is no perfect theory; each theory must occasionally break down in the face of experience with the actual world. Many religious ideas are “gap fillers” that explain these breakdowns in models of reality. Experiences such as lost objects seeming to violate object permanence highlight the imperfect nature of one’s theory of reality. Rituals uphold the plausibility structure for the gap filler, self-signalling that the belief is real and substantial. I inherited some household rituals (mostly relating to food preparation) from my older female relatives. It’s strange that they survive to the present day. They are not religious, or rather they are performed regardless of the religion of the woman, being passed in my case with no explanation or justification. These include throwing salt over your shoulder if you should spill it (I later learned this is frequently explained as “throwing salt in the devil’s eye,” but I did not receive this explanation from the relatives I received the ritual from). Another is rubbing the cut end of cucumbers against the cut cucumber to produce a foam. This is supposed to “suck the toxins out of a cucumber.” I still perform this ritual, even though it obviously makes no sense. I am not sure why, but rituals seem valuable for their own sake. I have recently been reading a book of folklore, The Fairy-Faith in Celtic Countries by W. Y. Evans-Wentz, written in 1911. The author traveled around Ireland and its environs, interviewing people and learning their traditions involving pixies, fairies, and the like—euphemized as the Good People, the Gentle People, or sometimes even “them people.” Many of the rituals described are very appealing, and I have begun practicing some of them. One thing that interests me about the legends of the Gentle People is their inscrutable nature: they are at turns cruel and benevolent, sometimes stealing babies from their cribs and sometimes filling the house’s larder with meal. This is the background context for what follows. I recently experienced an object permanence violation, which is to say, my bright blue plastic dish scrubber completely disappeared from my kitchen. This was very strange, as I have a fairly organized kitchen and tend to know where all my kitchen implements are at any given time. But the bright blue dish scrubber was just gone—not in any hiding place big enough to hold it in my entire house. My sense of object permanence was seriously threatened. And in the context of my ritual performance, it actually occurred to me: those asshole fairies stole it! Obviously, the Gentle People did not steal my dish scrubber, inscrutable as they are. What happened was that I failed to record my own behavior, and when thinking about other things, I placed or dropped the scrubber somewhere I would not think to look for it. But it surprised me how easily this thought came to my mind—me, a proper woo-free atheist. I could see why the fairies have a dual nature, naughty and nice: they can act as a gap-filler for all sorts of violations in one’s theory of the world, such as apparent object permanence violations. And every theory violation thus explained becomes evidence for the existence of the fairies, supporting the belief. Of course, the mistaken theory in the case of a lost object is the fallacy of thinking one records one’s actions like a video camera. A lost object is a cognitive phenomenon. But it can definitely feel subjectively like a violation of object permanence. A gap-filler that explains apparent object permanence violations—such as fairies that pilfer things—can be satisfyingly called up to caulk over this hole in one’s theory of the world, supplying the gift of a comfortably whole theory of reality with no gaps. Performing rituals can facilitate belief in such gap-fillers. The act of throwing salt over one’s shoulder after spilling the salt, or taking a tiny bite of dropped food and throwing the rest back “for the fairies,” or referring to fairies euphemistically (“the good people”) creates a kind of plausibility structure for the belief. Acting on a belief makes it more real. Sharing a belief socially with others also makes it more real; there is social proof, and the belief acts as an in-group solidifier. The belief may be socially rendered magical, not subject to rational examination. Subversion myths (the belief in bad guys doing bad things, discussed in the previous chapter), and beliefs about powerful enemies in general, serve the same needs as fairy beliefs: they provide comfortable explanations for experiences that don’t fit into one’s worldview. If a subversion myth begins to be supported by rituals (and other parts of a plausibility structure), it may spread and exist stably for a long time. The Gentle People are ambiguous; they do frightening deeds and benevolent deeds, forcing those in their thrall to commit murder but also to help out around the house. They represent a worldview that is violated in both good and bad directions, one with unexpected misery but also unexpected boons. A widespread subversion myth, however, may suggest a worldview that is mostly violated by bad experiences. The motion from ambiguous, inscrutable mythic beings to purely evil mythic beings is notable. Another possibility is that it accompanies a worldview that is much too nice and positive, and hence mostly needs gap filling when bad events occur. This may be a feature of the Experience Machine that it co-exists with: the more utopian the vision, the more purely evil the gap-filling creatures must be. Another possibility is that it is a feature of the experiences that get through and affect people—a feature of the experienced world—rather than a feature of the theory. A theory will need more patches for bad information if the world gets a lot worse, even if the theory remains the same. Friendly Neighborhood Experience Machines: Where Do They Come From? The belief in fairies seems an obviously pagan belief and precedes Christianity on the islands by many centuries. However, just as Christianity co-opted pagan cultural items for its benefit, the fairy faith rendered itself compatible with Christianity. A legend collected in multiple places (explicitly believed by many sources) is that the fairies are the angels who followed Lucifer out of Heaven and sort of got locked out of Heaven by God, being condemned to live in the caves and hollows of the earth. By fitting the fairies into the Christian legend, the islanders were able to keep their valuable fairy faith with its rituals and traditions while apparently bowing to the memetic sweep of Christianity. Small-scale Experience Machines evolve just like biological organisms; they are aspects of culture subject to mutation, selection, and even extinction in the face of environmental change. Those to whom the thought experiment seems distasteful feel that experiencing life through this Experience Machine would not be real; it would not entail contact with the deepest reality, and would be limited to the creative power of human beings. It would not provide us with pleasing signals about our true selves, but only fictitious signals about an imaginary self. Of course, many people (myself included) would be more than happy to enter a nice Experience Machine rather than undergo the allegedly real slings and arrows of outrageous fortune. But my contention here is that we all utilize one or more genuine Experience Machines all the time. These real life, friendly neighborhood Experience Machines include, most notably, religions and aesthetics. These are socially created, culturally reproduced information artifacts that provide a framework for our experiences, allowing us to select experiences to some degree and to give meaning to all our experiences, selected or not. They are created solely by humans, being further selected and shaped by generations of cultural evolution. They seem to suffer from the same problems as Nozick’s hypothetical Experience Machines in terms of connection to deepest reality, offering information about the true self, and being limited by human creativity. To the extent that you buy that this is so, I argue that you must either deny the realness and desirability of experience mediated by these culturally evolved aesthetic and religious frameworks, or on the other hand allow for the choice to utilize other Experience Machines that may be superior to existing ones in the dimensions of effectiveness, voluntariness, and honesty. This manner of viewing human existence has implications for the desirability of suicide and of bringing new humans into existence. Aesthetics and Religions: A Minor Distinction A distinction between the two main ultimately-not-very-distinct types of homegrown Experience Machines will help communicate the meaning of that term as I use it. The filling out of the category is more important than the distinction. Art requires obstruction; pure, limitless freedom is the death of art. An aesthetic is necessary for the creation and experience of art. This aesthetic need not be explicit or articulable, and frequently includes inarticulable elements. But even purely legible rule sets can create much of the aesthetic context that art needs in order to be meaningful. The Dogme 95 movement (and Lars von Trier’s The Five Obstructions) the salubrious effects of even almost random limitations on art. Daniel Dennett and Douglas Hofstadter have praised the practice of JOOTSing, or jumping out of the system, but an aesthetic or cognitive leap requires a system to jump out of. Without any such system or any limitations, we see shark jumping on the level of contemporary fine art rather than the creation of meaningful experiences. Religions also allow us to create meaningful experiences from the random chaos of sensory experience—especially those scary experiences in which our best theory doesn’t match up with reality. They allow us to believe that we have a meaningful role to play in the heart of something that is deeply meaningful in and of itself. Equipped with this belief, we interpret our experiences accordingly. It is often difficult to tell aesthetics from religions—if in fact there is a difference. Both aesthetics and religions are created and maintained socially; they promote intra-tribal bonding in natural and synthetic tribes, and they facilitate the identification and rejection of outsiders. Both are experience selection devices that help us produce, select, reject, and interpret particular experiences. They are culturally evolved and variable but display observable patterns. The major difference is that aesthetics are much more explicit than religions about pointing to the experience itself, rather than to something higher beyond the experience. Many aesthetics demand that the experience itself be recognized as the ultimate value. Food criticism (along with many other aesthetic domains) has a morality of focusing on the eating experience itself; within that domain, focusing on anything but the experience (such as social signaling) is a shameful sin. Religions, on the other hand, generally claim to point to a higher something, an ultimate value that the experience only evidences and does not subsume. The proper pursuit of this “higher something” leads to meaningful experiences, but the point is not the meaningful experiences but the higher something. Insight porn27 is an aesthetic; truth seeking is a religion. One layer of meaning, one layer of about-ness, separates the aesthetic from the religion. But wild specimens need not be tidily lumped into either category; frequently they display characteristics of both. Experience Machines that are clearly aesthetics may use pointing-to-something-higher in order to produce experiences. Those that clearly seem to be religions may use honest, conscious experience selection just the same. It is common, for example, for aesthetics, not just religions, to promote magical thinking regarding objects in order to produce meaningful aesthetic experiences. The magical history of objects motivates much appreciation and meaningfully contextualizes rapture. In the summer of 2013, I was able to hear Jing Wang as concert master playing Mahler’s Third Symphony. I had never particularly noticed the first violin in that symphony, and was not informed enough to be expecting anything special. Hearing Jing Wang, though, with my mouth open and tears streaming down my face, it was immediately perceptible that he was the most special part of the experience. Reading the program after the show, I learned that he plays a special violin made by a master in the year 1700; this seemed to explain and contextualize some of the awe that I’d felt listening to him. It turns out that there is a common perception among serious violinists (and many classical music snobs) that old violins produce sounds that are not duplicable by modern violins. The magical history of the object, its induplicable nonfungibility, produces a similarly magical sound. I later found out that this idea may be spurious—at least according to one study28 that found that serious violinists wearing blindfolds did not consistently prefer ancient violins to modern ones after playing both (and in fact frequently preferred modern violins while identifying them as sounding older), and identified genuinely older violins as sounding too new. If beliefs were just “about” correctness and experimental validity, we would expect violinists and snobs to carefully update on this information. However, I would not expect nor even necessarily recommend this updating. The magical belief about old violins, I think, functions not for the purpose of making correct predictions about the world, but for social reasons, including in-group identification and bonding and satisfying the need to elevate and give meaning to rapturous experiences—experiences bought at the cost of inhuman hours of practice. It is not just any lie—it is part of an Experience Machine. Buddhism, generally identified as a religion, seems to be on the aesthetic side of the divide in the distinction presented here. It offers cognitive techniques (such as mortality salience inductions and meditation) that are explicitly designed to cause the experience of liberation. The “something greater” that various forms of Buddhism point to (such as liberation for all in Mahayana Buddhism) seem to be more afterthoughts than central to the project, though some forms of Buddhism embrace more woo than others. At its core, though, it is not so much directed at a thing for its own sake; it is more for the experience (and the rejection of experience, namely that of suffering) that it claims to be able to provide. A further set of examples will demonstrate the enmeshment of aesthetics and religion. (Hopefully, reviewing marginal cases will help us more clearly see our own, possibly more subtle religious and aesthetic Experience Machines.) The Five Percent Nation of Islam is an explicitly racist Islamic heresy that became a popular religious movement in the United States over the past few decades. Its doctrine provides that there is a tiny elite—the titular five percent—who are the Good Guys, aware of the truth and trying to spread light. Then there is a slightly less elite set of Bad Guys, and below that, a giant mob of sheeple (in Five-Percent-Nationspeak, the eighty-five percent). Only black people (referred to as the “Asiatic Blackman”) are truly people; white people are the devil. Despite its being an incredibly goofy religion, the Five Percent Nation managed to spawn one of the most productive religious artistic movements since the Shakers, inspiring Wu Tang Clan, Erykah Badu and others among the most interesting and original musicians of the end of the last century. In this case, the religion serves as a social background upon which a musical aesthetic evolves and within which geniuses flourish. Another religious movement has recently evolved that is also explicitly racist and also utilizes the Nation of Islam’s model of a tiny elite, an evil adversary group that is somewhat less elite, and an irrelevant mob of proles. The blogger known as Koanic Soul presents a world history in which a few modern humans (the elite good guys) evolved directly from Neanderthals, the evil less-elite humans evolved from Cro-Magnons, and the irrelevant mobs are, surprisingly, descended from an army genetically engineered by the ancient Cro-Magnon bad guys. The introductory come-on of this religion is the invitation to perceive an in-group aesthetic: as with n-rays,29 novices are invited to aesthetically perceive facial differences between modern humans in order to identify them as either Neanderthal or Cro-Magnon. This is a brilliant religious innovation, as aesthetic agreement over ambiguous stimuli can create a feeling of both understanding (insight) and connection to fellow perceivers. Of course, the Five Percent Nation did not invent this triarchic class structure (it shows up, among many other places, in Orwell’s 1984, albeit without the existence of good guys). It is merely one of many common patterns that exist within the patterned variation of religion and aesthetics, selecting and shaping the experiences most people accept as genuine and real enough to justify life itself. A Sneaky Dualism Aesthetics and religions, those large structures that filter and contextualize the smaller units of experience, are real in the sense that they are actually experienced by participants—but this experience is exclusively social. The experiences may not be individually or scientifically discernible (as with the violins) and the “higher something” is generally not demonstrable (as with the religious experience of speaking in tongues), but the participants nonetheless take value from the magically mediated experience. Social reality is meaningfully distinct from logical or scientific reality. The need for ultimate meaning—for base-level meaning that justifies itself and need not be further justified—seems to be a near-universal human characteristic. It makes up one quarter of Baumeister’s four-part descriptive model of meaning, outlined in the previous chapter, and it is the ultimate of meaning that people will seek out if it is not culturally provided. Frequently, the Ultimate End is an imagined state of future bliss. Examples of Ultimate Ends include Heaven in Christianity and other religions, everlasting romantic love in cultures such as our own that feature love matches in marriage, and amorphous personal “success” in the modern careerist cult of the self. Ultimate Ends can also be deities or concepts (work, “rock and roll,” political equality, existence itself) that feel valuable in and of themselves to faithful adherents, and that do not subjectively seem to require any further justification. In an objective sense, however, it is hard to see an end to justification. Believers in Ultimate Ends seem to be guilty of a sneaky dualism, of imposing a meaning layer upon objectively verifiable reality and then treating the meaning layer as if it were objectively, and not merely socially, real. In many cases, the Ultimate End is demonstrably pretend, not even a real thing. In other cases, the Ultimate End is a real concept, and it is only the idea that it is the base value that justifies everything that is not demonstrable. Experience Machines vary along the dimensions of being effective (producing desirable, meaningful experiences and preventing or at least domesticating negative experiences), honest (not hiding the fact that they are cultural artifacts designed to produce experiences), and voluntary (rather than forced upon adherents). These traits are not necessarily independent; I suspect the most effective Experience Machines that have evolved in human societies are probably some of the least honest and least voluntary, and I’d expect honesty and voluntariness to generally correlate negatively with effectiveness. The least voluntary Experience Machines are the jealous ones, described by William Burroughs as the One God Universe (though a jealous Experience Machine might just as well be polytheistic or atheistic). These Experience Machines claim not to be Experience Machines at all, but to just be actual objective reality. They frequently require the rejection (and even destruction) of competing Experience Machines, and sometimes even the destruction of their adherents for good measure. They are the sneakiest dualists, for they do not even admit to their nature as a meaning layer on top of objective reality. But such denial is obviously a good evolutionary strategy, and probably even makes them more effective in presenting a believable system to adherents. Voluntariness and honesty correlate with each other in Experience Machines, as in the case of much modern use of psychedelic drugs. To meaningfully choose to utilize an Experience Machine, one must be aware one is doing so; it would be hard for a dishonest experience machine to be voluntary. Similarly, it would be incredible if an involuntarily imposed Experience Machine were honest about its nature—to try to do so would violate, I think, strong and widely-shared (though rarely articulated) intuitions about what mere experiences, as opposed to Ultimate Ends, may justify. The Co-Evolution of Humans and Their Experience Machines The biological phenomenon of the supernormal stimulus (superstimulus) has a great deal in common with the Experience Machine. An Experience Machine is, in fact, a type of supernormal stimulus. In biology, some bees are tricked into fertilizing flowers because the flower triggers the mating instinct of bees more than even a female bee. The flower is experienced by the bee as better than nature; it is a superstimulus. Of course, a superstimulus, like a parasite, ought not to get too good, such that it disrupts the survival and reproductive patterns of the organism it depends on. An ideal Experience Machine like Nozick imagines would allow the user to jump in and forego survival needs and mating opportunities. Natural Experience Machines, aesthetics and religions, generally exact a much milder a drag on their hosts’ evolutionary goals than this ideal Experience Machine. In nature, superstimuli, just like parasites and naturally evolving Experience Machines, must achieve an equilibrium in which the host species expends enough energy to support its own needs while also expending plenty of energy supporting the reproduction of the parasite, superstimulus provider, or Experience Machine. (The reproductive needs of the Experience Machine can be substantial; it must not only reproduce by being passed to each successive generation, but must also be defended from new or invasive Experience Machines.) And so our co-evolved Experience Machines are demanding, but mild. The most effective, intense Experience Machines would likely interfere with our survival and reproductive processes so much that they would no more exist stably in nature than an extremely virulent parasitic organism. If we are willing to enter these new, powerful, addictive (however hypothetical) Experience Machines, we must be willing to abandon the “evolutionary goals” of survival, organism-level status, and reproduction—to declare them not our own goals. Effective Experience Machines may mean the end of our species, as better and better Experience Machines begin to out-compete other humans (including possible offspring) for human attention. However, this need not be the case. A society that could continue to reproduce itself despite the availability of every kind of experience imaginable for its members could come very close to being a just society. Whether or not it leads to extinction, this is the kindest path for humanity. The Protection of an Aesthetic Humans may be taken advantage of by sneaky competitors, both biological and memetic. However, some co-evolving memetic structures, especially aesthetics, might actually protect humans from exploitation. Human aesthetics can grow very subtle, assuming many layers beyond naive sensory impressions such as salty and sweet, melodic and upbeat. A subtle aesthetic can be a valuable cultural tool for evaluating the quality of necessary physical and cultural items. An old cattleman possesses an aesthetic of cattle that cannot be communicated in a checklist; he will not be cheated easily. Tribes with sensitive aesthetics will not be bought off with glass beads for long.30 In modern life, our aesthetics commonly protect us from threatening information. When we tune out or turn off a stream of information, we often do so in disgust. Pleasurable streams of information attract our attention instead. And what renders information streams pleasurable or disgusting is the aesthetic we have absorbed and created. Aesthetics, as memetically evolving items, are not “interested” in protecting us especially; they are interested in protecting themselves. They are old cognitive tools, and they are very useful, but at the same time, they tend to be conservative and to defend themselves from memetic threats. Ourselves as Experience Machines Humans do not exist alone. We are only constrained toward consciousness by other human beings. In relationships, each person has both the character of an experiencer and of an experience provider. In interactions with each other, we are always experiencing the other and being an Experience Machine for the other. This is the core of humanity. According to Roy Baumeister, it is the reason consciousness evolved. This is particularly important in sexual relationships. There is an immediately observable divide in the nature of experiences desired in a sexual relationship between men and women. This can be seen in the variety of pornography consumed by each gender, regardless of sexual orientation. For men, the pornography consumed tends to be explicit visual imagery of sex with attractive, young women or men—a substitute first-person experience of sex. That is not what women seek out and buy; what sells to women are romance novels, explicit or not, and rather than providing a first-person experience of sex, they provide a vicarious experience of being an extremely high-value female. “Valuedness” is the pornographic heart of women’s romance literature; the male lover is important to the extent that he demonstrates and supports the value of the heroine. So men desire first-person experiences with high-value women, and women desire experiences of valuedness. (Of course, the reverse is true as well, but not nearly to the same extent, as revealed in consumption patterns and as predicted by mating strategy theory.) We might say that in terms of sexuality, women are primarily Experience Machines, experiencing even ourselves as such, whereas men are primarily experiencers. Intense sexual selection has perhaps made us something like a creepy autonomous RealDoll with a womb. However, outside of sexuality, the sexes may be reversed; women, as the choosing and limiting sex, are the primary experiencers, and men are expected to provide experiences for them upon which to make their decisions. Men produce more instances of humor than women, for instance. In all relationships, sexual or not, each person has a dual nature: experiencer and experience provider. Each of these aspects, on each person, acts as a “selection site”—in both Darwinian and memetic senses. There are, on the one hand, experiences that humans avoid or seek out; on the other hand, there are experiences that one provides others or protects others from. Each of these has selection effects for reproductive fitness. Both one’s preference for certain experiences, and one’s ability to deliver certain experiences, are relevant to one’s social and mating success. To the extent that cultural items give us experiences and help us produce experiences in others, these dual natures also affect the evolution of cultural items. As an example, the book How to Win Friends and Influence People is a cultural item that demonstrates how to be a better Experience Machine for others. In friendships as well as mating, we will be accepted or get the high-status experiences we want to a greater degree if we can give those experiences to others. This cultural item (the book) has been successful at getting itself reproduced to the extent that it helps individuals create and have the experiences that they desire from and for each other. Another example involves the behavior of neonates. Infants are extremely dependent upon parental care, and vulnerable to parental rejection (especially in past societies, but even in our own). They have evolved to send signals (create experiences) almost immediately after birth that encourage parental care and discourage rejection (infanticide). They immediately signal vigor by crying, producing non-social smiles, and making eye contact within a few weeks of birth. Both aspects of our dual nature allow us to exercise some (bounded) control, and to have some limited effect on them. We can, to some degree, choose what we experience; again, to a limited degree, we can choose what we cause others to experience. However, the distance between what we try to cause others to experience and what they actually experience is frequently a dark chasm of longing and misery. *** The things that make life seem meaningful often depend on illusion and selective perception to maintain themselves. Social groups support religions and aesthetics that help us believe that certain things outside ourselves are meaningful. Not only items of culture, but even our own brains can be seen as miniature Experience Machines, letting us perceive and remember only a limited and modified aspect of external reality. Like other miniature Experience Machines, the brain is a product of evolutionary processes, serving reproductive goals orthogonal to the well-being of individual minds. Creating life in the real human world has much in common with creating life in a simulated environment. The experiences of individuals is what matters in either case, and values that give the appearance of mattering in and of themselves can frequently be demonstrated to be illusions designed to create just that experience. If it is meaning that justifies the suffering of life then meaning has a high burden of proof to demonstrate its inherent, non-instrumental value, and the frequent use of illusion in this domain invites skepticism. If it is the experience of meaning that justifies life’s hardships, then we are really back to a hedonic calculus based on experiences—and have little claim to govern individuals’ choice of experiences. The Reverse Experience Machine improves on Nozick’s experiment by removing the status quo bias. We might consider a variant on the question of whether to create a human life that removes the sacredness associated with this domain. Rather, consider creating a new, conscious character within an Experience Machine. How good would the Experience Machine have to be? What features would it require? If human life were a video game, would anyone choose to play it?",
      "word_count": 5993,
      "character_count": 37780,
      "chapter_number": 10,
      "section_number": null,
      "paragraph_number": null,
      "start_position": 0,
      "end_position": 37780,
      "parent_chunk_id": null
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch10_s1",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "section",
      "title": "Final Section",
      "content": "Chapter Four: Experience Machines and Their Ratification Suppose there were an experience machine that would give you any experience you desired. Superduper neuropsychologists could stimulate your brain so that you would think and feel you were writing a great novel, or making a friend, or reading an interesting book. All the time you would be floating in a tank, with electrodes attached to your brain. Should you plug into this machine for life, preprogramming your life’s experiences? —Robert Nozick, Anarchy, State, and Utopia I believe that we should be very cautious about creating conscious beings, and I believe that the ideal number of conscious beings (and perhaps even living beings) in the universe is probably zero, for the good of those beings themselves. Since suffering and misery are inescapable parts of life, if we are to justify creating life there must be something that outweighs suffering and misery within the space of universal judgments. Candidates generally fall into two categories. The first category is essentially hedonist: pleasure or good experiences are said to outnumber or outweigh bad experiences. This is the objection Bryan Caplan is making with his Free Disposal argument, discussed in the first chapter; assuming preferentism (that people choose what is good for them), and assuming that people have free choice in the relevant arenas, people would merely commit suicide if it were not true that the pleasure of life outweighs the suffering. And since only a million people per year commit suicide, creating life is obviously the right choice. A more subtle variation of this argument does not rely on suicide, but on a sort of imaginary survey: most people would probably report that their lives are worth living, that the good outweighs the bad, and therefore it must. The second category of responses is that there is something valuable and meaningful about life that makes it worth living even if the bad vastly outweighs the good. In the previous chapter, we explored and categorized some of the things that people find meaningful, noting how these change according to circumstance and over time. One of the most salient features of the things that make life seem meaningful is that they frequently rely on illusion: the illusion of unchanging permanence, of a future state of happiness, of one’s ability to affect the world. It is my view that the sense of meaningfulness is itself an illusion, a cognitive phenomenon that is very adaptive for individuals and groups. This illusion is maintained by communities in order to organize the behavior of individuals, in part by easing their suffering. One response to this is to counter that meaning is not an illusion—that there is real value in the world beyond what is experienced by living beings. Unfortunately, the proposed real and true meanings are often difficult to express in words to others who do not sense their truth. The feeling that life is meaningful is a pre-rational sensory perception that is widely shared. However, the specific meanings that people find satisfying and convincing are disparate and often contradictory. These underlying realities should make us question whether the sense that life is meaningful—or that some specific meaning can be found in life—is a true observation, or merely an illusion. The very adaptiveness of this belief, even if it were not true, must also make us suspect its veracity. The meaning realist has the further problem that no specific meaning is held by a majority of humanity; if there is one true meaning, then whatever it is, the majority of people’s lives go very badly because they do not perceive it. Another response is that while meanings vary, it is enough that almost everyone finds some meaning in life. In other words, the sense that life is meaningful is enough to justify life, and the myriad meanings found and elaborated by individuals are all, in fact, the meaning of life. This seems to be the most common position articulated in modern post-Christian Western societies: if a person finds his life to be meaningful, then it is meaningful—even if different people find contradictory meanings in life. One person might find a sense of meaning in fighting for equality, another in ethno-nationalism, and they are both right. This second response is actually a variation on hedonism, in that the experience of meaning, rather than the experience of pleasure, provides value. According to this view, a life of overwhelming suffering but with a deep experience of meaning might be better than a life of joy and pleasure that is internally felt to be meaningless. But ultimately, divorced from the meaning realism of the first response, this grounds meaning in subjective experiences; the sense of meaning becomes another form of pleasure. The modern idea that it is up to each individual to find meaning in life, and that this meaning justifies life, means accepting a meaning-based Experience Machine. The things that we find to be meaningful are, in fact, miniature Experience Machines. They rely on illusion and filter the information that reaches us so that we may continue to feel that life is meaningful, or continue to search for meaning in life if it is missing. They are very useful; they help us organize our behavior, coordinate with others, and manage our emotions. In a practical sense they often make the suffering of life bearable; but, once they are recognized to be illusions, they cannot justify suffering in an abstract sense any more than pleasure can. We need not jump into a Nozickian Experience Machine to get pleasure and a sense of meaning from intricate illusions. The Reverse Experience Machine experiment is close to the situation we find ourselves in—if we found out we were in an Experience Machine already, would we choose to leave it for the real world? Institutions, religions, social communities, and even individual people function as Experience Machines, creating and maintaining illusions that help us feel that life is worthwhile. A meaning realist would reject the Experience Machine, but to be consistent he must also reject those aspects of life that use illusion or information filters to provide meaning. A meaning subjectivist has little ground to reject the Experience Machine. This has implications for the justification of life’s misery based on meaningfulness. The True Gifts of the Good People: How Experience Machines Help Us Escape Uncertainty By necessity, each person must form a theory of the world that is abstracted from, and less detailed than, the territory of the world itself. There is no perfect theory; each theory must occasionally break down in the face of experience with the actual world. Many religious ideas are “gap fillers” that explain these breakdowns in models of reality. Experiences such as lost objects seeming to violate object permanence highlight the imperfect nature of one’s theory of reality. Rituals uphold the plausibility structure for the gap filler, self-signalling that the belief is real and substantial. I inherited some household rituals (mostly relating to food preparation) from my older female relatives. It’s strange that they survive to the present day. They are not religious, or rather they are performed regardless of the religion of the woman, being passed in my case with no explanation or justification. These include throwing salt over your shoulder if you should spill it (I later learned this is frequently explained as “throwing salt in the devil’s eye,” but I did not receive this explanation from the relatives I received the ritual from). Another is rubbing the cut end of cucumbers against the cut cucumber to produce a foam. This is supposed to “suck the toxins out of a cucumber.” I still perform this ritual, even though it obviously makes no sense. I am not sure why, but rituals seem valuable for their own sake. I have recently been reading a book of folklore, The Fairy-Faith in Celtic Countries by W. Y. Evans-Wentz, written in 1911. The author traveled around Ireland and its environs, interviewing people and learning their traditions involving pixies, fairies, and the like—euphemized as the Good People, the Gentle People, or sometimes even “them people.” Many of the rituals described are very appealing, and I have begun practicing some of them. One thing that interests me about the legends of the Gentle People is their inscrutable nature: they are at turns cruel and benevolent, sometimes stealing babies from their cribs and sometimes filling the house’s larder with meal. This is the background context for what follows. I recently experienced an object permanence violation, which is to say, my bright blue plastic dish scrubber completely disappeared from my kitchen. This was very strange, as I have a fairly organized kitchen and tend to know where all my kitchen implements are at any given time. But the bright blue dish scrubber was just gone—not in any hiding place big enough to hold it in my entire house. My sense of object permanence was seriously threatened. And in the context of my ritual performance, it actually occurred to me: those asshole fairies stole it! Obviously, the Gentle People did not steal my dish scrubber, inscrutable as they are. What happened was that I failed to record my own behavior, and when thinking about other things, I placed or dropped the scrubber somewhere I would not think to look for it. But it surprised me how easily this thought came to my mind—me, a proper woo-free atheist. I could see why the fairies have a dual nature, naughty and nice: they can act as a gap-filler for all sorts of violations in one’s theory of the world, such as apparent object permanence violations. And every theory violation thus explained becomes evidence for the existence of the fairies, supporting the belief. Of course, the mistaken theory in the case of a lost object is the fallacy of thinking one records one’s actions like a video camera. A lost object is a cognitive phenomenon. But it can definitely feel subjectively like a violation of object permanence. A gap-filler that explains apparent object permanence violations—such as fairies that pilfer things—can be satisfyingly called up to caulk over this hole in one’s theory of the world, supplying the gift of a comfortably whole theory of reality with no gaps. Performing rituals can facilitate belief in such gap-fillers. The act of throwing salt over one’s shoulder after spilling the salt, or taking a tiny bite of dropped food and throwing the rest back “for the fairies,” or referring to fairies euphemistically (“the good people”) creates a kind of plausibility structure for the belief. Acting on a belief makes it more real. Sharing a belief socially with others also makes it more real; there is social proof, and the belief acts as an in-group solidifier. The belief may be socially rendered magical, not subject to rational examination. Subversion myths (the belief in bad guys doing bad things, discussed in the previous chapter), and beliefs about powerful enemies in general, serve the same needs as fairy beliefs: they provide comfortable explanations for experiences that don’t fit into one’s worldview. If a subversion myth begins to be supported by rituals (and other parts of a plausibility structure), it may spread and exist stably for a long time. The Gentle People are ambiguous; they do frightening deeds and benevolent deeds, forcing those in their thrall to commit murder but also to help out around the house. They represent a worldview that is violated in both good and bad directions, one with unexpected misery but also unexpected boons. A widespread subversion myth, however, may suggest a worldview that is mostly violated by bad experiences. The motion from ambiguous, inscrutable mythic beings to purely evil mythic beings is notable. Another possibility is that it accompanies a worldview that is much too nice and positive, and hence mostly needs gap filling when bad events occur. This may be a feature of the Experience Machine that it co-exists with: the more utopian the vision, the more purely evil the gap-filling creatures must be. Another possibility is that it is a feature of the experiences that get through and affect people—a feature of the experienced world—rather than a feature of the theory. A theory will need more patches for bad information if the world gets a lot worse, even if the theory remains the same. Friendly Neighborhood Experience Machines: Where Do They Come From? The belief in fairies seems an obviously pagan belief and precedes Christianity on the islands by many centuries. However, just as Christianity co-opted pagan cultural items for its benefit, the fairy faith rendered itself compatible with Christianity. A legend collected in multiple places (explicitly believed by many sources) is that the fairies are the angels who followed Lucifer out of Heaven and sort of got locked out of Heaven by God, being condemned to live in the caves and hollows of the earth. By fitting the fairies into the Christian legend, the islanders were able to keep their valuable fairy faith with its rituals and traditions while apparently bowing to the memetic sweep of Christianity. Small-scale Experience Machines evolve just like biological organisms; they are aspects of culture subject to mutation, selection, and even extinction in the face of environmental change. Those to whom the thought experiment seems distasteful feel that experiencing life through this Experience Machine would not be real; it would not entail contact with the deepest reality, and would be limited to the creative power of human beings. It would not provide us with pleasing signals about our true selves, but only fictitious signals about an imaginary self. Of course, many people (myself included) would be more than happy to enter a nice Experience Machine rather than undergo the allegedly real slings and arrows of outrageous fortune. But my contention here is that we all utilize one or more genuine Experience Machines all the time. These real life, friendly neighborhood Experience Machines include, most notably, religions and aesthetics. These are socially created, culturally reproduced information artifacts that provide a framework for our experiences, allowing us to select experiences to some degree and to give meaning to all our experiences, selected or not. They are created solely by humans, being further selected and shaped by generations of cultural evolution. They seem to suffer from the same problems as Nozick’s hypothetical Experience Machines in terms of connection to deepest reality, offering information about the true self, and being limited by human creativity. To the extent that you buy that this is so, I argue that you must either deny the realness and desirability of experience mediated by these culturally evolved aesthetic and religious frameworks, or on the other hand allow for the choice to utilize other Experience Machines that may be superior to existing ones in the dimensions of effectiveness, voluntariness, and honesty. This manner of viewing human existence has implications for the desirability of suicide and of bringing new humans into existence. Aesthetics and Religions: A Minor Distinction A distinction between the two main ultimately-not-very-distinct types of homegrown Experience Machines will help communicate the meaning of that term as I use it. The filling out of the category is more important than the distinction. Art requires obstruction; pure, limitless freedom is the death of art. An aesthetic is necessary for the creation and experience of art. This aesthetic need not be explicit or articulable, and frequently includes inarticulable elements. But even purely legible rule sets can create much of the aesthetic context that art needs in order to be meaningful. The Dogme 95 movement (and Lars von Trier’s The Five Obstructions) the salubrious effects of even almost random limitations on art. Daniel Dennett and Douglas Hofstadter have praised the practice of JOOTSing, or jumping out of the system, but an aesthetic or cognitive leap requires a system to jump out of. Without any such system or any limitations, we see shark jumping on the level of contemporary fine art rather than the creation of meaningful experiences. Religions also allow us to create meaningful experiences from the random chaos of sensory experience—especially those scary experiences in which our best theory doesn’t match up with reality. They allow us to believe that we have a meaningful role to play in the heart of something that is deeply meaningful in and of itself. Equipped with this belief, we interpret our experiences accordingly. It is often difficult to tell aesthetics from religions—if in fact there is a difference. Both aesthetics and religions are created and maintained socially; they promote intra-tribal bonding in natural and synthetic tribes, and they facilitate the identification and rejection of outsiders. Both are experience selection devices that help us produce, select, reject, and interpret particular experiences. They are culturally evolved and variable but display observable patterns. The major difference is that aesthetics are much more explicit than religions about pointing to the experience itself, rather than to something higher beyond the experience. Many aesthetics demand that the experience itself be recognized as the ultimate value. Food criticism (along with many other aesthetic domains) has a morality of focusing on the eating experience itself; within that domain, focusing on anything but the experience (such as social signaling) is a shameful sin. Religions, on the other hand, generally claim to point to a higher something, an ultimate value that the experience only evidences and does not subsume. The proper pursuit of this “higher something” leads to meaningful experiences, but the point is not the meaningful experiences but the higher something. Insight porn27 is an aesthetic; truth seeking is a religion. One layer of meaning, one layer of about-ness, separates the aesthetic from the religion. But wild specimens need not be tidily lumped into either category; frequently they display characteristics of both. Experience Machines that are clearly aesthetics may use pointing-to-something-higher in order to produce experiences. Those that clearly seem to be religions may use honest, conscious experience selection just the same. It is common, for example, for aesthetics, not just religions, to promote magical thinking regarding objects in order to produce meaningful aesthetic experiences. The magical history of objects motivates much appreciation and meaningfully contextualizes rapture. In the summer of 2013, I was able to hear Jing Wang as concert master playing Mahler’s Third Symphony. I had never particularly noticed the first violin in that symphony, and was not informed enough to be expecting anything special. Hearing Jing Wang, though, with my mouth open and tears streaming down my face, it was immediately perceptible that he was the most special part of the experience. Reading the program after the show, I learned that he plays a special violin made by a master in the year 1700; this seemed to explain and contextualize some of the awe that I’d felt listening to him. It turns out that there is a common perception among serious violinists (and many classical music snobs) that old violins produce sounds that are not duplicable by modern violins. The magical history of the object, its induplicable nonfungibility, produces a similarly magical sound. I later found out that this idea may be spurious—at least according to one study28 that found that serious violinists wearing blindfolds did not consistently prefer ancient violins to modern ones after playing both (and in fact frequently preferred modern violins while identifying them as sounding older), and identified genuinely older violins as sounding too new. If beliefs were just “about” correctness and experimental validity, we would expect violinists and snobs to carefully update on this information. However, I would not expect nor even necessarily recommend this updating. The magical belief about old violins, I think, functions not for the purpose of making correct predictions about the world, but for social reasons, including in-group identification and bonding and satisfying the need to elevate and give meaning to rapturous experiences—experiences bought at the cost of inhuman hours of practice. It is not just any lie—it is part of an Experience Machine. Buddhism, generally identified as a religion, seems to be on the aesthetic side of the divide in the distinction presented here. It offers cognitive techniques (such as mortality salience inductions and meditation) that are explicitly designed to cause the experience of liberation. The “something greater” that various forms of Buddhism point to (such as liberation for all in Mahayana Buddhism) seem to be more afterthoughts than central to the project, though some forms of Buddhism embrace more woo than others. At its core, though, it is not so much directed at a thing for its own sake; it is more for the experience (and the rejection of experience, namely that of suffering) that it claims to be able to provide. A further set of examples will demonstrate the enmeshment of aesthetics and religion. (Hopefully, reviewing marginal cases will help us more clearly see our own, possibly more subtle religious and aesthetic Experience Machines.) The Five Percent Nation of Islam is an explicitly racist Islamic heresy that became a popular religious movement in the United States over the past few decades. Its doctrine provides that there is a tiny elite—the titular five percent—who are the Good Guys, aware of the truth and trying to spread light. Then there is a slightly less elite set of Bad Guys, and below that, a giant mob of sheeple (in Five-Percent-Nationspeak, the eighty-five percent). Only black people (referred to as the “Asiatic Blackman”) are truly people; white people are the devil. Despite its being an incredibly goofy religion, the Five Percent Nation managed to spawn one of the most productive religious artistic movements since the Shakers, inspiring Wu Tang Clan, Erykah Badu and others among the most interesting and original musicians of the end of the last century. In this case, the religion serves as a social background upon which a musical aesthetic evolves and within which geniuses flourish. Another religious movement has recently evolved that is also explicitly racist and also utilizes the Nation of Islam’s model of a tiny elite, an evil adversary group that is somewhat less elite, and an irrelevant mob of proles. The blogger known as Koanic Soul presents a world history in which a few modern humans (the elite good guys) evolved directly from Neanderthals, the evil less-elite humans evolved from Cro-Magnons, and the irrelevant mobs are, surprisingly, descended from an army genetically engineered by the ancient Cro-Magnon bad guys. The introductory come-on of this religion is the invitation to perceive an in-group aesthetic: as with n-rays,29 novices are invited to aesthetically perceive facial differences between modern humans in order to identify them as either Neanderthal or Cro-Magnon. This is a brilliant religious innovation, as aesthetic agreement over ambiguous stimuli can create a feeling of both understanding (insight) and connection to fellow perceivers. Of course, the Five Percent Nation did not invent this triarchic class structure (it shows up, among many other places, in Orwell’s 1984, albeit without the existence of good guys). It is merely one of many common patterns that exist within the patterned variation of religion and aesthetics, selecting and shaping the experiences most people accept as genuine and real enough to justify life itself. A Sneaky Dualism Aesthetics and religions, those large structures that filter and contextualize the smaller units of experience, are real in the sense that they are actually experienced by participants—but this experience is exclusively social. The experiences may not be individually or scientifically discernible (as with the violins) and the “higher something” is generally not demonstrable (as with the religious experience of speaking in tongues), but the participants nonetheless take value from the magically mediated experience. Social reality is meaningfully distinct from logical or scientific reality. The need for ultimate meaning—for base-level meaning that justifies itself and need not be further justified—seems to be a near-universal human characteristic. It makes up one quarter of Baumeister’s four-part descriptive model of meaning, outlined in the previous chapter, and it is the ultimate of meaning that people will seek out if it is not culturally provided. Frequently, the Ultimate End is an imagined state of future bliss. Examples of Ultimate Ends include Heaven in Christianity and other religions, everlasting romantic love in cultures such as our own that feature love matches in marriage, and amorphous personal “success” in the modern careerist cult of the self. Ultimate Ends can also be deities or concepts (work, “rock and roll,” political equality, existence itself) that feel valuable in and of themselves to faithful adherents, and that do not subjectively seem to require any further justification. In an objective sense, however, it is hard to see an end to justification. Believers in Ultimate Ends seem to be guilty of a sneaky dualism, of imposing a meaning layer upon objectively verifiable reality and then treating the meaning layer as if it were objectively, and not merely socially, real. In many cases, the Ultimate End is demonstrably pretend, not even a real thing. In other cases, the Ultimate End is a real concept, and it is only the idea that it is the base value that justifies everything that is not demonstrable. Experience Machines vary along the dimensions of being effective (producing desirable, meaningful experiences and preventing or at least domesticating negative experiences), honest (not hiding the fact that they are cultural artifacts designed to produce experiences), and voluntary (rather than forced upon adherents). These traits are not necessarily independent; I suspect the most effective Experience Machines that have evolved in human societies are probably some of the least honest and least voluntary, and I’d expect honesty and voluntariness to generally correlate negatively with effectiveness. The least voluntary Experience Machines are the jealous ones, described by William Burroughs as the One God Universe (though a jealous Experience Machine might just as well be polytheistic or atheistic). These Experience Machines claim not to be Experience Machines at all, but to just be actual objective reality. They frequently require the rejection (and even destruction) of competing Experience Machines, and sometimes even the destruction of their adherents for good measure. They are the sneakiest dualists, for they do not even admit to their nature as a meaning layer on top of objective reality. But such denial is obviously a good evolutionary strategy, and probably even makes them more effective in presenting a believable system to adherents. Voluntariness and honesty correlate with each other in Experience Machines, as in the case of much modern use of psychedelic drugs. To meaningfully choose to utilize an Experience Machine, one must be aware one is doing so; it would be hard for a dishonest experience machine to be voluntary. Similarly, it would be incredible if an involuntarily imposed Experience Machine were honest about its nature—to try to do so would violate, I think, strong and widely-shared (though rarely articulated) intuitions about what mere experiences, as opposed to Ultimate Ends, may justify. The Co-Evolution of Humans and Their Experience Machines The biological phenomenon of the supernormal stimulus (superstimulus) has a great deal in common with the Experience Machine. An Experience Machine is, in fact, a type of supernormal stimulus. In biology, some bees are tricked into fertilizing flowers because the flower triggers the mating instinct of bees more than even a female bee. The flower is experienced by the bee as better than nature; it is a superstimulus. Of course, a superstimulus, like a parasite, ought not to get too good, such that it disrupts the survival and reproductive patterns of the organism it depends on. An ideal Experience Machine like Nozick imagines would allow the user to jump in and forego survival needs and mating opportunities. Natural Experience Machines, aesthetics and religions, generally exact a much milder a drag on their hosts’ evolutionary goals than this ideal Experience Machine. In nature, superstimuli, just like parasites and naturally evolving Experience Machines, must achieve an equilibrium in which the host species expends enough energy to support its own needs while also expending plenty of energy supporting the reproduction of the parasite, superstimulus provider, or Experience Machine. (The reproductive needs of the Experience Machine can be substantial; it must not only reproduce by being passed to each successive generation, but must also be defended from new or invasive Experience Machines.) And so our co-evolved Experience Machines are demanding, but mild. The most effective, intense Experience Machines would likely interfere with our survival and reproductive processes so much that they would no more exist stably in nature than an extremely virulent parasitic organism. If we are willing to enter these new, powerful, addictive (however hypothetical) Experience Machines, we must be willing to abandon the “evolutionary goals” of survival, organism-level status, and reproduction—to declare them not our own goals. Effective Experience Machines may mean the end of our species, as better and better Experience Machines begin to out-compete other humans (including possible offspring) for human attention. However, this need not be the case. A society that could continue to reproduce itself despite the availability of every kind of experience imaginable for its members could come very close to being a just society. Whether or not it leads to extinction, this is the kindest path for humanity. The Protection of an Aesthetic Humans may be taken advantage of by sneaky competitors, both biological and memetic. However, some co-evolving memetic structures, especially aesthetics, might actually protect humans from exploitation. Human aesthetics can grow very subtle, assuming many layers beyond naive sensory impressions such as salty and sweet, melodic and upbeat. A subtle aesthetic can be a valuable cultural tool for evaluating the quality of necessary physical and cultural items. An old cattleman possesses an aesthetic of cattle that cannot be communicated in a checklist; he will not be cheated easily. Tribes with sensitive aesthetics will not be bought off with glass beads for long.30 In modern life, our aesthetics commonly protect us from threatening information. When we tune out or turn off a stream of information, we often do so in disgust. Pleasurable streams of information attract our attention instead. And what renders information streams pleasurable or disgusting is the aesthetic we have absorbed and created. Aesthetics, as memetically evolving items, are not “interested” in protecting us especially; they are interested in protecting themselves. They are old cognitive tools, and they are very useful, but at the same time, they tend to be conservative and to defend themselves from memetic threats. Ourselves as Experience Machines Humans do not exist alone. We are only constrained toward consciousness by other human beings. In relationships, each person has both the character of an experiencer and of an experience provider. In interactions with each other, we are always experiencing the other and being an Experience Machine for the other. This is the core of humanity. According to Roy Baumeister, it is the reason consciousness evolved. This is particularly important in sexual relationships. There is an immediately observable divide in the nature of experiences desired in a sexual relationship between men and women. This can be seen in the variety of pornography consumed by each gender, regardless of sexual orientation. For men, the pornography consumed tends to be explicit visual imagery of sex with attractive, young women or men—a substitute first-person experience of sex. That is not what women seek out and buy; what sells to women are romance novels, explicit or not, and rather than providing a first-person experience of sex, they provide a vicarious experience of being an extremely high-value female. “Valuedness” is the pornographic heart of women’s romance literature; the male lover is important to the extent that he demonstrates and supports the value of the heroine. So men desire first-person experiences with high-value women, and women desire experiences of valuedness. (Of course, the reverse is true as well, but not nearly to the same extent, as revealed in consumption patterns and as predicted by mating strategy theory.) We might say that in terms of sexuality, women are primarily Experience Machines, experiencing even ourselves as such, whereas men are primarily experiencers. Intense sexual selection has perhaps made us something like a creepy autonomous RealDoll with a womb. However, outside of sexuality, the sexes may be reversed; women, as the choosing and limiting sex, are the primary experiencers, and men are expected to provide experiences for them upon which to make their decisions. Men produce more instances of humor than women, for instance. In all relationships, sexual or not, each person has a dual nature: experiencer and experience provider. Each of these aspects, on each person, acts as a “selection site”—in both Darwinian and memetic senses. There are, on the one hand, experiences that humans avoid or seek out; on the other hand, there are experiences that one provides others or protects others from. Each of these has selection effects for reproductive fitness. Both one’s preference for certain experiences, and one’s ability to deliver certain experiences, are relevant to one’s social and mating success. To the extent that cultural items give us experiences and help us produce experiences in others, these dual natures also affect the evolution of cultural items. As an example, the book How to Win Friends and Influence People is a cultural item that demonstrates how to be a better Experience Machine for others. In friendships as well as mating, we will be accepted or get the high-status experiences we want to a greater degree if we can give those experiences to others. This cultural item (the book) has been successful at getting itself reproduced to the extent that it helps individuals create and have the experiences that they desire from and for each other. Another example involves the behavior of neonates. Infants are extremely dependent upon parental care, and vulnerable to parental rejection (especially in past societies, but even in our own). They have evolved to send signals (create experiences) almost immediately after birth that encourage parental care and discourage rejection (infanticide). They immediately signal vigor by crying, producing non-social smiles, and making eye contact within a few weeks of birth. Both aspects of our dual nature allow us to exercise some (bounded) control, and to have some limited effect on them. We can, to some degree, choose what we experience; again, to a limited degree, we can choose what we cause others to experience. However, the distance between what we try to cause others to experience and what they actually experience is frequently a dark chasm of longing and misery. *** The things that make life seem meaningful often depend on illusion and selective perception to maintain themselves. Social groups support religions and aesthetics that help us believe that certain things outside ourselves are meaningful. Not only items of culture, but even our own brains can be seen as miniature Experience Machines, letting us perceive and remember only a limited and modified aspect of external reality. Like other miniature Experience Machines, the brain is a product of evolutionary processes, serving reproductive goals orthogonal to the well-being of individual minds. Creating life in the real human world has much in common with creating life in a simulated environment. The experiences of individuals is what matters in either case, and values that give the appearance of mattering in and of themselves can frequently be demonstrated to be illusions designed to create just that experience. If it is meaning that justifies the suffering of life then meaning has a high burden of proof to demonstrate its inherent, non-instrumental value, and the frequent use of illusion in this domain invites skepticism. If it is the experience of meaning that justifies life’s hardships, then we are really back to a hedonic calculus based on experiences—and have little claim to govern individuals’ choice of experiences. The Reverse Experience Machine improves on Nozick’s experiment by removing the status quo bias. We might consider a variant on the question of whether to create a human life that removes the sacredness associated with this domain. Rather, consider creating a new, conscious character within an Experience Machine. How good would the Experience Machine have to be? What features would it require? If human life were a video game, would anyone choose to play it?",
      "word_count": 5993,
      "character_count": 37780,
      "chapter_number": 10,
      "section_number": 1,
      "paragraph_number": null,
      "start_position": 0,
      "end_position": 37780,
      "parent_chunk_id": "sarah_perryevery_cra_unknown_ch10"
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch10_p1",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "paragraph",
      "title": "Paragraph 1",
      "content": "Chapter Four: Experience Machines and Their Ratification Suppose there were an experience machine that would give you any experience you desired. Superduper neuropsychologists could stimulate your brain so that you would think and feel you were writing a great novel, or making a friend, or reading an interesting book. All the time you would be floating in a tank, with electrodes attached to your brain. Should you plug into this machine for life, preprogramming your life’s experiences? —Robert Nozick, Anarchy, State, and Utopia I believe that we should be very cautious about creating conscious beings, and I believe that the ideal number of conscious beings (and perhaps even living beings) in the universe is probably zero, for the good of those beings themselves. Since suffering and misery are inescapable parts of life, if we are to justify creating life there must be something that outweighs suffering and misery within the space of universal judgments. Candidates generally fall into two categories. The first category is essentially hedonist: pleasure or good experiences are said to outnumber or outweigh bad experiences. This is the objection Bryan Caplan is making with his Free Disposal argument, discussed in the first chapter; assuming preferentism (that people choose what is good for them), and assuming that people have free choice in the relevant arenas, people would merely commit suicide if it were not true that the pleasure of life outweighs the suffering. And since only a million people per year commit suicide, creating life is obviously the right choice. A more subtle variation of this argument does not rely on suicide, but on a sort of imaginary survey: most people would probably report that their lives are worth living, that the good outweighs the bad, and therefore it must. The second category of responses is that there is something valuable and meaningful about life that makes it worth living even if the bad vastly outweighs the good. In the previous chapter, we explored and categorized some of the things that people find meaningful, noting how these change according to circumstance and over time. One of the most salient features of the things that make life seem meaningful is that they frequently rely on illusion: the illusion of unchanging permanence, of a future state of happiness, of one’s ability to affect the world. It is my view that the sense of meaningfulness is itself an illusion, a cognitive phenomenon that is very adaptive for individuals and groups. This illusion is maintained by communities in order to organize the behavior of individuals, in part by easing their suffering. One response to this is to counter that meaning is not an illusion—that there is real value in the world beyond what is experienced by living beings. Unfortunately, the proposed real and true meanings are often difficult to express in words to others who do not sense their truth. The feeling that life is meaningful is a pre-rational sensory perception that is widely shared. However, the specific meanings that people find satisfying and convincing are disparate and often contradictory. These underlying realities should make us question whether the sense that life is meaningful—or that some specific meaning can be found in life—is a true observation, or merely an illusion. The very adaptiveness of this belief, even if it were not true, must also make us suspect its veracity. The meaning realist has the further problem that no specific meaning is held by a majority of humanity; if there is one true meaning, then whatever it is, the majority of people’s lives go very badly because they do not perceive it. Another response is that while meanings vary, it is enough that almost everyone finds some meaning in life. In other words, the sense that life is meaningful is enough to justify life, and the myriad meanings found and elaborated by individuals are all, in fact, the meaning of life. This seems to be the most common position articulated in modern post-Christian Western societies: if a person finds his life to be meaningful, then it is meaningful—even if different people find contradictory meanings in life. One person might find a sense of meaning in fighting for equality, another in ethno-nationalism, and they are both right. This second response is actually a variation on hedonism, in that the experience of meaning, rather than the experience of pleasure, provides value. According to this view, a life of overwhelming suffering but with a deep experience of meaning might be better than a life of joy and pleasure that is internally felt to be meaningless. But ultimately, divorced from the meaning realism of the first response, this grounds meaning in subjective experiences; the sense of meaning becomes another form of pleasure. The modern idea that it is up to each individual to find meaning in life, and that this meaning justifies life, means accepting a meaning-based Experience Machine. The things that we find to be meaningful are, in fact, miniature Experience Machines. They rely on illusion and filter the information that reaches us so that we may continue to feel that life is meaningful, or continue to search for meaning in life if it is missing. They are very useful; they help us organize our behavior, coordinate with others, and manage our emotions. In a practical sense they often make the suffering of life bearable; but, once they are recognized to be illusions, they cannot justify suffering in an abstract sense any more than pleasure can. We need not jump into a Nozickian Experience Machine to get pleasure and a sense of meaning from intricate illusions. The Reverse Experience Machine experiment is close to the situation we find ourselves in—if we found out we were in an Experience Machine already, would we choose to leave it for the real world? Institutions, religions, social communities, and even individual people function as Experience Machines, creating and maintaining illusions that help us feel that life is worthwhile. A meaning realist would reject the Experience Machine, but to be consistent he must also reject those aspects of life that use illusion or information filters to provide meaning. A meaning subjectivist has little ground to reject the Experience Machine. This has implications for the justification of life’s misery based on meaningfulness. The True Gifts of the Good People: How Experience Machines Help Us Escape Uncertainty By necessity, each person must form a theory of the world that is abstracted from, and less detailed than, the territory of the world itself. There is no perfect theory; each theory must occasionally break down in the face of experience with the actual world. Many religious ideas are “gap fillers” that explain these breakdowns in models of reality. Experiences such as lost objects seeming to violate object permanence highlight the imperfect nature of one’s theory of reality. Rituals uphold the plausibility structure for the gap filler, self-signalling that the belief is real and substantial. I inherited some household rituals (mostly relating to food preparation) from my older female relatives. It’s strange that they survive to the present day. They are not religious, or rather they are performed regardless of the religion of the woman, being passed in my case with no explanation or justification. These include throwing salt over your shoulder if you should spill it (I later learned this is frequently explained as “throwing salt in the devil’s eye,” but I did not receive this explanation from the relatives I received the ritual from). Another is rubbing the cut end of cucumbers against the cut cucumber to produce a foam. This is supposed to “suck the toxins out of a cucumber.” I still perform this ritual, even though it obviously makes no sense. I am not sure why, but rituals seem valuable for their own sake. I have recently been reading a book of folklore, The Fairy-Faith in Celtic Countries by W. Y. Evans-Wentz, written in 1911. The author traveled around Ireland and its environs, interviewing people and learning their traditions involving pixies, fairies, and the like—euphemized as the Good People, the Gentle People, or sometimes even “them people.” Many of the rituals described are very appealing, and I have begun practicing some of them. One thing that interests me about the legends of the Gentle People is their inscrutable nature: they are at turns cruel and benevolent, sometimes stealing babies from their cribs and sometimes filling the house’s larder with meal. This is the background context for what follows. I recently experienced an object permanence violation, which is to say, my bright blue plastic dish scrubber completely disappeared from my kitchen. This was very strange, as I have a fairly organized kitchen and tend to know where all my kitchen implements are at any given time. But the bright blue dish scrubber was just gone—not in any hiding place big enough to hold it in my entire house. My sense of object permanence was seriously threatened. And in the context of my ritual performance, it actually occurred to me: those asshole fairies stole it! Obviously, the Gentle People did not steal my dish scrubber, inscrutable as they are. What happened was that I failed to record my own behavior, and when thinking about other things, I placed or dropped the scrubber somewhere I would not think to look for it. But it surprised me how easily this thought came to my mind—me, a proper woo-free atheist. I could see why the fairies have a dual nature, naughty and nice: they can act as a gap-filler for all sorts of violations in one’s theory of the world, such as apparent object permanence violations. And every theory violation thus explained becomes evidence for the existence of the fairies, supporting the belief. Of course, the mistaken theory in the case of a lost object is the fallacy of thinking one records one’s actions like a video camera. A lost object is a cognitive phenomenon. But it can definitely feel subjectively like a violation of object permanence. A gap-filler that explains apparent object permanence violations—such as fairies that pilfer things—can be satisfyingly called up to caulk over this hole in one’s theory of the world, supplying the gift of a comfortably whole theory of reality with no gaps. Performing rituals can facilitate belief in such gap-fillers. The act of throwing salt over one’s shoulder after spilling the salt, or taking a tiny bite of dropped food and throwing the rest back “for the fairies,” or referring to fairies euphemistically (“the good people”) creates a kind of plausibility structure for the belief. Acting on a belief makes it more real. Sharing a belief socially with others also makes it more real; there is social proof, and the belief acts as an in-group solidifier. The belief may be socially rendered magical, not subject to rational examination. Subversion myths (the belief in bad guys doing bad things, discussed in the previous chapter), and beliefs about powerful enemies in general, serve the same needs as fairy beliefs: they provide comfortable explanations for experiences that don’t fit into one’s worldview. If a subversion myth begins to be supported by rituals (and other parts of a plausibility structure), it may spread and exist stably for a long time. The Gentle People are ambiguous; they do frightening deeds and benevolent deeds, forcing those in their thrall to commit murder but also to help out around the house. They represent a worldview that is violated in both good and bad directions, one with unexpected misery but also unexpected boons. A widespread subversion myth, however, may suggest a worldview that is mostly violated by bad experiences. The motion from ambiguous, inscrutable mythic beings to purely evil mythic beings is notable. Another possibility is that it accompanies a worldview that is much too nice and positive, and hence mostly needs gap filling when bad events occur. This may be a feature of the Experience Machine that it co-exists with: the more utopian the vision, the more purely evil the gap-filling creatures must be. Another possibility is that it is a feature of the experiences that get through and affect people—a feature of the experienced world—rather than a feature of the theory. A theory will need more patches for bad information if the world gets a lot worse, even if the theory remains the same. Friendly Neighborhood Experience Machines: Where Do They Come From? The belief in fairies seems an obviously pagan belief and precedes Christianity on the islands by many centuries. However, just as Christianity co-opted pagan cultural items for its benefit, the fairy faith rendered itself compatible with Christianity. A legend collected in multiple places (explicitly believed by many sources) is that the fairies are the angels who followed Lucifer out of Heaven and sort of got locked out of Heaven by God, being condemned to live in the caves and hollows of the earth. By fitting the fairies into the Christian legend, the islanders were able to keep their valuable fairy faith with its rituals and traditions while apparently bowing to the memetic sweep of Christianity. Small-scale Experience Machines evolve just like biological organisms; they are aspects of culture subject to mutation, selection, and even extinction in the face of environmental change. Those to whom the thought experiment seems distasteful feel that experiencing life through this Experience Machine would not be real; it would not entail contact with the deepest reality, and would be limited to the creative power of human beings. It would not provide us with pleasing signals about our true selves, but only fictitious signals about an imaginary self. Of course, many people (myself included) would be more than happy to enter a nice Experience Machine rather than undergo the allegedly real slings and arrows of outrageous fortune. But my contention here is that we all utilize one or more genuine Experience Machines all the time. These real life, friendly neighborhood Experience Machines include, most notably, religions and aesthetics. These are socially created, culturally reproduced information artifacts that provide a framework for our experiences, allowing us to select experiences to some degree and to give meaning to all our experiences, selected or not. They are created solely by humans, being further selected and shaped by generations of cultural evolution. They seem to suffer from the same problems as Nozick’s hypothetical Experience Machines in terms of connection to deepest reality, offering information about the true self, and being limited by human creativity. To the extent that you buy that this is so, I argue that you must either deny the realness and desirability of experience mediated by these culturally evolved aesthetic and religious frameworks, or on the other hand allow for the choice to utilize other Experience Machines that may be superior to existing ones in the dimensions of effectiveness, voluntariness, and honesty. This manner of viewing human existence has implications for the desirability of suicide and of bringing new humans into existence. Aesthetics and Religions: A Minor Distinction A distinction between the two main ultimately-not-very-distinct types of homegrown Experience Machines will help communicate the meaning of that term as I use it. The filling out of the category is more important than the distinction. Art requires obstruction; pure, limitless freedom is the death of art. An aesthetic is necessary for the creation and experience of art. This aesthetic need not be explicit or articulable, and frequently includes inarticulable elements. But even purely legible rule sets can create much of the aesthetic context that art needs in order to be meaningful. The Dogme 95 movement (and Lars von Trier’s The Five Obstructions) the salubrious effects of even almost random limitations on art. Daniel Dennett and Douglas Hofstadter have praised the practice of JOOTSing, or jumping out of the system, but an aesthetic or cognitive leap requires a system to jump out of. Without any such system or any limitations, we see shark jumping on the level of contemporary fine art rather than the creation of meaningful experiences. Religions also allow us to create meaningful experiences from the random chaos of sensory experience—especially those scary experiences in which our best theory doesn’t match up with reality. They allow us to believe that we have a meaningful role to play in the heart of something that is deeply meaningful in and of itself. Equipped with this belief, we interpret our experiences accordingly. It is often difficult to tell aesthetics from religions—if in fact there is a difference. Both aesthetics and religions are created and maintained socially; they promote intra-tribal bonding in natural and synthetic tribes, and they facilitate the identification and rejection of outsiders. Both are experience selection devices that help us produce, select, reject, and interpret particular experiences. They are culturally evolved and variable but display observable patterns. The major difference is that aesthetics are much more explicit than religions about pointing to the experience itself, rather than to something higher beyond the experience. Many aesthetics demand that the experience itself be recognized as the ultimate value. Food criticism (along with many other aesthetic domains) has a morality of focusing on the eating experience itself; within that domain, focusing on anything but the experience (such as social signaling) is a shameful sin. Religions, on the other hand, generally claim to point to a higher something, an ultimate value that the experience only evidences and does not subsume. The proper pursuit of this “higher something” leads to meaningful experiences, but the point is not the meaningful experiences but the higher something. Insight porn27 is an aesthetic; truth seeking is a religion. One layer of meaning, one layer of about-ness, separates the aesthetic from the religion. But wild specimens need not be tidily lumped into either category; frequently they display characteristics of both. Experience Machines that are clearly aesthetics may use pointing-to-something-higher in order to produce experiences. Those that clearly seem to be religions may use honest, conscious experience selection just the same. It is common, for example, for aesthetics, not just religions, to promote magical thinking regarding objects in order to produce meaningful aesthetic experiences. The magical history of objects motivates much appreciation and meaningfully contextualizes rapture. In the summer of 2013, I was able to hear Jing Wang as concert master playing Mahler’s Third Symphony. I had never particularly noticed the first violin in that symphony, and was not informed enough to be expecting anything special. Hearing Jing Wang, though, with my mouth open and tears streaming down my face, it was immediately perceptible that he was the most special part of the experience. Reading the program after the show, I learned that he plays a special violin made by a master in the year 1700; this seemed to explain and contextualize some of the awe that I’d felt listening to him. It turns out that there is a common perception among serious violinists (and many classical music snobs) that old violins produce sounds that are not duplicable by modern violins. The magical history of the object, its induplicable nonfungibility, produces a similarly magical sound. I later found out that this idea may be spurious—at least according to one study28 that found that serious violinists wearing blindfolds did not consistently prefer ancient violins to modern ones after playing both (and in fact frequently preferred modern violins while identifying them as sounding older), and identified genuinely older violins as sounding too new. If beliefs were just “about” correctness and experimental validity, we would expect violinists and snobs to carefully update on this information. However, I would not expect nor even necessarily recommend this updating. The magical belief about old violins, I think, functions not for the purpose of making correct predictions about the world, but for social reasons, including in-group identification and bonding and satisfying the need to elevate and give meaning to rapturous experiences—experiences bought at the cost of inhuman hours of practice. It is not just any lie—it is part of an Experience Machine. Buddhism, generally identified as a religion, seems to be on the aesthetic side of the divide in the distinction presented here. It offers cognitive techniques (such as mortality salience inductions and meditation) that are explicitly designed to cause the experience of liberation. The “something greater” that various forms of Buddhism point to (such as liberation for all in Mahayana Buddhism) seem to be more afterthoughts than central to the project, though some forms of Buddhism embrace more woo than others. At its core, though, it is not so much directed at a thing for its own sake; it is more for the experience (and the rejection of experience, namely that of suffering) that it claims to be able to provide. A further set of examples will demonstrate the enmeshment of aesthetics and religion. (Hopefully, reviewing marginal cases will help us more clearly see our own, possibly more subtle religious and aesthetic Experience Machines.) The Five Percent Nation of Islam is an explicitly racist Islamic heresy that became a popular religious movement in the United States over the past few decades. Its doctrine provides that there is a tiny elite—the titular five percent—who are the Good Guys, aware of the truth and trying to spread light. Then there is a slightly less elite set of Bad Guys, and below that, a giant mob of sheeple (in Five-Percent-Nationspeak, the eighty-five percent). Only black people (referred to as the “Asiatic Blackman”) are truly people; white people are the devil. Despite its being an incredibly goofy religion, the Five Percent Nation managed to spawn one of the most productive religious artistic movements since the Shakers, inspiring Wu Tang Clan, Erykah Badu and others among the most interesting and original musicians of the end of the last century. In this case, the religion serves as a social background upon which a musical aesthetic evolves and within which geniuses flourish. Another religious movement has recently evolved that is also explicitly racist and also utilizes the Nation of Islam’s model of a tiny elite, an evil adversary group that is somewhat less elite, and an irrelevant mob of proles. The blogger known as Koanic Soul presents a world history in which a few modern humans (the elite good guys) evolved directly from Neanderthals, the evil less-elite humans evolved from Cro-Magnons, and the irrelevant mobs are, surprisingly, descended from an army genetically engineered by the ancient Cro-Magnon bad guys. The introductory come-on of this religion is the invitation to perceive an in-group aesthetic: as with n-rays,29 novices are invited to aesthetically perceive facial differences between modern humans in order to identify them as either Neanderthal or Cro-Magnon. This is a brilliant religious innovation, as aesthetic agreement over ambiguous stimuli can create a feeling of both understanding (insight) and connection to fellow perceivers. Of course, the Five Percent Nation did not invent this triarchic class structure (it shows up, among many other places, in Orwell’s 1984, albeit without the existence of good guys). It is merely one of many common patterns that exist within the patterned variation of religion and aesthetics, selecting and shaping the experiences most people accept as genuine and real enough to justify life itself. A Sneaky Dualism Aesthetics and religions, those large structures that filter and contextualize the smaller units of experience, are real in the sense that they are actually experienced by participants—but this experience is exclusively social. The experiences may not be individually or scientifically discernible (as with the violins) and the “higher something” is generally not demonstrable (as with the religious experience of speaking in tongues), but the participants nonetheless take value from the magically mediated experience. Social reality is meaningfully distinct from logical or scientific reality. The need for ultimate meaning—for base-level meaning that justifies itself and need not be further justified—seems to be a near-universal human characteristic. It makes up one quarter of Baumeister’s four-part descriptive model of meaning, outlined in the previous chapter, and it is the ultimate of meaning that people will seek out if it is not culturally provided. Frequently, the Ultimate End is an imagined state of future bliss. Examples of Ultimate Ends include Heaven in Christianity and other religions, everlasting romantic love in cultures such as our own that feature love matches in marriage, and amorphous personal “success” in the modern careerist cult of the self. Ultimate Ends can also be deities or concepts (work, “rock and roll,” political equality, existence itself) that feel valuable in and of themselves to faithful adherents, and that do not subjectively seem to require any further justification. In an objective sense, however, it is hard to see an end to justification. Believers in Ultimate Ends seem to be guilty of a sneaky dualism, of imposing a meaning layer upon objectively verifiable reality and then treating the meaning layer as if it were objectively, and not merely socially, real. In many cases, the Ultimate End is demonstrably pretend, not even a real thing. In other cases, the Ultimate End is a real concept, and it is only the idea that it is the base value that justifies everything that is not demonstrable. Experience Machines vary along the dimensions of being effective (producing desirable, meaningful experiences and preventing or at least domesticating negative experiences), honest (not hiding the fact that they are cultural artifacts designed to produce experiences), and voluntary (rather than forced upon adherents). These traits are not necessarily independent; I suspect the most effective Experience Machines that have evolved in human societies are probably some of the least honest and least voluntary, and I’d expect honesty and voluntariness to generally correlate negatively with effectiveness. The least voluntary Experience Machines are the jealous ones, described by William Burroughs as the One God Universe (though a jealous Experience Machine might just as well be polytheistic or atheistic). These Experience Machines claim not to be Experience Machines at all, but to just be actual objective reality. They frequently require the rejection (and even destruction) of competing Experience Machines, and sometimes even the destruction of their adherents for good measure. They are the sneakiest dualists, for they do not even admit to their nature as a meaning layer on top of objective reality. But such denial is obviously a good evolutionary strategy, and probably even makes them more effective in presenting a believable system to adherents. Voluntariness and honesty correlate with each other in Experience Machines, as in the case of much modern use of psychedelic drugs. To meaningfully choose to utilize an Experience Machine, one must be aware one is doing so; it would be hard for a dishonest experience machine to be voluntary. Similarly, it would be incredible if an involuntarily imposed Experience Machine were honest about its nature—to try to do so would violate, I think, strong and widely-shared (though rarely articulated) intuitions about what mere experiences, as opposed to Ultimate Ends, may justify. The Co-Evolution of Humans and Their Experience Machines The biological phenomenon of the supernormal stimulus (superstimulus) has a great deal in common with the Experience Machine. An Experience Machine is, in fact, a type of supernormal stimulus. In biology, some bees are tricked into fertilizing flowers because the flower triggers the mating instinct of bees more than even a female bee. The flower is experienced by the bee as better than nature; it is a superstimulus. Of course, a superstimulus, like a parasite, ought not to get too good, such that it disrupts the survival and reproductive patterns of the organism it depends on. An ideal Experience Machine like Nozick imagines would allow the user to jump in and forego survival needs and mating opportunities. Natural Experience Machines, aesthetics and religions, generally exact a much milder a drag on their hosts’ evolutionary goals than this ideal Experience Machine. In nature, superstimuli, just like parasites and naturally evolving Experience Machines, must achieve an equilibrium in which the host species expends enough energy to support its own needs while also expending plenty of energy supporting the reproduction of the parasite, superstimulus provider, or Experience Machine. (The reproductive needs of the Experience Machine can be substantial; it must not only reproduce by being passed to each successive generation, but must also be defended from new or invasive Experience Machines.) And so our co-evolved Experience Machines are demanding, but mild. The most effective, intense Experience Machines would likely interfere with our survival and reproductive processes so much that they would no more exist stably in nature than an extremely virulent parasitic organism. If we are willing to enter these new, powerful, addictive (however hypothetical) Experience Machines, we must be willing to abandon the “evolutionary goals” of survival, organism-level status, and reproduction—to declare them not our own goals. Effective Experience Machines may mean the end of our species, as better and better Experience Machines begin to out-compete other humans (including possible offspring) for human attention. However, this need not be the case. A society that could continue to reproduce itself despite the availability of every kind of experience imaginable for its members could come very close to being a just society. Whether or not it leads to extinction, this is the kindest path for humanity. The Protection of an Aesthetic Humans may be taken advantage of by sneaky competitors, both biological and memetic. However, some co-evolving memetic structures, especially aesthetics, might actually protect humans from exploitation. Human aesthetics can grow very subtle, assuming many layers beyond naive sensory impressions such as salty and sweet, melodic and upbeat. A subtle aesthetic can be a valuable cultural tool for evaluating the quality of necessary physical and cultural items. An old cattleman possesses an aesthetic of cattle that cannot be communicated in a checklist; he will not be cheated easily. Tribes with sensitive aesthetics will not be bought off with glass beads for long.30 In modern life, our aesthetics commonly protect us from threatening information. When we tune out or turn off a stream of information, we often do so in disgust. Pleasurable streams of information attract our attention instead. And what renders information streams pleasurable or disgusting is the aesthetic we have absorbed and created. Aesthetics, as memetically evolving items, are not “interested” in protecting us especially; they are interested in protecting themselves. They are old cognitive tools, and they are very useful, but at the same time, they tend to be conservative and to defend themselves from memetic threats. Ourselves as Experience Machines Humans do not exist alone. We are only constrained toward consciousness by other human beings. In relationships, each person has both the character of an experiencer and of an experience provider. In interactions with each other, we are always experiencing the other and being an Experience Machine for the other. This is the core of humanity. According to Roy Baumeister, it is the reason consciousness evolved. This is particularly important in sexual relationships. There is an immediately observable divide in the nature of experiences desired in a sexual relationship between men and women. This can be seen in the variety of pornography consumed by each gender, regardless of sexual orientation. For men, the pornography consumed tends to be explicit visual imagery of sex with attractive, young women or men—a substitute first-person experience of sex. That is not what women seek out and buy; what sells to women are romance novels, explicit or not, and rather than providing a first-person experience of sex, they provide a vicarious experience of being an extremely high-value female. “Valuedness” is the pornographic heart of women’s romance literature; the male lover is important to the extent that he demonstrates and supports the value of the heroine. So men desire first-person experiences with high-value women, and women desire experiences of valuedness. (Of course, the reverse is true as well, but not nearly to the same extent, as revealed in consumption patterns and as predicted by mating strategy theory.) We might say that in terms of sexuality, women are primarily Experience Machines, experiencing even ourselves as such, whereas men are primarily experiencers. Intense sexual selection has perhaps made us something like a creepy autonomous RealDoll with a womb. However, outside of sexuality, the sexes may be reversed; women, as the choosing and limiting sex, are the primary experiencers, and men are expected to provide experiences for them upon which to make their decisions. Men produce more instances of humor than women, for instance. In all relationships, sexual or not, each person has a dual nature: experiencer and experience provider. Each of these aspects, on each person, acts as a “selection site”—in both Darwinian and memetic senses. There are, on the one hand, experiences that humans avoid or seek out; on the other hand, there are experiences that one provides others or protects others from. Each of these has selection effects for reproductive fitness. Both one’s preference for certain experiences, and one’s ability to deliver certain experiences, are relevant to one’s social and mating success. To the extent that cultural items give us experiences and help us produce experiences in others, these dual natures also affect the evolution of cultural items. As an example, the book How to Win Friends and Influence People is a cultural item that demonstrates how to be a better Experience Machine for others. In friendships as well as mating, we will be accepted or get the high-status experiences we want to a greater degree if we can give those experiences to others. This cultural item (the book) has been successful at getting itself reproduced to the extent that it helps individuals create and have the experiences that they desire from and for each other. Another example involves the behavior of neonates. Infants are extremely dependent upon parental care, and vulnerable to parental rejection (especially in past societies, but even in our own). They have evolved to send signals (create experiences) almost immediately after birth that encourage parental care and discourage rejection (infanticide). They immediately signal vigor by crying, producing non-social smiles, and making eye contact within a few weeks of birth. Both aspects of our dual nature allow us to exercise some (bounded) control, and to have some limited effect on them. We can, to some degree, choose what we experience; again, to a limited degree, we can choose what we cause others to experience. However, the distance between what we try to cause others to experience and what they actually experience is frequently a dark chasm of longing and misery. *** The things that make life seem meaningful often depend on illusion and selective perception to maintain themselves. Social groups support religions and aesthetics that help us believe that certain things outside ourselves are meaningful. Not only items of culture, but even our own brains can be seen as miniature Experience Machines, letting us perceive and remember only a limited and modified aspect of external reality. Like other miniature Experience Machines, the brain is a product of evolutionary processes, serving reproductive goals orthogonal to the well-being of individual minds. Creating life in the real human world has much in common with creating life in a simulated environment. The experiences of individuals is what matters in either case, and values that give the appearance of mattering in and of themselves can frequently be demonstrated to be illusions designed to create just that experience. If it is meaning that justifies the suffering of life then meaning has a high burden of proof to demonstrate its inherent, non-instrumental value, and the frequent use of illusion in this domain invites skepticism. If it is the experience of meaning that justifies life’s hardships, then we are really back to a hedonic calculus based on experiences—and have little claim to govern individuals’ choice of experiences. The Reverse Experience Machine improves on Nozick’s experiment by removing the status quo bias. We might consider a variant on the question of whether to create a human life that removes the sacredness associated with this domain. Rather, consider creating a new, conscious character within an Experience Machine. How good would the Experience Machine have to be? What features would it require? If human life were a video game, would anyone choose to play it?",
      "word_count": 5993,
      "character_count": 37780,
      "chapter_number": 10,
      "section_number": null,
      "paragraph_number": 1,
      "start_position": 0,
      "end_position": 37780,
      "parent_chunk_id": "sarah_perryevery_cra_unknown_ch10"
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch12",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "chapter",
      "title": "Chapter Five: Moral Foundations Analysis of Suicide and Childbearing",
      "content": "Chapter Five: Moral Foundations Analysis of Suicide and Childbearing The first part of this book investigated a modern worldview in which human moral beliefs are not the product of a rational utilitarian calculus, but rather of evolved heuristics that function to solve coordinated action problems and bind groups together. These include sacredness, loyalty, and authority as well as harm, fairness, and freedom. Human cultures are not rationally chosen sets of institutions, but messy, evolved collections of cultural items. We participate in them not because they give us accurate representations of reality, but because they meet our social and psychological needs. We now proceed to analyze the two specific subjects of this inquiry—suicide and childbearing—from this perspective. Suicide and Moral Foundations A. The harm of suicide Harm/care is a very rational model for moral intuition, and likely fails to account for most moral cognition surrounding suicide. This is the foundation, however, to which most philosophical arguments regarding suicide have been addressed (and indeed to which non-specialists willing to discuss their beliefs often instinctively appeal). What are the harms of suicide—and the harms of its prohibition? By what right might these harms be inflicted? 1. Harm to survivors—friends, relatives, and others Suicide opponents often call suicide a form of murder —self-murder. The suicide is viewed as improperly taking himself away from his friends and relatives earlier than they expected, frustrating their expectations. It is natural to assign a dysphemism to a hated practice that violates sacredness, but of course suicide is distinct from murder. People who commit suicide are not “victims” in the sense that people who are murdered are. Consent is a powerful element, transforming rape into consensual sex, slavery into work, kidnapping into a vacation. A suicide’s survivors are not victims, I will argue, because the type of harm that they suffer is a type of harm that the suicide himself, and not a murderer, has a right to inflict as a double effect of refusing to live. And it cannot be that the harm to survivors is the only—or even the major—reason that murder is wrong. The murder of a lonely person with no relatives is surely no less horrible (or not much less horrible) than the murder of a person with many relatives. Evolutionary psychologists Martin Daly and Margo Wilson31 point out that “tribal people may explain a particular act of seemingly unprovoked homicide to an appalled missionary or anthropologist by pointing out that the victim had no relatives”—that is, there was no danger of retaliation—but to a modern mind, this is hardly a moral defense. How much of the harm to survivors is due not to the suicide itself but to the suicide prohibition? A writer on the Internet suicide group alt.suicide.bus.stop, writing as “EverDawn,” asserts that a great deal of the harm to survivors of suicide—in particular, the perception of suicide as “tragic”—is an artifact of the policy of suicide prevention and its attendant doctrines: Perceiving an event as tragic makes it difficult to come to terms with, in contrast to an event which is just sad. If a sad event couldn’t have and shouldn’t have been prevented, then there is no blame to be placed, and nobody to be angry at. But a tragic event raises the questions: how could it be prevented, who should have prevented it. This leads to anger (when blaming others) and despair (when blaming self). The questions linger on, unanswered, making it far more difficult to come to terms with the event. We have been led to believe that suicide should be prevented because suicide is tragic, when in fact, the reason why suicide is tragic is because society has chosen a policy of suicide prevention. Suicide is a sad event, however, the perception of suicide as tragic is a result of the choice society has made—a choice which society is responsible for. Ultimately, society is to blame for the negative consequences of this choice. The harm of suicide is distinct from the harm of murder, and—a theme that will be highlighted throughout this book —the suicide prohibition itself is responsible for much of the harm that suicide does cause. Let us now specifically examine the harms that suicide causes to those left behind. a. Loss of company, support, and other expected goods The most commonly cited harm inflicted by suicide is the harm to the surviving friends and relatives. What, exactly, does that harm consist of? Certainly, it is not merely the fact that the person has died. Everyone dies eventually; suicides are not unique in this. Our surviving family and friends must eventually come to terms with all of our deaths. The only special harm attributable to the suicide is that he has died early, depriving the survivors of an expected period of his company and support—specifically, that period between the time of suicide and the time he would have otherwise died. During that time, the lover or spouse no longer enjoys the affection of the suicide; the relative no longer enjoys his visits and presents and sidewalk-shoveling; the friend no longer enjoys his opinions and companionship; the parent may no longer hope for grandchildren. The problem is that little of this “company and support” (and reproductive capacity) is morally obligatory. A person may, without committing a moral wrong by modern standards, leave his spouse due to irreconcilable differences or move away from his friends and relatives to pursue a career or refuse to have children. Providing our company is a voluntary act, and we are under no moral obligation to do so. The company and support of a person is best viewed as a privilege, not a right—with the important exception of a person’s voluntarily conceived children (there is a moral duty to care for one’s children that renders the suicide of a parent of dependent children, rebuttably, wrong). The losses inherent in a suicide are real, but unlike the losses inherent in a murder, they may be inflicted in the exercise of a moral right. At the very least, we are generally permitted to inflict those losses in other contexts. If suicide is prohibited because of the harm to our mothers, should we also be legally forbidden to move away from our mothers? b. Knowledge of permanent loss A loss of companionship and support is upsetting, but perhaps a suicide is worse than moving away because it creates the knowledge in the minds of survivors that the loss is permanent. It removes hope of an eventual return and reconciliation. Is this harm blameworthy? Do people have a right to this (often irrational) hope? Move-away losses and other estrangements are frequently permanent. While the knowledge of the permanence of a loss may be painful, it is also valuable to know the truth. The survivor of a suicide may in this way be better off than the person left behind in an estrangement he stubbornly refuses to admit is permanent. While both the loss of the company of the decedent and the knowledge that his departure is permanent are harms that survivors of a suicide suffer, it is important to recognize that these harms conflict with the liberty interests of the suicidal person (freedom/oppression foundation) and with a fairness analysis (fairness/cheating) of the act and its harms. c. Discovering and disposing of the body A distinctly visceral harm must be suffered by someone in any suicide in our prohibition society: the discovery and disposal of the body. Where the discoverer is a relative or close associate, the shock must be even greater. While discovering the body of one’s spouse or friend or child must necessarily be awful, it is an artifact of the suicide prohibition that this must happen. Legal suicide (allowing for chosen death and market mechanisms to accomplish it comfortably) would allow suicides to say goodbye before dying, to die in the presence of loved ones, or to discreetly provide for the professional disposal of their bodies. The shock of discovering the body of a suicide must be weighed against another harm that is also a consequence of prohibition: since he must hide his act in order to get away with it, a suicide may be “missing” for days or weeks (or more) prior to discovery. Given the suicide prohibition, privacy and a controlled environment are essential to a suicide’s success; his own home is often the only place where these are possible. Legal, preplanned suicide, perhaps taking place in a hospital, would eliminate this harm. Frequently in our prohibition society, another must suffer the great harm of being the unwilling agent of death for the suicide (as with suicides who jump in front of trains). This is unfortunate, and I see such suicides as particularly morally questionable. However, this harm (in fact, this type of suicide) is also an artifact of the suicide prohibition and would largely disappear if reliable suicide methods that did not cause harm to bystanders were commonly available. Everyone dies of something. And we can’t bury ourselves. This means that for every human being who has ever lived, someone must discover and dispose of the body. It is mistaken to attribute this harm only to suicides. It is part of our humanity that we—suicides and non-suicides alike—must inflict this harm on others. Once we have been given the dubious gift of life, we are destined to burden someone with the disposal of our dead body. 2. Harm to the Suicide Himself Those who are comfortable with paternalism often argue that suicide must be prevented—indeed, that it displays a lack of compassion to allow it—because of the harm to the suicide himself. a. Loss of future experiences Frequently the victim under consideration for the harm/ care foundation is the suicidal person—who is to be protected from himself. How can one harm oneself? The harm inflicted by the suicide upon himself must be the deprivation of possible future experiences (keep in mind that sacred harms, such as religious harm, belong under different moral foundations). However, by committing suicide, a person affirms that, in his evaluation, the expected future gains from living are not worth the expected costs. Many people intuitively support this line of thinking when it comes to people dying of a terminal illness. But why would people dying of a terminal illness be the only people miserable enough to rationally want to die? Hope is not necessarily rational. Prohibiting suicide amounts to substituting one’s own (poorly informed) judgment for the suicide’s own (immeasurably better informed) judgment of the degree to which his life is worth living. I have argued elsewhere that suicide is not, as many believe, the irrational product of mental illness. But what about suicide committed on impulse? Perhaps a person’s “self” evaluates the situation at time t and decides that suicide is preferable, but later, at time t plus 24 hours, he might decide he was mistaken, and dearly wish to keep living. One problem with this theory is that suicide does not, in fact, appear to be an impulsive act,32 but generally involves a plan. And given the existing barriers to suicide, a suicide that appears “impulsive” may actually reflect the genuine rational desires of the suicide. The person who rationally prefers to die may be unfairly prevented from doing so by legal and practical barriers; he may need an “impulse” to push him over the edge and enact his rational desire. Confronted with evidence that suicidality is not impulsive and fleeting, paternalists often point to statistics showing that only a small percentage of people who are caught before completing a suicide attempt go on to commit suicide, but this is a poor line of evidence. We live in a society that prohibits suicide and expends vast resources to prevent and punish it. Being forcibly prevented from exiting life by the medical and legal institutions of our culture is a devastating experience, encouraging a sense of learned helplessness and despair. Imagine you lived in one of the many countries that criminalizes abortion. In your country, it is the case that women who attempt abortion but are caught before they succeed rarely go on to actually get an abortion. Proponents of prohibition claim this is evidence that few women actually want abortions. Is this line of reasoning suspicious? (In both cases, prohibition increases the difficulty of achieving the desired result—abortion in one case, death in the other.) Even if we could be certain that a would-be suicide would be glad to be rescued (we can’t), this would not be a strong moral reason to prohibit suicide. The victim’s being “glad it happened” after the fact does not render interference morally justifiable. b. Harm from an unsuccessful suicide attempt Harm inflicted by an unsuccessful suicide attempt is entirely an artifact of the suicide prohibition, not a harm inherent in suicide. Every year, thousands of people are rendered permanently disabled by being forcibly rescued from suicide attempts; as noted earlier, this is one of many ways in which prohibition increases the cost of suicide—in this case, by increasing its potential for harm suffered by the suicidal person. c. Failed signaling It is commonly believed that a suicide attempt should be universally interpreted as a “cry for help.” A successful suicide may be seen, then, as a failed signal for help. But this attitude benefits neither serious suicides, nor would-be signalers. Again, the idea of “failed signaling” is an artifact of the suicide prohibition. In order for a person to send a reliable signal, the suicide attempt must appear lethal while not actually being lethal. If comfortable, reliable suicide were legally and practically available, there would be very little value in choosing any other method, and any other method would be less lethal than the medical option. This would interfere with the appearance of lethality communicated by a suicide attempt, thereby decreasing the motivation to make a “signal” attempt in the first place. What an insincere suicide attempter—a “signaler”—really wants is to be rescued. That is, he wants to be forcibly prevented from committing suicide, because he does not really want to commit suicide. Remove the possibility for rescue, and you remove this insincere suicide’s motivation to make the potentially harmful attempt in the first place. It is the suicide prohibition, and not suicide itself, that causes this harm to the would-be signaler. B. Loyalty When the topic of suicide is raised in a moral context, it becomes increasingly likely that someone with a personal connection to a suicide will bring up that connection. This is perfectly understandable, but it locates the harm of suicide in near others (in-group members especially) rather than diffusely among the populace. Someone with a near connection to a suicide may find that he is able to shift the discussion toward his preferred theory. If he takes a position in favor of government intervention and brings up a deceased family member who committed suicide (even though this is technically a non sequitur), the interlocutor taking an opposite position may be reframed as attacking the family member rather than a position. The interlocutor’s moral argument may thus be perceived, especially by him, as a loyalty violation toward his own in-group. It is natural, both psychologically and rhetorically, to emphasize an in-group connection to a phenomenon like suicide. There is nothing wrong with this. Faced with this natural tendency, opponents of prohibition must depersonalize arguments before engaging. One strategy is to emphasize loyalty toward the class of people who want to die through acknowledging their freedom to exit. This is further addressed below, in my discussion of “Liberty.” C. Fairness, Cheating, Selfishness, and Suicide Closely related to judgments of loyalty are judgments of fairness. What is to be expected of a person in our society? It is very common for proponents of prohibition to emphasize that suicide is “selfish,” generally relying on the visceral connotations of this term for effect rather than defining it precisely. Rather than accepting the idea that suicide is selfish, we must investigate what is meant by this statement and place our concerns in context according to the moral faculties swayed by such concerns. What is the standard by which reciprocity is judged? To say that suicide is selfish is to imply that the suicidal person has not lived up to a duty to his fellow man, a duty to go on living no matter the cost in personal misery. But what is the basis for this duty? Is it fair to expect someone to live out his natural life? What would make it fair or unfair? The length of a natural life varies, as do the circumstances in which it must be lived. The basis of fairness can’t be consent to life—consent occurs neither at the beginning (no one consents to being born) nor at the end (a suicidal person explicitly does not consent to being alive). Certainly social expectations are violated by suicide, if not stipulated contractual ones; though there was no express agreement to live up to, we might imagine a contract implied by certain actions, at whose heart is the promise to live out one’s natural life no matter what. What behaviors would indicate acceptance of such an implied contract? Perhaps merely staying alive indicates ongoing consent for life, but as I argued in the first chapter, an action without the genuine freedom to do the opposite cannot indicate consent. Perhaps forming serious relationships indicates consent, but how is a life to be made even potentially worth living without the formation of strong relationships of mutual reliance? Must a person choose a track for himself early on—suicide and solitude, or strong relationships and severe restriction on the moral right of suicide? Intuitively and in practice, attempts at social integration are rarely seen as violations by a suicidal person, and social withdrawal is not seen as a moral duty. D. Authority Supreme Court Justice Antonin Scalia,33 in refusing to recognize a right of citizens to refuse medical care that would prolong their lives, offers the defense that suicide was a felony at common law—which is to say that historically, in England for hundreds of years, the penalty for trying to kill yourself was hanging. Scalia grounds an authority-based argument against suicide in this early prohibition: because suicide was a felony, he argues, modern governments need not recognize a suffering person’s right to end his life. The authority foundation has not found much persuasive power within the context of suicide. Arguments like the above seem self-evident to those, like Scalia, who are moved by authority, but read as clumsy otherwise. However, a major force for the acceptance of the suicide prohibition has been the expanding authority of medicine in our society. Medicine, and the medical model of suicide, is as much a product of the authority framework as of the harm/care foundation. Medicine pretends to an almost exclusively harm/care orientation; however, it has acquired a halo of sacredness since its great successes in the last century with vaccines and antibiotics. And it has used this sacredness to cultivate an aura of authority. As detailed in the first chapter, the greater portion of the suicide prohibition is not legal, exactly, but medical. Doctors, as part of a hospital system, have the authority to imprison people on locked wards for displaying signs of mental illness that are presumed to indicate a danger to self or others. In practice, this means that even a rational suicidal person may be imprisoned. The authority to imprison, to medicate, to bully and coerce patients into compliance with treatment plans, goes along with expanding medical authority in a variety of contexts once thought to be the domain of the family or the individual. Hospital staff frequently remove children from parents judged to be a danger to the children—and, in many cases, the only danger is the disagreement with doctors as to the diagnosis and its appropriate treatment. Doctors have referred to this procedure as a “parent-ectomy,”34 as in surgical removal of the parents. That medical experts should have such authority is a very modern development. Another result of the expanded authority of medical practitioners is doctors assisting police by performing invasive cavity searches of suspects.35 The expanding authority of medicine is worrying. There are no checks or balances built into our system to counteract the authority of doctors, and experiments with socialized medicine mean that government is more involved with health care than ever. E. Suicide and Sanctity Among those who oppose suicide and approve of its prohibition, sanctity, not harm, appears to be the foremost reason. In laboratory experiments,36 the harm/care foundation was activated with regard to homicide, but did not substantially affect judgments of suicide. Instead, concern with the tainting of souls and moral disgust appeared to be the most powerful operative foundations. In the previous chapter, it was noted that a characteristic of sacred beliefs is that symbols tend to be confused with referents; images of cigarette smoking and discussion of rape may be seen as violations in addition to the underlying behaviors themselves. Thus it is with suicide: even conversations about suicide, whether artistic or mundane, have the power to trigger strong reaction, and this reaction often takes the form of censorship (discussed at length in a later chapter). The supposed suicide contagion is often brought up as a rational basis for such censorship, but the fact that suicide is open for contagion analysis, when other acts (such as interpersonal violence) are generally not, must be explained. And it is precisely the purity violation inherent in suicide and discussions of suicide that allows for contagion analysis: impurity is contagious, and moral degradation is seen to spread like an infection, whereas ordinary harm is not. If ordinary violence were seen to be contagious, its moral condemnation and retributive responses would be imperiled; but suicide, as a sanctified domain and a special sacredness violation, is frequently the subject of contagion framing. F. Liberty The liberty foundation is that which is most conducive to eliminating the suicide prohibition. Thomas Szasz and other libertarian writers have advocated for a right to die as part of a broader right of self-determination that includes the right to refuse psychiatric treatment. Responses to the pro-choice position that strive to maintain the liberty frame tend to balance future liberty interests of the person with present liberty interests, breaking a person into multiple selves over time and presenting the different selves’ interests as in conflict. The position that prioritizes future interests over present interests is in accordance with the suicide prohibition; paternalism often refuses to admit that it is paternalism, instead insisting that it is merely representing the true, genuine “freedoms” of a future person. In other contexts, restricting the actions of a future self is seen as an important freedom. All contracts, for instance, have this feature, as did the institution of marriage before modern no-fault interventions. In the suicide context, however, the decision of the present self to commit suicide is often stigmatized as disordered, insane, or impulsive; that it may be a rational and integrated decision makes the case for restricting it based on future interests more difficult. Childbearing and Moral Foundations The morality of suicide is distinct from the question of the morality of childbearing, as illustrated in the first chapter. But the two issues are connected, especially along the harm/ care, fairness, and loyalty foundations. Childbearing is especially sacralized in our culture; as with suicide, the sacredness foundation bears a great deal of the weight of moral cognition on childbearing, if often invisibly. Freedom, as applied to childbearing, is generally limited to analysis of the rights of parents—the right to bear children, and the right to prevent or abort children. Rarely are the liberty, harm, or fairness interests of the children seriously considered. A. Childbearing and Harm That being alive entails suffering has been acknowledged at least since the time of the Buddha. Even the best lives are frequently painful and boring, punctuated by unsatisfied longing, loneliness, fear, shame, hunger, anger, and grief. All humans age and die—and to make matters worse, they become aware early on that they will inevitably die. A naive view from the hedonic perspective, in which only pleasure and pain matter, was explored in the first chapter where I considered Bryan Caplan’s argument that since most people stay alive, rather than jump off of tall buildings, the pleasures of life must outweigh its many harms. A more nuanced view must allow that this is frequently not the case: that the harm of life frequently seems to outweigh any benefit it may be said to provide to the living person. The one million suicides per year, globally, put a lower bound on this condition, but it is difficult to know how many people suffer so much that life is, on net, a harm to them. This analysis is made more complicated by the fact that symbolic and social meaning, rather than a robotic pleasure/pain trade off, is in fact what seems to motivate human action. Not many people commit suicide, but many people act as if their lives are not very valuable to them. They risk actual death or social death by gambling their present circumstances on a small chance of future payoff, in a manner that is not actuarially sound. They choose, with their economic decisions, to believe in a counterfactual world, indicating dissatisfaction with the real world. They palliate present suffering in a manner that harms future prospects. This gamble/ palliate behavior is examined in detail in a later chapter; it indicates that, rather than valuing life as a precious gift, people frequently treat life as having zero or negative value with their actual actions. The suffering occasioned by life is great and undeniable, indicating that childbearing, at least in this aspect, does major harm to those brought into the world. Is there something that makes up for this harm, such that something causing so much misery might properly be regarded as a gift? This “balancing factor” might be meaning—either universal meaning, or subjective meaning found and elaborated by individuals; this is addressed in an earlier chapter. Another possibility is the proposition that, on balance, the pleasure and good experiences of life make up for the suffering it occasions. Rather than eschewing all suffering, individuals frequently accept some degree of suffering in pursuit of other rewards—either in the form of meaning, or in the form of pleasure. The mountain climber or medical student affirmatively chooses to suffer for the purpose of future experiences, pleasurable or meaningful. Others, looking back on times of suffering, say they are glad to have had such experiences. When making decisions for ourselves, there is no moral problem with trading off suffering for pleasure or meaning; it appears to be a social fact that people do not minimize suffering in their own lives. What about when we act upon others—especially strangers, whose preferences we know nothing about? Can we permissibly cause them serious harm in order to give them a benefit, and without their permission? This question, fundamental to the modern philosophic question of antinatalism, will be addressed in a later section, but it is important to root it in the “harm/care” moral foundation, and to notice what other moral foundations affect thinking about childbearing. B. Fairness, Cheating, and Reciprocity The fairness and reciprocity orientation regarding childbearing is prominent in many cultures. Life (and perhaps care, feeding, and rearing) is regarded as a gift that parents give their children. This is regarded as creating a debt owed by the child to the parents, which may be repaid with some form of filial piety. To see life as a gift is to accept that one is born owing a debt. It is a very prosocial world view, encouraging good behavior, care of parents, and perhaps even the production of grandchildren as a means of fulfilling the debt. The benefits that children supposedly provide, such as support in old age and grandchildren, are frequently mentioned in support of having children. And the absence of these benefits, or of children themselves, is commonly expressed in terms of fear—the fear of dying alone. Emphasis of the fairness foundation elides notice of the significant parent-offspring competition present in humans. Neither the evolutionary nor subjective interests of parents and offspring align perfectly; often they are very badly mismatched. (As a mild example, consider the differences between the suitor a young lady might choose for herself, and the one her parents might choose for her. A less mild example might take notice of real, modern arranged marriages between prepubescent girls and much older men, often relatives.) The fairness frame, among other things, uses the thought of the horror of nonexistence to coax filial piety out of children and give parents more power in parent-offspring competition. As noted above, this is likely a civilization-preserving cultural idea, encouraging action in accord with longer time horizons. It achieves this at the expense of coercion toward children. In agrarian societies, children have significant economic value; the cost of bearing, feeding, and caring for them is more than offset by the value of work they perform. In our society, however, children have negative economic value.37 How do parents in the modern world deal with the fact that children are, in economic terms, a “bad bargain”? One strategy is for parents to attribute more non-economic value to children38 when reminded of the economic loss they are taking, “exaggerating” their parental joy in response to the salience of the costliness of children. This will be explored below in the section on sanctity, but there is fairness and reciprocity at work here as well: if children cannot provide economic value in return for their economic cost, they are said to provide other kinds of value. The high cost of children is driven not just by their declining economic value, but by the increasing cost of giving a child socially appropriate resources. Spending on children is determined in part by the spending of those in the community. A status arms race drives up spending, not just on clothes and toys but also on education, extracurricular activities, and medicine. High-status parents may feel the need to distance their children, through spending, from the children of poor people (who at any rate have more children than wealthy, educated people). Since children impose such a high cost, those who opt out of childbearing are sometimes accused of “free riding,” of being lazy or selfish. In other words, childless people are seen as cheating on a supposedly reciprocal obligation — either with their own parents, or with others in society who have an interest in the genetic future of their race or species. No doubt the cost and burden of childbearing is a factor for many decisions not to reproduce, but it is incorrect to see parents as especially self-sacrificing in this regard. While the economic and well-being costs of having children are high, most of the “cost” of existence is borne by the children themselves, not by the parents in raising them. Parenting involves not just volunteering for the job of parent, but volunteering innocent children for the job of being people. C. Sanctity In the laboratory, when manipulated by researchers to think about the high economic cost of having children, parents tend to focus on and elaborate another kind of value that children have—their emotional and spiritual meaning, the value of the special connection between parent and child. In one experimental study, parents manipulated to think about the high cost of childrearing said they planned to spend more time with their children during the upcoming weekend than parents who had not been so manipulated.39 Outside the laboratory, elaborating new kinds of value for children seems to have been a widespread response to the changing economic value of children—and of women. The consequences of this new source of sanctity have not always been good for children. We need not go as far as Philippe Ariès (Centuries of Childhood) in positing that childhood was only recently invented and that parents five hundred years ago did not form strong, protective bonds with their children. The absence of such bonds, in a species requiring so much parental investment and care for survival, seems incredible, if only on evolutionary grounds. However, there have been drastic, visible changes in the typical treatment of children since the Industrial Revolution changed their economic meaning. In Meanings of Life Roy Baumeister summarizes the changing economic and social value of women during the industrial revolution: For centuries…women’s work had held a secure place in the social environment. It was inferior in prestige to men’s work, but it was no less vital. The family economy, even the family’s survival, was clearly and multiply dependent on the woman’s contribution. Work is a powerful source of purpose (goals) and efficacy in life, and so women’s lives certainly did not lack for meaning in these respects. The woman’s work was vital to the family, and everyone knew it. Then a remarkable thing happened. The Industrial Revolution took over women’s tasks one by one. First, the textile mills soon could produce cloth more cheaply and efficiently than more weaving. Then other tasks, ranging from candle-making to food processing, shifted out of the home and into the factory. The woman’s contribution to the family dwindled from vital and central to minor. To put it crudely, from an economic standpoint, women became obsolete. …The importance of these economic shifts cannot be underestimated for understanding the history of women… The “Woman Question” that vexed the 19th century was based on a profound uncertainty about what women were useful for. Such a question would have been unthinkable in previous eras, for women’s contribution to everyone’s daily life was palpable and vital, even when the treatment of women was a mixture of contempt and exploitation. An economically useless womanhood was a new and troubling phenomenon. [Emphasis mine; citations omitted.] The answer to the “Woman Question” that was elaborated in the nineteenth century is still a major source of sacredness today: the innovation of the “cult of motherhood.” The last remaining source of value that women had—childbearing and childrearing—was made into “a more comprehensive, fulfilling purpose”: The first step was the elevation of motherhood into an important, fulfilling life-task. A “cult” of motherhood appeared early in the 19th century. Speeches, sermons, and publications started to describe the importance of motherhood for the nation. It was mothers, they said, who determined the nation’s future, for mothers determined the character traits of the next generation. Around 1820, there began a rapid proliferation of books and pamphlets on how best to rear a child. It was addressed to mothers, who were not (for pretty much the first time in history) considered more important than fathers to their child’s upbringing. By mid-century, the glorification of the mother’s role had reached the point where the father’s role was all but forgotten, and it seemed that mothers alone could transform their innocent babies into productive, virtuous citizens of the Republic. Child care, which had previously been regarded as a minor and unprestigious job, now loomed as a sacred and difficult responsibility of mothers. …Writers and speakers began to refer to the ecstasies and raptures that supposedly characterized motherhood. To read these passages, many of which were written by men, one would think that taking care of children was a source of uninterrupted bliss. [Emphasis in original; citations omitted.] But women were not the only ones whose economic value had eroded: the economic value of children plummeted as the industrial revolution progressed. Both women and children were given new and different value through the glorification of motherhood. The consequences of this new arrangement for women, children, and society have been mixed. Victorian concern for the well-being of children as a special, protected class is associated with the passage of laws regulating child labor and criminalizing abuse. Women gained status both from their newly-important role as mothers and from their new alliance with the church; they became guardians of virtue, and translated this into political power for child welfare causes. Concern for the well-being of children, and recognition of women’s role in promoting it, contributed to other “women’s” causes, including temperance and female suffrage. However, once women attained equal legal and social status to that of men—in part because of their connection with religion and childbearing—the allure of childrearing as a sole source of meaning seems to have faded. The women’s liberation movement, the normalization of divorce, and the massive increase in women’s participation in college and work since the 1960s indicate that the cult of motherhood was not adequate to meet the needs of modern women for meaning. But the sacredness of motherhood (and of childhood) is alive and well. Only a few generations ago, children were allowed to roam on their own around cities and countryside. Today, for a child to be allowed outside his own yard without adult supervision is a legal scandal. Children’s freedom to roam and to socialize informally has been severely curtailed; their school environment has become more prisonlike, their physical safety protected at the expense of their education, development, and fun. The loss of children’s freedom to roam may be regarded as an unfortunate late stage in the sacralization of childrearing. Abuse panics, whether focused on satanic cults or neighborhood pedophiles, reflect the sacred status of children—and also the deep discomfort mothers have with sending them to be cared for by strangers while they work. That motherhood is sacred may be illustrated by the pattern of products and causes seeking to identify themselves with motherhood. Representing a mother rather than, say, a puppy or cartoon bear lends a consumer product advertisement a certain gravity. “Mothers Against Drunk Driving” is only one of dozens of groups that link their causes with the sacredness of the maternal bond. Sex workers, in lobbying for status and sometimes for the legalization of their profession, put the fact that they are mothers front and center, implying that motherhood “rubs off ” sacredness even on those whose moral behavior is most questionable. The sacredness of childbearing, as with other forms of sacredness, is often visible in its violation. Most obviously, the sacredness of children is applied to embryos and fetuses, informing opposition to abortion. This is not to say that abortion proponents like myself are immune from sacredness; the right to choose has become somewhat sacred, and the women’s body itself is a locus of sacredness vulnerable to violation by regulation. Controls on reproduction themselves violate sacredness: eugenics is metonymically associated with Nazis, and reproduction is considered a “fundamental right” in the United States. Even very mild and sensible controls on reproduction are rejected by courts. The freedom to reproduce—or not to reproduce—is discussed below, but it’s important to note that it straddles the line between the freedom foundation and the sacredness foundation. It is, in other words, a sacred right. D. Loyalty As mentioned above, those who do not reproduce are often viewed as lazy, “free-riding” on the efforts of others to promote the future of the species. Loyalty—whether to one’s kin, or to the species in general—is a moral foundation relevant to childbearing. Having children is now very costly, which suggests a new role for childbearing: as a costly signal of group commitment. Many religious groups (Catholics, Mormons, Orthodox Jews) strongly suggest or even mandate that followers have many children, and this prescription probably assists coordination between co-religionists. Religious communes that impose heavy costs on their members40 (in the form of prohibitions and requirements) tend to survive longer than less demanding cults; costly signals, whether observing dietary restrictions or having large families, make cooperation more reliable. E. Freedom The liberty of parents to procreate is now so deeply enshrined in American law and culture that it has come to function as a sacred right. Less than a hundred years ago, procreation was not the sacred right that it is now; popular family manuals and works of sociology extolled birth control in progressive terms not primarily as an individual right but as a means of controlling and improving the quality of human populations. Today, even in extreme cases, restrictions on childbearing are almost never tolerated. The forcible sterilization of people likely to have children with bad lives is hardly conceivable to moderns, and any suggestion that individual choice is not the ideal determinant of procreation is dismissed as eugenics. It is politically and socially permissible to sincerely argue for restrictions on abortion, but not for restrictions on reproduction. The right to have children, like many other modern rights, is not mentioned in the Constitution, but is interpreted as being protected by an implied right to privacy. It is now, as I have said, a sacred right that may not be violated even in the most extreme cases. Mothers who starve their children to death41 and fathers who make no effort to support their many children42 may not be restricted in their “fundamental right” to have as many children as they can. It is extremely rare, however, to consider the child’s liberty interests. Opponents of abortion maintain that the child has a “right to life,” but it is very strange to talk about a “right not to be born”—even a limited right not to be born under very bad circumstances. Life, of course, is the ultimate freedom, a human existence being the prerequisite for having any meaningful freedoms at all. But life is also a burden. That childbearing has been turned into a freedom, rather than something that just happens, is why discussions like this are possible. Birth control and abortion make it undeniable that having children is a choice. As childbearing has become more economically costly and more voluntary, the social meaning of children has changed.",
      "word_count": 6952,
      "character_count": 43138,
      "chapter_number": 12,
      "section_number": null,
      "paragraph_number": null,
      "start_position": 0,
      "end_position": 43138,
      "parent_chunk_id": null
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch12_s1",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "section",
      "title": "Final Section",
      "content": "Chapter Five: Moral Foundations Analysis of Suicide and Childbearing The first part of this book investigated a modern worldview in which human moral beliefs are not the product of a rational utilitarian calculus, but rather of evolved heuristics that function to solve coordinated action problems and bind groups together. These include sacredness, loyalty, and authority as well as harm, fairness, and freedom. Human cultures are not rationally chosen sets of institutions, but messy, evolved collections of cultural items. We participate in them not because they give us accurate representations of reality, but because they meet our social and psychological needs. We now proceed to analyze the two specific subjects of this inquiry—suicide and childbearing—from this perspective. Suicide and Moral Foundations A. The harm of suicide Harm/care is a very rational model for moral intuition, and likely fails to account for most moral cognition surrounding suicide. This is the foundation, however, to which most philosophical arguments regarding suicide have been addressed (and indeed to which non-specialists willing to discuss their beliefs often instinctively appeal). What are the harms of suicide—and the harms of its prohibition? By what right might these harms be inflicted? 1. Harm to survivors—friends, relatives, and others Suicide opponents often call suicide a form of murder —self-murder. The suicide is viewed as improperly taking himself away from his friends and relatives earlier than they expected, frustrating their expectations. It is natural to assign a dysphemism to a hated practice that violates sacredness, but of course suicide is distinct from murder. People who commit suicide are not “victims” in the sense that people who are murdered are. Consent is a powerful element, transforming rape into consensual sex, slavery into work, kidnapping into a vacation. A suicide’s survivors are not victims, I will argue, because the type of harm that they suffer is a type of harm that the suicide himself, and not a murderer, has a right to inflict as a double effect of refusing to live. And it cannot be that the harm to survivors is the only—or even the major—reason that murder is wrong. The murder of a lonely person with no relatives is surely no less horrible (or not much less horrible) than the murder of a person with many relatives. Evolutionary psychologists Martin Daly and Margo Wilson31 point out that “tribal people may explain a particular act of seemingly unprovoked homicide to an appalled missionary or anthropologist by pointing out that the victim had no relatives”—that is, there was no danger of retaliation—but to a modern mind, this is hardly a moral defense. How much of the harm to survivors is due not to the suicide itself but to the suicide prohibition? A writer on the Internet suicide group alt.suicide.bus.stop, writing as “EverDawn,” asserts that a great deal of the harm to survivors of suicide—in particular, the perception of suicide as “tragic”—is an artifact of the policy of suicide prevention and its attendant doctrines: Perceiving an event as tragic makes it difficult to come to terms with, in contrast to an event which is just sad. If a sad event couldn’t have and shouldn’t have been prevented, then there is no blame to be placed, and nobody to be angry at. But a tragic event raises the questions: how could it be prevented, who should have prevented it. This leads to anger (when blaming others) and despair (when blaming self). The questions linger on, unanswered, making it far more difficult to come to terms with the event. We have been led to believe that suicide should be prevented because suicide is tragic, when in fact, the reason why suicide is tragic is because society has chosen a policy of suicide prevention. Suicide is a sad event, however, the perception of suicide as tragic is a result of the choice society has made—a choice which society is responsible for. Ultimately, society is to blame for the negative consequences of this choice. The harm of suicide is distinct from the harm of murder, and—a theme that will be highlighted throughout this book —the suicide prohibition itself is responsible for much of the harm that suicide does cause. Let us now specifically examine the harms that suicide causes to those left behind. a. Loss of company, support, and other expected goods The most commonly cited harm inflicted by suicide is the harm to the surviving friends and relatives. What, exactly, does that harm consist of? Certainly, it is not merely the fact that the person has died. Everyone dies eventually; suicides are not unique in this. Our surviving family and friends must eventually come to terms with all of our deaths. The only special harm attributable to the suicide is that he has died early, depriving the survivors of an expected period of his company and support—specifically, that period between the time of suicide and the time he would have otherwise died. During that time, the lover or spouse no longer enjoys the affection of the suicide; the relative no longer enjoys his visits and presents and sidewalk-shoveling; the friend no longer enjoys his opinions and companionship; the parent may no longer hope for grandchildren. The problem is that little of this “company and support” (and reproductive capacity) is morally obligatory. A person may, without committing a moral wrong by modern standards, leave his spouse due to irreconcilable differences or move away from his friends and relatives to pursue a career or refuse to have children. Providing our company is a voluntary act, and we are under no moral obligation to do so. The company and support of a person is best viewed as a privilege, not a right—with the important exception of a person’s voluntarily conceived children (there is a moral duty to care for one’s children that renders the suicide of a parent of dependent children, rebuttably, wrong). The losses inherent in a suicide are real, but unlike the losses inherent in a murder, they may be inflicted in the exercise of a moral right. At the very least, we are generally permitted to inflict those losses in other contexts. If suicide is prohibited because of the harm to our mothers, should we also be legally forbidden to move away from our mothers? b. Knowledge of permanent loss A loss of companionship and support is upsetting, but perhaps a suicide is worse than moving away because it creates the knowledge in the minds of survivors that the loss is permanent. It removes hope of an eventual return and reconciliation. Is this harm blameworthy? Do people have a right to this (often irrational) hope? Move-away losses and other estrangements are frequently permanent. While the knowledge of the permanence of a loss may be painful, it is also valuable to know the truth. The survivor of a suicide may in this way be better off than the person left behind in an estrangement he stubbornly refuses to admit is permanent. While both the loss of the company of the decedent and the knowledge that his departure is permanent are harms that survivors of a suicide suffer, it is important to recognize that these harms conflict with the liberty interests of the suicidal person (freedom/oppression foundation) and with a fairness analysis (fairness/cheating) of the act and its harms. c. Discovering and disposing of the body A distinctly visceral harm must be suffered by someone in any suicide in our prohibition society: the discovery and disposal of the body. Where the discoverer is a relative or close associate, the shock must be even greater. While discovering the body of one’s spouse or friend or child must necessarily be awful, it is an artifact of the suicide prohibition that this must happen. Legal suicide (allowing for chosen death and market mechanisms to accomplish it comfortably) would allow suicides to say goodbye before dying, to die in the presence of loved ones, or to discreetly provide for the professional disposal of their bodies. The shock of discovering the body of a suicide must be weighed against another harm that is also a consequence of prohibition: since he must hide his act in order to get away with it, a suicide may be “missing” for days or weeks (or more) prior to discovery. Given the suicide prohibition, privacy and a controlled environment are essential to a suicide’s success; his own home is often the only place where these are possible. Legal, preplanned suicide, perhaps taking place in a hospital, would eliminate this harm. Frequently in our prohibition society, another must suffer the great harm of being the unwilling agent of death for the suicide (as with suicides who jump in front of trains). This is unfortunate, and I see such suicides as particularly morally questionable. However, this harm (in fact, this type of suicide) is also an artifact of the suicide prohibition and would largely disappear if reliable suicide methods that did not cause harm to bystanders were commonly available. Everyone dies of something. And we can’t bury ourselves. This means that for every human being who has ever lived, someone must discover and dispose of the body. It is mistaken to attribute this harm only to suicides. It is part of our humanity that we—suicides and non-suicides alike—must inflict this harm on others. Once we have been given the dubious gift of life, we are destined to burden someone with the disposal of our dead body. 2. Harm to the Suicide Himself Those who are comfortable with paternalism often argue that suicide must be prevented—indeed, that it displays a lack of compassion to allow it—because of the harm to the suicide himself. a. Loss of future experiences Frequently the victim under consideration for the harm/ care foundation is the suicidal person—who is to be protected from himself. How can one harm oneself? The harm inflicted by the suicide upon himself must be the deprivation of possible future experiences (keep in mind that sacred harms, such as religious harm, belong under different moral foundations). However, by committing suicide, a person affirms that, in his evaluation, the expected future gains from living are not worth the expected costs. Many people intuitively support this line of thinking when it comes to people dying of a terminal illness. But why would people dying of a terminal illness be the only people miserable enough to rationally want to die? Hope is not necessarily rational. Prohibiting suicide amounts to substituting one’s own (poorly informed) judgment for the suicide’s own (immeasurably better informed) judgment of the degree to which his life is worth living. I have argued elsewhere that suicide is not, as many believe, the irrational product of mental illness. But what about suicide committed on impulse? Perhaps a person’s “self” evaluates the situation at time t and decides that suicide is preferable, but later, at time t plus 24 hours, he might decide he was mistaken, and dearly wish to keep living. One problem with this theory is that suicide does not, in fact, appear to be an impulsive act,32 but generally involves a plan. And given the existing barriers to suicide, a suicide that appears “impulsive” may actually reflect the genuine rational desires of the suicide. The person who rationally prefers to die may be unfairly prevented from doing so by legal and practical barriers; he may need an “impulse” to push him over the edge and enact his rational desire. Confronted with evidence that suicidality is not impulsive and fleeting, paternalists often point to statistics showing that only a small percentage of people who are caught before completing a suicide attempt go on to commit suicide, but this is a poor line of evidence. We live in a society that prohibits suicide and expends vast resources to prevent and punish it. Being forcibly prevented from exiting life by the medical and legal institutions of our culture is a devastating experience, encouraging a sense of learned helplessness and despair. Imagine you lived in one of the many countries that criminalizes abortion. In your country, it is the case that women who attempt abortion but are caught before they succeed rarely go on to actually get an abortion. Proponents of prohibition claim this is evidence that few women actually want abortions. Is this line of reasoning suspicious? (In both cases, prohibition increases the difficulty of achieving the desired result—abortion in one case, death in the other.) Even if we could be certain that a would-be suicide would be glad to be rescued (we can’t), this would not be a strong moral reason to prohibit suicide. The victim’s being “glad it happened” after the fact does not render interference morally justifiable. b. Harm from an unsuccessful suicide attempt Harm inflicted by an unsuccessful suicide attempt is entirely an artifact of the suicide prohibition, not a harm inherent in suicide. Every year, thousands of people are rendered permanently disabled by being forcibly rescued from suicide attempts; as noted earlier, this is one of many ways in which prohibition increases the cost of suicide—in this case, by increasing its potential for harm suffered by the suicidal person. c. Failed signaling It is commonly believed that a suicide attempt should be universally interpreted as a “cry for help.” A successful suicide may be seen, then, as a failed signal for help. But this attitude benefits neither serious suicides, nor would-be signalers. Again, the idea of “failed signaling” is an artifact of the suicide prohibition. In order for a person to send a reliable signal, the suicide attempt must appear lethal while not actually being lethal. If comfortable, reliable suicide were legally and practically available, there would be very little value in choosing any other method, and any other method would be less lethal than the medical option. This would interfere with the appearance of lethality communicated by a suicide attempt, thereby decreasing the motivation to make a “signal” attempt in the first place. What an insincere suicide attempter—a “signaler”—really wants is to be rescued. That is, he wants to be forcibly prevented from committing suicide, because he does not really want to commit suicide. Remove the possibility for rescue, and you remove this insincere suicide’s motivation to make the potentially harmful attempt in the first place. It is the suicide prohibition, and not suicide itself, that causes this harm to the would-be signaler. B. Loyalty When the topic of suicide is raised in a moral context, it becomes increasingly likely that someone with a personal connection to a suicide will bring up that connection. This is perfectly understandable, but it locates the harm of suicide in near others (in-group members especially) rather than diffusely among the populace. Someone with a near connection to a suicide may find that he is able to shift the discussion toward his preferred theory. If he takes a position in favor of government intervention and brings up a deceased family member who committed suicide (even though this is technically a non sequitur), the interlocutor taking an opposite position may be reframed as attacking the family member rather than a position. The interlocutor’s moral argument may thus be perceived, especially by him, as a loyalty violation toward his own in-group. It is natural, both psychologically and rhetorically, to emphasize an in-group connection to a phenomenon like suicide. There is nothing wrong with this. Faced with this natural tendency, opponents of prohibition must depersonalize arguments before engaging. One strategy is to emphasize loyalty toward the class of people who want to die through acknowledging their freedom to exit. This is further addressed below, in my discussion of “Liberty.” C. Fairness, Cheating, Selfishness, and Suicide Closely related to judgments of loyalty are judgments of fairness. What is to be expected of a person in our society? It is very common for proponents of prohibition to emphasize that suicide is “selfish,” generally relying on the visceral connotations of this term for effect rather than defining it precisely. Rather than accepting the idea that suicide is selfish, we must investigate what is meant by this statement and place our concerns in context according to the moral faculties swayed by such concerns. What is the standard by which reciprocity is judged? To say that suicide is selfish is to imply that the suicidal person has not lived up to a duty to his fellow man, a duty to go on living no matter the cost in personal misery. But what is the basis for this duty? Is it fair to expect someone to live out his natural life? What would make it fair or unfair? The length of a natural life varies, as do the circumstances in which it must be lived. The basis of fairness can’t be consent to life—consent occurs neither at the beginning (no one consents to being born) nor at the end (a suicidal person explicitly does not consent to being alive). Certainly social expectations are violated by suicide, if not stipulated contractual ones; though there was no express agreement to live up to, we might imagine a contract implied by certain actions, at whose heart is the promise to live out one’s natural life no matter what. What behaviors would indicate acceptance of such an implied contract? Perhaps merely staying alive indicates ongoing consent for life, but as I argued in the first chapter, an action without the genuine freedom to do the opposite cannot indicate consent. Perhaps forming serious relationships indicates consent, but how is a life to be made even potentially worth living without the formation of strong relationships of mutual reliance? Must a person choose a track for himself early on—suicide and solitude, or strong relationships and severe restriction on the moral right of suicide? Intuitively and in practice, attempts at social integration are rarely seen as violations by a suicidal person, and social withdrawal is not seen as a moral duty. D. Authority Supreme Court Justice Antonin Scalia,33 in refusing to recognize a right of citizens to refuse medical care that would prolong their lives, offers the defense that suicide was a felony at common law—which is to say that historically, in England for hundreds of years, the penalty for trying to kill yourself was hanging. Scalia grounds an authority-based argument against suicide in this early prohibition: because suicide was a felony, he argues, modern governments need not recognize a suffering person’s right to end his life. The authority foundation has not found much persuasive power within the context of suicide. Arguments like the above seem self-evident to those, like Scalia, who are moved by authority, but read as clumsy otherwise. However, a major force for the acceptance of the suicide prohibition has been the expanding authority of medicine in our society. Medicine, and the medical model of suicide, is as much a product of the authority framework as of the harm/care foundation. Medicine pretends to an almost exclusively harm/care orientation; however, it has acquired a halo of sacredness since its great successes in the last century with vaccines and antibiotics. And it has used this sacredness to cultivate an aura of authority. As detailed in the first chapter, the greater portion of the suicide prohibition is not legal, exactly, but medical. Doctors, as part of a hospital system, have the authority to imprison people on locked wards for displaying signs of mental illness that are presumed to indicate a danger to self or others. In practice, this means that even a rational suicidal person may be imprisoned. The authority to imprison, to medicate, to bully and coerce patients into compliance with treatment plans, goes along with expanding medical authority in a variety of contexts once thought to be the domain of the family or the individual. Hospital staff frequently remove children from parents judged to be a danger to the children—and, in many cases, the only danger is the disagreement with doctors as to the diagnosis and its appropriate treatment. Doctors have referred to this procedure as a “parent-ectomy,”34 as in surgical removal of the parents. That medical experts should have such authority is a very modern development. Another result of the expanded authority of medical practitioners is doctors assisting police by performing invasive cavity searches of suspects.35 The expanding authority of medicine is worrying. There are no checks or balances built into our system to counteract the authority of doctors, and experiments with socialized medicine mean that government is more involved with health care than ever. E. Suicide and Sanctity Among those who oppose suicide and approve of its prohibition, sanctity, not harm, appears to be the foremost reason. In laboratory experiments,36 the harm/care foundation was activated with regard to homicide, but did not substantially affect judgments of suicide. Instead, concern with the tainting of souls and moral disgust appeared to be the most powerful operative foundations. In the previous chapter, it was noted that a characteristic of sacred beliefs is that symbols tend to be confused with referents; images of cigarette smoking and discussion of rape may be seen as violations in addition to the underlying behaviors themselves. Thus it is with suicide: even conversations about suicide, whether artistic or mundane, have the power to trigger strong reaction, and this reaction often takes the form of censorship (discussed at length in a later chapter). The supposed suicide contagion is often brought up as a rational basis for such censorship, but the fact that suicide is open for contagion analysis, when other acts (such as interpersonal violence) are generally not, must be explained. And it is precisely the purity violation inherent in suicide and discussions of suicide that allows for contagion analysis: impurity is contagious, and moral degradation is seen to spread like an infection, whereas ordinary harm is not. If ordinary violence were seen to be contagious, its moral condemnation and retributive responses would be imperiled; but suicide, as a sanctified domain and a special sacredness violation, is frequently the subject of contagion framing. F. Liberty The liberty foundation is that which is most conducive to eliminating the suicide prohibition. Thomas Szasz and other libertarian writers have advocated for a right to die as part of a broader right of self-determination that includes the right to refuse psychiatric treatment. Responses to the pro-choice position that strive to maintain the liberty frame tend to balance future liberty interests of the person with present liberty interests, breaking a person into multiple selves over time and presenting the different selves’ interests as in conflict. The position that prioritizes future interests over present interests is in accordance with the suicide prohibition; paternalism often refuses to admit that it is paternalism, instead insisting that it is merely representing the true, genuine “freedoms” of a future person. In other contexts, restricting the actions of a future self is seen as an important freedom. All contracts, for instance, have this feature, as did the institution of marriage before modern no-fault interventions. In the suicide context, however, the decision of the present self to commit suicide is often stigmatized as disordered, insane, or impulsive; that it may be a rational and integrated decision makes the case for restricting it based on future interests more difficult. Childbearing and Moral Foundations The morality of suicide is distinct from the question of the morality of childbearing, as illustrated in the first chapter. But the two issues are connected, especially along the harm/ care, fairness, and loyalty foundations. Childbearing is especially sacralized in our culture; as with suicide, the sacredness foundation bears a great deal of the weight of moral cognition on childbearing, if often invisibly. Freedom, as applied to childbearing, is generally limited to analysis of the rights of parents—the right to bear children, and the right to prevent or abort children. Rarely are the liberty, harm, or fairness interests of the children seriously considered. A. Childbearing and Harm That being alive entails suffering has been acknowledged at least since the time of the Buddha. Even the best lives are frequently painful and boring, punctuated by unsatisfied longing, loneliness, fear, shame, hunger, anger, and grief. All humans age and die—and to make matters worse, they become aware early on that they will inevitably die. A naive view from the hedonic perspective, in which only pleasure and pain matter, was explored in the first chapter where I considered Bryan Caplan’s argument that since most people stay alive, rather than jump off of tall buildings, the pleasures of life must outweigh its many harms. A more nuanced view must allow that this is frequently not the case: that the harm of life frequently seems to outweigh any benefit it may be said to provide to the living person. The one million suicides per year, globally, put a lower bound on this condition, but it is difficult to know how many people suffer so much that life is, on net, a harm to them. This analysis is made more complicated by the fact that symbolic and social meaning, rather than a robotic pleasure/pain trade off, is in fact what seems to motivate human action. Not many people commit suicide, but many people act as if their lives are not very valuable to them. They risk actual death or social death by gambling their present circumstances on a small chance of future payoff, in a manner that is not actuarially sound. They choose, with their economic decisions, to believe in a counterfactual world, indicating dissatisfaction with the real world. They palliate present suffering in a manner that harms future prospects. This gamble/ palliate behavior is examined in detail in a later chapter; it indicates that, rather than valuing life as a precious gift, people frequently treat life as having zero or negative value with their actual actions. The suffering occasioned by life is great and undeniable, indicating that childbearing, at least in this aspect, does major harm to those brought into the world. Is there something that makes up for this harm, such that something causing so much misery might properly be regarded as a gift? This “balancing factor” might be meaning—either universal meaning, or subjective meaning found and elaborated by individuals; this is addressed in an earlier chapter. Another possibility is the proposition that, on balance, the pleasure and good experiences of life make up for the suffering it occasions. Rather than eschewing all suffering, individuals frequently accept some degree of suffering in pursuit of other rewards—either in the form of meaning, or in the form of pleasure. The mountain climber or medical student affirmatively chooses to suffer for the purpose of future experiences, pleasurable or meaningful. Others, looking back on times of suffering, say they are glad to have had such experiences. When making decisions for ourselves, there is no moral problem with trading off suffering for pleasure or meaning; it appears to be a social fact that people do not minimize suffering in their own lives. What about when we act upon others—especially strangers, whose preferences we know nothing about? Can we permissibly cause them serious harm in order to give them a benefit, and without their permission? This question, fundamental to the modern philosophic question of antinatalism, will be addressed in a later section, but it is important to root it in the “harm/care” moral foundation, and to notice what other moral foundations affect thinking about childbearing. B. Fairness, Cheating, and Reciprocity The fairness and reciprocity orientation regarding childbearing is prominent in many cultures. Life (and perhaps care, feeding, and rearing) is regarded as a gift that parents give their children. This is regarded as creating a debt owed by the child to the parents, which may be repaid with some form of filial piety. To see life as a gift is to accept that one is born owing a debt. It is a very prosocial world view, encouraging good behavior, care of parents, and perhaps even the production of grandchildren as a means of fulfilling the debt. The benefits that children supposedly provide, such as support in old age and grandchildren, are frequently mentioned in support of having children. And the absence of these benefits, or of children themselves, is commonly expressed in terms of fear—the fear of dying alone. Emphasis of the fairness foundation elides notice of the significant parent-offspring competition present in humans. Neither the evolutionary nor subjective interests of parents and offspring align perfectly; often they are very badly mismatched. (As a mild example, consider the differences between the suitor a young lady might choose for herself, and the one her parents might choose for her. A less mild example might take notice of real, modern arranged marriages between prepubescent girls and much older men, often relatives.) The fairness frame, among other things, uses the thought of the horror of nonexistence to coax filial piety out of children and give parents more power in parent-offspring competition. As noted above, this is likely a civilization-preserving cultural idea, encouraging action in accord with longer time horizons. It achieves this at the expense of coercion toward children. In agrarian societies, children have significant economic value; the cost of bearing, feeding, and caring for them is more than offset by the value of work they perform. In our society, however, children have negative economic value.37 How do parents in the modern world deal with the fact that children are, in economic terms, a “bad bargain”? One strategy is for parents to attribute more non-economic value to children38 when reminded of the economic loss they are taking, “exaggerating” their parental joy in response to the salience of the costliness of children. This will be explored below in the section on sanctity, but there is fairness and reciprocity at work here as well: if children cannot provide economic value in return for their economic cost, they are said to provide other kinds of value. The high cost of children is driven not just by their declining economic value, but by the increasing cost of giving a child socially appropriate resources. Spending on children is determined in part by the spending of those in the community. A status arms race drives up spending, not just on clothes and toys but also on education, extracurricular activities, and medicine. High-status parents may feel the need to distance their children, through spending, from the children of poor people (who at any rate have more children than wealthy, educated people). Since children impose such a high cost, those who opt out of childbearing are sometimes accused of “free riding,” of being lazy or selfish. In other words, childless people are seen as cheating on a supposedly reciprocal obligation — either with their own parents, or with others in society who have an interest in the genetic future of their race or species. No doubt the cost and burden of childbearing is a factor for many decisions not to reproduce, but it is incorrect to see parents as especially self-sacrificing in this regard. While the economic and well-being costs of having children are high, most of the “cost” of existence is borne by the children themselves, not by the parents in raising them. Parenting involves not just volunteering for the job of parent, but volunteering innocent children for the job of being people. C. Sanctity In the laboratory, when manipulated by researchers to think about the high economic cost of having children, parents tend to focus on and elaborate another kind of value that children have—their emotional and spiritual meaning, the value of the special connection between parent and child. In one experimental study, parents manipulated to think about the high cost of childrearing said they planned to spend more time with their children during the upcoming weekend than parents who had not been so manipulated.39 Outside the laboratory, elaborating new kinds of value for children seems to have been a widespread response to the changing economic value of children—and of women. The consequences of this new source of sanctity have not always been good for children. We need not go as far as Philippe Ariès (Centuries of Childhood) in positing that childhood was only recently invented and that parents five hundred years ago did not form strong, protective bonds with their children. The absence of such bonds, in a species requiring so much parental investment and care for survival, seems incredible, if only on evolutionary grounds. However, there have been drastic, visible changes in the typical treatment of children since the Industrial Revolution changed their economic meaning. In Meanings of Life Roy Baumeister summarizes the changing economic and social value of women during the industrial revolution: For centuries…women’s work had held a secure place in the social environment. It was inferior in prestige to men’s work, but it was no less vital. The family economy, even the family’s survival, was clearly and multiply dependent on the woman’s contribution. Work is a powerful source of purpose (goals) and efficacy in life, and so women’s lives certainly did not lack for meaning in these respects. The woman’s work was vital to the family, and everyone knew it. Then a remarkable thing happened. The Industrial Revolution took over women’s tasks one by one. First, the textile mills soon could produce cloth more cheaply and efficiently than more weaving. Then other tasks, ranging from candle-making to food processing, shifted out of the home and into the factory. The woman’s contribution to the family dwindled from vital and central to minor. To put it crudely, from an economic standpoint, women became obsolete. …The importance of these economic shifts cannot be underestimated for understanding the history of women… The “Woman Question” that vexed the 19th century was based on a profound uncertainty about what women were useful for. Such a question would have been unthinkable in previous eras, for women’s contribution to everyone’s daily life was palpable and vital, even when the treatment of women was a mixture of contempt and exploitation. An economically useless womanhood was a new and troubling phenomenon. [Emphasis mine; citations omitted.] The answer to the “Woman Question” that was elaborated in the nineteenth century is still a major source of sacredness today: the innovation of the “cult of motherhood.” The last remaining source of value that women had—childbearing and childrearing—was made into “a more comprehensive, fulfilling purpose”: The first step was the elevation of motherhood into an important, fulfilling life-task. A “cult” of motherhood appeared early in the 19th century. Speeches, sermons, and publications started to describe the importance of motherhood for the nation. It was mothers, they said, who determined the nation’s future, for mothers determined the character traits of the next generation. Around 1820, there began a rapid proliferation of books and pamphlets on how best to rear a child. It was addressed to mothers, who were not (for pretty much the first time in history) considered more important than fathers to their child’s upbringing. By mid-century, the glorification of the mother’s role had reached the point where the father’s role was all but forgotten, and it seemed that mothers alone could transform their innocent babies into productive, virtuous citizens of the Republic. Child care, which had previously been regarded as a minor and unprestigious job, now loomed as a sacred and difficult responsibility of mothers. …Writers and speakers began to refer to the ecstasies and raptures that supposedly characterized motherhood. To read these passages, many of which were written by men, one would think that taking care of children was a source of uninterrupted bliss. [Emphasis in original; citations omitted.] But women were not the only ones whose economic value had eroded: the economic value of children plummeted as the industrial revolution progressed. Both women and children were given new and different value through the glorification of motherhood. The consequences of this new arrangement for women, children, and society have been mixed. Victorian concern for the well-being of children as a special, protected class is associated with the passage of laws regulating child labor and criminalizing abuse. Women gained status both from their newly-important role as mothers and from their new alliance with the church; they became guardians of virtue, and translated this into political power for child welfare causes. Concern for the well-being of children, and recognition of women’s role in promoting it, contributed to other “women’s” causes, including temperance and female suffrage. However, once women attained equal legal and social status to that of men—in part because of their connection with religion and childbearing—the allure of childrearing as a sole source of meaning seems to have faded. The women’s liberation movement, the normalization of divorce, and the massive increase in women’s participation in college and work since the 1960s indicate that the cult of motherhood was not adequate to meet the needs of modern women for meaning. But the sacredness of motherhood (and of childhood) is alive and well. Only a few generations ago, children were allowed to roam on their own around cities and countryside. Today, for a child to be allowed outside his own yard without adult supervision is a legal scandal. Children’s freedom to roam and to socialize informally has been severely curtailed; their school environment has become more prisonlike, their physical safety protected at the expense of their education, development, and fun. The loss of children’s freedom to roam may be regarded as an unfortunate late stage in the sacralization of childrearing. Abuse panics, whether focused on satanic cults or neighborhood pedophiles, reflect the sacred status of children—and also the deep discomfort mothers have with sending them to be cared for by strangers while they work. That motherhood is sacred may be illustrated by the pattern of products and causes seeking to identify themselves with motherhood. Representing a mother rather than, say, a puppy or cartoon bear lends a consumer product advertisement a certain gravity. “Mothers Against Drunk Driving” is only one of dozens of groups that link their causes with the sacredness of the maternal bond. Sex workers, in lobbying for status and sometimes for the legalization of their profession, put the fact that they are mothers front and center, implying that motherhood “rubs off ” sacredness even on those whose moral behavior is most questionable. The sacredness of childbearing, as with other forms of sacredness, is often visible in its violation. Most obviously, the sacredness of children is applied to embryos and fetuses, informing opposition to abortion. This is not to say that abortion proponents like myself are immune from sacredness; the right to choose has become somewhat sacred, and the women’s body itself is a locus of sacredness vulnerable to violation by regulation. Controls on reproduction themselves violate sacredness: eugenics is metonymically associated with Nazis, and reproduction is considered a “fundamental right” in the United States. Even very mild and sensible controls on reproduction are rejected by courts. The freedom to reproduce—or not to reproduce—is discussed below, but it’s important to note that it straddles the line between the freedom foundation and the sacredness foundation. It is, in other words, a sacred right. D. Loyalty As mentioned above, those who do not reproduce are often viewed as lazy, “free-riding” on the efforts of others to promote the future of the species. Loyalty—whether to one’s kin, or to the species in general—is a moral foundation relevant to childbearing. Having children is now very costly, which suggests a new role for childbearing: as a costly signal of group commitment. Many religious groups (Catholics, Mormons, Orthodox Jews) strongly suggest or even mandate that followers have many children, and this prescription probably assists coordination between co-religionists. Religious communes that impose heavy costs on their members40 (in the form of prohibitions and requirements) tend to survive longer than less demanding cults; costly signals, whether observing dietary restrictions or having large families, make cooperation more reliable. E. Freedom The liberty of parents to procreate is now so deeply enshrined in American law and culture that it has come to function as a sacred right. Less than a hundred years ago, procreation was not the sacred right that it is now; popular family manuals and works of sociology extolled birth control in progressive terms not primarily as an individual right but as a means of controlling and improving the quality of human populations. Today, even in extreme cases, restrictions on childbearing are almost never tolerated. The forcible sterilization of people likely to have children with bad lives is hardly conceivable to moderns, and any suggestion that individual choice is not the ideal determinant of procreation is dismissed as eugenics. It is politically and socially permissible to sincerely argue for restrictions on abortion, but not for restrictions on reproduction. The right to have children, like many other modern rights, is not mentioned in the Constitution, but is interpreted as being protected by an implied right to privacy. It is now, as I have said, a sacred right that may not be violated even in the most extreme cases. Mothers who starve their children to death41 and fathers who make no effort to support their many children42 may not be restricted in their “fundamental right” to have as many children as they can. It is extremely rare, however, to consider the child’s liberty interests. Opponents of abortion maintain that the child has a “right to life,” but it is very strange to talk about a “right not to be born”—even a limited right not to be born under very bad circumstances. Life, of course, is the ultimate freedom, a human existence being the prerequisite for having any meaningful freedoms at all. But life is also a burden. That childbearing has been turned into a freedom, rather than something that just happens, is why discussions like this are possible. Birth control and abortion make it undeniable that having children is a choice. As childbearing has become more economically costly and more voluntary, the social meaning of children has changed.",
      "word_count": 6952,
      "character_count": 43138,
      "chapter_number": 12,
      "section_number": 1,
      "paragraph_number": null,
      "start_position": 0,
      "end_position": 43138,
      "parent_chunk_id": "sarah_perryevery_cra_unknown_ch12"
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch12_p1",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "paragraph",
      "title": "Paragraph 1",
      "content": "Chapter Five: Moral Foundations Analysis of Suicide and Childbearing The first part of this book investigated a modern worldview in which human moral beliefs are not the product of a rational utilitarian calculus, but rather of evolved heuristics that function to solve coordinated action problems and bind groups together. These include sacredness, loyalty, and authority as well as harm, fairness, and freedom. Human cultures are not rationally chosen sets of institutions, but messy, evolved collections of cultural items. We participate in them not because they give us accurate representations of reality, but because they meet our social and psychological needs. We now proceed to analyze the two specific subjects of this inquiry—suicide and childbearing—from this perspective. Suicide and Moral Foundations A. The harm of suicide Harm/care is a very rational model for moral intuition, and likely fails to account for most moral cognition surrounding suicide. This is the foundation, however, to which most philosophical arguments regarding suicide have been addressed (and indeed to which non-specialists willing to discuss their beliefs often instinctively appeal). What are the harms of suicide—and the harms of its prohibition? By what right might these harms be inflicted? 1. Harm to survivors—friends, relatives, and others Suicide opponents often call suicide a form of murder —self-murder. The suicide is viewed as improperly taking himself away from his friends and relatives earlier than they expected, frustrating their expectations. It is natural to assign a dysphemism to a hated practice that violates sacredness, but of course suicide is distinct from murder. People who commit suicide are not “victims” in the sense that people who are murdered are. Consent is a powerful element, transforming rape into consensual sex, slavery into work, kidnapping into a vacation. A suicide’s survivors are not victims, I will argue, because the type of harm that they suffer is a type of harm that the suicide himself, and not a murderer, has a right to inflict as a double effect of refusing to live. And it cannot be that the harm to survivors is the only—or even the major—reason that murder is wrong. The murder of a lonely person with no relatives is surely no less horrible (or not much less horrible) than the murder of a person with many relatives. Evolutionary psychologists Martin Daly and Margo Wilson31 point out that “tribal people may explain a particular act of seemingly unprovoked homicide to an appalled missionary or anthropologist by pointing out that the victim had no relatives”—that is, there was no danger of retaliation—but to a modern mind, this is hardly a moral defense. How much of the harm to survivors is due not to the suicide itself but to the suicide prohibition? A writer on the Internet suicide group alt.suicide.bus.stop, writing as “EverDawn,” asserts that a great deal of the harm to survivors of suicide—in particular, the perception of suicide as “tragic”—is an artifact of the policy of suicide prevention and its attendant doctrines: Perceiving an event as tragic makes it difficult to come to terms with, in contrast to an event which is just sad. If a sad event couldn’t have and shouldn’t have been prevented, then there is no blame to be placed, and nobody to be angry at. But a tragic event raises the questions: how could it be prevented, who should have prevented it. This leads to anger (when blaming others) and despair (when blaming self). The questions linger on, unanswered, making it far more difficult to come to terms with the event. We have been led to believe that suicide should be prevented because suicide is tragic, when in fact, the reason why suicide is tragic is because society has chosen a policy of suicide prevention. Suicide is a sad event, however, the perception of suicide as tragic is a result of the choice society has made—a choice which society is responsible for. Ultimately, society is to blame for the negative consequences of this choice. The harm of suicide is distinct from the harm of murder, and—a theme that will be highlighted throughout this book —the suicide prohibition itself is responsible for much of the harm that suicide does cause. Let us now specifically examine the harms that suicide causes to those left behind. a. Loss of company, support, and other expected goods The most commonly cited harm inflicted by suicide is the harm to the surviving friends and relatives. What, exactly, does that harm consist of? Certainly, it is not merely the fact that the person has died. Everyone dies eventually; suicides are not unique in this. Our surviving family and friends must eventually come to terms with all of our deaths. The only special harm attributable to the suicide is that he has died early, depriving the survivors of an expected period of his company and support—specifically, that period between the time of suicide and the time he would have otherwise died. During that time, the lover or spouse no longer enjoys the affection of the suicide; the relative no longer enjoys his visits and presents and sidewalk-shoveling; the friend no longer enjoys his opinions and companionship; the parent may no longer hope for grandchildren. The problem is that little of this “company and support” (and reproductive capacity) is morally obligatory. A person may, without committing a moral wrong by modern standards, leave his spouse due to irreconcilable differences or move away from his friends and relatives to pursue a career or refuse to have children. Providing our company is a voluntary act, and we are under no moral obligation to do so. The company and support of a person is best viewed as a privilege, not a right—with the important exception of a person’s voluntarily conceived children (there is a moral duty to care for one’s children that renders the suicide of a parent of dependent children, rebuttably, wrong). The losses inherent in a suicide are real, but unlike the losses inherent in a murder, they may be inflicted in the exercise of a moral right. At the very least, we are generally permitted to inflict those losses in other contexts. If suicide is prohibited because of the harm to our mothers, should we also be legally forbidden to move away from our mothers? b. Knowledge of permanent loss A loss of companionship and support is upsetting, but perhaps a suicide is worse than moving away because it creates the knowledge in the minds of survivors that the loss is permanent. It removes hope of an eventual return and reconciliation. Is this harm blameworthy? Do people have a right to this (often irrational) hope? Move-away losses and other estrangements are frequently permanent. While the knowledge of the permanence of a loss may be painful, it is also valuable to know the truth. The survivor of a suicide may in this way be better off than the person left behind in an estrangement he stubbornly refuses to admit is permanent. While both the loss of the company of the decedent and the knowledge that his departure is permanent are harms that survivors of a suicide suffer, it is important to recognize that these harms conflict with the liberty interests of the suicidal person (freedom/oppression foundation) and with a fairness analysis (fairness/cheating) of the act and its harms. c. Discovering and disposing of the body A distinctly visceral harm must be suffered by someone in any suicide in our prohibition society: the discovery and disposal of the body. Where the discoverer is a relative or close associate, the shock must be even greater. While discovering the body of one’s spouse or friend or child must necessarily be awful, it is an artifact of the suicide prohibition that this must happen. Legal suicide (allowing for chosen death and market mechanisms to accomplish it comfortably) would allow suicides to say goodbye before dying, to die in the presence of loved ones, or to discreetly provide for the professional disposal of their bodies. The shock of discovering the body of a suicide must be weighed against another harm that is also a consequence of prohibition: since he must hide his act in order to get away with it, a suicide may be “missing” for days or weeks (or more) prior to discovery. Given the suicide prohibition, privacy and a controlled environment are essential to a suicide’s success; his own home is often the only place where these are possible. Legal, preplanned suicide, perhaps taking place in a hospital, would eliminate this harm. Frequently in our prohibition society, another must suffer the great harm of being the unwilling agent of death for the suicide (as with suicides who jump in front of trains). This is unfortunate, and I see such suicides as particularly morally questionable. However, this harm (in fact, this type of suicide) is also an artifact of the suicide prohibition and would largely disappear if reliable suicide methods that did not cause harm to bystanders were commonly available. Everyone dies of something. And we can’t bury ourselves. This means that for every human being who has ever lived, someone must discover and dispose of the body. It is mistaken to attribute this harm only to suicides. It is part of our humanity that we—suicides and non-suicides alike—must inflict this harm on others. Once we have been given the dubious gift of life, we are destined to burden someone with the disposal of our dead body. 2. Harm to the Suicide Himself Those who are comfortable with paternalism often argue that suicide must be prevented—indeed, that it displays a lack of compassion to allow it—because of the harm to the suicide himself. a. Loss of future experiences Frequently the victim under consideration for the harm/ care foundation is the suicidal person—who is to be protected from himself. How can one harm oneself? The harm inflicted by the suicide upon himself must be the deprivation of possible future experiences (keep in mind that sacred harms, such as religious harm, belong under different moral foundations). However, by committing suicide, a person affirms that, in his evaluation, the expected future gains from living are not worth the expected costs. Many people intuitively support this line of thinking when it comes to people dying of a terminal illness. But why would people dying of a terminal illness be the only people miserable enough to rationally want to die? Hope is not necessarily rational. Prohibiting suicide amounts to substituting one’s own (poorly informed) judgment for the suicide’s own (immeasurably better informed) judgment of the degree to which his life is worth living. I have argued elsewhere that suicide is not, as many believe, the irrational product of mental illness. But what about suicide committed on impulse? Perhaps a person’s “self” evaluates the situation at time t and decides that suicide is preferable, but later, at time t plus 24 hours, he might decide he was mistaken, and dearly wish to keep living. One problem with this theory is that suicide does not, in fact, appear to be an impulsive act,32 but generally involves a plan. And given the existing barriers to suicide, a suicide that appears “impulsive” may actually reflect the genuine rational desires of the suicide. The person who rationally prefers to die may be unfairly prevented from doing so by legal and practical barriers; he may need an “impulse” to push him over the edge and enact his rational desire. Confronted with evidence that suicidality is not impulsive and fleeting, paternalists often point to statistics showing that only a small percentage of people who are caught before completing a suicide attempt go on to commit suicide, but this is a poor line of evidence. We live in a society that prohibits suicide and expends vast resources to prevent and punish it. Being forcibly prevented from exiting life by the medical and legal institutions of our culture is a devastating experience, encouraging a sense of learned helplessness and despair. Imagine you lived in one of the many countries that criminalizes abortion. In your country, it is the case that women who attempt abortion but are caught before they succeed rarely go on to actually get an abortion. Proponents of prohibition claim this is evidence that few women actually want abortions. Is this line of reasoning suspicious? (In both cases, prohibition increases the difficulty of achieving the desired result—abortion in one case, death in the other.) Even if we could be certain that a would-be suicide would be glad to be rescued (we can’t), this would not be a strong moral reason to prohibit suicide. The victim’s being “glad it happened” after the fact does not render interference morally justifiable. b. Harm from an unsuccessful suicide attempt Harm inflicted by an unsuccessful suicide attempt is entirely an artifact of the suicide prohibition, not a harm inherent in suicide. Every year, thousands of people are rendered permanently disabled by being forcibly rescued from suicide attempts; as noted earlier, this is one of many ways in which prohibition increases the cost of suicide—in this case, by increasing its potential for harm suffered by the suicidal person. c. Failed signaling It is commonly believed that a suicide attempt should be universally interpreted as a “cry for help.” A successful suicide may be seen, then, as a failed signal for help. But this attitude benefits neither serious suicides, nor would-be signalers. Again, the idea of “failed signaling” is an artifact of the suicide prohibition. In order for a person to send a reliable signal, the suicide attempt must appear lethal while not actually being lethal. If comfortable, reliable suicide were legally and practically available, there would be very little value in choosing any other method, and any other method would be less lethal than the medical option. This would interfere with the appearance of lethality communicated by a suicide attempt, thereby decreasing the motivation to make a “signal” attempt in the first place. What an insincere suicide attempter—a “signaler”—really wants is to be rescued. That is, he wants to be forcibly prevented from committing suicide, because he does not really want to commit suicide. Remove the possibility for rescue, and you remove this insincere suicide’s motivation to make the potentially harmful attempt in the first place. It is the suicide prohibition, and not suicide itself, that causes this harm to the would-be signaler. B. Loyalty When the topic of suicide is raised in a moral context, it becomes increasingly likely that someone with a personal connection to a suicide will bring up that connection. This is perfectly understandable, but it locates the harm of suicide in near others (in-group members especially) rather than diffusely among the populace. Someone with a near connection to a suicide may find that he is able to shift the discussion toward his preferred theory. If he takes a position in favor of government intervention and brings up a deceased family member who committed suicide (even though this is technically a non sequitur), the interlocutor taking an opposite position may be reframed as attacking the family member rather than a position. The interlocutor’s moral argument may thus be perceived, especially by him, as a loyalty violation toward his own in-group. It is natural, both psychologically and rhetorically, to emphasize an in-group connection to a phenomenon like suicide. There is nothing wrong with this. Faced with this natural tendency, opponents of prohibition must depersonalize arguments before engaging. One strategy is to emphasize loyalty toward the class of people who want to die through acknowledging their freedom to exit. This is further addressed below, in my discussion of “Liberty.” C. Fairness, Cheating, Selfishness, and Suicide Closely related to judgments of loyalty are judgments of fairness. What is to be expected of a person in our society? It is very common for proponents of prohibition to emphasize that suicide is “selfish,” generally relying on the visceral connotations of this term for effect rather than defining it precisely. Rather than accepting the idea that suicide is selfish, we must investigate what is meant by this statement and place our concerns in context according to the moral faculties swayed by such concerns. What is the standard by which reciprocity is judged? To say that suicide is selfish is to imply that the suicidal person has not lived up to a duty to his fellow man, a duty to go on living no matter the cost in personal misery. But what is the basis for this duty? Is it fair to expect someone to live out his natural life? What would make it fair or unfair? The length of a natural life varies, as do the circumstances in which it must be lived. The basis of fairness can’t be consent to life—consent occurs neither at the beginning (no one consents to being born) nor at the end (a suicidal person explicitly does not consent to being alive). Certainly social expectations are violated by suicide, if not stipulated contractual ones; though there was no express agreement to live up to, we might imagine a contract implied by certain actions, at whose heart is the promise to live out one’s natural life no matter what. What behaviors would indicate acceptance of such an implied contract? Perhaps merely staying alive indicates ongoing consent for life, but as I argued in the first chapter, an action without the genuine freedom to do the opposite cannot indicate consent. Perhaps forming serious relationships indicates consent, but how is a life to be made even potentially worth living without the formation of strong relationships of mutual reliance? Must a person choose a track for himself early on—suicide and solitude, or strong relationships and severe restriction on the moral right of suicide? Intuitively and in practice, attempts at social integration are rarely seen as violations by a suicidal person, and social withdrawal is not seen as a moral duty. D. Authority Supreme Court Justice Antonin Scalia,33 in refusing to recognize a right of citizens to refuse medical care that would prolong their lives, offers the defense that suicide was a felony at common law—which is to say that historically, in England for hundreds of years, the penalty for trying to kill yourself was hanging. Scalia grounds an authority-based argument against suicide in this early prohibition: because suicide was a felony, he argues, modern governments need not recognize a suffering person’s right to end his life. The authority foundation has not found much persuasive power within the context of suicide. Arguments like the above seem self-evident to those, like Scalia, who are moved by authority, but read as clumsy otherwise. However, a major force for the acceptance of the suicide prohibition has been the expanding authority of medicine in our society. Medicine, and the medical model of suicide, is as much a product of the authority framework as of the harm/care foundation. Medicine pretends to an almost exclusively harm/care orientation; however, it has acquired a halo of sacredness since its great successes in the last century with vaccines and antibiotics. And it has used this sacredness to cultivate an aura of authority. As detailed in the first chapter, the greater portion of the suicide prohibition is not legal, exactly, but medical. Doctors, as part of a hospital system, have the authority to imprison people on locked wards for displaying signs of mental illness that are presumed to indicate a danger to self or others. In practice, this means that even a rational suicidal person may be imprisoned. The authority to imprison, to medicate, to bully and coerce patients into compliance with treatment plans, goes along with expanding medical authority in a variety of contexts once thought to be the domain of the family or the individual. Hospital staff frequently remove children from parents judged to be a danger to the children—and, in many cases, the only danger is the disagreement with doctors as to the diagnosis and its appropriate treatment. Doctors have referred to this procedure as a “parent-ectomy,”34 as in surgical removal of the parents. That medical experts should have such authority is a very modern development. Another result of the expanded authority of medical practitioners is doctors assisting police by performing invasive cavity searches of suspects.35 The expanding authority of medicine is worrying. There are no checks or balances built into our system to counteract the authority of doctors, and experiments with socialized medicine mean that government is more involved with health care than ever. E. Suicide and Sanctity Among those who oppose suicide and approve of its prohibition, sanctity, not harm, appears to be the foremost reason. In laboratory experiments,36 the harm/care foundation was activated with regard to homicide, but did not substantially affect judgments of suicide. Instead, concern with the tainting of souls and moral disgust appeared to be the most powerful operative foundations. In the previous chapter, it was noted that a characteristic of sacred beliefs is that symbols tend to be confused with referents; images of cigarette smoking and discussion of rape may be seen as violations in addition to the underlying behaviors themselves. Thus it is with suicide: even conversations about suicide, whether artistic or mundane, have the power to trigger strong reaction, and this reaction often takes the form of censorship (discussed at length in a later chapter). The supposed suicide contagion is often brought up as a rational basis for such censorship, but the fact that suicide is open for contagion analysis, when other acts (such as interpersonal violence) are generally not, must be explained. And it is precisely the purity violation inherent in suicide and discussions of suicide that allows for contagion analysis: impurity is contagious, and moral degradation is seen to spread like an infection, whereas ordinary harm is not. If ordinary violence were seen to be contagious, its moral condemnation and retributive responses would be imperiled; but suicide, as a sanctified domain and a special sacredness violation, is frequently the subject of contagion framing. F. Liberty The liberty foundation is that which is most conducive to eliminating the suicide prohibition. Thomas Szasz and other libertarian writers have advocated for a right to die as part of a broader right of self-determination that includes the right to refuse psychiatric treatment. Responses to the pro-choice position that strive to maintain the liberty frame tend to balance future liberty interests of the person with present liberty interests, breaking a person into multiple selves over time and presenting the different selves’ interests as in conflict. The position that prioritizes future interests over present interests is in accordance with the suicide prohibition; paternalism often refuses to admit that it is paternalism, instead insisting that it is merely representing the true, genuine “freedoms” of a future person. In other contexts, restricting the actions of a future self is seen as an important freedom. All contracts, for instance, have this feature, as did the institution of marriage before modern no-fault interventions. In the suicide context, however, the decision of the present self to commit suicide is often stigmatized as disordered, insane, or impulsive; that it may be a rational and integrated decision makes the case for restricting it based on future interests more difficult. Childbearing and Moral Foundations The morality of suicide is distinct from the question of the morality of childbearing, as illustrated in the first chapter. But the two issues are connected, especially along the harm/ care, fairness, and loyalty foundations. Childbearing is especially sacralized in our culture; as with suicide, the sacredness foundation bears a great deal of the weight of moral cognition on childbearing, if often invisibly. Freedom, as applied to childbearing, is generally limited to analysis of the rights of parents—the right to bear children, and the right to prevent or abort children. Rarely are the liberty, harm, or fairness interests of the children seriously considered. A. Childbearing and Harm That being alive entails suffering has been acknowledged at least since the time of the Buddha. Even the best lives are frequently painful and boring, punctuated by unsatisfied longing, loneliness, fear, shame, hunger, anger, and grief. All humans age and die—and to make matters worse, they become aware early on that they will inevitably die. A naive view from the hedonic perspective, in which only pleasure and pain matter, was explored in the first chapter where I considered Bryan Caplan’s argument that since most people stay alive, rather than jump off of tall buildings, the pleasures of life must outweigh its many harms. A more nuanced view must allow that this is frequently not the case: that the harm of life frequently seems to outweigh any benefit it may be said to provide to the living person. The one million suicides per year, globally, put a lower bound on this condition, but it is difficult to know how many people suffer so much that life is, on net, a harm to them. This analysis is made more complicated by the fact that symbolic and social meaning, rather than a robotic pleasure/pain trade off, is in fact what seems to motivate human action. Not many people commit suicide, but many people act as if their lives are not very valuable to them. They risk actual death or social death by gambling their present circumstances on a small chance of future payoff, in a manner that is not actuarially sound. They choose, with their economic decisions, to believe in a counterfactual world, indicating dissatisfaction with the real world. They palliate present suffering in a manner that harms future prospects. This gamble/ palliate behavior is examined in detail in a later chapter; it indicates that, rather than valuing life as a precious gift, people frequently treat life as having zero or negative value with their actual actions. The suffering occasioned by life is great and undeniable, indicating that childbearing, at least in this aspect, does major harm to those brought into the world. Is there something that makes up for this harm, such that something causing so much misery might properly be regarded as a gift? This “balancing factor” might be meaning—either universal meaning, or subjective meaning found and elaborated by individuals; this is addressed in an earlier chapter. Another possibility is the proposition that, on balance, the pleasure and good experiences of life make up for the suffering it occasions. Rather than eschewing all suffering, individuals frequently accept some degree of suffering in pursuit of other rewards—either in the form of meaning, or in the form of pleasure. The mountain climber or medical student affirmatively chooses to suffer for the purpose of future experiences, pleasurable or meaningful. Others, looking back on times of suffering, say they are glad to have had such experiences. When making decisions for ourselves, there is no moral problem with trading off suffering for pleasure or meaning; it appears to be a social fact that people do not minimize suffering in their own lives. What about when we act upon others—especially strangers, whose preferences we know nothing about? Can we permissibly cause them serious harm in order to give them a benefit, and without their permission? This question, fundamental to the modern philosophic question of antinatalism, will be addressed in a later section, but it is important to root it in the “harm/care” moral foundation, and to notice what other moral foundations affect thinking about childbearing. B. Fairness, Cheating, and Reciprocity The fairness and reciprocity orientation regarding childbearing is prominent in many cultures. Life (and perhaps care, feeding, and rearing) is regarded as a gift that parents give their children. This is regarded as creating a debt owed by the child to the parents, which may be repaid with some form of filial piety. To see life as a gift is to accept that one is born owing a debt. It is a very prosocial world view, encouraging good behavior, care of parents, and perhaps even the production of grandchildren as a means of fulfilling the debt. The benefits that children supposedly provide, such as support in old age and grandchildren, are frequently mentioned in support of having children. And the absence of these benefits, or of children themselves, is commonly expressed in terms of fear—the fear of dying alone. Emphasis of the fairness foundation elides notice of the significant parent-offspring competition present in humans. Neither the evolutionary nor subjective interests of parents and offspring align perfectly; often they are very badly mismatched. (As a mild example, consider the differences between the suitor a young lady might choose for herself, and the one her parents might choose for her. A less mild example might take notice of real, modern arranged marriages between prepubescent girls and much older men, often relatives.) The fairness frame, among other things, uses the thought of the horror of nonexistence to coax filial piety out of children and give parents more power in parent-offspring competition. As noted above, this is likely a civilization-preserving cultural idea, encouraging action in accord with longer time horizons. It achieves this at the expense of coercion toward children. In agrarian societies, children have significant economic value; the cost of bearing, feeding, and caring for them is more than offset by the value of work they perform. In our society, however, children have negative economic value.37 How do parents in the modern world deal with the fact that children are, in economic terms, a “bad bargain”? One strategy is for parents to attribute more non-economic value to children38 when reminded of the economic loss they are taking, “exaggerating” their parental joy in response to the salience of the costliness of children. This will be explored below in the section on sanctity, but there is fairness and reciprocity at work here as well: if children cannot provide economic value in return for their economic cost, they are said to provide other kinds of value. The high cost of children is driven not just by their declining economic value, but by the increasing cost of giving a child socially appropriate resources. Spending on children is determined in part by the spending of those in the community. A status arms race drives up spending, not just on clothes and toys but also on education, extracurricular activities, and medicine. High-status parents may feel the need to distance their children, through spending, from the children of poor people (who at any rate have more children than wealthy, educated people). Since children impose such a high cost, those who opt out of childbearing are sometimes accused of “free riding,” of being lazy or selfish. In other words, childless people are seen as cheating on a supposedly reciprocal obligation — either with their own parents, or with others in society who have an interest in the genetic future of their race or species. No doubt the cost and burden of childbearing is a factor for many decisions not to reproduce, but it is incorrect to see parents as especially self-sacrificing in this regard. While the economic and well-being costs of having children are high, most of the “cost” of existence is borne by the children themselves, not by the parents in raising them. Parenting involves not just volunteering for the job of parent, but volunteering innocent children for the job of being people. C. Sanctity In the laboratory, when manipulated by researchers to think about the high economic cost of having children, parents tend to focus on and elaborate another kind of value that children have—their emotional and spiritual meaning, the value of the special connection between parent and child. In one experimental study, parents manipulated to think about the high cost of childrearing said they planned to spend more time with their children during the upcoming weekend than parents who had not been so manipulated.39 Outside the laboratory, elaborating new kinds of value for children seems to have been a widespread response to the changing economic value of children—and of women. The consequences of this new source of sanctity have not always been good for children. We need not go as far as Philippe Ariès (Centuries of Childhood) in positing that childhood was only recently invented and that parents five hundred years ago did not form strong, protective bonds with their children. The absence of such bonds, in a species requiring so much parental investment and care for survival, seems incredible, if only on evolutionary grounds. However, there have been drastic, visible changes in the typical treatment of children since the Industrial Revolution changed their economic meaning. In Meanings of Life Roy Baumeister summarizes the changing economic and social value of women during the industrial revolution: For centuries…women’s work had held a secure place in the social environment. It was inferior in prestige to men’s work, but it was no less vital. The family economy, even the family’s survival, was clearly and multiply dependent on the woman’s contribution. Work is a powerful source of purpose (goals) and efficacy in life, and so women’s lives certainly did not lack for meaning in these respects. The woman’s work was vital to the family, and everyone knew it. Then a remarkable thing happened. The Industrial Revolution took over women’s tasks one by one. First, the textile mills soon could produce cloth more cheaply and efficiently than more weaving. Then other tasks, ranging from candle-making to food processing, shifted out of the home and into the factory. The woman’s contribution to the family dwindled from vital and central to minor. To put it crudely, from an economic standpoint, women became obsolete. …The importance of these economic shifts cannot be underestimated for understanding the history of women… The “Woman Question” that vexed the 19th century was based on a profound uncertainty about what women were useful for. Such a question would have been unthinkable in previous eras, for women’s contribution to everyone’s daily life was palpable and vital, even when the treatment of women was a mixture of contempt and exploitation. An economically useless womanhood was a new and troubling phenomenon. [Emphasis mine; citations omitted.] The answer to the “Woman Question” that was elaborated in the nineteenth century is still a major source of sacredness today: the innovation of the “cult of motherhood.” The last remaining source of value that women had—childbearing and childrearing—was made into “a more comprehensive, fulfilling purpose”: The first step was the elevation of motherhood into an important, fulfilling life-task. A “cult” of motherhood appeared early in the 19th century. Speeches, sermons, and publications started to describe the importance of motherhood for the nation. It was mothers, they said, who determined the nation’s future, for mothers determined the character traits of the next generation. Around 1820, there began a rapid proliferation of books and pamphlets on how best to rear a child. It was addressed to mothers, who were not (for pretty much the first time in history) considered more important than fathers to their child’s upbringing. By mid-century, the glorification of the mother’s role had reached the point where the father’s role was all but forgotten, and it seemed that mothers alone could transform their innocent babies into productive, virtuous citizens of the Republic. Child care, which had previously been regarded as a minor and unprestigious job, now loomed as a sacred and difficult responsibility of mothers. …Writers and speakers began to refer to the ecstasies and raptures that supposedly characterized motherhood. To read these passages, many of which were written by men, one would think that taking care of children was a source of uninterrupted bliss. [Emphasis in original; citations omitted.] But women were not the only ones whose economic value had eroded: the economic value of children plummeted as the industrial revolution progressed. Both women and children were given new and different value through the glorification of motherhood. The consequences of this new arrangement for women, children, and society have been mixed. Victorian concern for the well-being of children as a special, protected class is associated with the passage of laws regulating child labor and criminalizing abuse. Women gained status both from their newly-important role as mothers and from their new alliance with the church; they became guardians of virtue, and translated this into political power for child welfare causes. Concern for the well-being of children, and recognition of women’s role in promoting it, contributed to other “women’s” causes, including temperance and female suffrage. However, once women attained equal legal and social status to that of men—in part because of their connection with religion and childbearing—the allure of childrearing as a sole source of meaning seems to have faded. The women’s liberation movement, the normalization of divorce, and the massive increase in women’s participation in college and work since the 1960s indicate that the cult of motherhood was not adequate to meet the needs of modern women for meaning. But the sacredness of motherhood (and of childhood) is alive and well. Only a few generations ago, children were allowed to roam on their own around cities and countryside. Today, for a child to be allowed outside his own yard without adult supervision is a legal scandal. Children’s freedom to roam and to socialize informally has been severely curtailed; their school environment has become more prisonlike, their physical safety protected at the expense of their education, development, and fun. The loss of children’s freedom to roam may be regarded as an unfortunate late stage in the sacralization of childrearing. Abuse panics, whether focused on satanic cults or neighborhood pedophiles, reflect the sacred status of children—and also the deep discomfort mothers have with sending them to be cared for by strangers while they work. That motherhood is sacred may be illustrated by the pattern of products and causes seeking to identify themselves with motherhood. Representing a mother rather than, say, a puppy or cartoon bear lends a consumer product advertisement a certain gravity. “Mothers Against Drunk Driving” is only one of dozens of groups that link their causes with the sacredness of the maternal bond. Sex workers, in lobbying for status and sometimes for the legalization of their profession, put the fact that they are mothers front and center, implying that motherhood “rubs off ” sacredness even on those whose moral behavior is most questionable. The sacredness of childbearing, as with other forms of sacredness, is often visible in its violation. Most obviously, the sacredness of children is applied to embryos and fetuses, informing opposition to abortion. This is not to say that abortion proponents like myself are immune from sacredness; the right to choose has become somewhat sacred, and the women’s body itself is a locus of sacredness vulnerable to violation by regulation. Controls on reproduction themselves violate sacredness: eugenics is metonymically associated with Nazis, and reproduction is considered a “fundamental right” in the United States. Even very mild and sensible controls on reproduction are rejected by courts. The freedom to reproduce—or not to reproduce—is discussed below, but it’s important to note that it straddles the line between the freedom foundation and the sacredness foundation. It is, in other words, a sacred right. D. Loyalty As mentioned above, those who do not reproduce are often viewed as lazy, “free-riding” on the efforts of others to promote the future of the species. Loyalty—whether to one’s kin, or to the species in general—is a moral foundation relevant to childbearing. Having children is now very costly, which suggests a new role for childbearing: as a costly signal of group commitment. Many religious groups (Catholics, Mormons, Orthodox Jews) strongly suggest or even mandate that followers have many children, and this prescription probably assists coordination between co-religionists. Religious communes that impose heavy costs on their members40 (in the form of prohibitions and requirements) tend to survive longer than less demanding cults; costly signals, whether observing dietary restrictions or having large families, make cooperation more reliable. E. Freedom The liberty of parents to procreate is now so deeply enshrined in American law and culture that it has come to function as a sacred right. Less than a hundred years ago, procreation was not the sacred right that it is now; popular family manuals and works of sociology extolled birth control in progressive terms not primarily as an individual right but as a means of controlling and improving the quality of human populations. Today, even in extreme cases, restrictions on childbearing are almost never tolerated. The forcible sterilization of people likely to have children with bad lives is hardly conceivable to moderns, and any suggestion that individual choice is not the ideal determinant of procreation is dismissed as eugenics. It is politically and socially permissible to sincerely argue for restrictions on abortion, but not for restrictions on reproduction. The right to have children, like many other modern rights, is not mentioned in the Constitution, but is interpreted as being protected by an implied right to privacy. It is now, as I have said, a sacred right that may not be violated even in the most extreme cases. Mothers who starve their children to death41 and fathers who make no effort to support their many children42 may not be restricted in their “fundamental right” to have as many children as they can. It is extremely rare, however, to consider the child’s liberty interests. Opponents of abortion maintain that the child has a “right to life,” but it is very strange to talk about a “right not to be born”—even a limited right not to be born under very bad circumstances. Life, of course, is the ultimate freedom, a human existence being the prerequisite for having any meaningful freedoms at all. But life is also a burden. That childbearing has been turned into a freedom, rather than something that just happens, is why discussions like this are possible. Birth control and abortion make it undeniable that having children is a choice. As childbearing has become more economically costly and more voluntary, the social meaning of children has changed.",
      "word_count": 6952,
      "character_count": 43138,
      "chapter_number": 12,
      "section_number": null,
      "paragraph_number": 1,
      "start_position": 0,
      "end_position": 43138,
      "parent_chunk_id": "sarah_perryevery_cra_unknown_ch12"
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch13",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "chapter",
      "title": "Chapter Six:What Really Causes Suicide",
      "content": "Chapter Six:What Really Causes Suicide Despite decades of clinical research into the causes of suicide, including robust and well-supported models, scientific explanations for suicide have been ignored in popular understanding. A 2013 article43 in the New York Times on the rise of suicide in middle-aged people provides the following mistaken explanation by Ileana Arias, Principal Deputy Director of the Centers for Disease Control (and someone who should know better): Dr. Arias noted that the higher suicide rates might be due to a series of life and financial circumstances that are unique to the baby boomer generation. Men and women in that age group are often coping with the stress of caring for aging parents while still providing financial and emotional support to adult children. “Their lives are configured a little differently than it has been in the past for that age group,” Dr. Arias said. “It may not be that they are more sensitive or that they have a predisposition to suicide, but that they may be dealing with more.” The most robust, empirically supported model in modern suicidology is that provided by Thomas Joiner, who summarizes his findings in the book Why People Die By Suicide. According to Joiner, there are three main factors that influence the decision to commit suicide: the feeling of being a burden on others, a failure of social belonging, and acquired competence in one’s suicide method. The idea the people commit suicide because they are “dealing with more,” that they are driven to suicide by being asked to provide too much “financial and emotional support” and the “stress of caring” for others, is in fact the opposite of the truth: it is not being over-burdened that causes suicide, but rather being a burden on others. Failed Social Belonging The single largest factor in predicting suicide, both at the individual and the national level, is the failure to belong in relationships with the opposite sex, family members, and society. A broad array of sources supports this conclusion. Not just any pain, but the pain of social rejection and failed belonging, causes suicide. While chronic pain44 causes only a modest increase in suicide rates, or none at all for most types of pain, the psychological pain of failed belonging is a major risk factor. Divorce rates consistently predict suicide rates in countries all over the world at the national level; within countries, divorce significantly predicts suicide at the individual level, especially for men. Breakups of cohabitation relationships are significantly associated with suicide, too. Pregnant women have among the lowest rates of suicide of any group. The rate of suicide for pregnant women is only about one third45 to one sixth46 the rate for non-pregnant women; pregnancy is a major protective factor. Having dependent small children (especially under the age of two47) is also protective. However, women who experience a stillbirth have an elevated risk of suicide48 relative to women who experience live births. Marriage and parental relationships are the strongest relationships most people experience; social belonging at this intimate level is very protective against suicide, whereas losing this source of belonging is a major risk factor. But wider community belonging is also relevant. Religiosity is protective against suicide, but it is church attendance49 that explains this effect as much as religious beliefs about the morality of suicide. Churches provide a community in which to belong; the absence of a social community puts people at risk. Similarly, loss of employment is a significant predictor of suicide when unemployment is of long duration,50 and when it is part of a mass lay-off indicating a reduced likelihood of finding comparable employment. At the national level, suicide rates tend to increase in economic downturns. The loss in social position—not absolute wealth status—is the explanatory factor. The threat of social death—of disgrace, of exile from the community—often seems to make death look appealing in comparison. Suicides that are most widely reported in the media follow a common pattern: a person of very high status experiences a disgrace (moral, financial, or both) and commits suicide. Though the person’s status would have remained high relative to the average person even after the disgrace, the impending loss of social status and relationships looks from his perspective like social death. A large metastudy on risk factors for suicide in prison,51 using data covering over four thousand prison suicides, revealed interactions that support the failed social belonging risk factor for suicide. Even though in the general population, being married and employed is protective against suicide, among prisoners, being married or employed was associated with a higher risk of suicide. Why should this be? Married prisoners and those with jobs outside prison faced a loss of previous belonging, a social death. Unmarried, unemployed prisoners, on the other hand, might view prison as a normal part of life, a continuation of previous belonging experiences. Being housed in a single cell was also associated with higher risk of suicide; a cellmate may provide a greater sense of belonging. Being white was associated with a higher risk of suicide and being black with a decreased risk, but that is true of non-imprisoned populations as well. Race may have effects on the level of belonging in prison,52 as it does on sexual victimization rates, with white inmates being much more likely to be victimized. Gay people are more likely to commit suicide53 than straight people. This is often attributed to bullying and homophobia, but it may in part be explained by failed belonging relative to peers, parents and family, and in relationships. Failed belonging may explain an apparent puzzle about suicide and intelligence. At the individual level IQ is negatively associated with suicide, but although smarter people are generally less likely to kill themselves the rule does not hold for those at the very top (“Terman’s Termites”54) or at the very bottom (the mentally retarded55) of the intelligence distribution. The exception of those with very low IQ from the overall negative association of IQ with suicide may be a result of a cognitive “floor” for suicide—the abstract thought, planning, and competence necessary to commit suicide may be missing among these individuals. The increased suicide risk among very high IQ individuals may result from gifted individuals having high expectations for social status and belonging that are thwarted, or from having a mind that is very different from others, making it difficult to form relationships. With the exceptions of many suicides in a small sample of extremely gifted individuals and rare suicides among those with intellects far below the level of normal functioning, in general low IQ is a risk factor for suicide.56 (Having well-educated parents57 and a low IQ score has been associated with particularly high risk, perhaps because failing to live up to the standards of one’s parents and community is a form of social death.) However, despite the negative relationship at the individual level, when aggregate data are viewed on the national level (and even at the regional level, in many cases), there is a actually positive association between mean IQ and the suicide rate; countries with higher mean IQs58 experience more suicides (but fewer homicides). How can these seemingly contradictory observations be resolved? One confounding factor is that latitude (distance from the equator) is also highly correlated with suicide rates, both on the national and regional level, and IQ is also highly correlated to distance from the equator. However, since the suicide rates of immigrant populations are closer to those of their countries of origin than to those of their host countries (as with blacks in the United States and whites in South Africa), the population IQ effect is likely independent of latitude. One explanation for the discrepancy is that high-IQ populations create complex societies in which it is easy to fall through the cracks and experience social death. Where mean intelligence is high, expectations are high. Those who can’t handle such complexity face the risk of social exclusion. In populations with lower intelligence, life is simpler, fertility (a protective factor) is higher, and social bonds are not as fleeting or fragile. Burdensomeness Another broad risk factor for suicide, somewhat related to social belonging, is perceived burdensomeness—the feeling that one is a burden on others. Many sources of evidence point to perceptions of burdensomeness as a risk factor. Even though younger people are more violent than older people, older people commit suicide much more often than younger people. Suicide is positively associated with age in both men and women. The perception of burdensomeness is likely to increase with age and infirmity. Indeed, when terminally ill patients ask their doctors to assist them with suicide they frequently cite concerns59 of being a burden on others, losing control, being dependent on others for physical care, and loss of dignity; physical pain does not seem to be nearly as important a motivation. Among elderly people, factors that influence burdensomeness (including disability preventing them from activities of daily living, visual impairment, and institutionalization) are associated with suicidal ideation.60 In a study of the contents of suicide notes61 that compared the notes of attempters who did not complete suicide with the notes of completed suicides themes of burdensomeness predicted the lethality of a suicide attempt better than the “desire to control one’s own feelings, desire to control others, emotional pain, and hopelessness,” none of which independently predicted lethality. It should be noted that some studies of suicide notes62 have failed to find thwarted belonging and burdensomeness present in the majority of suicide notes, but both of these themes do frequently occur in genuine suicide notes, at rates of 42.5% and 15.5% respectively. Most suicides do not leave notes, and analysis of the content of notes is at best suggestive of the motivation of those who do. The presence of thwarted belonging and burdensomeness themes in the suicide notes of completed suicides is suggestive of motivation. While not as strong a predictor of suicide as thwarted belonging, burdensomeness appears to be a strong predictor of suicide. Both of these factors are relevant to the evolutionary analysis of suicide, which is addressed below. Competence The final factor with a major effect on suicide is competence—a measure of the suicidal person’s developed capability to harm himself using the chosen method. Competence is obtained through familiarity with the chosen method and through the practice of increasingly provocative self-harm, by which process individuals break down their natural resistance to harming themselves. Suicidal individuals are often very dependent on a particular method. Another way to express this is that the demand for suicide demonstrates low elasticity with respect to method. Suicide barriers are often erected on bridges that are suicide “hot spots,” places known in the community to be the site of previous successful suicides. When these barriers are erected, surprisingly, suicides at nearby bridges often do not increase, as would be expected if suicides simply substituted comparable methods. In Australia, when tightened emissions standards for motor vehicle exhaust reduced the lethality of suicide attempts using this method, and overall suicide rates declined as a result.63 It appears that Australians who were predisposed to die in this manner did not simply switch to more lethal methods. Indeed, information about the lethality of suicide methods is not widely available, and when the lethality of a method changes drastically, this change will likely not factor into method decisions until it is too late. Similarly, the suicide rate in the United Kingdom fell in the period after 196364 when household gas was detoxified, rendering this previously reliable method non-lethal. Again, people did not substitute a new, lethal method for many years after the detoxification; if they had, the suicide rate would have remained constant or increased (as predicted by economic troubles at the time). Using a “tried and true” method that has been demonstrated in the past to work, whether a bridge or motor vehicle exhaust, appears to be important to many suicides. As noted in an earlier section, humans have a natural resistance to physically harming themselves. Joiner notes that suicides frequently go through a process of engaging in increasingly provocative acts of self harm before committing suicide; they may engage in non-lethal self harm, such as cutting, or make potentially lethal suicide attempts. The single biggest predictor of completed suicide is a history of a suicide attempt;65 individuals may “practice” suicide until they get it right. Certain professions have higher suicide rates than the baseline, and often choose methods that their occupations have trained them to use. Doctors, as well as nurses, dentists, and scientists66 experience elevated suicide rates even when controlling for demographic factors, and they tend to choose drug overdoses. (Mathematicians and artists also experience elevated rates of suicide, but factors other than acquired competence likely account for these.) Some but not all studies worldwide show an elevated suicide rate for police officers that is not explained by demographic factors, e.g. being mostly male.67 Method preferences also appear to differ by gender. Both male and female physicians experience an elevated rate of suicide, but the rate for female physicians is much more elevated against the baseline female population68 compared to that of men. This could be explained by a female preference for drug overdose rather than firearms. Firearms are more popular among men. Men are more likely to develop familiarity and competence with firearms than women, and when men use firearms to attempt suicide, they are more likely to complete suicide69 than women who use firearms. There is evidence that women prefer poisoning in general; in areas in which lethal chemicals are widely available, such as India and China, female suicides account for a much higher percentage of total suicides. In China, which accounts for a quarter of suicides worldwide, women are significantly more likely70 to commit suicide than men. Indeed, a majority of suicides in China utilize the method of poisoning by lethal pesticides;71 this also accounts for the greater risk of suicide among rural Chinese. Taken together, thwarted belonging, perceived burdensomeness, and acquired competence parsimoniously account for a huge portion of the variation in suicide rates. What Doesn’t Cause Suicide Some factors are commonly associated with suicide, but have little demonstrable, independent effect on suicide apart from the previously named factors. Depression, for instance, accounts for a very mild increase in suicide risk, mostly in males.72 It would be shocking if there were not some effect, as suicide and suicidal ideation are themselves diagnostic factors in major depressive disorder. But the claim that “the number one cause of suicide is untreated depression,” as asserted in popular sources such as suicide.org and even the Department of Health and Human Services’ website, has no basis in fact. It would be much more accurate to say that maleness is the leading cause of suicide. Depression occurs most often in women and young people; suicide, by contrast, occurs mostly in older people and men. Some mental illnesses other than depression, however, do drastically increase the risk of suicide. Importantly, while maintaining that mental illness is relevant to suicide, Joiner does not implicate mental illness in causing suicide—rather, his model explains the highly elevated suicide levels in people with disorders like bipolar I and II and borderline personality disorder by the fact that such disorders (a) facilitate comfort with increasingly lethal self-harm, (b) increase feelings of (and perhaps actual) burdensomeness, and (c) decrease the ability to belong. Evolutionary Considerations Is suicide an adaptive phenomenon? Why do our brains, themselves the product of millions of years of evolution, occasionally allow us to kill ourselves and destroy any hope of future reproduction? Denys deCatanzaro has been researching the evolutionary biology of human suicide since the early 1980s.73 He outlines both adaptive and non-adaptive possibilities of the behavior of suicide. In considering the possibilities, keep in mind that the phenomenon of suicide may not have a single explanation; some suicides (or suicide attempts) may be better explained as adaptive behavior, others as maladaptive. For instance, in terms of being the product of adaptation, the suicides of the elderly might be in an entirely different category74 from those of adolescents. Here are the possibilities, broadly. First, suicide might not be an adaptation at all. It might be a logical decision made rationally by the individual, and not specifically influenced by inherited traits. The positive relationship between suicide and IQ on the national level, as well as the decreased risk of suicide seen in mentally retarded individuals, as noted in above, both make this hypothesis more likely; if suicide requires a certain minimum IQ in order to occur, then it must be a relatively new phenomenon in the development of human beings, with not much time for adaptations to occur. While lower animals sometimes engage in behavior that is lethal to themselves for kin-altruistic reasons, there is no true analogue to the human phenomenon of suicide among other animals. If Dan Everett is correct that suicide is completely absent among the Pirahã people,75 those humans whose culture most discourages abstract thought, then this is even more evidence that the level of abstraction required to commit suicide has only recently been reached by humans. However, since suicide seems to account for a significant proportion of deaths in virtually every human group ever studied,76 it is likely that populations have had some time to develop adaptations to this eventuality. But there is another possibility, according to deCatanzaro: the adaptations that lead to suicide in the modern world did not lead to suicide in past environments of evolutionary adaptation. That is, there is a mismatch between human nature and the modern environments in which we find ourselves, and this mismatch is the cause of suicide. The most intriguing possibility is that suicide is itself an adaptive behavior, under certain circumstances. How could this be so, given that suicide ends one’s survival and destroys any future chance at reproduction, the two most crucial factors for selection? The answer lies in kin selection. Genes are not carried by the individual only, but shared with relatives; offspring are not the only chance for reproductive success. Parents, siblings, nieces and nephews also carry one’s genes. And future children are not the only path to evolutionary success; investment in previously-born children (and their reproductive success) also advances genetic interests. One gets “inclusive fitness”—an increase in the chance of one’s genes being passed on—from promoting the survival and reproduction of close kin as well as by promoting one’s own survival and reproduction. deCatanzaro proposes a mathematical model77 of “adaptive suicide” in which individuals monitor their “inclusive fitness”—the likelihood of having future surviving offspring, plus the ability to contribute to the survival and reproduction of existing relatives in proportion to their relatedness. Under certain conditions, one’s expected contribution to one’s own genetic fitness (likelihood of reproduction, likelihood of the survival of one’s future offspring to reproduce, effectiveness at materially supporting one’s offspring and other relatives) may fall to virtually nothing. However, as long as one survives under these circumstances, an individual not only contributes nothing to his own genetic fitness, but also likely drains the resources of his genetic relatives. His internal meter of his inclusive fitness would read a negative value, meaning that his continued survival is contrary to his genetic interests. Therefore, suicide, in this limited situation, must be said to be adaptive. This adaptation would require that humans have a kind of “inclusive fitness monitor,” noticing factors such as future fertility, ability to contribute, and burdensomeness on close kin. It would require that the brain have a mechanism for causing suicide (or mechanisms for inhibiting suicide that it could cease to inhibit), and this suicide mechanism would have to be triggered by a negative reading on the inclusive fitness meter. Also, for this adaptation to have come into existence, situations in which people were a significant burden on the genetic interests of their kin must have been so common in human history as to be a selective force. In our modern world, it would be callous and cruel to think of a sick, elderly relative as a burden who would be better off dead. And that is not the message of an inclusive fitness model—its message is merely that, in the recent past during which modern humans were evolving, a heritable trait that functioned to tell a human something like “die if you’re a net burden on your genetic kin, otherwise stay alive” may have carried benefits in terms of selection. Unfortunately, Thomas Joiner cannot get past the (admittedly substantial) emotional load of the adaptive model of suicide, and rejects it on what are essentially aesthetic grounds: …I do not much like this adaptive suicide view; my own dad died by suicide and the idea that he was an actual burden is offensive. My view is that self-sacrifice is adaptive in some animal species. It may have been adaptive under certain conditions in the course of human evolution, but we will never really know. Most important, it does not really matter now. What matters now is that perceived burdensomeness—and, to the extent that it exists, actual burdensomeness—are remediable through perception- and skill-based psychotherapies. Death is no longer adaptive, if it ever was.78 This is a strange statement for a scientist. Although Joiner is writing a book called Why People Die By Suicide, he asserts that the essential “why” of his research does not matter— especially to the extent that it might be “offensive.” In this, I think he misunderstands the nature of the adaptive view. It is not to say that suicide is good or bad, or that Joiner’s dad really was a burden to Joiner or his family; it is simply that, in the human environment of evolutionary adaptedness, the ability and predilection to commit suicide under certain conditions may have conferred a benefit. Joiner also wrongly asserts that “we will never really know” about the adaptive theory, when he should know that the evolutionary psychology model is perfectly capable of generating testable hypotheses, and has done so in the past with robust results.79 Joiner repeatedly impresses upon readers the notion that it is perceived burdensomeness—not actual burdensomeness—that facilitates suicide. However, this may be more nice than true: suicidal persons’ perceptions of their own burdensomeness may in fact be highly accurate. Just before he dismisses the adaptive theory of suicide, Joiner summarizes a study supporting the view that suicides really are a burden: “when researchers interviewed the significant others of eighty-one people who had recently attempted suicide, a majority of significant others reported that their support of the patient represented a burden to them.” The adaptive model leads to different predictions (and, in turn, possibly different risk assessments and treatment models) from Joiner’s model. For instance, in Joiner’s model, “belongingness” is all that matters. But an adaptive model would predict that some forms of belongingness would be more protective against suicide than others—specifically, contributing to the welfare of one’s genetic relatives (or perhaps surrogates for genetic relatives) would be more protective than other forms of belonging. Relationships (especially heterosexual) with spouses and children would matter more than relationships with friends in an adaptive model (as they seem to do), but not in Joiner’s model. Similarly, in Joiner’s model all that matters is “burdensomeness”—no matter who is burdened. An adaptive model might predict that burdensomeness on genetic relatives in particular (or their surrogates) would trigger suicidal behavior, rather than burdensomeness on non-relatives. In fact, suicidal ideation is predicted by feelings of burdensomeness on kin,80 in particular among the elderly and other high-risk groups. The fact that marriage, pregnancy, and the presence of small dependent children are all protective against suicide is suggestive; not just any belongingness prevents suicide, but especially those types most closely associated with genetic fitness. Sex differences in suicide and suicidal behavior are also better explained by an adaptive model than a purely nonadaptive model. Around the world, men commit the vast majority of suicides; women attempt suicide more frequently than men, but account for fewer completed suicides. Joiner’s model accounts for sex differences between the suicide rates of men and women in two ways: first, in terms of competence, men are more likely to be exposed to provocative stimulation (all kinds of violence and more) that break down one’s fear of death over time; second, in terms of desire for death, men are more likely to be disconnected and more likely than women to feel they are burdensome. This is probably true—but, again, why should this be? Why should men be more prone to risky, painful, violent, or as Joiner terms it, “provocative” behavior? The answer, again, lies in evolutionary biology. Men are not merely “socialized” to be more violent—there are good evolutionary reasons for their greater violence and risktaking in all areas. A great deal of this is due to what Daly and Wilson81 term the “effective polygyny” of human beings (at least in our Environments of Evolutionary Adaptedness, or EEAs)—that is, that the fertility variance among men is much higher than among women. Many more men than women have a high number of children, and many more men than women have zero children. This leads to the sad phenomenon of male disposability. While a woman is “valuable,” with a certain, nearly guaranteed level of reproductive success, a man may have no reproductive success at all—but may, by engaging in risky behavior (e.g., successful killing in wars or honor battles), increase his reproductive success to well beyond what a woman might have. A human male is, sadly, invited by his genetic heritage to gamble his life on the chance of a big payoff in reproductive success. What is driving differential violence in general may also drive differential suicides—even independently from the greater access to fear-reducing, provocative experiences. Note that in this case suicide may, but need not be, adaptive in itself; the loss from an occasional suicide may be outweighed by better performance by surviving males who also engage in provocative behavior. More specifically, Joiner’s model does not explain why, in addition to varying between genders and across age groups, the time pattern in suicides across age groups is different between men and women. Men’s suicide rates are a linear function of age: the older the male, the higher the suicide rate. Women’s suicide rates vary with time differently, however. While in some countries, the pattern for women matches that for men, in other countries the pattern is very different. In Canada, rather than rising linearly with age, suicide among women peaks during the 35–44 age range; in the United States, the Netherlands, and Sweden, it peaks during the 45–54 age range; and in Australia, Denmark, and Poland, female suicides peak in the 55–64 age range.82 While belonging and burdensomeness are probably implicated, the fact that these are the age ranges of menopause and postmenopause in women seems to lend support to the adaptive view as to why burdensomeness and thwarted belonging would come into play at those times: future reproductive fitness zeroes out, making the possibility of a negative contribution value (burdensomeness) salient. While Joiner’s three-factor model is compelling, I think there is persuasive evidence that an adaptive model should be considered. At the very least, such a hypothesis should not be rejected on merely aesthetic grounds. To do so is irresponsible and unscientific. An accurate analysis of the etiology of suicide affects both assessment of the risk of suicide and treatment for the suffering that causes suicide. Attempted Suicide as an Adaptive Behavior: Suicide Gambles Suicide itself may be adaptive in circumstances in which one’s inclusive fitness is negative; however, even if inclusive fitness is positive, a suicide attempt may be adaptive if the expected benefits from possibly surviving exceed the expected loss from death. An apparently lethal but ultimately unsuccessful suicide attempt may be not only adaptive, but economically beneficial—provided one does not die in the attempt. In a 2003 article in the Southern Economic Journal, Dave Marcotte presented data that suicide attempters experience an increase in income after the attempt that is proportional to the lethality of the attempt. Charles Duhigg summarizes83 in his Slate article, provocatively subtitled “Why trying to kill yourself may be a smart business decision”: Marcotte’s study found that after people attempt suicide and fail, their incomes increase by an average of 20.6 percent compared to peers who seriously contemplate suicide but never make an attempt. In fact, the more serious the attempt, the larger the boost—“hard-suicide” attempts, in which luck is the only reason the attempts fail, are associated with a 36.3 percent increase in income. (The presence of nonattempters as a control group suggests the suicide effort is the root cause of the boost.) Marcotte’s data suggest that a suicide attempt, particularly an apparently lethal one, acts as a signal that the individual needs help—and, as it is a signal that entails significant cost (the risk of death), it is a particularly believable signal. This signal seems to act to make resources “cheaper”—a suicide attempter may get access to resources that he did not have access to before the attempt. Suicide attempts can represent a kind of gamble for people in very difficult situations. Indeed, Marcotte found that the increase in income was proportional to the lethality of the attempt, an indication of the cost—hence reliability—of the signal sent by the attempt. If a suicide attempt is a (perhaps wholly unconscious) gambling strategy for increased investment from others, then suicide attempts may be adaptive even when one’s own death decreases one’s inclusive fitness (as with a healthy young person), if the expected value of extra fitness from “winning” the gamble makes up for it. If young girls, for instance, frequently make attempts of low lethality, this may reflect that their internal “inclusive fitness meters” are still giving positive values, but that they are willing to take a slight risk of self-harm in exchange for an increase in attention (and potentially fitness). As noted above, our species’ moderate effective polygyny—the fact that male fitness has higher variance than female fitness—means that a male is more likely to die childless than a woman. His inclusive fitness is more likely to be negative, but in addition, he has less to lose and more to gain from a more serious suicide attempt. If he dies, from his genes’ perspective, it might not be much loss compared to the benefits of “winning” the gamble and surviving the attempt. Recall that women commit suicide much more often when lethal poisons are available (e.g., Chinese rural women, women physicians). This is a method unlikely to be lethal in our environments of evolutionary adaptedness; its relatively low lethality might be the deeper reason that women feel comfortable using it, even though modern chemicals in some cases make it reliably lethal. Also, the period during which a person “acquires competence” by engaging in increasingly provocative behaviors may provide the opportunity for group members to intervene and offer support; women are likely to be arrested earlier in this process than men, in part due to their more secure reproductive value compared to male “disposability.” These hypothesized adaptive processes are not necessarily conscious, if they exist; many people who make serious suicide attempts do sincerely intend to die. From the genes’ perspective, it is enough to get the organism to perform the adaptive behavior (in this case, attempting suicide when the expected gain from surviving exceeds the expected loss in fitness from dying)—the strategy, if it exists, is genetically encoded, not rationally calculated. Of course, even if nonconscious, an adaptation may still respond to economic incentives. If it is capable of choosing an appropriately lethal means of suicide, it is capable of responding to a change in the likelihood of rescue. If rescue is forbidden, for example, the likelihood of survival is close to zero for many methods. Again, Joiner is ideologically opposed to this line of thinking, and again, it’s for aesthetic, not scientific, reasons. Joiner’s complaints are two: the economic “viewpoint” is dangerous, in that it may encourage lethal-seeming suicide attempts; and it is callous, in that it denies the reality of the suffering experienced by the suicidal individual. Both of these complaints are without merit. As to the “danger” of the economic model, Joiner says: The danger of viewpoints like this should be pointed out. Any analysis that encourages suicidal behavior in any way—particularly in ways that romanticize or glorify it, or make it seem easy and normative—has potential negative consequences for public health. But it is hardly the viewpoint that is dangerous—it’s the existing incentive structure in our society that encourages apparently lethal suicide attempts in people who often don’t really want to die. I have argued that if the suicide prohibition were ended, this dangerous incentive structure—the “fantasy of rescue”—would also end. Analyses are not dangerous. Problems are dangerous. Analyses identify the problems and point the way to solutions. By suggesting that the economic analysis is dangerous, Joiner is contributing to the taboo against speaking about suicide. Joiner also argues that the economic hypothesis denies the reality of the suffering of suicide attempters. He believes that the economic idea is part of a kind of “deconstructionist” philosophy in the school of Jacques Derrida: “What is left for the deconstructionist, then, is a constant questioning of the very existence of reality and meaning—including the reality of emotional pain. Try telling that to a suicidal person.” This objection is misguided. Joiner thinks that the economic model does not account for the pain suffered by those who attempt suicide. But the economic model suggests no such thing! Duhigg’s unfortunate opening example in his popular summary of the Marcotte study reports that right before the depressed, suicidal Kirk Jones jumped over the guardrail at Niagara Falls and survived, he had bragged to friends that he would “make some money” if he went over the Falls and lived. Despite this unfortunate and likely unrepresentative example, the core hypothesis is not that people coldly calculate that they will get a benefit from an apparently lethal suicide attempt. Rather, suffering people are motivated by that awful, extremely real suffering to do something awful—to essentially gamble their lives on a chance at making the suffering stop. An economic explanation, especially an adaptive one, need not imply cold, conscious processing and weighing of “expected values” at all. In a later chapter I will revisit the subject of “suicide gambles” in a broader sense, including behaviors apparently unrelated to suicide.",
      "word_count": 5725,
      "character_count": 36605,
      "chapter_number": 13,
      "section_number": null,
      "paragraph_number": null,
      "start_position": 0,
      "end_position": 36605,
      "parent_chunk_id": null
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch13_s1",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "section",
      "title": "Final Section",
      "content": "Chapter Six:What Really Causes Suicide Despite decades of clinical research into the causes of suicide, including robust and well-supported models, scientific explanations for suicide have been ignored in popular understanding. A 2013 article43 in the New York Times on the rise of suicide in middle-aged people provides the following mistaken explanation by Ileana Arias, Principal Deputy Director of the Centers for Disease Control (and someone who should know better): Dr. Arias noted that the higher suicide rates might be due to a series of life and financial circumstances that are unique to the baby boomer generation. Men and women in that age group are often coping with the stress of caring for aging parents while still providing financial and emotional support to adult children. “Their lives are configured a little differently than it has been in the past for that age group,” Dr. Arias said. “It may not be that they are more sensitive or that they have a predisposition to suicide, but that they may be dealing with more.” The most robust, empirically supported model in modern suicidology is that provided by Thomas Joiner, who summarizes his findings in the book Why People Die By Suicide. According to Joiner, there are three main factors that influence the decision to commit suicide: the feeling of being a burden on others, a failure of social belonging, and acquired competence in one’s suicide method. The idea the people commit suicide because they are “dealing with more,” that they are driven to suicide by being asked to provide too much “financial and emotional support” and the “stress of caring” for others, is in fact the opposite of the truth: it is not being over-burdened that causes suicide, but rather being a burden on others. Failed Social Belonging The single largest factor in predicting suicide, both at the individual and the national level, is the failure to belong in relationships with the opposite sex, family members, and society. A broad array of sources supports this conclusion. Not just any pain, but the pain of social rejection and failed belonging, causes suicide. While chronic pain44 causes only a modest increase in suicide rates, or none at all for most types of pain, the psychological pain of failed belonging is a major risk factor. Divorce rates consistently predict suicide rates in countries all over the world at the national level; within countries, divorce significantly predicts suicide at the individual level, especially for men. Breakups of cohabitation relationships are significantly associated with suicide, too. Pregnant women have among the lowest rates of suicide of any group. The rate of suicide for pregnant women is only about one third45 to one sixth46 the rate for non-pregnant women; pregnancy is a major protective factor. Having dependent small children (especially under the age of two47) is also protective. However, women who experience a stillbirth have an elevated risk of suicide48 relative to women who experience live births. Marriage and parental relationships are the strongest relationships most people experience; social belonging at this intimate level is very protective against suicide, whereas losing this source of belonging is a major risk factor. But wider community belonging is also relevant. Religiosity is protective against suicide, but it is church attendance49 that explains this effect as much as religious beliefs about the morality of suicide. Churches provide a community in which to belong; the absence of a social community puts people at risk. Similarly, loss of employment is a significant predictor of suicide when unemployment is of long duration,50 and when it is part of a mass lay-off indicating a reduced likelihood of finding comparable employment. At the national level, suicide rates tend to increase in economic downturns. The loss in social position—not absolute wealth status—is the explanatory factor. The threat of social death—of disgrace, of exile from the community—often seems to make death look appealing in comparison. Suicides that are most widely reported in the media follow a common pattern: a person of very high status experiences a disgrace (moral, financial, or both) and commits suicide. Though the person’s status would have remained high relative to the average person even after the disgrace, the impending loss of social status and relationships looks from his perspective like social death. A large metastudy on risk factors for suicide in prison,51 using data covering over four thousand prison suicides, revealed interactions that support the failed social belonging risk factor for suicide. Even though in the general population, being married and employed is protective against suicide, among prisoners, being married or employed was associated with a higher risk of suicide. Why should this be? Married prisoners and those with jobs outside prison faced a loss of previous belonging, a social death. Unmarried, unemployed prisoners, on the other hand, might view prison as a normal part of life, a continuation of previous belonging experiences. Being housed in a single cell was also associated with higher risk of suicide; a cellmate may provide a greater sense of belonging. Being white was associated with a higher risk of suicide and being black with a decreased risk, but that is true of non-imprisoned populations as well. Race may have effects on the level of belonging in prison,52 as it does on sexual victimization rates, with white inmates being much more likely to be victimized. Gay people are more likely to commit suicide53 than straight people. This is often attributed to bullying and homophobia, but it may in part be explained by failed belonging relative to peers, parents and family, and in relationships. Failed belonging may explain an apparent puzzle about suicide and intelligence. At the individual level IQ is negatively associated with suicide, but although smarter people are generally less likely to kill themselves the rule does not hold for those at the very top (“Terman’s Termites”54) or at the very bottom (the mentally retarded55) of the intelligence distribution. The exception of those with very low IQ from the overall negative association of IQ with suicide may be a result of a cognitive “floor” for suicide—the abstract thought, planning, and competence necessary to commit suicide may be missing among these individuals. The increased suicide risk among very high IQ individuals may result from gifted individuals having high expectations for social status and belonging that are thwarted, or from having a mind that is very different from others, making it difficult to form relationships. With the exceptions of many suicides in a small sample of extremely gifted individuals and rare suicides among those with intellects far below the level of normal functioning, in general low IQ is a risk factor for suicide.56 (Having well-educated parents57 and a low IQ score has been associated with particularly high risk, perhaps because failing to live up to the standards of one’s parents and community is a form of social death.) However, despite the negative relationship at the individual level, when aggregate data are viewed on the national level (and even at the regional level, in many cases), there is a actually positive association between mean IQ and the suicide rate; countries with higher mean IQs58 experience more suicides (but fewer homicides). How can these seemingly contradictory observations be resolved? One confounding factor is that latitude (distance from the equator) is also highly correlated with suicide rates, both on the national and regional level, and IQ is also highly correlated to distance from the equator. However, since the suicide rates of immigrant populations are closer to those of their countries of origin than to those of their host countries (as with blacks in the United States and whites in South Africa), the population IQ effect is likely independent of latitude. One explanation for the discrepancy is that high-IQ populations create complex societies in which it is easy to fall through the cracks and experience social death. Where mean intelligence is high, expectations are high. Those who can’t handle such complexity face the risk of social exclusion. In populations with lower intelligence, life is simpler, fertility (a protective factor) is higher, and social bonds are not as fleeting or fragile. Burdensomeness Another broad risk factor for suicide, somewhat related to social belonging, is perceived burdensomeness—the feeling that one is a burden on others. Many sources of evidence point to perceptions of burdensomeness as a risk factor. Even though younger people are more violent than older people, older people commit suicide much more often than younger people. Suicide is positively associated with age in both men and women. The perception of burdensomeness is likely to increase with age and infirmity. Indeed, when terminally ill patients ask their doctors to assist them with suicide they frequently cite concerns59 of being a burden on others, losing control, being dependent on others for physical care, and loss of dignity; physical pain does not seem to be nearly as important a motivation. Among elderly people, factors that influence burdensomeness (including disability preventing them from activities of daily living, visual impairment, and institutionalization) are associated with suicidal ideation.60 In a study of the contents of suicide notes61 that compared the notes of attempters who did not complete suicide with the notes of completed suicides themes of burdensomeness predicted the lethality of a suicide attempt better than the “desire to control one’s own feelings, desire to control others, emotional pain, and hopelessness,” none of which independently predicted lethality. It should be noted that some studies of suicide notes62 have failed to find thwarted belonging and burdensomeness present in the majority of suicide notes, but both of these themes do frequently occur in genuine suicide notes, at rates of 42.5% and 15.5% respectively. Most suicides do not leave notes, and analysis of the content of notes is at best suggestive of the motivation of those who do. The presence of thwarted belonging and burdensomeness themes in the suicide notes of completed suicides is suggestive of motivation. While not as strong a predictor of suicide as thwarted belonging, burdensomeness appears to be a strong predictor of suicide. Both of these factors are relevant to the evolutionary analysis of suicide, which is addressed below. Competence The final factor with a major effect on suicide is competence—a measure of the suicidal person’s developed capability to harm himself using the chosen method. Competence is obtained through familiarity with the chosen method and through the practice of increasingly provocative self-harm, by which process individuals break down their natural resistance to harming themselves. Suicidal individuals are often very dependent on a particular method. Another way to express this is that the demand for suicide demonstrates low elasticity with respect to method. Suicide barriers are often erected on bridges that are suicide “hot spots,” places known in the community to be the site of previous successful suicides. When these barriers are erected, surprisingly, suicides at nearby bridges often do not increase, as would be expected if suicides simply substituted comparable methods. In Australia, when tightened emissions standards for motor vehicle exhaust reduced the lethality of suicide attempts using this method, and overall suicide rates declined as a result.63 It appears that Australians who were predisposed to die in this manner did not simply switch to more lethal methods. Indeed, information about the lethality of suicide methods is not widely available, and when the lethality of a method changes drastically, this change will likely not factor into method decisions until it is too late. Similarly, the suicide rate in the United Kingdom fell in the period after 196364 when household gas was detoxified, rendering this previously reliable method non-lethal. Again, people did not substitute a new, lethal method for many years after the detoxification; if they had, the suicide rate would have remained constant or increased (as predicted by economic troubles at the time). Using a “tried and true” method that has been demonstrated in the past to work, whether a bridge or motor vehicle exhaust, appears to be important to many suicides. As noted in an earlier section, humans have a natural resistance to physically harming themselves. Joiner notes that suicides frequently go through a process of engaging in increasingly provocative acts of self harm before committing suicide; they may engage in non-lethal self harm, such as cutting, or make potentially lethal suicide attempts. The single biggest predictor of completed suicide is a history of a suicide attempt;65 individuals may “practice” suicide until they get it right. Certain professions have higher suicide rates than the baseline, and often choose methods that their occupations have trained them to use. Doctors, as well as nurses, dentists, and scientists66 experience elevated suicide rates even when controlling for demographic factors, and they tend to choose drug overdoses. (Mathematicians and artists also experience elevated rates of suicide, but factors other than acquired competence likely account for these.) Some but not all studies worldwide show an elevated suicide rate for police officers that is not explained by demographic factors, e.g. being mostly male.67 Method preferences also appear to differ by gender. Both male and female physicians experience an elevated rate of suicide, but the rate for female physicians is much more elevated against the baseline female population68 compared to that of men. This could be explained by a female preference for drug overdose rather than firearms. Firearms are more popular among men. Men are more likely to develop familiarity and competence with firearms than women, and when men use firearms to attempt suicide, they are more likely to complete suicide69 than women who use firearms. There is evidence that women prefer poisoning in general; in areas in which lethal chemicals are widely available, such as India and China, female suicides account for a much higher percentage of total suicides. In China, which accounts for a quarter of suicides worldwide, women are significantly more likely70 to commit suicide than men. Indeed, a majority of suicides in China utilize the method of poisoning by lethal pesticides;71 this also accounts for the greater risk of suicide among rural Chinese. Taken together, thwarted belonging, perceived burdensomeness, and acquired competence parsimoniously account for a huge portion of the variation in suicide rates. What Doesn’t Cause Suicide Some factors are commonly associated with suicide, but have little demonstrable, independent effect on suicide apart from the previously named factors. Depression, for instance, accounts for a very mild increase in suicide risk, mostly in males.72 It would be shocking if there were not some effect, as suicide and suicidal ideation are themselves diagnostic factors in major depressive disorder. But the claim that “the number one cause of suicide is untreated depression,” as asserted in popular sources such as suicide.org and even the Department of Health and Human Services’ website, has no basis in fact. It would be much more accurate to say that maleness is the leading cause of suicide. Depression occurs most often in women and young people; suicide, by contrast, occurs mostly in older people and men. Some mental illnesses other than depression, however, do drastically increase the risk of suicide. Importantly, while maintaining that mental illness is relevant to suicide, Joiner does not implicate mental illness in causing suicide—rather, his model explains the highly elevated suicide levels in people with disorders like bipolar I and II and borderline personality disorder by the fact that such disorders (a) facilitate comfort with increasingly lethal self-harm, (b) increase feelings of (and perhaps actual) burdensomeness, and (c) decrease the ability to belong. Evolutionary Considerations Is suicide an adaptive phenomenon? Why do our brains, themselves the product of millions of years of evolution, occasionally allow us to kill ourselves and destroy any hope of future reproduction? Denys deCatanzaro has been researching the evolutionary biology of human suicide since the early 1980s.73 He outlines both adaptive and non-adaptive possibilities of the behavior of suicide. In considering the possibilities, keep in mind that the phenomenon of suicide may not have a single explanation; some suicides (or suicide attempts) may be better explained as adaptive behavior, others as maladaptive. For instance, in terms of being the product of adaptation, the suicides of the elderly might be in an entirely different category74 from those of adolescents. Here are the possibilities, broadly. First, suicide might not be an adaptation at all. It might be a logical decision made rationally by the individual, and not specifically influenced by inherited traits. The positive relationship between suicide and IQ on the national level, as well as the decreased risk of suicide seen in mentally retarded individuals, as noted in above, both make this hypothesis more likely; if suicide requires a certain minimum IQ in order to occur, then it must be a relatively new phenomenon in the development of human beings, with not much time for adaptations to occur. While lower animals sometimes engage in behavior that is lethal to themselves for kin-altruistic reasons, there is no true analogue to the human phenomenon of suicide among other animals. If Dan Everett is correct that suicide is completely absent among the Pirahã people,75 those humans whose culture most discourages abstract thought, then this is even more evidence that the level of abstraction required to commit suicide has only recently been reached by humans. However, since suicide seems to account for a significant proportion of deaths in virtually every human group ever studied,76 it is likely that populations have had some time to develop adaptations to this eventuality. But there is another possibility, according to deCatanzaro: the adaptations that lead to suicide in the modern world did not lead to suicide in past environments of evolutionary adaptation. That is, there is a mismatch between human nature and the modern environments in which we find ourselves, and this mismatch is the cause of suicide. The most intriguing possibility is that suicide is itself an adaptive behavior, under certain circumstances. How could this be so, given that suicide ends one’s survival and destroys any future chance at reproduction, the two most crucial factors for selection? The answer lies in kin selection. Genes are not carried by the individual only, but shared with relatives; offspring are not the only chance for reproductive success. Parents, siblings, nieces and nephews also carry one’s genes. And future children are not the only path to evolutionary success; investment in previously-born children (and their reproductive success) also advances genetic interests. One gets “inclusive fitness”—an increase in the chance of one’s genes being passed on—from promoting the survival and reproduction of close kin as well as by promoting one’s own survival and reproduction. deCatanzaro proposes a mathematical model77 of “adaptive suicide” in which individuals monitor their “inclusive fitness”—the likelihood of having future surviving offspring, plus the ability to contribute to the survival and reproduction of existing relatives in proportion to their relatedness. Under certain conditions, one’s expected contribution to one’s own genetic fitness (likelihood of reproduction, likelihood of the survival of one’s future offspring to reproduce, effectiveness at materially supporting one’s offspring and other relatives) may fall to virtually nothing. However, as long as one survives under these circumstances, an individual not only contributes nothing to his own genetic fitness, but also likely drains the resources of his genetic relatives. His internal meter of his inclusive fitness would read a negative value, meaning that his continued survival is contrary to his genetic interests. Therefore, suicide, in this limited situation, must be said to be adaptive. This adaptation would require that humans have a kind of “inclusive fitness monitor,” noticing factors such as future fertility, ability to contribute, and burdensomeness on close kin. It would require that the brain have a mechanism for causing suicide (or mechanisms for inhibiting suicide that it could cease to inhibit), and this suicide mechanism would have to be triggered by a negative reading on the inclusive fitness meter. Also, for this adaptation to have come into existence, situations in which people were a significant burden on the genetic interests of their kin must have been so common in human history as to be a selective force. In our modern world, it would be callous and cruel to think of a sick, elderly relative as a burden who would be better off dead. And that is not the message of an inclusive fitness model—its message is merely that, in the recent past during which modern humans were evolving, a heritable trait that functioned to tell a human something like “die if you’re a net burden on your genetic kin, otherwise stay alive” may have carried benefits in terms of selection. Unfortunately, Thomas Joiner cannot get past the (admittedly substantial) emotional load of the adaptive model of suicide, and rejects it on what are essentially aesthetic grounds: …I do not much like this adaptive suicide view; my own dad died by suicide and the idea that he was an actual burden is offensive. My view is that self-sacrifice is adaptive in some animal species. It may have been adaptive under certain conditions in the course of human evolution, but we will never really know. Most important, it does not really matter now. What matters now is that perceived burdensomeness—and, to the extent that it exists, actual burdensomeness—are remediable through perception- and skill-based psychotherapies. Death is no longer adaptive, if it ever was.78 This is a strange statement for a scientist. Although Joiner is writing a book called Why People Die By Suicide, he asserts that the essential “why” of his research does not matter— especially to the extent that it might be “offensive.” In this, I think he misunderstands the nature of the adaptive view. It is not to say that suicide is good or bad, or that Joiner’s dad really was a burden to Joiner or his family; it is simply that, in the human environment of evolutionary adaptedness, the ability and predilection to commit suicide under certain conditions may have conferred a benefit. Joiner also wrongly asserts that “we will never really know” about the adaptive theory, when he should know that the evolutionary psychology model is perfectly capable of generating testable hypotheses, and has done so in the past with robust results.79 Joiner repeatedly impresses upon readers the notion that it is perceived burdensomeness—not actual burdensomeness—that facilitates suicide. However, this may be more nice than true: suicidal persons’ perceptions of their own burdensomeness may in fact be highly accurate. Just before he dismisses the adaptive theory of suicide, Joiner summarizes a study supporting the view that suicides really are a burden: “when researchers interviewed the significant others of eighty-one people who had recently attempted suicide, a majority of significant others reported that their support of the patient represented a burden to them.” The adaptive model leads to different predictions (and, in turn, possibly different risk assessments and treatment models) from Joiner’s model. For instance, in Joiner’s model, “belongingness” is all that matters. But an adaptive model would predict that some forms of belongingness would be more protective against suicide than others—specifically, contributing to the welfare of one’s genetic relatives (or perhaps surrogates for genetic relatives) would be more protective than other forms of belonging. Relationships (especially heterosexual) with spouses and children would matter more than relationships with friends in an adaptive model (as they seem to do), but not in Joiner’s model. Similarly, in Joiner’s model all that matters is “burdensomeness”—no matter who is burdened. An adaptive model might predict that burdensomeness on genetic relatives in particular (or their surrogates) would trigger suicidal behavior, rather than burdensomeness on non-relatives. In fact, suicidal ideation is predicted by feelings of burdensomeness on kin,80 in particular among the elderly and other high-risk groups. The fact that marriage, pregnancy, and the presence of small dependent children are all protective against suicide is suggestive; not just any belongingness prevents suicide, but especially those types most closely associated with genetic fitness. Sex differences in suicide and suicidal behavior are also better explained by an adaptive model than a purely nonadaptive model. Around the world, men commit the vast majority of suicides; women attempt suicide more frequently than men, but account for fewer completed suicides. Joiner’s model accounts for sex differences between the suicide rates of men and women in two ways: first, in terms of competence, men are more likely to be exposed to provocative stimulation (all kinds of violence and more) that break down one’s fear of death over time; second, in terms of desire for death, men are more likely to be disconnected and more likely than women to feel they are burdensome. This is probably true—but, again, why should this be? Why should men be more prone to risky, painful, violent, or as Joiner terms it, “provocative” behavior? The answer, again, lies in evolutionary biology. Men are not merely “socialized” to be more violent—there are good evolutionary reasons for their greater violence and risktaking in all areas. A great deal of this is due to what Daly and Wilson81 term the “effective polygyny” of human beings (at least in our Environments of Evolutionary Adaptedness, or EEAs)—that is, that the fertility variance among men is much higher than among women. Many more men than women have a high number of children, and many more men than women have zero children. This leads to the sad phenomenon of male disposability. While a woman is “valuable,” with a certain, nearly guaranteed level of reproductive success, a man may have no reproductive success at all—but may, by engaging in risky behavior (e.g., successful killing in wars or honor battles), increase his reproductive success to well beyond what a woman might have. A human male is, sadly, invited by his genetic heritage to gamble his life on the chance of a big payoff in reproductive success. What is driving differential violence in general may also drive differential suicides—even independently from the greater access to fear-reducing, provocative experiences. Note that in this case suicide may, but need not be, adaptive in itself; the loss from an occasional suicide may be outweighed by better performance by surviving males who also engage in provocative behavior. More specifically, Joiner’s model does not explain why, in addition to varying between genders and across age groups, the time pattern in suicides across age groups is different between men and women. Men’s suicide rates are a linear function of age: the older the male, the higher the suicide rate. Women’s suicide rates vary with time differently, however. While in some countries, the pattern for women matches that for men, in other countries the pattern is very different. In Canada, rather than rising linearly with age, suicide among women peaks during the 35–44 age range; in the United States, the Netherlands, and Sweden, it peaks during the 45–54 age range; and in Australia, Denmark, and Poland, female suicides peak in the 55–64 age range.82 While belonging and burdensomeness are probably implicated, the fact that these are the age ranges of menopause and postmenopause in women seems to lend support to the adaptive view as to why burdensomeness and thwarted belonging would come into play at those times: future reproductive fitness zeroes out, making the possibility of a negative contribution value (burdensomeness) salient. While Joiner’s three-factor model is compelling, I think there is persuasive evidence that an adaptive model should be considered. At the very least, such a hypothesis should not be rejected on merely aesthetic grounds. To do so is irresponsible and unscientific. An accurate analysis of the etiology of suicide affects both assessment of the risk of suicide and treatment for the suffering that causes suicide. Attempted Suicide as an Adaptive Behavior: Suicide Gambles Suicide itself may be adaptive in circumstances in which one’s inclusive fitness is negative; however, even if inclusive fitness is positive, a suicide attempt may be adaptive if the expected benefits from possibly surviving exceed the expected loss from death. An apparently lethal but ultimately unsuccessful suicide attempt may be not only adaptive, but economically beneficial—provided one does not die in the attempt. In a 2003 article in the Southern Economic Journal, Dave Marcotte presented data that suicide attempters experience an increase in income after the attempt that is proportional to the lethality of the attempt. Charles Duhigg summarizes83 in his Slate article, provocatively subtitled “Why trying to kill yourself may be a smart business decision”: Marcotte’s study found that after people attempt suicide and fail, their incomes increase by an average of 20.6 percent compared to peers who seriously contemplate suicide but never make an attempt. In fact, the more serious the attempt, the larger the boost—“hard-suicide” attempts, in which luck is the only reason the attempts fail, are associated with a 36.3 percent increase in income. (The presence of nonattempters as a control group suggests the suicide effort is the root cause of the boost.) Marcotte’s data suggest that a suicide attempt, particularly an apparently lethal one, acts as a signal that the individual needs help—and, as it is a signal that entails significant cost (the risk of death), it is a particularly believable signal. This signal seems to act to make resources “cheaper”—a suicide attempter may get access to resources that he did not have access to before the attempt. Suicide attempts can represent a kind of gamble for people in very difficult situations. Indeed, Marcotte found that the increase in income was proportional to the lethality of the attempt, an indication of the cost—hence reliability—of the signal sent by the attempt. If a suicide attempt is a (perhaps wholly unconscious) gambling strategy for increased investment from others, then suicide attempts may be adaptive even when one’s own death decreases one’s inclusive fitness (as with a healthy young person), if the expected value of extra fitness from “winning” the gamble makes up for it. If young girls, for instance, frequently make attempts of low lethality, this may reflect that their internal “inclusive fitness meters” are still giving positive values, but that they are willing to take a slight risk of self-harm in exchange for an increase in attention (and potentially fitness). As noted above, our species’ moderate effective polygyny—the fact that male fitness has higher variance than female fitness—means that a male is more likely to die childless than a woman. His inclusive fitness is more likely to be negative, but in addition, he has less to lose and more to gain from a more serious suicide attempt. If he dies, from his genes’ perspective, it might not be much loss compared to the benefits of “winning” the gamble and surviving the attempt. Recall that women commit suicide much more often when lethal poisons are available (e.g., Chinese rural women, women physicians). This is a method unlikely to be lethal in our environments of evolutionary adaptedness; its relatively low lethality might be the deeper reason that women feel comfortable using it, even though modern chemicals in some cases make it reliably lethal. Also, the period during which a person “acquires competence” by engaging in increasingly provocative behaviors may provide the opportunity for group members to intervene and offer support; women are likely to be arrested earlier in this process than men, in part due to their more secure reproductive value compared to male “disposability.” These hypothesized adaptive processes are not necessarily conscious, if they exist; many people who make serious suicide attempts do sincerely intend to die. From the genes’ perspective, it is enough to get the organism to perform the adaptive behavior (in this case, attempting suicide when the expected gain from surviving exceeds the expected loss in fitness from dying)—the strategy, if it exists, is genetically encoded, not rationally calculated. Of course, even if nonconscious, an adaptation may still respond to economic incentives. If it is capable of choosing an appropriately lethal means of suicide, it is capable of responding to a change in the likelihood of rescue. If rescue is forbidden, for example, the likelihood of survival is close to zero for many methods. Again, Joiner is ideologically opposed to this line of thinking, and again, it’s for aesthetic, not scientific, reasons. Joiner’s complaints are two: the economic “viewpoint” is dangerous, in that it may encourage lethal-seeming suicide attempts; and it is callous, in that it denies the reality of the suffering experienced by the suicidal individual. Both of these complaints are without merit. As to the “danger” of the economic model, Joiner says: The danger of viewpoints like this should be pointed out. Any analysis that encourages suicidal behavior in any way—particularly in ways that romanticize or glorify it, or make it seem easy and normative—has potential negative consequences for public health. But it is hardly the viewpoint that is dangerous—it’s the existing incentive structure in our society that encourages apparently lethal suicide attempts in people who often don’t really want to die. I have argued that if the suicide prohibition were ended, this dangerous incentive structure—the “fantasy of rescue”—would also end. Analyses are not dangerous. Problems are dangerous. Analyses identify the problems and point the way to solutions. By suggesting that the economic analysis is dangerous, Joiner is contributing to the taboo against speaking about suicide. Joiner also argues that the economic hypothesis denies the reality of the suffering of suicide attempters. He believes that the economic idea is part of a kind of “deconstructionist” philosophy in the school of Jacques Derrida: “What is left for the deconstructionist, then, is a constant questioning of the very existence of reality and meaning—including the reality of emotional pain. Try telling that to a suicidal person.” This objection is misguided. Joiner thinks that the economic model does not account for the pain suffered by those who attempt suicide. But the economic model suggests no such thing! Duhigg’s unfortunate opening example in his popular summary of the Marcotte study reports that right before the depressed, suicidal Kirk Jones jumped over the guardrail at Niagara Falls and survived, he had bragged to friends that he would “make some money” if he went over the Falls and lived. Despite this unfortunate and likely unrepresentative example, the core hypothesis is not that people coldly calculate that they will get a benefit from an apparently lethal suicide attempt. Rather, suffering people are motivated by that awful, extremely real suffering to do something awful—to essentially gamble their lives on a chance at making the suffering stop. An economic explanation, especially an adaptive one, need not imply cold, conscious processing and weighing of “expected values” at all. In a later chapter I will revisit the subject of “suicide gambles” in a broader sense, including behaviors apparently unrelated to suicide.",
      "word_count": 5725,
      "character_count": 36605,
      "chapter_number": 13,
      "section_number": 1,
      "paragraph_number": null,
      "start_position": 0,
      "end_position": 36605,
      "parent_chunk_id": "sarah_perryevery_cra_unknown_ch13"
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch13_p1",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "paragraph",
      "title": "Paragraph 1",
      "content": "Chapter Six:What Really Causes Suicide Despite decades of clinical research into the causes of suicide, including robust and well-supported models, scientific explanations for suicide have been ignored in popular understanding. A 2013 article43 in the New York Times on the rise of suicide in middle-aged people provides the following mistaken explanation by Ileana Arias, Principal Deputy Director of the Centers for Disease Control (and someone who should know better): Dr. Arias noted that the higher suicide rates might be due to a series of life and financial circumstances that are unique to the baby boomer generation. Men and women in that age group are often coping with the stress of caring for aging parents while still providing financial and emotional support to adult children. “Their lives are configured a little differently than it has been in the past for that age group,” Dr. Arias said. “It may not be that they are more sensitive or that they have a predisposition to suicide, but that they may be dealing with more.” The most robust, empirically supported model in modern suicidology is that provided by Thomas Joiner, who summarizes his findings in the book Why People Die By Suicide. According to Joiner, there are three main factors that influence the decision to commit suicide: the feeling of being a burden on others, a failure of social belonging, and acquired competence in one’s suicide method. The idea the people commit suicide because they are “dealing with more,” that they are driven to suicide by being asked to provide too much “financial and emotional support” and the “stress of caring” for others, is in fact the opposite of the truth: it is not being over-burdened that causes suicide, but rather being a burden on others. Failed Social Belonging The single largest factor in predicting suicide, both at the individual and the national level, is the failure to belong in relationships with the opposite sex, family members, and society. A broad array of sources supports this conclusion. Not just any pain, but the pain of social rejection and failed belonging, causes suicide. While chronic pain44 causes only a modest increase in suicide rates, or none at all for most types of pain, the psychological pain of failed belonging is a major risk factor. Divorce rates consistently predict suicide rates in countries all over the world at the national level; within countries, divorce significantly predicts suicide at the individual level, especially for men. Breakups of cohabitation relationships are significantly associated with suicide, too. Pregnant women have among the lowest rates of suicide of any group. The rate of suicide for pregnant women is only about one third45 to one sixth46 the rate for non-pregnant women; pregnancy is a major protective factor. Having dependent small children (especially under the age of two47) is also protective. However, women who experience a stillbirth have an elevated risk of suicide48 relative to women who experience live births. Marriage and parental relationships are the strongest relationships most people experience; social belonging at this intimate level is very protective against suicide, whereas losing this source of belonging is a major risk factor. But wider community belonging is also relevant. Religiosity is protective against suicide, but it is church attendance49 that explains this effect as much as religious beliefs about the morality of suicide. Churches provide a community in which to belong; the absence of a social community puts people at risk. Similarly, loss of employment is a significant predictor of suicide when unemployment is of long duration,50 and when it is part of a mass lay-off indicating a reduced likelihood of finding comparable employment. At the national level, suicide rates tend to increase in economic downturns. The loss in social position—not absolute wealth status—is the explanatory factor. The threat of social death—of disgrace, of exile from the community—often seems to make death look appealing in comparison. Suicides that are most widely reported in the media follow a common pattern: a person of very high status experiences a disgrace (moral, financial, or both) and commits suicide. Though the person’s status would have remained high relative to the average person even after the disgrace, the impending loss of social status and relationships looks from his perspective like social death. A large metastudy on risk factors for suicide in prison,51 using data covering over four thousand prison suicides, revealed interactions that support the failed social belonging risk factor for suicide. Even though in the general population, being married and employed is protective against suicide, among prisoners, being married or employed was associated with a higher risk of suicide. Why should this be? Married prisoners and those with jobs outside prison faced a loss of previous belonging, a social death. Unmarried, unemployed prisoners, on the other hand, might view prison as a normal part of life, a continuation of previous belonging experiences. Being housed in a single cell was also associated with higher risk of suicide; a cellmate may provide a greater sense of belonging. Being white was associated with a higher risk of suicide and being black with a decreased risk, but that is true of non-imprisoned populations as well. Race may have effects on the level of belonging in prison,52 as it does on sexual victimization rates, with white inmates being much more likely to be victimized. Gay people are more likely to commit suicide53 than straight people. This is often attributed to bullying and homophobia, but it may in part be explained by failed belonging relative to peers, parents and family, and in relationships. Failed belonging may explain an apparent puzzle about suicide and intelligence. At the individual level IQ is negatively associated with suicide, but although smarter people are generally less likely to kill themselves the rule does not hold for those at the very top (“Terman’s Termites”54) or at the very bottom (the mentally retarded55) of the intelligence distribution. The exception of those with very low IQ from the overall negative association of IQ with suicide may be a result of a cognitive “floor” for suicide—the abstract thought, planning, and competence necessary to commit suicide may be missing among these individuals. The increased suicide risk among very high IQ individuals may result from gifted individuals having high expectations for social status and belonging that are thwarted, or from having a mind that is very different from others, making it difficult to form relationships. With the exceptions of many suicides in a small sample of extremely gifted individuals and rare suicides among those with intellects far below the level of normal functioning, in general low IQ is a risk factor for suicide.56 (Having well-educated parents57 and a low IQ score has been associated with particularly high risk, perhaps because failing to live up to the standards of one’s parents and community is a form of social death.) However, despite the negative relationship at the individual level, when aggregate data are viewed on the national level (and even at the regional level, in many cases), there is a actually positive association between mean IQ and the suicide rate; countries with higher mean IQs58 experience more suicides (but fewer homicides). How can these seemingly contradictory observations be resolved? One confounding factor is that latitude (distance from the equator) is also highly correlated with suicide rates, both on the national and regional level, and IQ is also highly correlated to distance from the equator. However, since the suicide rates of immigrant populations are closer to those of their countries of origin than to those of their host countries (as with blacks in the United States and whites in South Africa), the population IQ effect is likely independent of latitude. One explanation for the discrepancy is that high-IQ populations create complex societies in which it is easy to fall through the cracks and experience social death. Where mean intelligence is high, expectations are high. Those who can’t handle such complexity face the risk of social exclusion. In populations with lower intelligence, life is simpler, fertility (a protective factor) is higher, and social bonds are not as fleeting or fragile. Burdensomeness Another broad risk factor for suicide, somewhat related to social belonging, is perceived burdensomeness—the feeling that one is a burden on others. Many sources of evidence point to perceptions of burdensomeness as a risk factor. Even though younger people are more violent than older people, older people commit suicide much more often than younger people. Suicide is positively associated with age in both men and women. The perception of burdensomeness is likely to increase with age and infirmity. Indeed, when terminally ill patients ask their doctors to assist them with suicide they frequently cite concerns59 of being a burden on others, losing control, being dependent on others for physical care, and loss of dignity; physical pain does not seem to be nearly as important a motivation. Among elderly people, factors that influence burdensomeness (including disability preventing them from activities of daily living, visual impairment, and institutionalization) are associated with suicidal ideation.60 In a study of the contents of suicide notes61 that compared the notes of attempters who did not complete suicide with the notes of completed suicides themes of burdensomeness predicted the lethality of a suicide attempt better than the “desire to control one’s own feelings, desire to control others, emotional pain, and hopelessness,” none of which independently predicted lethality. It should be noted that some studies of suicide notes62 have failed to find thwarted belonging and burdensomeness present in the majority of suicide notes, but both of these themes do frequently occur in genuine suicide notes, at rates of 42.5% and 15.5% respectively. Most suicides do not leave notes, and analysis of the content of notes is at best suggestive of the motivation of those who do. The presence of thwarted belonging and burdensomeness themes in the suicide notes of completed suicides is suggestive of motivation. While not as strong a predictor of suicide as thwarted belonging, burdensomeness appears to be a strong predictor of suicide. Both of these factors are relevant to the evolutionary analysis of suicide, which is addressed below. Competence The final factor with a major effect on suicide is competence—a measure of the suicidal person’s developed capability to harm himself using the chosen method. Competence is obtained through familiarity with the chosen method and through the practice of increasingly provocative self-harm, by which process individuals break down their natural resistance to harming themselves. Suicidal individuals are often very dependent on a particular method. Another way to express this is that the demand for suicide demonstrates low elasticity with respect to method. Suicide barriers are often erected on bridges that are suicide “hot spots,” places known in the community to be the site of previous successful suicides. When these barriers are erected, surprisingly, suicides at nearby bridges often do not increase, as would be expected if suicides simply substituted comparable methods. In Australia, when tightened emissions standards for motor vehicle exhaust reduced the lethality of suicide attempts using this method, and overall suicide rates declined as a result.63 It appears that Australians who were predisposed to die in this manner did not simply switch to more lethal methods. Indeed, information about the lethality of suicide methods is not widely available, and when the lethality of a method changes drastically, this change will likely not factor into method decisions until it is too late. Similarly, the suicide rate in the United Kingdom fell in the period after 196364 when household gas was detoxified, rendering this previously reliable method non-lethal. Again, people did not substitute a new, lethal method for many years after the detoxification; if they had, the suicide rate would have remained constant or increased (as predicted by economic troubles at the time). Using a “tried and true” method that has been demonstrated in the past to work, whether a bridge or motor vehicle exhaust, appears to be important to many suicides. As noted in an earlier section, humans have a natural resistance to physically harming themselves. Joiner notes that suicides frequently go through a process of engaging in increasingly provocative acts of self harm before committing suicide; they may engage in non-lethal self harm, such as cutting, or make potentially lethal suicide attempts. The single biggest predictor of completed suicide is a history of a suicide attempt;65 individuals may “practice” suicide until they get it right. Certain professions have higher suicide rates than the baseline, and often choose methods that their occupations have trained them to use. Doctors, as well as nurses, dentists, and scientists66 experience elevated suicide rates even when controlling for demographic factors, and they tend to choose drug overdoses. (Mathematicians and artists also experience elevated rates of suicide, but factors other than acquired competence likely account for these.) Some but not all studies worldwide show an elevated suicide rate for police officers that is not explained by demographic factors, e.g. being mostly male.67 Method preferences also appear to differ by gender. Both male and female physicians experience an elevated rate of suicide, but the rate for female physicians is much more elevated against the baseline female population68 compared to that of men. This could be explained by a female preference for drug overdose rather than firearms. Firearms are more popular among men. Men are more likely to develop familiarity and competence with firearms than women, and when men use firearms to attempt suicide, they are more likely to complete suicide69 than women who use firearms. There is evidence that women prefer poisoning in general; in areas in which lethal chemicals are widely available, such as India and China, female suicides account for a much higher percentage of total suicides. In China, which accounts for a quarter of suicides worldwide, women are significantly more likely70 to commit suicide than men. Indeed, a majority of suicides in China utilize the method of poisoning by lethal pesticides;71 this also accounts for the greater risk of suicide among rural Chinese. Taken together, thwarted belonging, perceived burdensomeness, and acquired competence parsimoniously account for a huge portion of the variation in suicide rates. What Doesn’t Cause Suicide Some factors are commonly associated with suicide, but have little demonstrable, independent effect on suicide apart from the previously named factors. Depression, for instance, accounts for a very mild increase in suicide risk, mostly in males.72 It would be shocking if there were not some effect, as suicide and suicidal ideation are themselves diagnostic factors in major depressive disorder. But the claim that “the number one cause of suicide is untreated depression,” as asserted in popular sources such as suicide.org and even the Department of Health and Human Services’ website, has no basis in fact. It would be much more accurate to say that maleness is the leading cause of suicide. Depression occurs most often in women and young people; suicide, by contrast, occurs mostly in older people and men. Some mental illnesses other than depression, however, do drastically increase the risk of suicide. Importantly, while maintaining that mental illness is relevant to suicide, Joiner does not implicate mental illness in causing suicide—rather, his model explains the highly elevated suicide levels in people with disorders like bipolar I and II and borderline personality disorder by the fact that such disorders (a) facilitate comfort with increasingly lethal self-harm, (b) increase feelings of (and perhaps actual) burdensomeness, and (c) decrease the ability to belong. Evolutionary Considerations Is suicide an adaptive phenomenon? Why do our brains, themselves the product of millions of years of evolution, occasionally allow us to kill ourselves and destroy any hope of future reproduction? Denys deCatanzaro has been researching the evolutionary biology of human suicide since the early 1980s.73 He outlines both adaptive and non-adaptive possibilities of the behavior of suicide. In considering the possibilities, keep in mind that the phenomenon of suicide may not have a single explanation; some suicides (or suicide attempts) may be better explained as adaptive behavior, others as maladaptive. For instance, in terms of being the product of adaptation, the suicides of the elderly might be in an entirely different category74 from those of adolescents. Here are the possibilities, broadly. First, suicide might not be an adaptation at all. It might be a logical decision made rationally by the individual, and not specifically influenced by inherited traits. The positive relationship between suicide and IQ on the national level, as well as the decreased risk of suicide seen in mentally retarded individuals, as noted in above, both make this hypothesis more likely; if suicide requires a certain minimum IQ in order to occur, then it must be a relatively new phenomenon in the development of human beings, with not much time for adaptations to occur. While lower animals sometimes engage in behavior that is lethal to themselves for kin-altruistic reasons, there is no true analogue to the human phenomenon of suicide among other animals. If Dan Everett is correct that suicide is completely absent among the Pirahã people,75 those humans whose culture most discourages abstract thought, then this is even more evidence that the level of abstraction required to commit suicide has only recently been reached by humans. However, since suicide seems to account for a significant proportion of deaths in virtually every human group ever studied,76 it is likely that populations have had some time to develop adaptations to this eventuality. But there is another possibility, according to deCatanzaro: the adaptations that lead to suicide in the modern world did not lead to suicide in past environments of evolutionary adaptation. That is, there is a mismatch between human nature and the modern environments in which we find ourselves, and this mismatch is the cause of suicide. The most intriguing possibility is that suicide is itself an adaptive behavior, under certain circumstances. How could this be so, given that suicide ends one’s survival and destroys any future chance at reproduction, the two most crucial factors for selection? The answer lies in kin selection. Genes are not carried by the individual only, but shared with relatives; offspring are not the only chance for reproductive success. Parents, siblings, nieces and nephews also carry one’s genes. And future children are not the only path to evolutionary success; investment in previously-born children (and their reproductive success) also advances genetic interests. One gets “inclusive fitness”—an increase in the chance of one’s genes being passed on—from promoting the survival and reproduction of close kin as well as by promoting one’s own survival and reproduction. deCatanzaro proposes a mathematical model77 of “adaptive suicide” in which individuals monitor their “inclusive fitness”—the likelihood of having future surviving offspring, plus the ability to contribute to the survival and reproduction of existing relatives in proportion to their relatedness. Under certain conditions, one’s expected contribution to one’s own genetic fitness (likelihood of reproduction, likelihood of the survival of one’s future offspring to reproduce, effectiveness at materially supporting one’s offspring and other relatives) may fall to virtually nothing. However, as long as one survives under these circumstances, an individual not only contributes nothing to his own genetic fitness, but also likely drains the resources of his genetic relatives. His internal meter of his inclusive fitness would read a negative value, meaning that his continued survival is contrary to his genetic interests. Therefore, suicide, in this limited situation, must be said to be adaptive. This adaptation would require that humans have a kind of “inclusive fitness monitor,” noticing factors such as future fertility, ability to contribute, and burdensomeness on close kin. It would require that the brain have a mechanism for causing suicide (or mechanisms for inhibiting suicide that it could cease to inhibit), and this suicide mechanism would have to be triggered by a negative reading on the inclusive fitness meter. Also, for this adaptation to have come into existence, situations in which people were a significant burden on the genetic interests of their kin must have been so common in human history as to be a selective force. In our modern world, it would be callous and cruel to think of a sick, elderly relative as a burden who would be better off dead. And that is not the message of an inclusive fitness model—its message is merely that, in the recent past during which modern humans were evolving, a heritable trait that functioned to tell a human something like “die if you’re a net burden on your genetic kin, otherwise stay alive” may have carried benefits in terms of selection. Unfortunately, Thomas Joiner cannot get past the (admittedly substantial) emotional load of the adaptive model of suicide, and rejects it on what are essentially aesthetic grounds: …I do not much like this adaptive suicide view; my own dad died by suicide and the idea that he was an actual burden is offensive. My view is that self-sacrifice is adaptive in some animal species. It may have been adaptive under certain conditions in the course of human evolution, but we will never really know. Most important, it does not really matter now. What matters now is that perceived burdensomeness—and, to the extent that it exists, actual burdensomeness—are remediable through perception- and skill-based psychotherapies. Death is no longer adaptive, if it ever was.78 This is a strange statement for a scientist. Although Joiner is writing a book called Why People Die By Suicide, he asserts that the essential “why” of his research does not matter— especially to the extent that it might be “offensive.” In this, I think he misunderstands the nature of the adaptive view. It is not to say that suicide is good or bad, or that Joiner’s dad really was a burden to Joiner or his family; it is simply that, in the human environment of evolutionary adaptedness, the ability and predilection to commit suicide under certain conditions may have conferred a benefit. Joiner also wrongly asserts that “we will never really know” about the adaptive theory, when he should know that the evolutionary psychology model is perfectly capable of generating testable hypotheses, and has done so in the past with robust results.79 Joiner repeatedly impresses upon readers the notion that it is perceived burdensomeness—not actual burdensomeness—that facilitates suicide. However, this may be more nice than true: suicidal persons’ perceptions of their own burdensomeness may in fact be highly accurate. Just before he dismisses the adaptive theory of suicide, Joiner summarizes a study supporting the view that suicides really are a burden: “when researchers interviewed the significant others of eighty-one people who had recently attempted suicide, a majority of significant others reported that their support of the patient represented a burden to them.” The adaptive model leads to different predictions (and, in turn, possibly different risk assessments and treatment models) from Joiner’s model. For instance, in Joiner’s model, “belongingness” is all that matters. But an adaptive model would predict that some forms of belongingness would be more protective against suicide than others—specifically, contributing to the welfare of one’s genetic relatives (or perhaps surrogates for genetic relatives) would be more protective than other forms of belonging. Relationships (especially heterosexual) with spouses and children would matter more than relationships with friends in an adaptive model (as they seem to do), but not in Joiner’s model. Similarly, in Joiner’s model all that matters is “burdensomeness”—no matter who is burdened. An adaptive model might predict that burdensomeness on genetic relatives in particular (or their surrogates) would trigger suicidal behavior, rather than burdensomeness on non-relatives. In fact, suicidal ideation is predicted by feelings of burdensomeness on kin,80 in particular among the elderly and other high-risk groups. The fact that marriage, pregnancy, and the presence of small dependent children are all protective against suicide is suggestive; not just any belongingness prevents suicide, but especially those types most closely associated with genetic fitness. Sex differences in suicide and suicidal behavior are also better explained by an adaptive model than a purely nonadaptive model. Around the world, men commit the vast majority of suicides; women attempt suicide more frequently than men, but account for fewer completed suicides. Joiner’s model accounts for sex differences between the suicide rates of men and women in two ways: first, in terms of competence, men are more likely to be exposed to provocative stimulation (all kinds of violence and more) that break down one’s fear of death over time; second, in terms of desire for death, men are more likely to be disconnected and more likely than women to feel they are burdensome. This is probably true—but, again, why should this be? Why should men be more prone to risky, painful, violent, or as Joiner terms it, “provocative” behavior? The answer, again, lies in evolutionary biology. Men are not merely “socialized” to be more violent—there are good evolutionary reasons for their greater violence and risktaking in all areas. A great deal of this is due to what Daly and Wilson81 term the “effective polygyny” of human beings (at least in our Environments of Evolutionary Adaptedness, or EEAs)—that is, that the fertility variance among men is much higher than among women. Many more men than women have a high number of children, and many more men than women have zero children. This leads to the sad phenomenon of male disposability. While a woman is “valuable,” with a certain, nearly guaranteed level of reproductive success, a man may have no reproductive success at all—but may, by engaging in risky behavior (e.g., successful killing in wars or honor battles), increase his reproductive success to well beyond what a woman might have. A human male is, sadly, invited by his genetic heritage to gamble his life on the chance of a big payoff in reproductive success. What is driving differential violence in general may also drive differential suicides—even independently from the greater access to fear-reducing, provocative experiences. Note that in this case suicide may, but need not be, adaptive in itself; the loss from an occasional suicide may be outweighed by better performance by surviving males who also engage in provocative behavior. More specifically, Joiner’s model does not explain why, in addition to varying between genders and across age groups, the time pattern in suicides across age groups is different between men and women. Men’s suicide rates are a linear function of age: the older the male, the higher the suicide rate. Women’s suicide rates vary with time differently, however. While in some countries, the pattern for women matches that for men, in other countries the pattern is very different. In Canada, rather than rising linearly with age, suicide among women peaks during the 35–44 age range; in the United States, the Netherlands, and Sweden, it peaks during the 45–54 age range; and in Australia, Denmark, and Poland, female suicides peak in the 55–64 age range.82 While belonging and burdensomeness are probably implicated, the fact that these are the age ranges of menopause and postmenopause in women seems to lend support to the adaptive view as to why burdensomeness and thwarted belonging would come into play at those times: future reproductive fitness zeroes out, making the possibility of a negative contribution value (burdensomeness) salient. While Joiner’s three-factor model is compelling, I think there is persuasive evidence that an adaptive model should be considered. At the very least, such a hypothesis should not be rejected on merely aesthetic grounds. To do so is irresponsible and unscientific. An accurate analysis of the etiology of suicide affects both assessment of the risk of suicide and treatment for the suffering that causes suicide. Attempted Suicide as an Adaptive Behavior: Suicide Gambles Suicide itself may be adaptive in circumstances in which one’s inclusive fitness is negative; however, even if inclusive fitness is positive, a suicide attempt may be adaptive if the expected benefits from possibly surviving exceed the expected loss from death. An apparently lethal but ultimately unsuccessful suicide attempt may be not only adaptive, but economically beneficial—provided one does not die in the attempt. In a 2003 article in the Southern Economic Journal, Dave Marcotte presented data that suicide attempters experience an increase in income after the attempt that is proportional to the lethality of the attempt. Charles Duhigg summarizes83 in his Slate article, provocatively subtitled “Why trying to kill yourself may be a smart business decision”: Marcotte’s study found that after people attempt suicide and fail, their incomes increase by an average of 20.6 percent compared to peers who seriously contemplate suicide but never make an attempt. In fact, the more serious the attempt, the larger the boost—“hard-suicide” attempts, in which luck is the only reason the attempts fail, are associated with a 36.3 percent increase in income. (The presence of nonattempters as a control group suggests the suicide effort is the root cause of the boost.) Marcotte’s data suggest that a suicide attempt, particularly an apparently lethal one, acts as a signal that the individual needs help—and, as it is a signal that entails significant cost (the risk of death), it is a particularly believable signal. This signal seems to act to make resources “cheaper”—a suicide attempter may get access to resources that he did not have access to before the attempt. Suicide attempts can represent a kind of gamble for people in very difficult situations. Indeed, Marcotte found that the increase in income was proportional to the lethality of the attempt, an indication of the cost—hence reliability—of the signal sent by the attempt. If a suicide attempt is a (perhaps wholly unconscious) gambling strategy for increased investment from others, then suicide attempts may be adaptive even when one’s own death decreases one’s inclusive fitness (as with a healthy young person), if the expected value of extra fitness from “winning” the gamble makes up for it. If young girls, for instance, frequently make attempts of low lethality, this may reflect that their internal “inclusive fitness meters” are still giving positive values, but that they are willing to take a slight risk of self-harm in exchange for an increase in attention (and potentially fitness). As noted above, our species’ moderate effective polygyny—the fact that male fitness has higher variance than female fitness—means that a male is more likely to die childless than a woman. His inclusive fitness is more likely to be negative, but in addition, he has less to lose and more to gain from a more serious suicide attempt. If he dies, from his genes’ perspective, it might not be much loss compared to the benefits of “winning” the gamble and surviving the attempt. Recall that women commit suicide much more often when lethal poisons are available (e.g., Chinese rural women, women physicians). This is a method unlikely to be lethal in our environments of evolutionary adaptedness; its relatively low lethality might be the deeper reason that women feel comfortable using it, even though modern chemicals in some cases make it reliably lethal. Also, the period during which a person “acquires competence” by engaging in increasingly provocative behaviors may provide the opportunity for group members to intervene and offer support; women are likely to be arrested earlier in this process than men, in part due to their more secure reproductive value compared to male “disposability.” These hypothesized adaptive processes are not necessarily conscious, if they exist; many people who make serious suicide attempts do sincerely intend to die. From the genes’ perspective, it is enough to get the organism to perform the adaptive behavior (in this case, attempting suicide when the expected gain from surviving exceeds the expected loss in fitness from dying)—the strategy, if it exists, is genetically encoded, not rationally calculated. Of course, even if nonconscious, an adaptation may still respond to economic incentives. If it is capable of choosing an appropriately lethal means of suicide, it is capable of responding to a change in the likelihood of rescue. If rescue is forbidden, for example, the likelihood of survival is close to zero for many methods. Again, Joiner is ideologically opposed to this line of thinking, and again, it’s for aesthetic, not scientific, reasons. Joiner’s complaints are two: the economic “viewpoint” is dangerous, in that it may encourage lethal-seeming suicide attempts; and it is callous, in that it denies the reality of the suffering experienced by the suicidal individual. Both of these complaints are without merit. As to the “danger” of the economic model, Joiner says: The danger of viewpoints like this should be pointed out. Any analysis that encourages suicidal behavior in any way—particularly in ways that romanticize or glorify it, or make it seem easy and normative—has potential negative consequences for public health. But it is hardly the viewpoint that is dangerous—it’s the existing incentive structure in our society that encourages apparently lethal suicide attempts in people who often don’t really want to die. I have argued that if the suicide prohibition were ended, this dangerous incentive structure—the “fantasy of rescue”—would also end. Analyses are not dangerous. Problems are dangerous. Analyses identify the problems and point the way to solutions. By suggesting that the economic analysis is dangerous, Joiner is contributing to the taboo against speaking about suicide. Joiner also argues that the economic hypothesis denies the reality of the suffering of suicide attempters. He believes that the economic idea is part of a kind of “deconstructionist” philosophy in the school of Jacques Derrida: “What is left for the deconstructionist, then, is a constant questioning of the very existence of reality and meaning—including the reality of emotional pain. Try telling that to a suicidal person.” This objection is misguided. Joiner thinks that the economic model does not account for the pain suffered by those who attempt suicide. But the economic model suggests no such thing! Duhigg’s unfortunate opening example in his popular summary of the Marcotte study reports that right before the depressed, suicidal Kirk Jones jumped over the guardrail at Niagara Falls and survived, he had bragged to friends that he would “make some money” if he went over the Falls and lived. Despite this unfortunate and likely unrepresentative example, the core hypothesis is not that people coldly calculate that they will get a benefit from an apparently lethal suicide attempt. Rather, suffering people are motivated by that awful, extremely real suffering to do something awful—to essentially gamble their lives on a chance at making the suffering stop. An economic explanation, especially an adaptive one, need not imply cold, conscious processing and weighing of “expected values” at all. In a later chapter I will revisit the subject of “suicide gambles” in a broader sense, including behaviors apparently unrelated to suicide.",
      "word_count": 5725,
      "character_count": 36605,
      "chapter_number": 13,
      "section_number": null,
      "paragraph_number": 1,
      "start_position": 0,
      "end_position": 36605,
      "parent_chunk_id": "sarah_perryevery_cra_unknown_ch13"
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch14",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "chapter",
      "title": "Chapter Seven: On Contagion",
      "content": "Chapter Seven: On Contagion Behavioral Contagion Infectious diseases spread through contagion; one person infected with the flu can infect dozens of others. The specific microorganisms that cause each disease can be identified, and patterns of transmission can be discerned using epidemiological methods. Wells infected with cholera can be identified and sealed off. Many human behaviors are transmitted in patterns that mimic disease contagion. Pathological homesickness, apotemnophilia, multiple personality disorder, and even Ursuline convents in seventeenth-century France have all been posited to spread by sociogenic contagion. Just as cultural items such as computer viruses spread through direct contagion of software, our minds may be similarly vulnerable to contagious ideas and behaviors, viruses on the informational level rather than the microbiological level. Cultural contagion is even an explicit goal: an essay or a video “goes viral” when it succeeds in getting itself replicated on computers all over the world. Behaviors are not, for the most part, transmitted by germs; they must be transmitted culturally. The metaphorical “germs” by which behavioral contagion occurs are abstract and vague compared to real germs. If we find the contagion metaphor useful for thinking about behavioral change, we must keep in mind the ways in which the metaphor is incomplete, for here there is no tidy, legible mechanism of transmission. Ethical Perspectives on Suicide Contagion Is suicide contagious? Could it be like a computer virus, infecting the software of the mind itself? Here the analogy to biological science has taken on moral proportions. On the one hand, if suicide can be contagious, the agency of a person committing suicide is called into question; as with the disease model of addiction, the outcome seems to be less his fault when viewed as partly the product of contagion. On the other hand, if suicide is contagious in the sense that one suicide might meaningfully cause many others, then there may be a special ethical duty to refrain from committing suicide in order to avoid having a causative effect on others. This is, of course, assuming suicide is always a bad outcome, to be prevented no matter how much suffering and ignorance is required to do so. This latter perspective—that there is a moral duty not to commit suicide, grounded in large part in the possible contagious effects of a suicide—is taken by Jennifer Michael Hecht in her recent popular book Stay: A History of Suicide and the Philosophies Against It.84 During the twentieth century, moral public discourse on suicide was largely replaced with medical discourse; psychologists reframed suicide as being necessarily the result of mental illness, undermining the agency and moral responsibility attributable to suicides. Contemporary philosophers85 have struggled to articulate arguments for the intuition that suicide is wrong without reference to religion. Hecht takes up the challenge to provide a secular account of the case against suicide, and she motivates the duty not to commit suicide, in large part, by reference to the alleged contagious effects of suicide. Examining the phenomenon of contagion can help sort out the moral implications of this new basis for the wrongness of suicide. The Science of Suicide Contagion Swabs and microscopes will not reveal the secrets of behavioral contagion, but what about epidemiological analysis? Dozens of studies have investigated the phenomenon of suicide contagion, using statistical analysis to attempt to identify clusters of suicides in space and time. So is there such a thing as suicide contagion, or not? In a 2003 paper entitled “Media Contagion and Suicide Among the Young”86 Madelyn Gould and co-authors assert that there is “ample evidence from the literature on suicide clusters and the impact of the media to support the contention that suicide is ‘contagious.’” In contrast, Thomas Joiner, a suicide researcher mentioned in previous chapters, calls the evidence for large-scale clusters “equivocal.”87 In a 1999 paper on suicide contagion, Joiner goes on to say that contagion “has not been conceptually well developed nor empirically well supported as an explanation for suicide clusters.” Writing in 2009, a team led by Michael Westerlund elaborately qualify their claim as follows: “Although disputed, most researchers in the field of suicide and mass media agree that the studies carried out to date have substantiated the existence, under certain circumstances, of genuine suicidal ‘contagion’ from suicide reports in the media.”88 Why the discrepancy between researchers writing on the same subject at approximately the same time? To understand the dissonant claims, we must first figure out what, exactly, the phenomenon of contagion precisely is. The purported phenomenon of suicide contagion happens as follows: A person commits suicide; Another person learns of the suicide, through media or otherwise; and Learning about the suicide causes the second person to also commit suicide. The slipperiest part of the above definition is the word “cause,” which might be interpreted in a number of ways—in context, it might reasonably mean anything from necessary “but-for” causation to a subtle influence, or something as abstract as a condition of possibility. The word “cause” here stands in for the mechanism of suicide contagion akin to biological germs, discussed above. Moral Contagion or Informational Contagion? There are really two types of “cause” that we care about, two distinct aspects of the message presumably conveyed by a suicide to any imitators. First, there is the implied moral message that suicide is acceptable. When a vulnerable person is considering suicide, the theory goes, a news report of a celebrity suicide functions as “social proof” that suicide is an acceptable solution to serious problems. The moral licensing effect is posited to be strong enough to push a suicidal person over the edge. This is the message stressed in the “social learning theory” model of suicide contagion.89 It is also the message emphasized by Hecht in her moral argument based on contagion: “don’t kill yourself, because it teaches other people that suicide is okay.” But the second aspect of the message conveyed by a suicide is purely informational. Instead of (or in addition to) its moral message, a successful act of suicide provides cold, hard facts—especially regarding the specifics of the method used. Useful information making its way through a population follows the same patterns of dissemination as a disease infecting a population. Information about how to commit suicide successfully is difficult to find; a single, salient case study providing careful description of the not-too-horrible sounding method is better-quality information than may otherwise be available. People who have never been seriously suicidal generally underestimate the practical difficulty of successfully committing suicide; a part of this difficulty is the lack of reliable information about method. A single successful suicide would only be valuable information among people starved for quality information about suicide, and our suicide prohibition ensures that we are so starved. In this aspect, the suicide’s crime against society, if he commits one, is epistemic. The moral claim grounded in this type of contagion would sound more like this: “don’t kill yourself, because it teaches other people that suicide is possible.” There seems to be less moral weight in this duty than in the earlier phrasing; the violation amounts to passing forbidden information, perhaps even inadvertently. Within suicide contagion research, no effort is made to distinguish information-heavy “contagion” from moral licensing “contagion.” In a meta-analysis of papers investigating suicide contagion, Steven Stack90 reviews what he calls “perhaps the most dramatic illustration of an imitative effect”—the publication of the suicide self-help book Final Exit in 1991. Suicides by asphyxiation, a method recommended in the book, reportedly increased by 313% in the year after the book’s publication, and over a quarter of these suicides had a copy of the book present at the death scene.91 Of course, the publication of the book Final Exit is very different from a celebrity suicide—the deceased, in suffocating themselves, were presumably using information they had sought out in the book, and it is strange that Stack characterizes this as an “imitative effect.” While there are descriptions of actual assisted suicides in Final Exit, it would likewise be strange to characterize the cluster suicides as “imitating” them—or of imitating anyone. The sense in which the book “caused” the suicides is limited; as Stack notes, the overall rate of suicide did not rise. Rather, people who wanted to commit suicide did research and were able to use a comfortable, reliable method. This is not a case of contagion, but of research. Studies do not attempt to distinguish the informational from the moral component of contagion. This is unfortunate. As I will explain, it appears to me that the information component of suicides dominates observed contagion effects, surpassing the effects, if any, of moral licensing. Where contagion is most apparent, the information component of the original suicide will be apparent as well. Mass Clusters and Point Clusters There are two types of suicide clusters, according to Joiner (1999) and Mesoudi (2009).92 A mass cluster is an episode of suicide contagion on a national scale, without spatial clustering. An example is the suicide of Marilyn Monroe, discussed below, with effects detectable in national suicide statistics. The other type is a point cluster, a local cluster of suicides often confined to one school, prison, or hospital. Again, the evidence for the existence of mass clusters is “equivocal,” according to Joiner. In the rare cases in which contagion patterns are clearly detectable, we will see that the suicides in question were high in information content. For local-level suicide clustering there is a great deal of evidence—but, as Joiner points out, there is little evidence that this clustering is caused by contagion. In fact, computer models testing Joiner’s (1999) hypothesis93 suggest that either contagion or geographic sorting of similar people (homophily) could explain the degree to which suicides appear to cluster. The cause of suicides is difficult to sort out even when contagion is assumed to be present; but clustering may be present even in the absence of any contagion whatsoever, because people tend to live near people similar to them. In a related study,94 assortative relating—self-sorting by trait—accounted for patterns of suicidality in pairs of college roommates. Suicide clusters in Scotland have been found to be adequately explained by spatial concentrations of economic deprivation.95 Whether a mass cluster or a point cluster is under study, statistical analysis of the numerical data determines whether there is a significant result. Researchers must use discretion in specifying how cluster-like is cluster-like enough. Estimates of the proportion of suicides accounted for by clusters vary widely, from less than 1% to 13% or more.96 A recent quantitative review of 419 findings across 55 studies investigating media suicide contagion97 concluded that only 35% of the findings under study supported the existence of clustering or contagion; the vast majority of findings were negative. (If publication bias applies here, and positive findings are preferentially reported, then the evidence appears even worse.) In contrast to what Stack characterizes as “narrative” literature reviews, which, like Gould’s 2003 study, often conclude that contagion unquestionably exists, Stack notes that in this quantitative review, “the weight of the evidence is, in fact, against an imitative effect. Indeed, 269/419 findings or 64.2% reported the absence of an imitative effect.” The evidence for suicide contagion is equivocal, and its peculiarities subtle. To cut through the mathematical abstractions, let’s take a look at one of the most dramatic suicide mass clusters in American history—that following the suicide of Marilyn Monroe. The Death of Marilyn Monroe On August 5, 1962, Marilyn Monroe committed suicide by an overdose of the barbiturate Nembutal. Examining national suicide data from the years surrounding her death, a “copycat” cluster clearly suggests itself even without the application of statistical analysis tools. David Phillips reported that there were 197 suicides in the week after the death of Marilyn Monroe,98 a 12% increase over the expected number. But the increase is perceptible at the monthly and yearly level as well. The apparent copycat effect is most pronounced among women, and highly localized to the specific method used by Marilyn Monroe. Between the years of 1958 and 1971 in the United States, the number of suicides rose gradually with the population; the rate of suicide did not change substantially during that time period (see Figure 1). The rate of suicides by poisoning, however, increased, and the rate of poisoning by barbiturates specifically doubled.99 Figure 1. Suicide rate and poisoning suicide rate, 1958–1971 Poisoning suicides, and especially barbiturate overdoses, had been increasing for years before Marilyn Monroe’s suicide (see Figure 2). A gradually increasing trend was established between 1958, when there were 912 barbiturate overdoses, and 1961, when there were 1,341. In 1962, however, the gradual trend was suddenly replaced with an even steeper increase (see Figure 2). In 1962, there were 1,739 barbiturate overdose suicides; 1963 saw even more, with 1,997 such deaths. The sudden increase is then followed by a gradual decrease, even falling below the trend line predicted by the initial 1958–1961 increase. Figure 2. Barbiturate suicide rate, overall and by sex, 1958–1971 Barbiturate overdoses during this period follow a clear pattern: there tend to be about twice as many women as men committing suicide by barbiturate overdose. This is remarkable since men are about four times as likely to commit suicide as women, and this holds true for most suicide methods. When it comes to suicide by poison, though, and especially by barbiturate overdose, women are twice as represented as men. Viewing the graphs of male and female overdoses separately (Figure 2), there is an increase in male suicides of this type following Marilyn Monroe’s death, but most of the “extra” barbiturate suicides appear to be women. The sudden uptick in suicides is also detectable at the monthly level. From January 1958 until July 1962, the monthly number of suicides bounces from 1,300 to 1,800. Monthly poisoning suicide numbers range from the high 200s to the low 400s, with a secular increasing trend. In August 1962, the number of suicides is up a little, but the number of poisoning suicides is up a lot (Figure 3). In 1961, there had been 1,620 suicides in July and 1,579 in August; in 1962, there were 1,659 suicides in July and 1,838 in August. Again in 1961, there were 390 poisoning deaths in July and 367 in August; in 1962, there were 370 poisoning deaths in July and 543 in August, the first time during the study period (and perhaps ever) that the figure exceeded 500. Figure 3Figure 3. Monthly suicides and poisoning suicides, 1962 It is possible that the rise in suicide during the week and month of Marilyn Monroe’s death, and the acceleration of deaths by poisoning and especially barbiturate overdose by women in the months and years after her death, are the product of coincidence, not causally related to her suicide at all. It is also possible that some third factor caused both Monroe’s suicide and the other female poisoning suicides. However, the evidence is strongly suggestive of a causal connection, even in the absence of statistical analysis. Marilyn Monroe’s death was a high-information suicide; the New York Mirror even specified the number of pills she had taken on its front page (Figure 4). Barbiturate sleeping pills were commonly prescribed at the time, and even available on the black market. (Today, much less lethal benzodiazepines have replaced barbiturates on both the prescription market and the black market; however, barbiturates are still the drug typically prescribed for assisted suicide in the United States.) Monroe’s suicide presented an extremely useful piece of information for those considering suicide: 40 Nembutal taken by mouth are lethal to a small woman. Figure 4. Cover of the New York Mirror, August 6, 1962 The death of Marilyn Monroe provides an unusually clear example of an apparent mass suicide cluster. Most correlations are much weaker; recall that the majority of findings of suicide contagion studies reviewed in Stack’s 2005 analysis were negative. Often no correlation can be found at all. Certain features of studies make them more or less likely to have a negative or positive result.100 One is femaleness: researchers looking at suicide rates of women specifically are more likely to detect contagion than researchers looking at men’s or overall suicide rates. Another is the celebrity status of the original suicide, particularly entertainment or political celebrity status, which is positively correlated with finding a contagion effect compared to studies examining non-celebrity suicides. If researchers study a suicide that is portrayed negatively in the media, they are much less likely to find a contagion pattern than researchers who are not studying suicides they deem to have been portrayed negatively in the media. Studies looking at youth suicide rates have also been less likely to find a contagion effect than studies of the general population,101 casting doubt on the theory that youth are particularly susceptible to suicide contagion. Detecting a suicide cluster using statistical analysis, even when the numbers are very suggestive of causation, can say nothing about the mechanism by which causation might occur. If media reports of suicides are contagious and importantly causative of future suicides—if they are truly a risk factor for suicide—then we would expect survivors of nearly-lethal suicide attempts to be more likely to have recently been exposed to reports of a suicide than non-suicidal matched controls. If, on the other hand, serious suicide attempters do not differ significantly from non-suicidal matched controls in terms of exposure to media reports of suicide, then it is less likely this kind of media exposure is importantly causative of suicide. Absence of correlation (between suicide attempter status and suicide media exposure), in this case, would likely indicate absence of causation. This was the experimental design of a 2001 study by James Mercy et al.,102 “Is Suicide Contagious? A Study of the Relation between Exposure to the Suicidal Behavior of Others and Nearly Lethal Suicide Attempts.” 153 young people, ages 13–34, who had recently been hospitalized for a nearly-lethal suicide attempt, along with 513 non-suicidal matched controls, were interviewed about their exposure to media accounts of suicide, as well as suicidal behavior on the part of parents, relatives, or friends. Exposure to the suicidal behavior of parents and relatives was not significantly different between the groups—but more non-suicidal controls than suicide attempters had been exposed to media reports of suicide and to the suicidal behavior of friends. Contrary to expectation, and again based on this one study, suicide media and suicidal behavior by friends appears to have a protective effect against suicide. If our world happens to work according to the principles of this study, then suicide exhibits a moral de-licensing effect, the opposite of the moral contagion of social learning theory; and if this is true, committing suicide yourself makes your friends less likely to commit suicide. Gould et al. (2003) criticize the findings of the Mercy et al. (2001) study on the grounds that around half of the subjects were adults between the ages of 25 and 34. Groups this old are not known to exhibit suicide contagion, says Gould. Stack (2005) contradicts this statement with the finding that studies of youth were less likely to find a contagion effect than studies of the entire population. He notes that the misperception that youth are prone to suicide contagion is the result of a few studies with “atypical research design and/or samples,” such as counting only suicides by a particular method rather than the entire population’s suicide rates. In addition, many studies around the world have identified suicide clusters in non-teenage populations. Perhaps Gould et al. reject these studies and their conclusions as well, if it is so clear that suicide contagion is undetectable outside of a teenage population. Jennifer Michael Hecht103 attempts to make a moral case against suicide without appealing to God or to religious injunctions—and turns instead to science to support the moral obligation. The Mercy study serves as a kind of reversal test, to see if the facts of suicide contagion matter to the moral outcome in Hecht’s case. If suicide, encountered in both personal and public life, could be shown to modestly decrease future suicides, would that make suicide not wrong (or at least not as wrong)? Based on my reading of Hecht, I suspect that she would insist that suicide remains completely wrong, even if Mercy et al.’s findings had been replicated dozens of times. Suicide contagion is not weight-bearing; no part of the anti-suicide argument hinges on its truth or falsity. Hecht uses suicide contagion more like a decoration than as support for the case against suicide; nothing turns on it, and none of her conclusions would change if she came to agree that “suicide contagion” is exaggerated and misleading, and more about information than moral licensing. I suspect that the “information payload” of a suicide is strongly predictive of whether that suicide will cause contagion-like effects. Marilyn Monroe’s suicide carried a dense information payload, and produced a detectable wave of suicides. Final Exit is nothing but information payload—and even though no suicide was associated with it, it produced a “contagion” effect stronger than any real suicide. Another well-supported suicide cluster occurred after the suicide of Quebecois journalist Gaetan Girouard. Girouard committed suicide by hanging; this may not seem like a major information payload, but it actually is. Hanging is around 70% lethal,104 which is actually slightly higher than the lethality level of suicidal gunshot wounds for women. Hanging is not as violent or traumatic as other methods, and it is easily achievable with common materials. And it is this information payload, rather than the moral licensing payload, that primarily drives the apparent contagiousness of suicide. Why Women? According to Stack (2005), studies investigating female suicide rates are almost five times more likely to find a contagion effect than studies investigating suicide rates in men or in the population as a whole. The Marilyn Monroe suicide cluster is perceptibly driven by female suicides. Why should women be especially subject to contagion? Women are more likely to experience psychosomatic illness in general, and to display physical symptoms from social suggestion (as in mass hysteria) than men. Suicide contagion might function similar to a socially-transmitted hysterical illness. There is a simpler explanation, though: women are pickier about method than men. Female suicide rates are around a quarter of men’s suicide rates overall, and the statistics for most suicide methods reflect this sex difference. But as noted earlier in the chapter, women are twice as likely to die by barbiturate overdose as men—but few women use firearms to commit suicide compared to men. Women in China commit suicide more often than men; lethal poisons (such as agricultural pesticides) are legal and available in China that are not available in the United States, and most Chinese women who commit suicide do so by ingesting poison. The physician suicide rate is elevated for both men and women, but the suicide rate for female doctors is relatively more elevated than that for male doctors. Access to lethal drugs or poisons appears to be more of a determining factor in female than male suicides; males are more flexible with regard to method. Government suicide prevention policies include drug prohibition, restrictions on gun purchases, barriers on bridges and high places, and even emissions standards on car exhaust. (Australia’s suicide rate dropped as car exhaust systems became more efficient and therefore less lethal.) These prohibitions burden both men and women, but the drug prohibition falls particularly hard on women. As a result, suicidal women in our society are likely to be experiencing an information gap compared to suicidal men—having the will to commit suicide, but lacking an acceptable method to accomplish it. The information provided by the event of a celebrity suicide and the method used—prescription drugs, hanging, or asphyxiation, by plastic bag or charcoal burning—would therefore be more likely to be collected and used by a woman than a man. In summary, the association of femaleness with suicide contagion is likely a function of women’s greater sensitivity to method, including women’s preference for less violent methods, especially poison. Other Factors in Contagion: Negative Definition of Suicide The evidence for suicide clusters—much less contagion— is more suggestive than compelling. Most findings are null. But one study feature in particular is particularly likely to guarantee a null result (that is, no contagion): a story that portrays suicide in a negative light, providing “negative definitions” for the suicide and its effects. In Stack (2005), researchers investigating “negative light” portrayals of suicide were 99% less likely to find a positive result than those not investigating a self-described negative portrayal (odds ratio 0.01). Keeping the sketchiness of the entire domain in mind, this finding might be a fluke. Whether a given story involved a “negative portrayal” was, according to Stack, defined by the authors of the studies themselves; it may not be measuring any feature of reality that is reliable across observers. Those (few) studies that sought to examine suicides receiving negative portrayals may have many things in common with each other besides the negative portrayal, including low information content. Examples of “negative definition” stories provided by Stack (2005) include the mass suicide of the People’s Temple cult members in Jonestown and the suicide of Nirvana singer Kurt Cobain; the “negative definition” hypothesis seems arbitrary enough to risk being a fully general excuse for why a particular suicide did not result in a contagion cluster. Take another look at Figure 4; one might easily characterize its sordid emphasis on Monroe’s nudity as a negative portrayal of a suicide—despite the dozens of imitators. However, it is also possible that suicide contagion does regularly occur, and that the negative portrayal of suicide somehow halts the ordinary process of transmission. If the negative portrayal of suicide in the media has the capacity to shut down suicide contagion effects from suicides, then the role of the media is more important than the role of the original suicide in meaningfully causing the contagious suicides. Touching back to Hecht yet again, if contagion were really a basis for assigning blame to suicide, then this finding would put most of the blame on media outlets and hardly any on individuals. I doubt whether Hecht would let individuals off that easily. Rather, the individual duty to live, no matter how much one is suffering and wants to die, does not seem to be affected by consequential arguments about suicide contagion. Ultimately, suicide contagion is superfluous to her argument. Unfortunately, there is not much left when you take the over-hyped science away. Suicide contagion is used by Hecht to motivate a secular moral duty against suicide. The evidence for suicide contagion is mixed and frequently self-contradictory, but even if Hecht discovered it to be wholly imaginary, it would probably not affect her analysis of the duty not to commit suicide. Suicide contagion is a prop that looks good with the argument, rather than a genuinely relevant proposition that might have real-world effects. Suicide contagion is also the chief justification for the censorship of reports of suicide. The next chapter will examine the censorship of suicide, as well as the censorship or failure to censor other behaviors that may contribute to contagion.",
      "word_count": 4510,
      "character_count": 28878,
      "chapter_number": 14,
      "section_number": null,
      "paragraph_number": null,
      "start_position": 0,
      "end_position": 28878,
      "parent_chunk_id": null
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch14_p1",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "paragraph",
      "title": "Paragraph 1",
      "content": "Chapter Seven: On Contagion Behavioral Contagion Infectious diseases spread through contagion; one person infected with the flu can infect dozens of others. The specific microorganisms that cause each disease can be identified, and patterns of transmission can be discerned using epidemiological methods. Wells infected with cholera can be identified and sealed off. Many human behaviors are transmitted in patterns that mimic disease contagion. Pathological homesickness, apotemnophilia, multiple personality disorder, and even Ursuline convents in seventeenth-century France have all been posited to spread by sociogenic contagion. Just as cultural items such as computer viruses spread through direct contagion of software, our minds may be similarly vulnerable to contagious ideas and behaviors, viruses on the informational level rather than the microbiological level. Cultural contagion is even an explicit goal: an essay or a video “goes viral” when it succeeds in getting itself replicated on computers all over the world. Behaviors are not, for the most part, transmitted by germs; they must be transmitted culturally. The metaphorical “germs” by which behavioral contagion occurs are abstract and vague compared to real germs. If we find the contagion metaphor useful for thinking about behavioral change, we must keep in mind the ways in which the metaphor is incomplete, for here there is no tidy, legible mechanism of transmission. Ethical Perspectives on Suicide Contagion Is suicide contagious? Could it be like a computer virus, infecting the software of the mind itself? Here the analogy to biological science has taken on moral proportions. On the one hand, if suicide can be contagious, the agency of a person committing suicide is called into question; as with the disease model of addiction, the outcome seems to be less his fault when viewed as partly the product of contagion. On the other hand, if suicide is contagious in the sense that one suicide might meaningfully cause many others, then there may be a special ethical duty to refrain from committing suicide in order to avoid having a causative effect on others. This is, of course, assuming suicide is always a bad outcome, to be prevented no matter how much suffering and ignorance is required to do so. This latter perspective—that there is a moral duty not to commit suicide, grounded in large part in the possible contagious effects of a suicide—is taken by Jennifer Michael Hecht in her recent popular book Stay: A History of Suicide and the Philosophies Against It.84 During the twentieth century, moral public discourse on suicide was largely replaced with medical discourse; psychologists reframed suicide as being necessarily the result of mental illness, undermining the agency and moral responsibility attributable to suicides. Contemporary philosophers85 have struggled to articulate arguments for the intuition that suicide is wrong without reference to religion. Hecht takes up the challenge to provide a secular account of the case against suicide, and she motivates the duty not to commit suicide, in large part, by reference to the alleged contagious effects of suicide. Examining the phenomenon of contagion can help sort out the moral implications of this new basis for the wrongness of suicide. The Science of Suicide Contagion Swabs and microscopes will not reveal the secrets of behavioral contagion, but what about epidemiological analysis? Dozens of studies have investigated the phenomenon of suicide contagion, using statistical analysis to attempt to identify clusters of suicides in space and time. So is there such a thing as suicide contagion, or not? In a 2003 paper entitled “Media Contagion and Suicide Among the Young”86 Madelyn Gould and co-authors assert that there is “ample evidence from the literature on suicide clusters and the impact of the media to support the contention that suicide is ‘contagious.’” In contrast, Thomas Joiner, a suicide researcher mentioned in previous chapters, calls the evidence for large-scale clusters “equivocal.”87 In a 1999 paper on suicide contagion, Joiner goes on to say that contagion “has not been conceptually well developed nor empirically well supported as an explanation for suicide clusters.” Writing in 2009, a team led by Michael Westerlund elaborately qualify their claim as follows: “Although disputed, most researchers in the field of suicide and mass media agree that the studies carried out to date have substantiated the existence, under certain circumstances, of genuine suicidal ‘contagion’ from suicide reports in the media.”88 Why the discrepancy between researchers writing on the same subject at approximately the same time? To understand the dissonant claims, we must first figure out what, exactly, the phenomenon of contagion precisely is. The purported phenomenon of suicide contagion happens as follows: A person commits suicide; Another person learns of the suicide, through media or otherwise; and Learning about the suicide causes the second person to also commit suicide. The slipperiest part of the above definition is the word “cause,” which might be interpreted in a number of ways—in context, it might reasonably mean anything from necessary “but-for” causation to a subtle influence, or something as abstract as a condition of possibility. The word “cause” here stands in for the mechanism of suicide contagion akin to biological germs, discussed above. Moral Contagion or Informational Contagion? There are really two types of “cause” that we care about, two distinct aspects of the message presumably conveyed by a suicide to any imitators. First, there is the implied moral message that suicide is acceptable. When a vulnerable person is considering suicide, the theory goes, a news report of a celebrity suicide functions as “social proof” that suicide is an acceptable solution to serious problems. The moral licensing effect is posited to be strong enough to push a suicidal person over the edge. This is the message stressed in the “social learning theory” model of suicide contagion.89 It is also the message emphasized by Hecht in her moral argument based on contagion: “don’t kill yourself, because it teaches other people that suicide is okay.” But the second aspect of the message conveyed by a suicide is purely informational. Instead of (or in addition to) its moral message, a successful act of suicide provides cold, hard facts—especially regarding the specifics of the method used. Useful information making its way through a population follows the same patterns of dissemination as a disease infecting a population. Information about how to commit suicide successfully is difficult to find; a single, salient case study providing careful description of the not-too-horrible sounding method is better-quality information than may otherwise be available. People who have never been seriously suicidal generally underestimate the practical difficulty of successfully committing suicide; a part of this difficulty is the lack of reliable information about method. A single successful suicide would only be valuable information among people starved for quality information about suicide, and our suicide prohibition ensures that we are so starved. In this aspect, the suicide’s crime against society, if he commits one, is epistemic. The moral claim grounded in this type of contagion would sound more like this: “don’t kill yourself, because it teaches other people that suicide is possible.” There seems to be less moral weight in this duty than in the earlier phrasing; the violation amounts to passing forbidden information, perhaps even inadvertently. Within suicide contagion research, no effort is made to distinguish information-heavy “contagion” from moral licensing “contagion.” In a meta-analysis of papers investigating suicide contagion, Steven Stack90 reviews what he calls “perhaps the most dramatic illustration of an imitative effect”—the publication of the suicide self-help book Final Exit in 1991. Suicides by asphyxiation, a method recommended in the book, reportedly increased by 313% in the year after the book’s publication, and over a quarter of these suicides had a copy of the book present at the death scene.91 Of course, the publication of the book Final Exit is very different from a celebrity suicide—the deceased, in suffocating themselves, were presumably using information they had sought out in the book, and it is strange that Stack characterizes this as an “imitative effect.” While there are descriptions of actual assisted suicides in Final Exit, it would likewise be strange to characterize the cluster suicides as “imitating” them—or of imitating anyone. The sense in which the book “caused” the suicides is limited; as Stack notes, the overall rate of suicide did not rise. Rather, people who wanted to commit suicide did research and were able to use a comfortable, reliable method. This is not a case of contagion, but of research. Studies do not attempt to distinguish the informational from the moral component of contagion. This is unfortunate. As I will explain, it appears to me that the information component of suicides dominates observed contagion effects, surpassing the effects, if any, of moral licensing. Where contagion is most apparent, the information component of the original suicide will be apparent as well. Mass Clusters and Point Clusters There are two types of suicide clusters, according to Joiner (1999) and Mesoudi (2009).92 A mass cluster is an episode of suicide contagion on a national scale, without spatial clustering. An example is the suicide of Marilyn Monroe, discussed below, with effects detectable in national suicide statistics. The other type is a point cluster, a local cluster of suicides often confined to one school, prison, or hospital. Again, the evidence for the existence of mass clusters is “equivocal,” according to Joiner. In the rare cases in which contagion patterns are clearly detectable, we will see that the suicides in question were high in information content. For local-level suicide clustering there is a great deal of evidence—but, as Joiner points out, there is little evidence that this clustering is caused by contagion. In fact, computer models testing Joiner’s (1999) hypothesis93 suggest that either contagion or geographic sorting of similar people (homophily) could explain the degree to which suicides appear to cluster. The cause of suicides is difficult to sort out even when contagion is assumed to be present; but clustering may be present even in the absence of any contagion whatsoever, because people tend to live near people similar to them. In a related study,94 assortative relating—self-sorting by trait—accounted for patterns of suicidality in pairs of college roommates. Suicide clusters in Scotland have been found to be adequately explained by spatial concentrations of economic deprivation.95 Whether a mass cluster or a point cluster is under study, statistical analysis of the numerical data determines whether there is a significant result. Researchers must use discretion in specifying how cluster-like is cluster-like enough. Estimates of the proportion of suicides accounted for by clusters vary widely, from less than 1% to 13% or more.96 A recent quantitative review of 419 findings across 55 studies investigating media suicide contagion97 concluded that only 35% of the findings under study supported the existence of clustering or contagion; the vast majority of findings were negative. (If publication bias applies here, and positive findings are preferentially reported, then the evidence appears even worse.) In contrast to what Stack characterizes as “narrative” literature reviews, which, like Gould’s 2003 study, often conclude that contagion unquestionably exists, Stack notes that in this quantitative review, “the weight of the evidence is, in fact, against an imitative effect. Indeed, 269/419 findings or 64.2% reported the absence of an imitative effect.” The evidence for suicide contagion is equivocal, and its peculiarities subtle. To cut through the mathematical abstractions, let’s take a look at one of the most dramatic suicide mass clusters in American history—that following the suicide of Marilyn Monroe. The Death of Marilyn Monroe On August 5, 1962, Marilyn Monroe committed suicide by an overdose of the barbiturate Nembutal. Examining national suicide data from the years surrounding her death, a “copycat” cluster clearly suggests itself even without the application of statistical analysis tools. David Phillips reported that there were 197 suicides in the week after the death of Marilyn Monroe,98 a 12% increase over the expected number. But the increase is perceptible at the monthly and yearly level as well. The apparent copycat effect is most pronounced among women, and highly localized to the specific method used by Marilyn Monroe. Between the years of 1958 and 1971 in the United States, the number of suicides rose gradually with the population; the rate of suicide did not change substantially during that time period (see Figure 1). The rate of suicides by poisoning, however, increased, and the rate of poisoning by barbiturates specifically doubled.99 Figure 1. Suicide rate and poisoning suicide rate, 1958–1971 Poisoning suicides, and especially barbiturate overdoses, had been increasing for years before Marilyn Monroe’s suicide (see Figure 2). A gradually increasing trend was established between 1958, when there were 912 barbiturate overdoses, and 1961, when there were 1,341. In 1962, however, the gradual trend was suddenly replaced with an even steeper increase (see Figure 2). In 1962, there were 1,739 barbiturate overdose suicides; 1963 saw even more, with 1,997 such deaths. The sudden increase is then followed by a gradual decrease, even falling below the trend line predicted by the initial 1958–1961 increase. Figure 2. Barbiturate suicide rate, overall and by sex, 1958–1971 Barbiturate overdoses during this period follow a clear pattern: there tend to be about twice as many women as men committing suicide by barbiturate overdose. This is remarkable since men are about four times as likely to commit suicide as women, and this holds true for most suicide methods. When it comes to suicide by poison, though, and especially by barbiturate overdose, women are twice as represented as men. Viewing the graphs of male and female overdoses separately (Figure 2), there is an increase in male suicides of this type following Marilyn Monroe’s death, but most of the “extra” barbiturate suicides appear to be women. The sudden uptick in suicides is also detectable at the monthly level. From January 1958 until July 1962, the monthly number of suicides bounces from 1,300 to 1,800. Monthly poisoning suicide numbers range from the high 200s to the low 400s, with a secular increasing trend. In August 1962, the number of suicides is up a little, but the number of poisoning suicides is up a lot (Figure 3). In 1961, there had been 1,620 suicides in July and 1,579 in August; in 1962, there were 1,659 suicides in July and 1,838 in August. Again in 1961, there were 390 poisoning deaths in July and 367 in August; in 1962, there were 370 poisoning deaths in July and 543 in August, the first time during the study period (and perhaps ever) that the figure exceeded 500. Figure 3Figure 3. Monthly suicides and poisoning suicides, 1962 It is possible that the rise in suicide during the week and month of Marilyn Monroe’s death, and the acceleration of deaths by poisoning and especially barbiturate overdose by women in the months and years after her death, are the product of coincidence, not causally related to her suicide at all. It is also possible that some third factor caused both Monroe’s suicide and the other female poisoning suicides. However, the evidence is strongly suggestive of a causal connection, even in the absence of statistical analysis. Marilyn Monroe’s death was a high-information suicide; the New York Mirror even specified the number of pills she had taken on its front page (Figure 4). Barbiturate sleeping pills were commonly prescribed at the time, and even available on the black market. (Today, much less lethal benzodiazepines have replaced barbiturates on both the prescription market and the black market; however, barbiturates are still the drug typically prescribed for assisted suicide in the United States.) Monroe’s suicide presented an extremely useful piece of information for those considering suicide: 40 Nembutal taken by mouth are lethal to a small woman. Figure 4. Cover of the New York Mirror, August 6, 1962 The death of Marilyn Monroe provides an unusually clear example of an apparent mass suicide cluster. Most correlations are much weaker; recall that the majority of findings of suicide contagion studies reviewed in Stack’s 2005 analysis were negative. Often no correlation can be found at all. Certain features of studies make them more or less likely to have a negative or positive result.100 One is femaleness: researchers looking at suicide rates of women specifically are more likely to detect contagion than researchers looking at men’s or overall suicide rates. Another is the celebrity status of the original suicide, particularly entertainment or political celebrity status, which is positively correlated with finding a contagion effect compared to studies examining non-celebrity suicides. If researchers study a suicide that is portrayed negatively in the media, they are much less likely to find a contagion pattern than researchers who are not studying suicides they deem to have been portrayed negatively in the media. Studies looking at youth suicide rates have also been less likely to find a contagion effect than studies of the general population,101 casting doubt on the theory that youth are particularly susceptible to suicide contagion. Detecting a suicide cluster using statistical analysis, even when the numbers are very suggestive of causation, can say nothing about the mechanism by which causation might occur. If media reports of suicides are contagious and importantly causative of future suicides—if they are truly a risk factor for suicide—then we would expect survivors of nearly-lethal suicide attempts to be more likely to have recently been exposed to reports of a suicide than non-suicidal matched controls. If, on the other hand, serious suicide attempters do not differ significantly from non-suicidal matched controls in terms of exposure to media reports of suicide, then it is less likely this kind of media exposure is importantly causative of suicide. Absence of correlation (between suicide attempter status and suicide media exposure), in this case, would likely indicate absence of causation. This was the experimental design of a 2001 study by James Mercy et al.,102 “Is Suicide Contagious? A Study of the Relation between Exposure to the Suicidal Behavior of Others and Nearly Lethal Suicide Attempts.” 153 young people, ages 13–34, who had recently been hospitalized for a nearly-lethal suicide attempt, along with 513 non-suicidal matched controls, were interviewed about their exposure to media accounts of suicide, as well as suicidal behavior on the part of parents, relatives, or friends. Exposure to the suicidal behavior of parents and relatives was not significantly different between the groups—but more non-suicidal controls than suicide attempters had been exposed to media reports of suicide and to the suicidal behavior of friends. Contrary to expectation, and again based on this one study, suicide media and suicidal behavior by friends appears to have a protective effect against suicide. If our world happens to work according to the principles of this study, then suicide exhibits a moral de-licensing effect, the opposite of the moral contagion of social learning theory; and if this is true, committing suicide yourself makes your friends less likely to commit suicide. Gould et al. (2003) criticize the findings of the Mercy et al. (2001) study on the grounds that around half of the subjects were adults between the ages of 25 and 34. Groups this old are not known to exhibit suicide contagion, says Gould. Stack (2005) contradicts this statement with the finding that studies of youth were less likely to find a contagion effect than studies of the entire population. He notes that the misperception that youth are prone to suicide contagion is the result of a few studies with “atypical research design and/or samples,” such as counting only suicides by a particular method rather than the entire population’s suicide rates. In addition, many studies around the world have identified suicide clusters in non-teenage populations. Perhaps Gould et al. reject these studies and their conclusions as well, if it is so clear that suicide contagion is undetectable outside of a teenage population. Jennifer Michael Hecht103 attempts to make a moral case against suicide without appealing to God or to religious injunctions—and turns instead to science to support the moral obligation. The Mercy study serves as a kind of reversal test, to see if the facts of suicide contagion matter to the moral outcome in Hecht’s case. If suicide, encountered in both personal and public life, could be shown to modestly decrease future suicides, would that make suicide not wrong (or at least not as wrong)? Based on my reading of Hecht, I suspect that she would insist that suicide remains completely wrong, even if Mercy et al.’s findings had been replicated dozens of times. Suicide contagion is not weight-bearing; no part of the anti-suicide argument hinges on its truth or falsity. Hecht uses suicide contagion more like a decoration than as support for the case against suicide; nothing turns on it, and none of her conclusions would change if she came to agree that “suicide contagion” is exaggerated and misleading, and more about information than moral licensing. I suspect that the “information payload” of a suicide is strongly predictive of whether that suicide will cause contagion-like effects. Marilyn Monroe’s suicide carried a dense information payload, and produced a detectable wave of suicides. Final Exit is nothing but information payload—and even though no suicide was associated with it, it produced a “contagion” effect stronger than any real suicide. Another well-supported suicide cluster occurred after the suicide of Quebecois journalist Gaetan Girouard. Girouard committed suicide by hanging; this may not seem like a major information payload, but it actually is. Hanging is around 70% lethal,104 which is actually slightly higher than the lethality level of suicidal gunshot wounds for women. Hanging is not as violent or traumatic as other methods, and it is easily achievable with common materials. And it is this information payload, rather than the moral licensing payload, that primarily drives the apparent contagiousness of suicide. Why Women? According to Stack (2005), studies investigating female suicide rates are almost five times more likely to find a contagion effect than studies investigating suicide rates in men or in the population as a whole. The Marilyn Monroe suicide cluster is perceptibly driven by female suicides. Why should women be especially subject to contagion? Women are more likely to experience psychosomatic illness in general, and to display physical symptoms from social suggestion (as in mass hysteria) than men. Suicide contagion might function similar to a socially-transmitted hysterical illness. There is a simpler explanation, though: women are pickier about method than men. Female suicide rates are around a quarter of men’s suicide rates overall, and the statistics for most suicide methods reflect this sex difference. But as noted earlier in the chapter, women are twice as likely to die by barbiturate overdose as men—but few women use firearms to commit suicide compared to men. Women in China commit suicide more often than men; lethal poisons (such as agricultural pesticides) are legal and available in China that are not available in the United States, and most Chinese women who commit suicide do so by ingesting poison. The physician suicide rate is elevated for both men and women, but the suicide rate for female doctors is relatively more elevated than that for male doctors. Access to lethal drugs or poisons appears to be more of a determining factor in female than male suicides; males are more flexible with regard to method. Government suicide prevention policies include drug prohibition, restrictions on gun purchases, barriers on bridges and high places, and even emissions standards on car exhaust. (Australia’s suicide rate dropped as car exhaust systems became more efficient and therefore less lethal.) These prohibitions burden both men and women, but the drug prohibition falls particularly hard on women. As a result, suicidal women in our society are likely to be experiencing an information gap compared to suicidal men—having the will to commit suicide, but lacking an acceptable method to accomplish it. The information provided by the event of a celebrity suicide and the method used—prescription drugs, hanging, or asphyxiation, by plastic bag or charcoal burning—would therefore be more likely to be collected and used by a woman than a man. In summary, the association of femaleness with suicide contagion is likely a function of women’s greater sensitivity to method, including women’s preference for less violent methods, especially poison. Other Factors in Contagion: Negative Definition of Suicide The evidence for suicide clusters—much less contagion— is more suggestive than compelling. Most findings are null. But one study feature in particular is particularly likely to guarantee a null result (that is, no contagion): a story that portrays suicide in a negative light, providing “negative definitions” for the suicide and its effects. In Stack (2005), researchers investigating “negative light” portrayals of suicide were 99% less likely to find a positive result than those not investigating a self-described negative portrayal (odds ratio 0.01). Keeping the sketchiness of the entire domain in mind, this finding might be a fluke. Whether a given story involved a “negative portrayal” was, according to Stack, defined by the authors of the studies themselves; it may not be measuring any feature of reality that is reliable across observers. Those (few) studies that sought to examine suicides receiving negative portrayals may have many things in common with each other besides the negative portrayal, including low information content. Examples of “negative definition” stories provided by Stack (2005) include the mass suicide of the People’s Temple cult members in Jonestown and the suicide of Nirvana singer Kurt Cobain; the “negative definition” hypothesis seems arbitrary enough to risk being a fully general excuse for why a particular suicide did not result in a contagion cluster. Take another look at Figure 4; one might easily characterize its sordid emphasis on Monroe’s nudity as a negative portrayal of a suicide—despite the dozens of imitators. However, it is also possible that suicide contagion does regularly occur, and that the negative portrayal of suicide somehow halts the ordinary process of transmission. If the negative portrayal of suicide in the media has the capacity to shut down suicide contagion effects from suicides, then the role of the media is more important than the role of the original suicide in meaningfully causing the contagious suicides. Touching back to Hecht yet again, if contagion were really a basis for assigning blame to suicide, then this finding would put most of the blame on media outlets and hardly any on individuals. I doubt whether Hecht would let individuals off that easily. Rather, the individual duty to live, no matter how much one is suffering and wants to die, does not seem to be affected by consequential arguments about suicide contagion. Ultimately, suicide contagion is superfluous to her argument. Unfortunately, there is not much left when you take the over-hyped science away. Suicide contagion is used by Hecht to motivate a secular moral duty against suicide. The evidence for suicide contagion is mixed and frequently self-contradictory, but even if Hecht discovered it to be wholly imaginary, it would probably not affect her analysis of the duty not to commit suicide. Suicide contagion is a prop that looks good with the argument, rather than a genuinely relevant proposition that might have real-world effects. Suicide contagion is also the chief justification for the censorship of reports of suicide. The next chapter will examine the censorship of suicide, as well as the censorship or failure to censor other behaviors that may contribute to contagion.",
      "word_count": 4510,
      "character_count": 28878,
      "chapter_number": 14,
      "section_number": null,
      "paragraph_number": 1,
      "start_position": 0,
      "end_position": 28878,
      "parent_chunk_id": "sarah_perryevery_cra_unknown_ch14"
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch15",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "chapter",
      "title": "Chapter Eight: The Censorship of Suicide",
      "content": "Chapter Eight: The Censorship of Suicide Sex and violence are ubiquitous in high and low art today, but artwork depicting suicide remains in danger of censorship merely because of its subject. In London, Paul Day’s compelling, emotionally dense frieze was pulled from a rail station because it depicted a skeleton driving a train and a commuter “wobbling precariously” close to the tracks—alluding to suicide by train. The Pepsi corporation apologized for and retracted ads (published in a German magazine) that depicted a “lonely single calorie” committing suicide. Chris Abraham, the self-appointed censor who received the apology indicated that electronic communication will help him carry out his inquisition into commercial art: “The lesson here,” Abraham declared, “is that social media has eyes everywhere and the network to make sure that advertisers can no longer hide stuff in niche markets.” Art, advertisements, and video games that deal with suicide—entry points for conversations about suicide among ordinary people—are unjustly criticized, censored, and destroyed. There is only one appropriate way to speak of suicide, one appropriate attitude toward it, and all others are quickly suppressed. This is not the case for other controversial topics—murder, race, gender, drug use—nor should it be. Suicide is tabooed in a unique and unfortunate way. Joan Wickersham, author of The Suicide Index and daughter of a suicide, thinks that more conversation about suicide would be a good thing: I think there is a kind of shame and a kind of taboo attached to suicide…We would prefer to think it doesn’t happen. I think we have to acknowledge it does happen. We have to acknowledge that it’s a mystery, that we don’t understand it very well. I just wanted to give a sense of what it is really like to go through this.105 Wickersham says there is a reluctance to talk about suicide, adding, “I would love to see more honest conversation about it.”106 Contrary to Wickersham’s goal, “honest conversation” about suicide is suppressed in the media when a suicide occurs. This suppression is often based on well-intentioned but flawed “media guidelines” published by anti-suicide groups. In addition to the fact that these guidelines promote the ethical position that suicide is wrong, I see two major problems with these guidelines: one, they promote myths about suicide as if they were facts; two, they increase the guilt of survivors by portraying suicide as preventable. The “Media Guidelines for Suicide” on suicide.org advise reporters as follows: • Emphasize the number one cause for suicide: • The number one cause for suicide is untreated depression. • And then indicate that depression is treatable, and thus anyone suffering from depression needs to receive IMMEDIATE help. This, as we have seen, is contrary to the scientific studies, which show that depression only slightly increases the risk for suicide—a fact which in itself carries little weight, since suicidality is one of the possible criteria for diagnosing depression. According to Thomas Joiner,107 borderline personality disorder and anorexia nervosa are far more predictive of suicide than depression. (BPD is associated with a 10% lifetime risk of suicide and a 50% lifetime rate of at least one very severe suicide attempt.) Even given a slight correlation between depression and suicide, it’s overstating the case to say that depression causes suicide. It would be more accurate, but less satisfying, to say that the desire to die, coupled with the acquired ability to die, is the leading cause of suicide. The suicide.org guidelines also recommend using the “fact” that “Over 90% of the people who die by suicide have clinical depression or a similar mental illness when they die.” I have repeatedly attempted to debunk this statistic, but the comfortable idea that suicide is caused by mental illness is hard to dislodge and unlikely to be questioned too closely. Other “media guidelines” offered by suicide.org range from silly to intrusive to Orwellian: • Do not begin a television newscast with a suicide story. • Do not place suicide stories on the cover of newspapers or magazines. • Never portray suicides as heroic. • Never say that a suicide “ended pain” or “ended suffering.” Suicide CAUSES excruciating pain for suicide survivors. • Also, people need to be alive to feel relief from pain. Suicide CAUSES pain. • Do not use the terms “successful suicide” or “committed suicide.” Use the term “died by suicide” instead. • The term “committed suicide” is NOT accurate and is VERY hurtful to those who have attempted suicide and to suicide survivors. Say “died by suicide.” The media guidelines proposed by suicide.org strictly fit my definition of “politically correct bullshit”: they express majority opinion in a manner unconcerned with truth, and have the function of a moral taboo to protect an important cultural narrative from negation. The guidelines promulgated by the National Institutes of Mental Health are much more harmful, however, in that they function to increase the pain and guilt experienced by people close to a person who committed suicide. The message promoted by the NIMH guidelines is that suicide is always preventable, and there are always warning signs. The guidelines advise reporters that: Studies of suicide based on in-depth interviews with those close to the victim indicate that, in their first, shocked reaction, friends and family members may find a loved one’s death by suicide inexplicable or they may deny that there were warning signs. Accounts based on these initial reactions are often unreliable.108 That is, there are always warning signs; push family remembers until they “remember” the politically correct story. Reporters are advised to ask survivors questions such as: • Had the victim ever received treatment for depression or any other mental disorder? • Did the victim have a problem with substance abuse? The message is that there were warning signs that, had the family cared enough to look, would have revealed the suicide’s intentions so that the suicide could have been prevented. Unfortunately, this serves to increase the guilt of survivors, legitimize increasingly coercive suicide prevention tactics, and increase the survivors’ sense that the suicide was a tragedy because it was “preventable.” The problems I identify—promoting false information and unnecessarily increasing survivors’ guilt and pain—are in addition to the harm to the marketplace of ideas that is done in the name of curbing the controversial phenomenon of suicide contagion. A single ethical idea is given precedence over all others, and false facts are repeated in the name of protecting it, and of protecting the institutions that depend on it (“Mention that Suicide.org is available 24 hours a day for anyone who is suicidal,” advises suicide.org). Censorship of Suicide versus Censorship of Violence In the previous chapter, I examined the evidence for the claim that censorship of suicide is necessary because suicide is contagious. But why censor reports of suicide and not reports of other contagious behaviors—such as violence? The evidence for violence contagion is much stronger than that for suicide contagion. But whereas suicide censorship is widely accepted, censorship of other-directed violence in media stories is rare. Violence contagion is demonstrated by the same type of ecological study as suicide contagion,109 and there is a body of laboratory evidence—not found in the suicide research— suggesting that exposure to violent stimuli increases aggressive behavior. However, despite both sources of evidence, the theory that media reports of violence “cause” real-life violence is not at all universally accepted.110 Despite greater evidence for a causal link in the case of violence, the idea that the media should voluntarily self-censor with regard to reports of violence is much less widely accepted than the corresponding idea applied to reports of suicide. Contagion and Moral Responsibility The insistence that suicide is media-contagious, but violence is not, is not rational. It is better understood, I believe, as a consequence of the differential attributions of moral responsibility in cases of suicide versus other-directed violence. Suicide is seen as an irrational act; the actor, as the story goes, is not in control of himself, certainly not sane, and is therefore vulnerable to external effects. On the other hand, the idea that violent acts like homicides are attributable to media suggestion is generally seen as a pathetic excuse. Perpetrators of violence are perceived as much more morally responsible for their acts than suicides. Despite evidence to the contrary, idea contagion is thus psychologically ruled out as a cause of violence, but not of suicides. Is political corruption contagious? How about adultery? Prostitution? Riots? Drug abuse? Such questions are rarely even studied. Obesity certainly appears to be contagious. If so, should we censor reports of these topics to avoid a contagion effect? To do so would seem ludicrous and counterproductive, not to mention contrary to our political ideals. But the censorship of suicide goes unchallenged. Moral Responsibility and Willingness to Censor The more an actor is seen as the agent of his actions, the less outside influences are seen as affecting his actions. In cases where moral responsibility is strongly attributed to an actor, it follows that outside influences are unlikely to be taken seriously as a cause of his actions—and, therefore, it is not necessary to censor these “outside influences” (such as media reports). It is my belief that the widespread voluntary censorship of reports of suicide—from use of politically correct language to pervasive norms of message content—are the result of the modern trend to exculpate suicides from moral responsibility and to redefine suicide as an act of insanity. There is, however, little evidence that suicides are any less morally responsible for their actions than murderers. Certainly, many other behaviors are media-contagious—but they are not censored, nor are many of them even studied. I think that one possible explanation is that, at a deep level, people understand that suicide is just not that bad compared to actual acts of violence—despite hysterical language describing suicide as “self-murder.” We want to exculpate people from acts to which we are sympathetic. While we often refuse to define acts outside of societal norms as “not wrong,” we may nonetheless refuse to attribute full moral responsibility to these acts. But this sort of sympathy backfires in our society. People who are “not responsible for their actions” must be “protected,” often in painful and dehumanizing ways; and society is responsible for their “protection,” often to the detriment of freedom.",
      "word_count": 1708,
      "character_count": 10866,
      "chapter_number": 15,
      "section_number": null,
      "paragraph_number": null,
      "start_position": 0,
      "end_position": 10866,
      "parent_chunk_id": null
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch15_p1",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "paragraph",
      "title": "Paragraph 1",
      "content": "Chapter Eight: The Censorship of Suicide Sex and violence are ubiquitous in high and low art today, but artwork depicting suicide remains in danger of censorship merely because of its subject. In London, Paul Day’s compelling, emotionally dense frieze was pulled from a rail station because it depicted a skeleton driving a train and a commuter “wobbling precariously” close to the tracks—alluding to suicide by train. The Pepsi corporation apologized for and retracted ads (published in a German magazine) that depicted a “lonely single calorie” committing suicide. Chris Abraham, the self-appointed censor who received the apology indicated that electronic communication will help him carry out his inquisition into commercial art: “The lesson here,” Abraham declared, “is that social media has eyes everywhere and the network to make sure that advertisers can no longer hide stuff in niche markets.” Art, advertisements, and video games that deal with suicide—entry points for conversations about suicide among ordinary people—are unjustly criticized, censored, and destroyed. There is only one appropriate way to speak of suicide, one appropriate attitude toward it, and all others are quickly suppressed. This is not the case for other controversial topics—murder, race, gender, drug use—nor should it be. Suicide is tabooed in a unique and unfortunate way. Joan Wickersham, author of The Suicide Index and daughter of a suicide, thinks that more conversation about suicide would be a good thing: I think there is a kind of shame and a kind of taboo attached to suicide…We would prefer to think it doesn’t happen. I think we have to acknowledge it does happen. We have to acknowledge that it’s a mystery, that we don’t understand it very well. I just wanted to give a sense of what it is really like to go through this.105 Wickersham says there is a reluctance to talk about suicide, adding, “I would love to see more honest conversation about it.”106 Contrary to Wickersham’s goal, “honest conversation” about suicide is suppressed in the media when a suicide occurs. This suppression is often based on well-intentioned but flawed “media guidelines” published by anti-suicide groups. In addition to the fact that these guidelines promote the ethical position that suicide is wrong, I see two major problems with these guidelines: one, they promote myths about suicide as if they were facts; two, they increase the guilt of survivors by portraying suicide as preventable. The “Media Guidelines for Suicide” on suicide.org advise reporters as follows: • Emphasize the number one cause for suicide: • The number one cause for suicide is untreated depression. • And then indicate that depression is treatable, and thus anyone suffering from depression needs to receive IMMEDIATE help. This, as we have seen, is contrary to the scientific studies, which show that depression only slightly increases the risk for suicide—a fact which in itself carries little weight, since suicidality is one of the possible criteria for diagnosing depression. According to Thomas Joiner,107 borderline personality disorder and anorexia nervosa are far more predictive of suicide than depression. (BPD is associated with a 10% lifetime risk of suicide and a 50% lifetime rate of at least one very severe suicide attempt.) Even given a slight correlation between depression and suicide, it’s overstating the case to say that depression causes suicide. It would be more accurate, but less satisfying, to say that the desire to die, coupled with the acquired ability to die, is the leading cause of suicide. The suicide.org guidelines also recommend using the “fact” that “Over 90% of the people who die by suicide have clinical depression or a similar mental illness when they die.” I have repeatedly attempted to debunk this statistic, but the comfortable idea that suicide is caused by mental illness is hard to dislodge and unlikely to be questioned too closely. Other “media guidelines” offered by suicide.org range from silly to intrusive to Orwellian: • Do not begin a television newscast with a suicide story. • Do not place suicide stories on the cover of newspapers or magazines. • Never portray suicides as heroic. • Never say that a suicide “ended pain” or “ended suffering.” Suicide CAUSES excruciating pain for suicide survivors. • Also, people need to be alive to feel relief from pain. Suicide CAUSES pain. • Do not use the terms “successful suicide” or “committed suicide.” Use the term “died by suicide” instead. • The term “committed suicide” is NOT accurate and is VERY hurtful to those who have attempted suicide and to suicide survivors. Say “died by suicide.” The media guidelines proposed by suicide.org strictly fit my definition of “politically correct bullshit”: they express majority opinion in a manner unconcerned with truth, and have the function of a moral taboo to protect an important cultural narrative from negation. The guidelines promulgated by the National Institutes of Mental Health are much more harmful, however, in that they function to increase the pain and guilt experienced by people close to a person who committed suicide. The message promoted by the NIMH guidelines is that suicide is always preventable, and there are always warning signs. The guidelines advise reporters that: Studies of suicide based on in-depth interviews with those close to the victim indicate that, in their first, shocked reaction, friends and family members may find a loved one’s death by suicide inexplicable or they may deny that there were warning signs. Accounts based on these initial reactions are often unreliable.108 That is, there are always warning signs; push family remembers until they “remember” the politically correct story. Reporters are advised to ask survivors questions such as: • Had the victim ever received treatment for depression or any other mental disorder? • Did the victim have a problem with substance abuse? The message is that there were warning signs that, had the family cared enough to look, would have revealed the suicide’s intentions so that the suicide could have been prevented. Unfortunately, this serves to increase the guilt of survivors, legitimize increasingly coercive suicide prevention tactics, and increase the survivors’ sense that the suicide was a tragedy because it was “preventable.” The problems I identify—promoting false information and unnecessarily increasing survivors’ guilt and pain—are in addition to the harm to the marketplace of ideas that is done in the name of curbing the controversial phenomenon of suicide contagion. A single ethical idea is given precedence over all others, and false facts are repeated in the name of protecting it, and of protecting the institutions that depend on it (“Mention that Suicide.org is available 24 hours a day for anyone who is suicidal,” advises suicide.org). Censorship of Suicide versus Censorship of Violence In the previous chapter, I examined the evidence for the claim that censorship of suicide is necessary because suicide is contagious. But why censor reports of suicide and not reports of other contagious behaviors—such as violence? The evidence for violence contagion is much stronger than that for suicide contagion. But whereas suicide censorship is widely accepted, censorship of other-directed violence in media stories is rare. Violence contagion is demonstrated by the same type of ecological study as suicide contagion,109 and there is a body of laboratory evidence—not found in the suicide research— suggesting that exposure to violent stimuli increases aggressive behavior. However, despite both sources of evidence, the theory that media reports of violence “cause” real-life violence is not at all universally accepted.110 Despite greater evidence for a causal link in the case of violence, the idea that the media should voluntarily self-censor with regard to reports of violence is much less widely accepted than the corresponding idea applied to reports of suicide. Contagion and Moral Responsibility The insistence that suicide is media-contagious, but violence is not, is not rational. It is better understood, I believe, as a consequence of the differential attributions of moral responsibility in cases of suicide versus other-directed violence. Suicide is seen as an irrational act; the actor, as the story goes, is not in control of himself, certainly not sane, and is therefore vulnerable to external effects. On the other hand, the idea that violent acts like homicides are attributable to media suggestion is generally seen as a pathetic excuse. Perpetrators of violence are perceived as much more morally responsible for their acts than suicides. Despite evidence to the contrary, idea contagion is thus psychologically ruled out as a cause of violence, but not of suicides. Is political corruption contagious? How about adultery? Prostitution? Riots? Drug abuse? Such questions are rarely even studied. Obesity certainly appears to be contagious. If so, should we censor reports of these topics to avoid a contagion effect? To do so would seem ludicrous and counterproductive, not to mention contrary to our political ideals. But the censorship of suicide goes unchallenged. Moral Responsibility and Willingness to Censor The more an actor is seen as the agent of his actions, the less outside influences are seen as affecting his actions. In cases where moral responsibility is strongly attributed to an actor, it follows that outside influences are unlikely to be taken seriously as a cause of his actions—and, therefore, it is not necessary to censor these “outside influences” (such as media reports). It is my belief that the widespread voluntary censorship of reports of suicide—from use of politically correct language to pervasive norms of message content—are the result of the modern trend to exculpate suicides from moral responsibility and to redefine suicide as an act of insanity. There is, however, little evidence that suicides are any less morally responsible for their actions than murderers. Certainly, many other behaviors are media-contagious—but they are not censored, nor are many of them even studied. I think that one possible explanation is that, at a deep level, people understand that suicide is just not that bad compared to actual acts of violence—despite hysterical language describing suicide as “self-murder.” We want to exculpate people from acts to which we are sympathetic. While we often refuse to define acts outside of societal norms as “not wrong,” we may nonetheless refuse to attribute full moral responsibility to these acts. But this sort of sympathy backfires in our society. People who are “not responsible for their actions” must be “protected,” often in painful and dehumanizing ways; and society is responsible for their “protection,” often to the detriment of freedom.",
      "word_count": 1708,
      "character_count": 10866,
      "chapter_number": 15,
      "section_number": null,
      "paragraph_number": 1,
      "start_position": 0,
      "end_position": 10866,
      "parent_chunk_id": "sarah_perryevery_cra_unknown_ch15"
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch17",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "chapter",
      "title": "Chapter Nine: Procreative Responsibility: A Road Map",
      "content": "Chapter Nine: Procreative Responsibility: A Road Map Is it good to make people? Rather than construct a traditional argument, the present chapter will map out the branches of this question, its possible meanings, modes of investigation, and evidences. It is my intention here to clarify the space of argument so that the reader can see how the pieces fit together, rather than to persuade along the single axis of antinatalism. The first branch we encounter is the source of “good” in “is it good to make people?” Descriptively, we are looking for the “sake” that is at the foundation of meaning and value itself, an ultimate value that needs no further justification. Values contending to fill this role may be external or abstract—God is a common ultimate value, though newer values such as “intelligence itself,” or “the present and future existence of humans in our universe” have become popular abstract values in the absence of otherwise reified religious faith. The other sort of “sake” is people themselves—things are good or not to the extent that they are good or not for particular people, both already-existing people and people not yet (and possibly never to be) born. Most antinatalist theory focuses on this branch. Although David Benatar presents many religious arguments in his antinatalist treatise Better Never to Have Been, his (and my) main focus has been on whether it is good for people themselves to be born. Even where religious or abstract values are very strong, significant harm to particular people makes the moral determination difficult; not all Abrahams put in a position to sacrifice their Isaacs are willing to do so. Even where sacred values dominate, the harm/care and fairness foundations can still be powerful motivations. Liberty Being created is a necessary condition for having any sort of experience. While one cannot choose to be created, being created is necessary for having any freedom to make choices at all. But is liberty always a gift? In “A Right of Self-Termination?”111 J. David Velleman shows that there are many situations in which getting a choice makes us worse off than if we did not have that choice. This is true not in the paternalist sense that we might make the wrong decisions if given a choice, as even an optimal decision maker can be harmed by being offered certain choices. For instance, if you are invited to a boring dinner party you might prefer never to have been asked rather than face the decision to suffer through the party or refuse the invitation and risk offending the host. A convenience store clerk would prefer not to have the option to open the safe, because having that option makes her a target for robbers. And, Velleman argues, some people may prefer not to have the option to die; some people would rather stay alive, but not bear the moral responsibility for staying alive (and perhaps draining their family’s resources for medical care). Life is often the same kind of freedom: an unwanted one that makes people worse off than if they didn’t have it. The fact that it is the basis for other freedoms does not demonstrate that it is a desirable thing to get. Harm and Measurement: Preferentist and Non-Preferentist Approaches Being born necessarily entails many bad experiences, not the least of which is death. But many (not all) people also have many good experiences. Causing a person to be born causes them to have all the experiences they end up having. How are we to know whether the positive aspects of life are strong and numerous enough to outweigh the harms? Approaches to this question can be divided into two categories: preferentist and non-preferentist. Preferentist approaches assume that people’s preferences are good evidence of what is actually good for them. Non-preferentist approaches take a more abstract perspective, and do not assume that people’s preferences—stated or otherwise inferred—are strong evidence of what is good for them. Preferentist Approaches and Evidence Preferentism is perhaps the most natural mode of ethical analysis. A preferentist might answer the question “is it good for people to be born?” with the suggestion to just ask people whether they are happy to have been born. Preferentists might in addition ask what decisions would be made by people in ideal circumstances with complete information.112 Thought experiments and careful attention to biases may be helpful in teasing out underlying preferences, but the only evidence available, by definition, concerns real people in real, non-ideal circumstances, with limited information. Free Disposal and the Imaginary Survey The casual antinatalist in the wild is certain to encounter two preferentist bodies of evidence regarding the value of life: “why don’t you just kill yourself?” and the Imaginary Survey. The former body of evidence is of the same class as the “free disposal” argument, treated in the first chapter of this book: since only a small percentage of people commit suicide (and the antinatalist interlocutor himself is by definition not among them), this is evidence for the preferentist case that people are generally happy to be born. However, fear of death is not love of life. There are many factors that cause rational people to prefer life to suicide even if their lives are not worth living. There is the pain, uncertainty, and risk of a suicide attempt under prohibition. There is the wish to avoid causing pain to family and friends. There is the instinctual horror of death itself. Even given these and many other obstacles, many people do commit suicide—about a million people a year, worldwide. Millions more attempt suicide but are unsuccessful. Some classes of people have a much higher suicide rate than others—men, white people and Asians, those with certain mental illnesses such as bipolar disorder, and gay and transgendered people. According to the preferentist “free disposal” case, certain classes of people may be ethically forbidden from reproducing based merely on the suicide statistics of similarly situated people. But I have never heard preferentists express a percentage likelihood of suicide that makes reproduction ethically wrong, except to anchor at 50% without explanation—as if a 50% chance of having a hellish life is a morally neutral thing to cause. Bipolar disorder, for example, is highly heritable and likely has a strong genetic component. If one monozygotic (“identical”) twin has bipolar disorder, the other twin has a 40–70% chance of having the disorder too.113 Only about 1% of the population has bipolar disorder, but if a parent has bipolar disorder, the risk goes up to 5–10%—up to ten times the risk. Between 10% and 15% of people with bipolar disorder commit suicide,114 and up to 56% of sufferers make a serious suicide attempt. While the outcome is not determinable by simple multiplication, a preferentist pronatalist who sticks with the likelihood of suicide as a measure of preference for life must at least grant that a bipolar individual takes a very serious risk of harm by bringing offspring into the world. Unfortunately, it is impossible to be aware of all the risk factors in one’s genome that might contribute to the misery of one’s children. The very uncertainty of one’s offspring being in the miserable class is addressed below in the section on uncertainty. The second most common preferentist body of evidence, as presented in the wild, is the Imaginary Survey. The nature of this evidence is that it feels obvious to interlocutors that everyone is very glad to have been born, and they are expected to say so if asked. They perform an “imaginary survey” of people worldwide, and the results are clear: people prefer to be alive. How realistic is this Imaginary Survey? In 1932, sociologist Ruth Shonle Cavan published a paper detailing the responses of 7,852 children from diverse geographic, economic, and racial backgrounds.115 Each child was asked if he had experienced having the wish to never have been born. Around 30% of children indeed reported having had this wish. What caused children to wish they had never been born? The biggest predictor was what was then called neuroticism —81% of highly neurotic children expressed the wish to never have been born, whereas only 7% of well-adjusted, non-neurotic children reported so wishing. Poverty and family trouble, such as being from a broken home and having a poor relationship with parents, was correlated somewhat with girls, but not boys, wishing they had never been born. Perhaps the most disturbing finding was that the wish to never have been born was spread fairly evenly among all children, urban and rural, white, black, and Mexican, rich and poor, from happy or broken homes. Girls were more likely to express the wish to never have been born than boys, even though men commit suicide more often than women. Based on this sample, it appears that the wish to never have been born is a poor predictor of suicide later in life. Since suicide and the wish to never have been born appear poorly correlated, they cannot both be strong evidence for the likely subjective value of life. Revealed Preference in Non-Suicidal Behavior There is another line of evidence that is important to take note of for preferentists: the revelation of preference (the subjective valuing of life) in people’s behaviors aside from suicide. I explore this line of evidence at length in the next chapter (“The Mathematics of Misery”), but will outline the evidence here. If life is subjectively very valuable to people, we would expect them at a minimum to behave as if this is so—for instance, to rarely engage in life-risking behavior unless there is a very strong reason to do so, and to minimize risk to life when it is easy to do so. We might also expect them to avoid actuarially unfair gambles and to display low time preference, making decisions that favor long-term security and well being. The behaviors we would most expect from individuals who do not value their lives would be risking their lives in dangerous situations, engaging in gambles whose expected value is negative (such as joining a street gang, buying lottery tickets, and going to law school), and palliating their misery in ways that harm their long-term prospects (as with drugs, alcohol, or casual sex). These behaviors are in fact widespread, affecting many times more people than suicide. A detailed portrait of the high time preference state of mind is provided by Richard T. Wright and Scott H. Decker in their criminology book Armed Robbers in Action: Stickups and Street Culture.116 They term this state of mind “desperate partying”: A majority of the offenders in our sample spent much of the money they obtained through armed robbery to pursue what was for them an open-ended quest for excitement and sensory stimulation. Forty of the fifty-nine offenders who told us what they did with the proceeds of their stickups said they used most of the cash to initiate or sustain various forms of illicit action, including gambling, drug use, and heavy drinking. While the offenders often referred to such activities as partying, there is a danger in accepting this definition of the situation uncritically; the activities were pursued with an intensity and grim determination that suggest something far more serious was at stake. For those in our sample, participation in illicit street action was no party, at least not in the conventional sense of the term. They appeared to find it anything but relaxing and showed little or no inclination to exercise the personal restraint that characterizes suburban cocktail parties. Rather, they gambled, used drugs, and drank alcohol heedless of any consequences. In the process, many of them began to contemplate their next stickup. …The offenders are easily seduced by street culture at least in part because they view their future prospects as bleak and see little point in long-range planning. The behavior of “desperate partying” is not only seen among poor people in the worst circumstances; it is widespread across many classes. The pursuit of drug-induced euphoria and intense experiences will be familiar to many people who have suffered long-term anxiety or depression. Palliating with drugs or intense experiences that have serious long-term risks and harms suggests that, subjectively, the present is so bad that it’s worth trading off quality of life in the future to make the present tolerable. Similarly, making a gamble with a low likelihood of success and a high likelihood of very bad consequences suggests that one’s present situation is not worth preserving by behaving cautiously. These behaviors, and not just suicide, are evidence that life is not a universally valued commodity. People are not, of course, perfectly rational beings. Behavioral economists argue that humans are at best partially rational, and generally exhibit major departures from rationality. Therefore their behavior may not reflect their genuine preferences. When a person exhibits high time preference, rather than placing a low value on his life, he may just be stupid. To the extent that this criticism is accepted as weighing against the evidentiary value of these “desperate partying” palliation behaviors and gambling behaviors, however, it must also weigh against accepting the suicide data as evidence of life’s value. To the extent that it means something that people rarely commit suicide, it must also mean something that they often act as if their lives are a burden to them. This latter argument will be elaborated in the next chapter. Non-Preferentist Approaches Non-preferentist approaches to the question of making people do not assume that people’s self reports or behavior reveals what is best for them. Rather, they attempt to answer the question from a broader perspective (while still treating subjective experience as real and crucially important). The most important non-preferentist approach to the question of making new people is David Benatar’s, presented in his 2006 book Better Never to Have Been. The core of this non-preferentist argument lies in what he terms “the asymmetry”—a difference in valuing good and bad experiences depending on whether the person experiencing them has been created, or not. Naive Weighing From a naive perspective, we might expect to weigh the harms of life against the benefits of life as we expect the yet-to-be-created person to experience them. If the benefits somehow outweigh the harms, then creating the life, from this perspective, is permissible. There are arguments— Benatar himself examines this line of thought—that the harms of life do outweigh the positive aspects, even when the “positive aspects” are conceived broadly and not just limited to a purely hedonic analysis. Loneliness and boredom, discomfort and pain, aging and death affect everyone who is born (unless, in the case of aging, they die in childhood). To make matters worse, there is evidence that bad experiences affect people more intensely than good experiences. In Baumeister et al.’s paper “Bad Is Stronger Than Good”117 the authors present evidence for the universal psychological principle that bad experiences produce a stronger psychological effect than good experiences. For instance, the authors revisit the 1978 study conducted by Brickman et al., “Lottery winners and accident victims: Is happiness relative?”118 In that study Brickman and co-authors interviewed people who had won the lottery and people who had been paralyzed in a serious accident (with either event having occurred about one year prior to the interview), as well as a control group. The lottery winners were no happier than the other two groups: The euphoria over the lottery win did not last, and the winners’ happiness levels quickly returned to what they had been before the lottery win. Ironically, perhaps, the only lasting effect of winning the lottery appeared to be the bad ones, such as a reduction in enjoyment of ordinary pleasures. The accident victims, on the other hand, had not returned to their previous level of happiness one year after the accident. On the contrary, they often thought about how much better life was before the accident. People do not appear to bounce back from bad experiences to nearly the degree to which they get over good experiences. “Loss aversion” is the economic term for this human psychological peculiarity (otherwise known as “adaptation level theory” or “prospect theory”)—people would much rather avoid loss than pursue gain. The possibility of losing a thousand dollars is not made up for by an equal possibility of gaining a thousand dollars. Because bad is stronger than good in human psychology, in order to make up for the bad experiences, good experiences must not merely outnumber, but vastly outnumber, bad experiences. Benatar’s Asymmetry Benatar’s asymmetry proposes that this naive weighing from the previous section is ethically inappropriate. This is because the good and bad experiences of possible future beings are not mirror images of each other (symmetrical), but are rather completely different. The popular mystic poet Khalil Gibran said, “Do not the spirits in the aether envy us our pains?” The answer the asymmetry gives to this whimsical line is a simple “no.” Pain, broadly conceived, is bad. Here we are not talking about the pain of eating spicy food or exercising to soreness, but rather the pain of loneliness, hopelessness, boredom, grief, illness, aging, and death. Suffering is terrible, no matter whom it is happening to. This is especially true of the large subset of suffering that leads not to growth or awakening, but only to misery. It is unfortunate that anyone suffers—people or animals. The prevention of suffering is simply good. On the other hand, people being happy (again, broadly construed) is good. It is good that people have good experiences and find ways to connect to one another and alleviate each other’s suffering. But what about those spirits in the aether—possible future people? Gibran’s spirits are having subjective experiences (envy). Actual possible people have no subjective experiences. If nothing good happens to them because they are never born, they are not missing anything. Giving possible future people good experiences is simply not as strong an ethical motivator as preventing future people from having bad experiences. A bad experience happening to anyone is bad; preventing bad experiences (even by preventing experiencers from existing) is good. But a good experience NOT happening to someone is only bad if the person already exists such that he can be deprived of the experience. Imagine for a moment that the asymmetry is false. Then providing possible people with good experiences is a strong ethical reason to create new people. If this is the case, we each have a strong moral duty to have as many children as possible, and to expand the human population to its maximum, so long as lives are barely worth living.119 Every sperm that does not fertilize an egg represents a tragedy. These moral intuitions implied by denying the asymmetry are alien (Derek Parfit’s “Repugnant Conclusion” is so named for a reason). If accepting the asymmetry seems alien, consider the implications of its opposite. Shiffrin’s Asymmetries To summarize the previous section, David Benatar argues that bringing someone into existence is always a harm, and grounds his argument in a particular asymmetry—the “goodness” of absent pain, versus the mere neutrality of absent pleasure where no one is thereby deprived. Seana Shiffrin, on the other hand, doesn’t argue that procreation is always a harm, but does refuse to characterize procreation as a “morally innocent endeavor.” She argues for a more equivocal view of bringing people into existence. While procreation is not necessarily always a harm, according to Shiffrin, it is often a harm, and procreators should bear moral responsibility for the harm they do.120 Shiffrin defends her view with a different asymmetry— that, while it is fine to harm someone in order to prevent a greater harm to him (even without his consent, such as in the case of rescue), it is not fine to harm a person without his consent merely to provide him a benefit. Her core example involves a wealthy recluse (“Wealthy”) whose only means of helping others is by dropping five-million-dollar cubes of gold from the air on a neighboring island. Many lucky islanders receive Wealthy’s presents with no complications, but one recipient (“Unlucky”) is hit with the cube and breaks his arm. While the Unlucky might, after the fact, be glad to have been hit with the gold cube, and consider the broken arm worth it, intuition suggests that dropping five million-dollar gold cubes on people is wrong: Unlucky admits that all-things-considered, he is better off for receiving the $5 million, despite the injury. In some way he is glad that this happened to him, although he is unsure whether he would have consented to being subjected to the risk of a broken arm (and worse fates) if he had been asked in advance; he regards his conjectured ex-ante hesitation as reasonable. Given the shock of the event and the severity of the pain and disability associated with the broken arm, he is not certain whether he would consent to undergo the same experience again. Shiffrin also points out a “related asymmetry,” proposed by Thomas Scanlon,121 between the harm that is morally correct to inflict on another, and the “harm” that a person may inflict on himself. In Shiffrin’s words (summarizing Scanlon), One may reasonably put much greater weight on a project from the first-person perspective than would reasonably be accorded to it from a third-party’s viewpoint. A person may reasonably value her religion’s mission over her health, but the state may reasonably direct its welfare efforts toward her nutrition needs rather than to funding her religious endeavors. This “related asymmetry” is concerned with both the problem of consent and, indirectly, with the kind of value that may be acted on for another person’s “own good.” A person may consent to “harm” for any reason whatever, agent-relative or otherwise; but in order to inflict harm on another without consent, we must either (a) have such a good model of the person’s values that we can infer hypothetical consent based on the person’s own values, or (b) act in furtherance of values that any possible person would share. The logic of these three asymmetries is further explored in a later chapter, “Hurting People and Doing Good.” Uncertainty Finally, even if we agree on the standard for measuring whether a life is good, the extreme uncertainty in predicting whether a given life will in fact be good counsels against reproduction. This is the approach taken by Jason Marsh in his 2014 paper “Quality of Life Assessments, Cognitive Reliability, and Procreative Responsibility.”122 While the author does not agree with Benatar that no life is good, he proposes that we should take very seriously the lack of certainty we have that a particular life will be good. This uncertainty includes not only predicting future events, but uncertainty as to whether we are, ourselves, reliable evaluators of our own quality of life. The sufferings that make lives seem not worth living are hard to predict; some of them may be hiding in our genomes; others are events yet to occur. Even if we performed our ideal Imaginary Survey and almost every respondent replied that he was glad to be alive, there remains uncertainty as to how much we can trust that these embodied selfreports are accurate reflections of reality. The principle of caution, respecting the gravity of human suffering, weighs against procreating to the extent that it is unpredictable whether the person created will have a good life.",
      "word_count": 3883,
      "character_count": 23838,
      "chapter_number": 17,
      "section_number": null,
      "paragraph_number": null,
      "start_position": 0,
      "end_position": 23838,
      "parent_chunk_id": null
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch17_p1",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "paragraph",
      "title": "Paragraph 1",
      "content": "Chapter Nine: Procreative Responsibility: A Road Map Is it good to make people? Rather than construct a traditional argument, the present chapter will map out the branches of this question, its possible meanings, modes of investigation, and evidences. It is my intention here to clarify the space of argument so that the reader can see how the pieces fit together, rather than to persuade along the single axis of antinatalism. The first branch we encounter is the source of “good” in “is it good to make people?” Descriptively, we are looking for the “sake” that is at the foundation of meaning and value itself, an ultimate value that needs no further justification. Values contending to fill this role may be external or abstract—God is a common ultimate value, though newer values such as “intelligence itself,” or “the present and future existence of humans in our universe” have become popular abstract values in the absence of otherwise reified religious faith. The other sort of “sake” is people themselves—things are good or not to the extent that they are good or not for particular people, both already-existing people and people not yet (and possibly never to be) born. Most antinatalist theory focuses on this branch. Although David Benatar presents many religious arguments in his antinatalist treatise Better Never to Have Been, his (and my) main focus has been on whether it is good for people themselves to be born. Even where religious or abstract values are very strong, significant harm to particular people makes the moral determination difficult; not all Abrahams put in a position to sacrifice their Isaacs are willing to do so. Even where sacred values dominate, the harm/care and fairness foundations can still be powerful motivations. Liberty Being created is a necessary condition for having any sort of experience. While one cannot choose to be created, being created is necessary for having any freedom to make choices at all. But is liberty always a gift? In “A Right of Self-Termination?”111 J. David Velleman shows that there are many situations in which getting a choice makes us worse off than if we did not have that choice. This is true not in the paternalist sense that we might make the wrong decisions if given a choice, as even an optimal decision maker can be harmed by being offered certain choices. For instance, if you are invited to a boring dinner party you might prefer never to have been asked rather than face the decision to suffer through the party or refuse the invitation and risk offending the host. A convenience store clerk would prefer not to have the option to open the safe, because having that option makes her a target for robbers. And, Velleman argues, some people may prefer not to have the option to die; some people would rather stay alive, but not bear the moral responsibility for staying alive (and perhaps draining their family’s resources for medical care). Life is often the same kind of freedom: an unwanted one that makes people worse off than if they didn’t have it. The fact that it is the basis for other freedoms does not demonstrate that it is a desirable thing to get. Harm and Measurement: Preferentist and Non-Preferentist Approaches Being born necessarily entails many bad experiences, not the least of which is death. But many (not all) people also have many good experiences. Causing a person to be born causes them to have all the experiences they end up having. How are we to know whether the positive aspects of life are strong and numerous enough to outweigh the harms? Approaches to this question can be divided into two categories: preferentist and non-preferentist. Preferentist approaches assume that people’s preferences are good evidence of what is actually good for them. Non-preferentist approaches take a more abstract perspective, and do not assume that people’s preferences—stated or otherwise inferred—are strong evidence of what is good for them. Preferentist Approaches and Evidence Preferentism is perhaps the most natural mode of ethical analysis. A preferentist might answer the question “is it good for people to be born?” with the suggestion to just ask people whether they are happy to have been born. Preferentists might in addition ask what decisions would be made by people in ideal circumstances with complete information.112 Thought experiments and careful attention to biases may be helpful in teasing out underlying preferences, but the only evidence available, by definition, concerns real people in real, non-ideal circumstances, with limited information. Free Disposal and the Imaginary Survey The casual antinatalist in the wild is certain to encounter two preferentist bodies of evidence regarding the value of life: “why don’t you just kill yourself?” and the Imaginary Survey. The former body of evidence is of the same class as the “free disposal” argument, treated in the first chapter of this book: since only a small percentage of people commit suicide (and the antinatalist interlocutor himself is by definition not among them), this is evidence for the preferentist case that people are generally happy to be born. However, fear of death is not love of life. There are many factors that cause rational people to prefer life to suicide even if their lives are not worth living. There is the pain, uncertainty, and risk of a suicide attempt under prohibition. There is the wish to avoid causing pain to family and friends. There is the instinctual horror of death itself. Even given these and many other obstacles, many people do commit suicide—about a million people a year, worldwide. Millions more attempt suicide but are unsuccessful. Some classes of people have a much higher suicide rate than others—men, white people and Asians, those with certain mental illnesses such as bipolar disorder, and gay and transgendered people. According to the preferentist “free disposal” case, certain classes of people may be ethically forbidden from reproducing based merely on the suicide statistics of similarly situated people. But I have never heard preferentists express a percentage likelihood of suicide that makes reproduction ethically wrong, except to anchor at 50% without explanation—as if a 50% chance of having a hellish life is a morally neutral thing to cause. Bipolar disorder, for example, is highly heritable and likely has a strong genetic component. If one monozygotic (“identical”) twin has bipolar disorder, the other twin has a 40–70% chance of having the disorder too.113 Only about 1% of the population has bipolar disorder, but if a parent has bipolar disorder, the risk goes up to 5–10%—up to ten times the risk. Between 10% and 15% of people with bipolar disorder commit suicide,114 and up to 56% of sufferers make a serious suicide attempt. While the outcome is not determinable by simple multiplication, a preferentist pronatalist who sticks with the likelihood of suicide as a measure of preference for life must at least grant that a bipolar individual takes a very serious risk of harm by bringing offspring into the world. Unfortunately, it is impossible to be aware of all the risk factors in one’s genome that might contribute to the misery of one’s children. The very uncertainty of one’s offspring being in the miserable class is addressed below in the section on uncertainty. The second most common preferentist body of evidence, as presented in the wild, is the Imaginary Survey. The nature of this evidence is that it feels obvious to interlocutors that everyone is very glad to have been born, and they are expected to say so if asked. They perform an “imaginary survey” of people worldwide, and the results are clear: people prefer to be alive. How realistic is this Imaginary Survey? In 1932, sociologist Ruth Shonle Cavan published a paper detailing the responses of 7,852 children from diverse geographic, economic, and racial backgrounds.115 Each child was asked if he had experienced having the wish to never have been born. Around 30% of children indeed reported having had this wish. What caused children to wish they had never been born? The biggest predictor was what was then called neuroticism —81% of highly neurotic children expressed the wish to never have been born, whereas only 7% of well-adjusted, non-neurotic children reported so wishing. Poverty and family trouble, such as being from a broken home and having a poor relationship with parents, was correlated somewhat with girls, but not boys, wishing they had never been born. Perhaps the most disturbing finding was that the wish to never have been born was spread fairly evenly among all children, urban and rural, white, black, and Mexican, rich and poor, from happy or broken homes. Girls were more likely to express the wish to never have been born than boys, even though men commit suicide more often than women. Based on this sample, it appears that the wish to never have been born is a poor predictor of suicide later in life. Since suicide and the wish to never have been born appear poorly correlated, they cannot both be strong evidence for the likely subjective value of life. Revealed Preference in Non-Suicidal Behavior There is another line of evidence that is important to take note of for preferentists: the revelation of preference (the subjective valuing of life) in people’s behaviors aside from suicide. I explore this line of evidence at length in the next chapter (“The Mathematics of Misery”), but will outline the evidence here. If life is subjectively very valuable to people, we would expect them at a minimum to behave as if this is so—for instance, to rarely engage in life-risking behavior unless there is a very strong reason to do so, and to minimize risk to life when it is easy to do so. We might also expect them to avoid actuarially unfair gambles and to display low time preference, making decisions that favor long-term security and well being. The behaviors we would most expect from individuals who do not value their lives would be risking their lives in dangerous situations, engaging in gambles whose expected value is negative (such as joining a street gang, buying lottery tickets, and going to law school), and palliating their misery in ways that harm their long-term prospects (as with drugs, alcohol, or casual sex). These behaviors are in fact widespread, affecting many times more people than suicide. A detailed portrait of the high time preference state of mind is provided by Richard T. Wright and Scott H. Decker in their criminology book Armed Robbers in Action: Stickups and Street Culture.116 They term this state of mind “desperate partying”: A majority of the offenders in our sample spent much of the money they obtained through armed robbery to pursue what was for them an open-ended quest for excitement and sensory stimulation. Forty of the fifty-nine offenders who told us what they did with the proceeds of their stickups said they used most of the cash to initiate or sustain various forms of illicit action, including gambling, drug use, and heavy drinking. While the offenders often referred to such activities as partying, there is a danger in accepting this definition of the situation uncritically; the activities were pursued with an intensity and grim determination that suggest something far more serious was at stake. For those in our sample, participation in illicit street action was no party, at least not in the conventional sense of the term. They appeared to find it anything but relaxing and showed little or no inclination to exercise the personal restraint that characterizes suburban cocktail parties. Rather, they gambled, used drugs, and drank alcohol heedless of any consequences. In the process, many of them began to contemplate their next stickup. …The offenders are easily seduced by street culture at least in part because they view their future prospects as bleak and see little point in long-range planning. The behavior of “desperate partying” is not only seen among poor people in the worst circumstances; it is widespread across many classes. The pursuit of drug-induced euphoria and intense experiences will be familiar to many people who have suffered long-term anxiety or depression. Palliating with drugs or intense experiences that have serious long-term risks and harms suggests that, subjectively, the present is so bad that it’s worth trading off quality of life in the future to make the present tolerable. Similarly, making a gamble with a low likelihood of success and a high likelihood of very bad consequences suggests that one’s present situation is not worth preserving by behaving cautiously. These behaviors, and not just suicide, are evidence that life is not a universally valued commodity. People are not, of course, perfectly rational beings. Behavioral economists argue that humans are at best partially rational, and generally exhibit major departures from rationality. Therefore their behavior may not reflect their genuine preferences. When a person exhibits high time preference, rather than placing a low value on his life, he may just be stupid. To the extent that this criticism is accepted as weighing against the evidentiary value of these “desperate partying” palliation behaviors and gambling behaviors, however, it must also weigh against accepting the suicide data as evidence of life’s value. To the extent that it means something that people rarely commit suicide, it must also mean something that they often act as if their lives are a burden to them. This latter argument will be elaborated in the next chapter. Non-Preferentist Approaches Non-preferentist approaches to the question of making people do not assume that people’s self reports or behavior reveals what is best for them. Rather, they attempt to answer the question from a broader perspective (while still treating subjective experience as real and crucially important). The most important non-preferentist approach to the question of making new people is David Benatar’s, presented in his 2006 book Better Never to Have Been. The core of this non-preferentist argument lies in what he terms “the asymmetry”—a difference in valuing good and bad experiences depending on whether the person experiencing them has been created, or not. Naive Weighing From a naive perspective, we might expect to weigh the harms of life against the benefits of life as we expect the yet-to-be-created person to experience them. If the benefits somehow outweigh the harms, then creating the life, from this perspective, is permissible. There are arguments— Benatar himself examines this line of thought—that the harms of life do outweigh the positive aspects, even when the “positive aspects” are conceived broadly and not just limited to a purely hedonic analysis. Loneliness and boredom, discomfort and pain, aging and death affect everyone who is born (unless, in the case of aging, they die in childhood). To make matters worse, there is evidence that bad experiences affect people more intensely than good experiences. In Baumeister et al.’s paper “Bad Is Stronger Than Good”117 the authors present evidence for the universal psychological principle that bad experiences produce a stronger psychological effect than good experiences. For instance, the authors revisit the 1978 study conducted by Brickman et al., “Lottery winners and accident victims: Is happiness relative?”118 In that study Brickman and co-authors interviewed people who had won the lottery and people who had been paralyzed in a serious accident (with either event having occurred about one year prior to the interview), as well as a control group. The lottery winners were no happier than the other two groups: The euphoria over the lottery win did not last, and the winners’ happiness levels quickly returned to what they had been before the lottery win. Ironically, perhaps, the only lasting effect of winning the lottery appeared to be the bad ones, such as a reduction in enjoyment of ordinary pleasures. The accident victims, on the other hand, had not returned to their previous level of happiness one year after the accident. On the contrary, they often thought about how much better life was before the accident. People do not appear to bounce back from bad experiences to nearly the degree to which they get over good experiences. “Loss aversion” is the economic term for this human psychological peculiarity (otherwise known as “adaptation level theory” or “prospect theory”)—people would much rather avoid loss than pursue gain. The possibility of losing a thousand dollars is not made up for by an equal possibility of gaining a thousand dollars. Because bad is stronger than good in human psychology, in order to make up for the bad experiences, good experiences must not merely outnumber, but vastly outnumber, bad experiences. Benatar’s Asymmetry Benatar’s asymmetry proposes that this naive weighing from the previous section is ethically inappropriate. This is because the good and bad experiences of possible future beings are not mirror images of each other (symmetrical), but are rather completely different. The popular mystic poet Khalil Gibran said, “Do not the spirits in the aether envy us our pains?” The answer the asymmetry gives to this whimsical line is a simple “no.” Pain, broadly conceived, is bad. Here we are not talking about the pain of eating spicy food or exercising to soreness, but rather the pain of loneliness, hopelessness, boredom, grief, illness, aging, and death. Suffering is terrible, no matter whom it is happening to. This is especially true of the large subset of suffering that leads not to growth or awakening, but only to misery. It is unfortunate that anyone suffers—people or animals. The prevention of suffering is simply good. On the other hand, people being happy (again, broadly construed) is good. It is good that people have good experiences and find ways to connect to one another and alleviate each other’s suffering. But what about those spirits in the aether—possible future people? Gibran’s spirits are having subjective experiences (envy). Actual possible people have no subjective experiences. If nothing good happens to them because they are never born, they are not missing anything. Giving possible future people good experiences is simply not as strong an ethical motivator as preventing future people from having bad experiences. A bad experience happening to anyone is bad; preventing bad experiences (even by preventing experiencers from existing) is good. But a good experience NOT happening to someone is only bad if the person already exists such that he can be deprived of the experience. Imagine for a moment that the asymmetry is false. Then providing possible people with good experiences is a strong ethical reason to create new people. If this is the case, we each have a strong moral duty to have as many children as possible, and to expand the human population to its maximum, so long as lives are barely worth living.119 Every sperm that does not fertilize an egg represents a tragedy. These moral intuitions implied by denying the asymmetry are alien (Derek Parfit’s “Repugnant Conclusion” is so named for a reason). If accepting the asymmetry seems alien, consider the implications of its opposite. Shiffrin’s Asymmetries To summarize the previous section, David Benatar argues that bringing someone into existence is always a harm, and grounds his argument in a particular asymmetry—the “goodness” of absent pain, versus the mere neutrality of absent pleasure where no one is thereby deprived. Seana Shiffrin, on the other hand, doesn’t argue that procreation is always a harm, but does refuse to characterize procreation as a “morally innocent endeavor.” She argues for a more equivocal view of bringing people into existence. While procreation is not necessarily always a harm, according to Shiffrin, it is often a harm, and procreators should bear moral responsibility for the harm they do.120 Shiffrin defends her view with a different asymmetry— that, while it is fine to harm someone in order to prevent a greater harm to him (even without his consent, such as in the case of rescue), it is not fine to harm a person without his consent merely to provide him a benefit. Her core example involves a wealthy recluse (“Wealthy”) whose only means of helping others is by dropping five-million-dollar cubes of gold from the air on a neighboring island. Many lucky islanders receive Wealthy’s presents with no complications, but one recipient (“Unlucky”) is hit with the cube and breaks his arm. While the Unlucky might, after the fact, be glad to have been hit with the gold cube, and consider the broken arm worth it, intuition suggests that dropping five million-dollar gold cubes on people is wrong: Unlucky admits that all-things-considered, he is better off for receiving the $5 million, despite the injury. In some way he is glad that this happened to him, although he is unsure whether he would have consented to being subjected to the risk of a broken arm (and worse fates) if he had been asked in advance; he regards his conjectured ex-ante hesitation as reasonable. Given the shock of the event and the severity of the pain and disability associated with the broken arm, he is not certain whether he would consent to undergo the same experience again. Shiffrin also points out a “related asymmetry,” proposed by Thomas Scanlon,121 between the harm that is morally correct to inflict on another, and the “harm” that a person may inflict on himself. In Shiffrin’s words (summarizing Scanlon), One may reasonably put much greater weight on a project from the first-person perspective than would reasonably be accorded to it from a third-party’s viewpoint. A person may reasonably value her religion’s mission over her health, but the state may reasonably direct its welfare efforts toward her nutrition needs rather than to funding her religious endeavors. This “related asymmetry” is concerned with both the problem of consent and, indirectly, with the kind of value that may be acted on for another person’s “own good.” A person may consent to “harm” for any reason whatever, agent-relative or otherwise; but in order to inflict harm on another without consent, we must either (a) have such a good model of the person’s values that we can infer hypothetical consent based on the person’s own values, or (b) act in furtherance of values that any possible person would share. The logic of these three asymmetries is further explored in a later chapter, “Hurting People and Doing Good.” Uncertainty Finally, even if we agree on the standard for measuring whether a life is good, the extreme uncertainty in predicting whether a given life will in fact be good counsels against reproduction. This is the approach taken by Jason Marsh in his 2014 paper “Quality of Life Assessments, Cognitive Reliability, and Procreative Responsibility.”122 While the author does not agree with Benatar that no life is good, he proposes that we should take very seriously the lack of certainty we have that a particular life will be good. This uncertainty includes not only predicting future events, but uncertainty as to whether we are, ourselves, reliable evaluators of our own quality of life. The sufferings that make lives seem not worth living are hard to predict; some of them may be hiding in our genomes; others are events yet to occur. Even if we performed our ideal Imaginary Survey and almost every respondent replied that he was glad to be alive, there remains uncertainty as to how much we can trust that these embodied selfreports are accurate reflections of reality. The principle of caution, respecting the gravity of human suffering, weighs against procreating to the extent that it is unpredictable whether the person created will have a good life.",
      "word_count": 3883,
      "character_count": 23838,
      "chapter_number": 17,
      "section_number": null,
      "paragraph_number": 1,
      "start_position": 0,
      "end_position": 23838,
      "parent_chunk_id": "sarah_perryevery_cra_unknown_ch17"
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch18",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "chapter",
      "title": "Chapter Ten: The Mathematics of Misery",
      "content": "Chapter Ten: The Mathematics of Misery Is life a precious gift, or is it a costly burden? Are we impossibly lucky to be alive—or impossibly unlucky? In the previous chapter, I noted that preferentist theories of procreative responsibility would seek to determine what people’s behavior reveals about how much they value their lives. This chapter examines an approach to measuring nonsuicidal behaviors that indicate a negative assessment of the value of one’s own life. Truncated Utility Functions and the Value of Life “Utility” is an economic concept similar to happiness, but broader. It is the ultimate emotional evaluation of whether things are good or bad. The concept of utility does not rest on a purely hedonistic model of life; economics recognizes that utility may be gotten from a variety of transactions and experiences, springing from motives self-interested, altruistic, and everything in between. Generally speaking, utility is a function of “income”— again, very broadly defined. Income in this sense need not be monetary income in dollars, as from a job or investments, but may include items that are not even available directly on any market, such as affection from other humans and self-respect. I will address below the question of what real human utility functions are actually a function of. (I reserve the right to switch willy-nilly and with no warning between speaking of utility functions that are functions of monetary income and those that are functions of other things, depending upon context to clarify which I mean.) As Gary Becker and Richard Posner note in their important (but unpublished) 2004 paper, “Suicide: An Economic Approach,”123 economists studying how utility responds to changes in income have primarily focused on middle-class individuals—people who own houses, earn money from investments, and buy fire, health, and automobile insurance. This has led to the conclusions of economics occasionally not being true observations of general human nature, as they often purport to be, but rather observations of middleclass human nature. One of these suspect observations is that utility functions are concave. This is a typical representation of a concave utility function: What this means is that a person gains a lot of utility from the first dollar he gets—even the first thousand or ten thousand dollars—but he doesn’t get nearly as much utility from the 40,000th dollar, and gets even less from the millionth dollar. (Modern American utility functions of income apparently top out at around $75,000 per year.) What this, in turn, means is that, dollar for dollar, gains are less valuable to the average suburbanite than losses are painful. He would rather pay $1000 a year in car insurance, say, than take a one-in-ten chance at a $10,000 loss during that year. This phenomenon—that makes the insurance industry viable and makes utility functions concave—is called risk aversion. Many people behave in ways that are not consistent with risk aversion. They make “bad” bets—bets where the expected payoff (probability of success times magnitude of win) is less than the cost of the bet. They take risks seemingly without regard for possible bad consequences. They appear focused on the present and immediate future, at the expense of the far future (they are “extreme future discounters”). Miserable people and poor people are particularly likely to fit these criteria. Negative Utility and the Death Wish Economy In a paper entitled “Behavioral Economics and Perverse Effects of the Welfare State,”124 Bryan Caplan and Scott Beaulier present a possible solution: irrationality and akrasia. The bad choices made by poor people are a result of their inability to forecast the future effects of their actions, combined with laziness. Welfare and other social programs, rather than making the poor better off, paradoxically make them worse off, say Caplan and Beaulier, because their irrational, akratic minds cannot handle the extra choices.125 Becker and Posner offer a different solution: miserable and poor people don’t “properly” consider the future because their lives are so painful that they are effectively suicidal. Poor people look around and rationally weigh the costs and benefits of different courses of action, but choose to gamble on long shots precisely because their current situations are not worth living in. They would just as soon die as remain in their current situations, so they gamble what little they have on the hope of a meaningful life. Don’t just think gangs and lotteries and crime and crack. Think about people pursuing acting or singing careers, or going to law school or business school, or marrying in haste, or even, perhaps, having children. Think of people who bet everything—including their futures—on winning a particular gamble, even if it’s not a fair gamble and the likelihood of payoff doesn’t make up for the losses necessarily incurred when the chips are down. The utility function pictured above has a lot of space beneath it and above the x axis, even at the origin. This reflects a judgment that even at zero income, a person takes great value from being alive. This may or may not fit the facts. The actual points at which actual human utility functions intersect the x axis may be far to the right of the y axis, as with this utility function for a person who only begins to get positive utility at income Id. For all incomes below Id, the person experiences negative utility—that is, he suffers. This utility function is a model illustrating the phenomenon that many people (myself included) do not seem to derive much utility at all from incomes (broadly conceived) much greater than zero. Many people are so miserable that they do not want to enter the future at all. Their whole future projected life is worthless to them. In technical terms, their utility over all future time intervals, appropriately discounted, is less than zero. Also, their current utility (present circumstance) is zero or negative (otherwise they’d stick around a bit longer to pick up extra utility). Suicide is one option for such people. But there are two other options, according to Becker & Posner (terminology is mine): Take what you have and “bet” it on a chance at something that would make life worth living. If it fails, you can always kill yourself. (Gamble) Since there is an element of uncertainty to the future, take what you have and use it to make the present livable so you can postpone suicide. Something to make life worth living might be just around the corner. If not, you can always kill yourself. (Palliate & Wait) The utility function above for inefficient utility producers (like myself), where the utility function dips below the x axis, means that the person modeled must fear losing income below this point, because having income below Id means he will suffer. But a would-be suicide need not suffer. He has an ace up his sleeve: all suffering is the same as death to him, for he can use death to escape any suffering. His utility function is effectively truncated. It looks like this: Instead of dipping below the x axis, his utility function continues along the x axis all the way to the y axis (and beyond, if you allow for negative income). Now there is a portion of the utility function that is convex—the signature of risk preference, the opposite of risk aversion described above. Any income below the critical level Id is worth nothing to the effectively suicidal person. This means that it will not make sense for him to expend any effort in securing income below this level. Like a depressed person who has lost the sense of the value of things, he is not motivated to get up in the morning, to work hard, to be responsible, if all it means is income below Id. It’s the same as death to him. How can we tell who is effectively suicidal? Nonsuicidal people still often rationally accept gambles, even gambles with a risk of death. The main way to tell the difference between effectively suicidal people (with a truncated utility function, as above) and nonsuicidal people is that suicidal people are insensitive to the potential for great losses, and are only motivated by the possibility of a big win; effectively suicidal people accept actuarially unfair gambles which do not properly compensate them for risk of loss (including risk of death). Nonsuicidal people demand to be compensated for risks of loss, including risk of death. To the extent that people display risk preference and extreme future discounting of losses but not large gains—to the extent that they are willing to accept unfair gambles with a high probability of loss (Gamble) or improve their short term well-being at potentially great cost to their future selves (Palliate & Wait)—the hypothesis of effective suicidality must be considered. Only by considering and rejecting this hypothesis, based on data and/or reasons, could we meaningfully attribute these features to departures from the rational actor model, as Beaulier and Caplan do prematurely. Beaulier and Caplan essentially argue against “welfare floors” because by cushioning the bad consequences of a gamble, they make antisocial gambles more attractive. But they ignore that there is a built-in welfare floor in any human society, welfare state or not: suicide. It is inconsistent to maintain that, on the one hand, a welfare floor is undesirable because negative utilities are necessary as motivators for action, and on the other hand, that utility is rarely negative and hence procreation is morally innocent. This model does not, however, predict mass suicides at any point, and the fact that suicide remains rare does not mean that many people do not have effectively suicidal, truncated utility functions. All this theory claims is that people act as if they don’t value their lives. Unsuccessful gambles may or may not be followed up with actual suicide; the costs of suicide are often greater than a pre-suicidal person realized when contemplating life paths, and are artificially elevated by the de facto suicide prohibition. Also, cheap palliation is widely available, allowing many would-be suicides (such as myself) to postpone this costly decision. Policy Implications The most important policy implication of the “mathematics of misery” I have outlined here—of the fact that many people appear to attach zero value to their lives—is that procreation becomes much more of a suspect enterprise. If people’s behavior reveals that they do not highly value their lives, then it is not “obvious,” as Bryan Caplan would have us believe, that human beings are benefitted by being brought into existence. A life that produces zero utility in the immediate present, and zero or negative utility for the foreseeable future, is hardly the kind of precious gift that would justify procreation, yet from this model it is likely that a substantial portion of the population of the world lives just this kind of life. Someone whose utility function is negative for all time intervals would have been better off not having been born. Many people are in this situation through no fault of their own. Once this much is understood, a second policy implication is a move toward greater compassion in providing “palliative care” to people whose present utility and expected future utility are negative and whose only incentive to remain alive is uncertainty. As a society, we are willing to allow “palliative care” for terminally ill persons, but our middle-class model of risk aversion and the value of life prevents us from recognizing the need for palliative care in “healthy” people as well. There are further implications for harm reduction, regardless of one’s position about the value of life. Viewing utility functions (and hence human motivation) in this light, we can see that a suffering person chooses from available gambles and palliation methods. Outlawing a particular type of gamble or palliation method will likely divert demand to other types of gambles or palliation, and hence will not reduce overall levels of harm unless substitution happens to be toward less harmful activities. Recognition of this “demand for risk” should guide policy decisions regarding dangerous activities. What Real Human Utility Functions Are Functions Of The utility function appears to be a function of income in the strict sense that, within a country, wealthier people tend to be less miserable. But it is also a function of one’s past incomes; receiving a higher income increases utility in the short run, but in the long run it sets a new baseline for utility (the “hedonic treadmill”). Utility is also a function of the incomes of near others, or of one’s within-group status. This is why more direct income-utility correlation is found within-country than between countries. More than anything, however, a human utility function is a function of social belonging. That’s the ultimate point not only of income, but of intelligence, beauty, and many other material and non-material goods: they may be traded for social belonging. The ability to provide others with what they want is the opposite of burdensomeness, a pillar factor of suicide risk in Thomas Joiner’s model (the other pillars are social belonging as such, and competence in carrying out the act of suicide). We want income because we want to be able to get the attention of others. We want a safe social place, primarily—and, of course, we want a better social place than the one we currently occupy. The primary good, for humans, is group belonging. There is only so far up or down you can go in a social group, only so much room for status manipulation before you have to find a whole new social group. Within a group or class, we like to go up, but we absolutely hate to go down. Each person sees a huge drop-off in utility when considering the loss of his present group belonging, no matter whether his present group is high or low in status relative to the greater society. This has very little to do with absolute material welfare. This is why the guy choosing television and phones over food is making the right choice.126 Group belonging really is more important than short-term well-being. He is even displaying risk aversion, as is the poor black parent who gives her child a name that strongly signals group belonging at the expense of belonging in other groups or classes. It’s extremely difficult to join a whole new social group. Everyone faces a utility drop-off, a chasm, at the prospect of losing social belonging—a process sometimes described as social death. People behave as if losing one’s social group and status is worse than death. This is strong evidence that social death really is worse than death. Poor Baby or Rich Baby: Which is Worse? Data about crime, drug use, and other forms of risk preference and palliation seem to indicate that poor people are more likely than rich people to display the kind of truncated, effectively suicidal utility function I have been discussing. This could support the claim that it is more wrong for a poor person to have a child than for a rich person. But when we realize that social belonging trumps everything, we see that what really determines the value of life is the opportunity to be part of a social group. Middle class people have different relevant social groups from poor people, and the very wealthy have different social groups altogether. A child born into one of these groups must establish a place for himself; if few places are available, downward mobility (social death) is indicated. A person born into a very wealthy social group that has few opportunities for belonging may thus be in a worse position than a person born into poverty but with many opportunities for belonging. As Becker and Posner note, the nature of the “Gamble” you can afford depends on your present income; higher present incomes buy better gambles, with a higher probability of success. Therefore, wealthier people may succeed in their suicide gambles more often than poor people, so their gambles are more socially invisible than those of the poor— but they are still making them. However, the social belonging hypothesis that I have been advancing here (that social belonging is the primary determinant of utility) implies that the income at which life becomes worth living, Id, varies with one’s existing social situation, hence with initial income. Wealthy effectively-suicidal people start out with more initial income—they have more to gamble with—but they have a higher mark to reach for their gambles to be successful. It is not clear which effect predominates. The Economics of Palliation and Bullshit This model outlined above applies not only to serious gambles with significant downsides as well as significant, potentially permanent upsides (suicide gambles, like joining a street gang or going to law school), but also applies on a smaller scale to measures that temporarily reduce the pain experienced by the actor, though with potential future costs (palliation, like smoking cigarettes or playing World of Warcraft). Palliative remedies may have significant present and future costs, but at least they are generally effective at alleviating pain temporarily. However, looking around at the transactions taking place in the world economy, one cannot help but notice the market share of bullshit. Huge numbers of consumers prove willing to spend money on products and services that measurably don’t do what they promise to do. These products and services may or may not be particularly harmful, but they all have monetary cost, and they all have a very low likelihood of solving the problem they purport to solve. The market in expensive placebos is massive. Here are exemplary lists of both Palliation phenomena and Expensive Placebo phenomena, so that the reader will have a better idea of what I’m talking about: Palliation Expensive Placebo Budweiser Cheleda weight loss potion heroin face de-wrinkling potion World of Warcraft breast augmentation potion cigarettes penis growth and erection potion The McRib multi-level marketing wealth potion 7th Heaven psychic services lactation porn Jesus video poker nice Russian women looking for a good husband who need your credit card number In both cases, consumers seem blind to the downside. In the Palliation case there is a significant downside, but it’s made up for by the reliable temporary relief from pain. In the Expensive Placebo case, the downside is limited to the cost of the product or service, but the upside is measurably nil. The line between Palliation and Expensive Placebo may be fuzzy; for instance, a lonely person may get real social pleasure from interacting with a psychic consultant (and effective scammers, like all salesmen, tend to be pleasant people). An alcohol advertisement often includes implicit promises of social belonging, which if interpreted literally would make it more of an Expensive Placebo Belonging Serum than a genuine palliation tool. But the distinguishing characteristic is that in the case of what I call Expensive Placebos, the benefit that is bargained for is wholly imaginary, whereas with Palliation the essence of the promised benefit is, in fact, provided. Since the value of Expensive Placebos arises from pure fiction, ordinary measures of quality are not available; if acknowledged and utilized, real measures of quality would destroy the entire market. From this, we can distinguish Expensive Placebos from Palliation in terms of the effect of price. The price of an Expensive Placebo is a measure of social proof it carries—a more expensive placebo gets you better fantasies. A two-dollar penis enlargement pill probably doesn’t work, but one that costs $2,000 is a much more effective fantasy projection device. Price has to take on more epistemic weight in the evaluation of Expensive Placebos, because no other indicia of reliability are relevant. This is so because every indication of reliability, except price, would show the value to be zero. In order to maintain the fantasy, we must look at price instead of real quality indicators. To the degree that an intervention is Palliation, consumers would seek out the most palliation for the cost—these are ordinary goods where price is negatively correlated with demand. But to the degree that an intervention is an Expensive Placebo, price should behave much more weirdly, perhaps even correlating positively with demand, as with Veblen goods. It’s not just that the consumer of an Expensive Placebo makes himself blind to the downside of the purchase; the downside becomes the upside. (Here we may recall the similar phenomenon in which parents report getting more meaning and joy from child-rearing activities—and plan to spend more time with their children over a coming weekend—when they are reminded of the downside, but not the upside, of having kids.) There are some things that people will pay for even an imaginary chance at having. Youth, love, sex, wealth, and status are so deeply and painfully desired that people are willing to suspend their disbelief for the privilege of imagining that they might be obtainable. The need for social belonging trumps all other needs, and even trumps our own rationality. Being old, fat, poor, or impotent means being in social pain. Just as the desperate, terminally ill cancer patient often turns to expensive placebos for an imaginary chance at more life, desperate, terminally alive sad people turn to expensive placebos for a chance to imagine a decent life.",
      "word_count": 3521,
      "character_count": 21552,
      "chapter_number": 18,
      "section_number": null,
      "paragraph_number": null,
      "start_position": 0,
      "end_position": 21552,
      "parent_chunk_id": null
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch18_p1",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "paragraph",
      "title": "Paragraph 1",
      "content": "Chapter Ten: The Mathematics of Misery Is life a precious gift, or is it a costly burden? Are we impossibly lucky to be alive—or impossibly unlucky? In the previous chapter, I noted that preferentist theories of procreative responsibility would seek to determine what people’s behavior reveals about how much they value their lives. This chapter examines an approach to measuring nonsuicidal behaviors that indicate a negative assessment of the value of one’s own life. Truncated Utility Functions and the Value of Life “Utility” is an economic concept similar to happiness, but broader. It is the ultimate emotional evaluation of whether things are good or bad. The concept of utility does not rest on a purely hedonistic model of life; economics recognizes that utility may be gotten from a variety of transactions and experiences, springing from motives self-interested, altruistic, and everything in between. Generally speaking, utility is a function of “income”— again, very broadly defined. Income in this sense need not be monetary income in dollars, as from a job or investments, but may include items that are not even available directly on any market, such as affection from other humans and self-respect. I will address below the question of what real human utility functions are actually a function of. (I reserve the right to switch willy-nilly and with no warning between speaking of utility functions that are functions of monetary income and those that are functions of other things, depending upon context to clarify which I mean.) As Gary Becker and Richard Posner note in their important (but unpublished) 2004 paper, “Suicide: An Economic Approach,”123 economists studying how utility responds to changes in income have primarily focused on middle-class individuals—people who own houses, earn money from investments, and buy fire, health, and automobile insurance. This has led to the conclusions of economics occasionally not being true observations of general human nature, as they often purport to be, but rather observations of middleclass human nature. One of these suspect observations is that utility functions are concave. This is a typical representation of a concave utility function: What this means is that a person gains a lot of utility from the first dollar he gets—even the first thousand or ten thousand dollars—but he doesn’t get nearly as much utility from the 40,000th dollar, and gets even less from the millionth dollar. (Modern American utility functions of income apparently top out at around $75,000 per year.) What this, in turn, means is that, dollar for dollar, gains are less valuable to the average suburbanite than losses are painful. He would rather pay $1000 a year in car insurance, say, than take a one-in-ten chance at a $10,000 loss during that year. This phenomenon—that makes the insurance industry viable and makes utility functions concave—is called risk aversion. Many people behave in ways that are not consistent with risk aversion. They make “bad” bets—bets where the expected payoff (probability of success times magnitude of win) is less than the cost of the bet. They take risks seemingly without regard for possible bad consequences. They appear focused on the present and immediate future, at the expense of the far future (they are “extreme future discounters”). Miserable people and poor people are particularly likely to fit these criteria. Negative Utility and the Death Wish Economy In a paper entitled “Behavioral Economics and Perverse Effects of the Welfare State,”124 Bryan Caplan and Scott Beaulier present a possible solution: irrationality and akrasia. The bad choices made by poor people are a result of their inability to forecast the future effects of their actions, combined with laziness. Welfare and other social programs, rather than making the poor better off, paradoxically make them worse off, say Caplan and Beaulier, because their irrational, akratic minds cannot handle the extra choices.125 Becker and Posner offer a different solution: miserable and poor people don’t “properly” consider the future because their lives are so painful that they are effectively suicidal. Poor people look around and rationally weigh the costs and benefits of different courses of action, but choose to gamble on long shots precisely because their current situations are not worth living in. They would just as soon die as remain in their current situations, so they gamble what little they have on the hope of a meaningful life. Don’t just think gangs and lotteries and crime and crack. Think about people pursuing acting or singing careers, or going to law school or business school, or marrying in haste, or even, perhaps, having children. Think of people who bet everything—including their futures—on winning a particular gamble, even if it’s not a fair gamble and the likelihood of payoff doesn’t make up for the losses necessarily incurred when the chips are down. The utility function pictured above has a lot of space beneath it and above the x axis, even at the origin. This reflects a judgment that even at zero income, a person takes great value from being alive. This may or may not fit the facts. The actual points at which actual human utility functions intersect the x axis may be far to the right of the y axis, as with this utility function for a person who only begins to get positive utility at income Id. For all incomes below Id, the person experiences negative utility—that is, he suffers. This utility function is a model illustrating the phenomenon that many people (myself included) do not seem to derive much utility at all from incomes (broadly conceived) much greater than zero. Many people are so miserable that they do not want to enter the future at all. Their whole future projected life is worthless to them. In technical terms, their utility over all future time intervals, appropriately discounted, is less than zero. Also, their current utility (present circumstance) is zero or negative (otherwise they’d stick around a bit longer to pick up extra utility). Suicide is one option for such people. But there are two other options, according to Becker & Posner (terminology is mine): Take what you have and “bet” it on a chance at something that would make life worth living. If it fails, you can always kill yourself. (Gamble) Since there is an element of uncertainty to the future, take what you have and use it to make the present livable so you can postpone suicide. Something to make life worth living might be just around the corner. If not, you can always kill yourself. (Palliate & Wait) The utility function above for inefficient utility producers (like myself), where the utility function dips below the x axis, means that the person modeled must fear losing income below this point, because having income below Id means he will suffer. But a would-be suicide need not suffer. He has an ace up his sleeve: all suffering is the same as death to him, for he can use death to escape any suffering. His utility function is effectively truncated. It looks like this: Instead of dipping below the x axis, his utility function continues along the x axis all the way to the y axis (and beyond, if you allow for negative income). Now there is a portion of the utility function that is convex—the signature of risk preference, the opposite of risk aversion described above. Any income below the critical level Id is worth nothing to the effectively suicidal person. This means that it will not make sense for him to expend any effort in securing income below this level. Like a depressed person who has lost the sense of the value of things, he is not motivated to get up in the morning, to work hard, to be responsible, if all it means is income below Id. It’s the same as death to him. How can we tell who is effectively suicidal? Nonsuicidal people still often rationally accept gambles, even gambles with a risk of death. The main way to tell the difference between effectively suicidal people (with a truncated utility function, as above) and nonsuicidal people is that suicidal people are insensitive to the potential for great losses, and are only motivated by the possibility of a big win; effectively suicidal people accept actuarially unfair gambles which do not properly compensate them for risk of loss (including risk of death). Nonsuicidal people demand to be compensated for risks of loss, including risk of death. To the extent that people display risk preference and extreme future discounting of losses but not large gains—to the extent that they are willing to accept unfair gambles with a high probability of loss (Gamble) or improve their short term well-being at potentially great cost to their future selves (Palliate & Wait)—the hypothesis of effective suicidality must be considered. Only by considering and rejecting this hypothesis, based on data and/or reasons, could we meaningfully attribute these features to departures from the rational actor model, as Beaulier and Caplan do prematurely. Beaulier and Caplan essentially argue against “welfare floors” because by cushioning the bad consequences of a gamble, they make antisocial gambles more attractive. But they ignore that there is a built-in welfare floor in any human society, welfare state or not: suicide. It is inconsistent to maintain that, on the one hand, a welfare floor is undesirable because negative utilities are necessary as motivators for action, and on the other hand, that utility is rarely negative and hence procreation is morally innocent. This model does not, however, predict mass suicides at any point, and the fact that suicide remains rare does not mean that many people do not have effectively suicidal, truncated utility functions. All this theory claims is that people act as if they don’t value their lives. Unsuccessful gambles may or may not be followed up with actual suicide; the costs of suicide are often greater than a pre-suicidal person realized when contemplating life paths, and are artificially elevated by the de facto suicide prohibition. Also, cheap palliation is widely available, allowing many would-be suicides (such as myself) to postpone this costly decision. Policy Implications The most important policy implication of the “mathematics of misery” I have outlined here—of the fact that many people appear to attach zero value to their lives—is that procreation becomes much more of a suspect enterprise. If people’s behavior reveals that they do not highly value their lives, then it is not “obvious,” as Bryan Caplan would have us believe, that human beings are benefitted by being brought into existence. A life that produces zero utility in the immediate present, and zero or negative utility for the foreseeable future, is hardly the kind of precious gift that would justify procreation, yet from this model it is likely that a substantial portion of the population of the world lives just this kind of life. Someone whose utility function is negative for all time intervals would have been better off not having been born. Many people are in this situation through no fault of their own. Once this much is understood, a second policy implication is a move toward greater compassion in providing “palliative care” to people whose present utility and expected future utility are negative and whose only incentive to remain alive is uncertainty. As a society, we are willing to allow “palliative care” for terminally ill persons, but our middle-class model of risk aversion and the value of life prevents us from recognizing the need for palliative care in “healthy” people as well. There are further implications for harm reduction, regardless of one’s position about the value of life. Viewing utility functions (and hence human motivation) in this light, we can see that a suffering person chooses from available gambles and palliation methods. Outlawing a particular type of gamble or palliation method will likely divert demand to other types of gambles or palliation, and hence will not reduce overall levels of harm unless substitution happens to be toward less harmful activities. Recognition of this “demand for risk” should guide policy decisions regarding dangerous activities. What Real Human Utility Functions Are Functions Of The utility function appears to be a function of income in the strict sense that, within a country, wealthier people tend to be less miserable. But it is also a function of one’s past incomes; receiving a higher income increases utility in the short run, but in the long run it sets a new baseline for utility (the “hedonic treadmill”). Utility is also a function of the incomes of near others, or of one’s within-group status. This is why more direct income-utility correlation is found within-country than between countries. More than anything, however, a human utility function is a function of social belonging. That’s the ultimate point not only of income, but of intelligence, beauty, and many other material and non-material goods: they may be traded for social belonging. The ability to provide others with what they want is the opposite of burdensomeness, a pillar factor of suicide risk in Thomas Joiner’s model (the other pillars are social belonging as such, and competence in carrying out the act of suicide). We want income because we want to be able to get the attention of others. We want a safe social place, primarily—and, of course, we want a better social place than the one we currently occupy. The primary good, for humans, is group belonging. There is only so far up or down you can go in a social group, only so much room for status manipulation before you have to find a whole new social group. Within a group or class, we like to go up, but we absolutely hate to go down. Each person sees a huge drop-off in utility when considering the loss of his present group belonging, no matter whether his present group is high or low in status relative to the greater society. This has very little to do with absolute material welfare. This is why the guy choosing television and phones over food is making the right choice.126 Group belonging really is more important than short-term well-being. He is even displaying risk aversion, as is the poor black parent who gives her child a name that strongly signals group belonging at the expense of belonging in other groups or classes. It’s extremely difficult to join a whole new social group. Everyone faces a utility drop-off, a chasm, at the prospect of losing social belonging—a process sometimes described as social death. People behave as if losing one’s social group and status is worse than death. This is strong evidence that social death really is worse than death. Poor Baby or Rich Baby: Which is Worse? Data about crime, drug use, and other forms of risk preference and palliation seem to indicate that poor people are more likely than rich people to display the kind of truncated, effectively suicidal utility function I have been discussing. This could support the claim that it is more wrong for a poor person to have a child than for a rich person. But when we realize that social belonging trumps everything, we see that what really determines the value of life is the opportunity to be part of a social group. Middle class people have different relevant social groups from poor people, and the very wealthy have different social groups altogether. A child born into one of these groups must establish a place for himself; if few places are available, downward mobility (social death) is indicated. A person born into a very wealthy social group that has few opportunities for belonging may thus be in a worse position than a person born into poverty but with many opportunities for belonging. As Becker and Posner note, the nature of the “Gamble” you can afford depends on your present income; higher present incomes buy better gambles, with a higher probability of success. Therefore, wealthier people may succeed in their suicide gambles more often than poor people, so their gambles are more socially invisible than those of the poor— but they are still making them. However, the social belonging hypothesis that I have been advancing here (that social belonging is the primary determinant of utility) implies that the income at which life becomes worth living, Id, varies with one’s existing social situation, hence with initial income. Wealthy effectively-suicidal people start out with more initial income—they have more to gamble with—but they have a higher mark to reach for their gambles to be successful. It is not clear which effect predominates. The Economics of Palliation and Bullshit This model outlined above applies not only to serious gambles with significant downsides as well as significant, potentially permanent upsides (suicide gambles, like joining a street gang or going to law school), but also applies on a smaller scale to measures that temporarily reduce the pain experienced by the actor, though with potential future costs (palliation, like smoking cigarettes or playing World of Warcraft). Palliative remedies may have significant present and future costs, but at least they are generally effective at alleviating pain temporarily. However, looking around at the transactions taking place in the world economy, one cannot help but notice the market share of bullshit. Huge numbers of consumers prove willing to spend money on products and services that measurably don’t do what they promise to do. These products and services may or may not be particularly harmful, but they all have monetary cost, and they all have a very low likelihood of solving the problem they purport to solve. The market in expensive placebos is massive. Here are exemplary lists of both Palliation phenomena and Expensive Placebo phenomena, so that the reader will have a better idea of what I’m talking about: Palliation Expensive Placebo Budweiser Cheleda weight loss potion heroin face de-wrinkling potion World of Warcraft breast augmentation potion cigarettes penis growth and erection potion The McRib multi-level marketing wealth potion 7th Heaven psychic services lactation porn Jesus video poker nice Russian women looking for a good husband who need your credit card number In both cases, consumers seem blind to the downside. In the Palliation case there is a significant downside, but it’s made up for by the reliable temporary relief from pain. In the Expensive Placebo case, the downside is limited to the cost of the product or service, but the upside is measurably nil. The line between Palliation and Expensive Placebo may be fuzzy; for instance, a lonely person may get real social pleasure from interacting with a psychic consultant (and effective scammers, like all salesmen, tend to be pleasant people). An alcohol advertisement often includes implicit promises of social belonging, which if interpreted literally would make it more of an Expensive Placebo Belonging Serum than a genuine palliation tool. But the distinguishing characteristic is that in the case of what I call Expensive Placebos, the benefit that is bargained for is wholly imaginary, whereas with Palliation the essence of the promised benefit is, in fact, provided. Since the value of Expensive Placebos arises from pure fiction, ordinary measures of quality are not available; if acknowledged and utilized, real measures of quality would destroy the entire market. From this, we can distinguish Expensive Placebos from Palliation in terms of the effect of price. The price of an Expensive Placebo is a measure of social proof it carries—a more expensive placebo gets you better fantasies. A two-dollar penis enlargement pill probably doesn’t work, but one that costs $2,000 is a much more effective fantasy projection device. Price has to take on more epistemic weight in the evaluation of Expensive Placebos, because no other indicia of reliability are relevant. This is so because every indication of reliability, except price, would show the value to be zero. In order to maintain the fantasy, we must look at price instead of real quality indicators. To the degree that an intervention is Palliation, consumers would seek out the most palliation for the cost—these are ordinary goods where price is negatively correlated with demand. But to the degree that an intervention is an Expensive Placebo, price should behave much more weirdly, perhaps even correlating positively with demand, as with Veblen goods. It’s not just that the consumer of an Expensive Placebo makes himself blind to the downside of the purchase; the downside becomes the upside. (Here we may recall the similar phenomenon in which parents report getting more meaning and joy from child-rearing activities—and plan to spend more time with their children over a coming weekend—when they are reminded of the downside, but not the upside, of having kids.) There are some things that people will pay for even an imaginary chance at having. Youth, love, sex, wealth, and status are so deeply and painfully desired that people are willing to suspend their disbelief for the privilege of imagining that they might be obtainable. The need for social belonging trumps all other needs, and even trumps our own rationality. Being old, fat, poor, or impotent means being in social pain. Just as the desperate, terminally ill cancer patient often turns to expensive placebos for an imaginary chance at more life, desperate, terminally alive sad people turn to expensive placebos for a chance to imagine a decent life.",
      "word_count": 3521,
      "character_count": 21552,
      "chapter_number": 18,
      "section_number": null,
      "paragraph_number": 1,
      "start_position": 0,
      "end_position": 21552,
      "parent_chunk_id": "sarah_perryevery_cra_unknown_ch18"
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch19",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "chapter",
      "title": "Chapter Eleven: The Burden of Life",
      "content": "Chapter Eleven: The Burden of Life That being born is a good thing is treated as axiomatic by the majority of thinkers who consider the issue. The philosopher Thomas Nagel, for instance, states that “All of us, I believe, are fortunate to have been born,” even while affirming that not having been born is no misfortune.127 Bryan Caplan, even as he disdains to address substantive antinatalist objections to his devoutly pronatalist views, is fond of emphasizing the “obviousness” of his belief that being born is an unequivocal good for the person who is brought into being. In defending in vitro fertilization, for example, Caplan writes, “How can I neglect the welfare of the children created by artificial means? I’m not ‘neglecting’ children’s welfare. I just find it painfully obvious that being alive is good for them.”128 There are two elements to this kind of thinking. First, it represents a judgment that life is, on the whole, worth getting and having; but second, all the talk of “obviousness” also implies that there is something wrong with even asking the question. I want to address how quantitative methods, rather than intuition and assumption, might be used to measure the downside of existence. There is, I want to argue, a need to analyze quantitatively the obligations that we are all born with, if only to arrive at a better understanding of the inherent and uninvited pain of life. From this vantage, I want to deny the “obvious” by posing a simple question: if our lives are to be worth having on the whole, mustn’t such pain, at a minimum, be made up for with valuable experiences? Work and Leisure We might characterize the central unpleasant obligation in our lives as the obligation to “work” (broadly construed) in order to meet the salient and potentially misery-inducing needs we are born with or naturally develop. These needs include not only food, clothing, shelter, and medical care, but also status, love, sex, attention, and company.129 We can even quantify these needs by quantifying work done to satisfy them, for which we have a great deal of data. Some of these needs, of course, may actually be satisfied by working—the need to belong, to feel valuable, to not be a burden. At the same time, however, some of these needs are actually increased by working—that is, work may create disutility as well as utility. How can you tell the difference between what people do to merely to ease the pain and discomfort of existence, and what people actually want to be doing? Many economists have addressed the question of the difference between work and leisure, and how we may quantify and measure them. One crude-but-tempting measure of the value of leisure time is merely a person’s wage. But as economists Douglas Larson and Sabina Shaikh have explained,130 this is much too crude to get at the true nature of work and leisure: Assuming the average wage is the appropriate opportunity cost of time presumes that the individual faces no constraints on hours worked, derives no utility or disutility from work, and has a linear wage function…This is unlikely to be true for many people…an individual’s average wage does not necessarily reveal anything about the shadow value of discretionary leisure time, either as an upper or lower bound. The question of the value of leisure time is intimately related to the question of quantifying the unpleasant obligations placed on us by virtue of existence, so that we may have a starting point for a meaningful comparison of life’s costs and life’s benefits. How do we characterize “work”? What is the difference between “work” and “leisure”? Intuitively, we know the difference—or at least, there exist clear cases of “work” and clear cases of “leisure.” Operating a cash register is work. Washing dishes is work. Doing bong rips is leisure. Reading novels is leisure. Watching television and having sex are generally leisure (unless you’re in advertising or a prostitute). For most people, child care and lawn care qualify as work—whether paid or unpaid—but for some people, these same activities may qualify as leisure some of the time. These examples suggest that leisure is that which is done for the sake of the experience itself, whereas work is done with some goal in mind other than the experience itself, and is done only in service of that goal. Running ten miles is leisure for me, because I do it for the pleasure of the experience; running those same ten miles might be work for someone else, because he does it to lose weight, not for the pleasure of running. A third person might run for both reasons, in which case the action has aspects of both leisure and work. We should not necessarily expect that every action and every hour can be neatly categorized as “work” or “leisure,” even for a particular individual. This should give us pause when considering the appraisal of “leisure” preferred by Mark Aguiar and Erik Hurst in their 2007 paper “Measuring Trends in Leisure: The Allocation of Time Over Five Decades.”131 Aguiar and Hurst rely on an hour-by-hour tally of time not spent in market or nonmarket work (e.g., at work, or doing unpaid work around the house or around town), but in reality a single hour may have substantial aspects of both work and leisure. Aguiar and Hurst also remark on a potentially definitional characteristic of leisure: the degree to which market inputs (e.g., money, technology, etc.) are consumed to reduce the amount of time spent in the activity. They say: …one definition of whether an activity is “leisure” may be the degree of substitutability between the market input and the time input in the production of the commodity. That is, the leisure content of an activity is a function of technology rather than preferences. In the examples above, one can use the market to reduce time spent cooking (by getting a microwave or ordering takeout food) but cannot use the market to reduce the time input into watching television (although innovations like VCRs and Tivo allow some substitution). Let me give a definition of my own, to fit my question: Work is any action (or omission, perhaps) that we undertake in order to prevent or remedy some unpleasant state, and that we would not undertake if the unpleasant potential state were not a factor. An activity has a strong work component if technology is demanded by individuals to reduce the amount of time they spend in the activity. In other words, work is what you do only because you have to eat, and you spend as little time doing it as is possible to satisfy your (present and projected future) needs. Many studies since the 1980s have found that physicians’ demand for leisure directly affects the prevalence of cesarean sections.132 Cesarean sections are highly correlated to time variables associated with doctors wanting to get the hell out of there, although (further strengthening the theory) this correlation is dependent on the type of insurance covering the patient. Instead of relying on the Imaginary Survey justification to “prove” that coming into existence is a good thing, economists and ethicists could use more creative, quantitative methods to examine the question of how bad (and how good) life is. Specifically, we need to figure out how to tell the difference between suffering people attempting to remedy their shitty situation, and happy people chilling out —both of which may describe any of us at different times in our life, or even our day. “Are you glad you were born?” is unsubtle, an all-or-nothing approach that relies heavily on people knowing the answer to questions they may have only limited capacity to understand. Analyzing behavior in smaller chunks would give us a better idea of just how happy people are to be here. Poverty and Pain Behavioral economics is a strong tool for understanding ourselves and each other. However, many behavioral economists, consciously or unconsciously, rely heavily on the Imaginary Survey justification, and no economist, to my knowledge, has attempted to use behavioral economics methods to figure out how bad, or how good, life is to individuals. Let’s return to Bryan Caplan’s “Behavioral Economics and Perverse Effects of the Welfare State.” It’s a fascinating and even audacious paper. Caplan argues that giving the poor more life choices through charitable assistance seems to actually harm them because they are irrational and fail to choose the best option for themselves. From his abstract: Critics often argue that government poverty programs perversely make the poor worse off by encouraging unemployment, out-of-wedlock births, and other “social pathologies.” However, basic microeconomic theory tells us that you cannot make an agent worse off by expanding his choice set. The current paper argues that familiar findings in behavioral economics can be used to resolve this paradox. Insofar as the standard rational actor model is wrong, additional choices can make agents worse off. More importantly, existing empirical evidence suggests that the poor deviate from the rational actor model to an unusually large degree. The paper then considers the policy implications of our alternative perspective. The option Caplan fails to consider is this: the lives of the poor are unacceptably bad without charitable aid. We don’t think it irrational, exactly, when a person in extreme pain does something to relieve his pain that may have negative future consequences. A shrieking, sweating patient in horrible pain might be perfectly aware of the potential for developing a long-term addiction to opiates, but we do not consider his decision to take opiate medication to be irrational. His pain is so bad that we think it makes sense for him to use any means to stop it, even if such means harm his future interests. Connecting to my discussion of work vs. leisure, I think it a valid hypothesis that poverty is actually dreadfully painful —not only physically, but emotionally and socially. There is only so much pain we can expect a being to endure before his attempts to relieve it through future-damaging means become perfectly understandable and, in fact, rational. The Demand for Pain Relief An economic theory of rationality, to be in touch with human ethical reality, must include an account of pain. We must attempt to define and study pain (in the broad sense) in a behavioral economics context, rather than to define it away, as Caplan attempts to do. The economist Karl Smith notes133 that studies consistently show that consumers do not seem to take into account mortality data when choosing between health care providers, even when very good mortality data is widely available in a user-friendly format. Perhaps the demand for life is not as high as we might think. People seem willing to spend money on health care, but not to care about outcome. One approach suggested by this finding would be to study the revealed preferences of consumers’ willingness to pay for death risk reduction and broadly defined pain relief respectively, in different contexts and populations. Is Loss Aversion Irrational? Recent laboratory research134 demonstrates that tufted capuchin monkeys exhibit what behavioral economists consider to be a typical human departure from rationality— “loss aversion.” That is, monkeys trained to use metal discs as money preferred to buy fruit from a graduate student who would give them a smaller food reward but sometimes add a few grapes, rather than from a graduate student who would give them a larger food reward but then maybe remove a few grapes. The monkeys weren’t maximizing the number of grapes they got; they specifically exhibited a preference to have things added, rather than have things taken away. I don’t think this necessarily illustrates irrationality in the capuchins; it illustrates that they are utility maximizers, not grape maximizers. Monkeys experience a loss of utility from losing grapes that is greater than the utility produced by those grapes. Losing grapes, we might say, is painful. Doing the resource-maximizing thing does not necessarily equate with doing the utility-maximizing thing. A Place for Quantitative Methods Caplan’s conclusion is that we must not treat the poor as rational actors, because they deviate so heavily (compared to the wealthy) from being long-term best-interest maximizers. Therefore, he says, we should not expect to solve their problems by giving them money or other charitable aid. An equally supported conclusion would be that being poor is so awful it is unendurable, like severe physical pain. Taking this into account, the seemingly poor choices of poor people are actually quite rational, serving an overriding and immediate need to alleviate pain. Caplan also gives us a hint at what might be an indicator of painfulness: the degree to which the actor deviates from resource maximization. He says, The behavioral literature has documented that the average person frequently violates neoclassical assumptions. But it rarely investigates variation in the tendency to violate neoclassical assumptions. Casual empiricism and limited formal evidence suggest that the poor do deviate more. A great deal more could be learned at low cost if new behavioral studies collected information on participants’ income and education to test for heterogeneity. Analyzing many factors—not just income, but also education, and intelligence—for correlation to deviation from resource-maximization rationality could help us understand the circumstances under which life is so painful that we act “irrationally.”",
      "word_count": 2209,
      "character_count": 13557,
      "chapter_number": 19,
      "section_number": null,
      "paragraph_number": null,
      "start_position": 0,
      "end_position": 13557,
      "parent_chunk_id": null
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch19_p1",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "paragraph",
      "title": "Paragraph 1",
      "content": "Chapter Eleven: The Burden of Life That being born is a good thing is treated as axiomatic by the majority of thinkers who consider the issue. The philosopher Thomas Nagel, for instance, states that “All of us, I believe, are fortunate to have been born,” even while affirming that not having been born is no misfortune.127 Bryan Caplan, even as he disdains to address substantive antinatalist objections to his devoutly pronatalist views, is fond of emphasizing the “obviousness” of his belief that being born is an unequivocal good for the person who is brought into being. In defending in vitro fertilization, for example, Caplan writes, “How can I neglect the welfare of the children created by artificial means? I’m not ‘neglecting’ children’s welfare. I just find it painfully obvious that being alive is good for them.”128 There are two elements to this kind of thinking. First, it represents a judgment that life is, on the whole, worth getting and having; but second, all the talk of “obviousness” also implies that there is something wrong with even asking the question. I want to address how quantitative methods, rather than intuition and assumption, might be used to measure the downside of existence. There is, I want to argue, a need to analyze quantitatively the obligations that we are all born with, if only to arrive at a better understanding of the inherent and uninvited pain of life. From this vantage, I want to deny the “obvious” by posing a simple question: if our lives are to be worth having on the whole, mustn’t such pain, at a minimum, be made up for with valuable experiences? Work and Leisure We might characterize the central unpleasant obligation in our lives as the obligation to “work” (broadly construed) in order to meet the salient and potentially misery-inducing needs we are born with or naturally develop. These needs include not only food, clothing, shelter, and medical care, but also status, love, sex, attention, and company.129 We can even quantify these needs by quantifying work done to satisfy them, for which we have a great deal of data. Some of these needs, of course, may actually be satisfied by working—the need to belong, to feel valuable, to not be a burden. At the same time, however, some of these needs are actually increased by working—that is, work may create disutility as well as utility. How can you tell the difference between what people do to merely to ease the pain and discomfort of existence, and what people actually want to be doing? Many economists have addressed the question of the difference between work and leisure, and how we may quantify and measure them. One crude-but-tempting measure of the value of leisure time is merely a person’s wage. But as economists Douglas Larson and Sabina Shaikh have explained,130 this is much too crude to get at the true nature of work and leisure: Assuming the average wage is the appropriate opportunity cost of time presumes that the individual faces no constraints on hours worked, derives no utility or disutility from work, and has a linear wage function…This is unlikely to be true for many people…an individual’s average wage does not necessarily reveal anything about the shadow value of discretionary leisure time, either as an upper or lower bound. The question of the value of leisure time is intimately related to the question of quantifying the unpleasant obligations placed on us by virtue of existence, so that we may have a starting point for a meaningful comparison of life’s costs and life’s benefits. How do we characterize “work”? What is the difference between “work” and “leisure”? Intuitively, we know the difference—or at least, there exist clear cases of “work” and clear cases of “leisure.” Operating a cash register is work. Washing dishes is work. Doing bong rips is leisure. Reading novels is leisure. Watching television and having sex are generally leisure (unless you’re in advertising or a prostitute). For most people, child care and lawn care qualify as work—whether paid or unpaid—but for some people, these same activities may qualify as leisure some of the time. These examples suggest that leisure is that which is done for the sake of the experience itself, whereas work is done with some goal in mind other than the experience itself, and is done only in service of that goal. Running ten miles is leisure for me, because I do it for the pleasure of the experience; running those same ten miles might be work for someone else, because he does it to lose weight, not for the pleasure of running. A third person might run for both reasons, in which case the action has aspects of both leisure and work. We should not necessarily expect that every action and every hour can be neatly categorized as “work” or “leisure,” even for a particular individual. This should give us pause when considering the appraisal of “leisure” preferred by Mark Aguiar and Erik Hurst in their 2007 paper “Measuring Trends in Leisure: The Allocation of Time Over Five Decades.”131 Aguiar and Hurst rely on an hour-by-hour tally of time not spent in market or nonmarket work (e.g., at work, or doing unpaid work around the house or around town), but in reality a single hour may have substantial aspects of both work and leisure. Aguiar and Hurst also remark on a potentially definitional characteristic of leisure: the degree to which market inputs (e.g., money, technology, etc.) are consumed to reduce the amount of time spent in the activity. They say: …one definition of whether an activity is “leisure” may be the degree of substitutability between the market input and the time input in the production of the commodity. That is, the leisure content of an activity is a function of technology rather than preferences. In the examples above, one can use the market to reduce time spent cooking (by getting a microwave or ordering takeout food) but cannot use the market to reduce the time input into watching television (although innovations like VCRs and Tivo allow some substitution). Let me give a definition of my own, to fit my question: Work is any action (or omission, perhaps) that we undertake in order to prevent or remedy some unpleasant state, and that we would not undertake if the unpleasant potential state were not a factor. An activity has a strong work component if technology is demanded by individuals to reduce the amount of time they spend in the activity. In other words, work is what you do only because you have to eat, and you spend as little time doing it as is possible to satisfy your (present and projected future) needs. Many studies since the 1980s have found that physicians’ demand for leisure directly affects the prevalence of cesarean sections.132 Cesarean sections are highly correlated to time variables associated with doctors wanting to get the hell out of there, although (further strengthening the theory) this correlation is dependent on the type of insurance covering the patient. Instead of relying on the Imaginary Survey justification to “prove” that coming into existence is a good thing, economists and ethicists could use more creative, quantitative methods to examine the question of how bad (and how good) life is. Specifically, we need to figure out how to tell the difference between suffering people attempting to remedy their shitty situation, and happy people chilling out —both of which may describe any of us at different times in our life, or even our day. “Are you glad you were born?” is unsubtle, an all-or-nothing approach that relies heavily on people knowing the answer to questions they may have only limited capacity to understand. Analyzing behavior in smaller chunks would give us a better idea of just how happy people are to be here. Poverty and Pain Behavioral economics is a strong tool for understanding ourselves and each other. However, many behavioral economists, consciously or unconsciously, rely heavily on the Imaginary Survey justification, and no economist, to my knowledge, has attempted to use behavioral economics methods to figure out how bad, or how good, life is to individuals. Let’s return to Bryan Caplan’s “Behavioral Economics and Perverse Effects of the Welfare State.” It’s a fascinating and even audacious paper. Caplan argues that giving the poor more life choices through charitable assistance seems to actually harm them because they are irrational and fail to choose the best option for themselves. From his abstract: Critics often argue that government poverty programs perversely make the poor worse off by encouraging unemployment, out-of-wedlock births, and other “social pathologies.” However, basic microeconomic theory tells us that you cannot make an agent worse off by expanding his choice set. The current paper argues that familiar findings in behavioral economics can be used to resolve this paradox. Insofar as the standard rational actor model is wrong, additional choices can make agents worse off. More importantly, existing empirical evidence suggests that the poor deviate from the rational actor model to an unusually large degree. The paper then considers the policy implications of our alternative perspective. The option Caplan fails to consider is this: the lives of the poor are unacceptably bad without charitable aid. We don’t think it irrational, exactly, when a person in extreme pain does something to relieve his pain that may have negative future consequences. A shrieking, sweating patient in horrible pain might be perfectly aware of the potential for developing a long-term addiction to opiates, but we do not consider his decision to take opiate medication to be irrational. His pain is so bad that we think it makes sense for him to use any means to stop it, even if such means harm his future interests. Connecting to my discussion of work vs. leisure, I think it a valid hypothesis that poverty is actually dreadfully painful —not only physically, but emotionally and socially. There is only so much pain we can expect a being to endure before his attempts to relieve it through future-damaging means become perfectly understandable and, in fact, rational. The Demand for Pain Relief An economic theory of rationality, to be in touch with human ethical reality, must include an account of pain. We must attempt to define and study pain (in the broad sense) in a behavioral economics context, rather than to define it away, as Caplan attempts to do. The economist Karl Smith notes133 that studies consistently show that consumers do not seem to take into account mortality data when choosing between health care providers, even when very good mortality data is widely available in a user-friendly format. Perhaps the demand for life is not as high as we might think. People seem willing to spend money on health care, but not to care about outcome. One approach suggested by this finding would be to study the revealed preferences of consumers’ willingness to pay for death risk reduction and broadly defined pain relief respectively, in different contexts and populations. Is Loss Aversion Irrational? Recent laboratory research134 demonstrates that tufted capuchin monkeys exhibit what behavioral economists consider to be a typical human departure from rationality— “loss aversion.” That is, monkeys trained to use metal discs as money preferred to buy fruit from a graduate student who would give them a smaller food reward but sometimes add a few grapes, rather than from a graduate student who would give them a larger food reward but then maybe remove a few grapes. The monkeys weren’t maximizing the number of grapes they got; they specifically exhibited a preference to have things added, rather than have things taken away. I don’t think this necessarily illustrates irrationality in the capuchins; it illustrates that they are utility maximizers, not grape maximizers. Monkeys experience a loss of utility from losing grapes that is greater than the utility produced by those grapes. Losing grapes, we might say, is painful. Doing the resource-maximizing thing does not necessarily equate with doing the utility-maximizing thing. A Place for Quantitative Methods Caplan’s conclusion is that we must not treat the poor as rational actors, because they deviate so heavily (compared to the wealthy) from being long-term best-interest maximizers. Therefore, he says, we should not expect to solve their problems by giving them money or other charitable aid. An equally supported conclusion would be that being poor is so awful it is unendurable, like severe physical pain. Taking this into account, the seemingly poor choices of poor people are actually quite rational, serving an overriding and immediate need to alleviate pain. Caplan also gives us a hint at what might be an indicator of painfulness: the degree to which the actor deviates from resource maximization. He says, The behavioral literature has documented that the average person frequently violates neoclassical assumptions. But it rarely investigates variation in the tendency to violate neoclassical assumptions. Casual empiricism and limited formal evidence suggest that the poor do deviate more. A great deal more could be learned at low cost if new behavioral studies collected information on participants’ income and education to test for heterogeneity. Analyzing many factors—not just income, but also education, and intelligence—for correlation to deviation from resource-maximization rationality could help us understand the circumstances under which life is so painful that we act “irrationally.”",
      "word_count": 2209,
      "character_count": 13557,
      "chapter_number": 19,
      "section_number": null,
      "paragraph_number": 1,
      "start_position": 0,
      "end_position": 13557,
      "parent_chunk_id": "sarah_perryevery_cra_unknown_ch19"
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch20",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "chapter",
      "title": "Chapter Twelve: Hurting People and Doing Good",
      "content": "Chapter Twelve: Hurting People and Doing Good A 2008 report from the United Kingdom’s Home Office Advisory Council on the Misuse of Drugs concluded that ecstasy (at least, MDMA) is not nearly as dangerous as was previously thought, either in terms of lethality or long-term health consequences. The Council even recommended changing the classification of MDMA from its present status as Class A substance (heroin, crack, and amphetamines prepared for injection are Class A) to the less-dangerous Class B (which includes marijuana and Ritalin). The recommendation was, of course, rejected. A February 2009 editorial in New Scientist135 took the logic a step further: Imagine you are seated at a table with two bowls in front of you. One contains peanuts, the other tablets of the illegal recreational drug MDMA (ecstasy). A stranger joins you, and you have to decide whether to give them a peanut or a pill. Which is safest? You should give them ecstasy, of course. A much larger percentage of people suffer a fatal acute reaction to peanuts than to MDMA. The implication is that, when acting upon a stranger, we should minimize his risk of death. (We might also consider our own willingness to endure, on the one hand, a stranger’s slight peanut breath, and on the other, a stranger clinging to our leg like a baby macaque for three hours, but that is a separate calculus.) The blogger Caledonian136 has a slightly different take: we should focus on the relative likelihood of harm, he says, rather than the relative likelihood of death. Both of these goals—acting to minimize the risk of death to a stranger, and acting to minimize his risk of harm—are laudable and widely shared. But there’s a glaring aspect of the utilitarian calculus that almost no one seriously considers in making the decision to administer a peanut or a dose of ecstasy. This is the differential positive utility to be gained by the stranger in each case. A peanut is marginally sustaining, but unless it’s been boiled with star anise and Sichuan peppercorns, it’s not particularly enjoyable. Ecstasy, on the other hand, is fucking awesome. Why doesn’t anybody consider the relative benefit to the stranger along with the relative harm? While many of us would certainly consider the pleasure of ecstasy in deciding whether to eat the pill or the peanut ourselves, it’s proper and coherent not to consider the pleasurable effects of a potentially harmful action when it will be inflicted upon a non-consenting stranger whose values we do not know. This illustrates Seana Shiffrin’s principal that, while it’s morally acceptable to harm a stranger without his consent in order to prevent worse harm (e.g., to administer ecstasy in order to avoid administering a peanut or to break someone’s arm in order to pull him from a burning car), it’s not morally acceptable to harm a stranger without his consent in order to provide a pure benefit. But the ecstasy example supports a stronger inference: when evaluating actions that will harm a non-consenting stranger, his potential pleasure doesn’t count. When we’re acting toward someone whose values we do not know, we should not think in terms of maximizing his utility, but in terms of minimizing our harm to him. The distinction between acting toward a non-consenting stranger whose values we do not know, and acting toward ourselves (or toward someone whose values we know), is one that is ignored by S.D. Baum in his article “Better to exist: a reply to Benatar.”137 Baum’s “reply” (to David Benatar’s position that it is always better not to bring people into existence) is, in relevant part, as follows: The benefits/harms asymmetry is commonly manifested (including in Benatar’s writing) in the claim that no amount of benefit, however large, can make up for any amount of harm, however small. This claim comes from an intuition that while we have a duty to reduce harm, we have no duty to increase benefit. The corresponding ethical framework is often called “negative utilitarianism.” Negative utilitarianism resembles maximin in its resolute focus on the worst off—as long as some of those worst off are in a state of harm, instead of just in a state of low benefit. Like maximin, negative utilitarianism can recommend that no one be brought into existence—and that all existing people be euthanised. I find negative utilitarianism decidedly unreasonable: our willingness to accept some harm in order to enjoy the benefits of another day seems praiseworthy, not mistaken. I thus urge the rejection of this manifestation of the benefits/harms asymmetry. Our own willingness to accept suffering in the interest of pleasure (or any other value) is no reason to think that it is right to inflict that same suffering on a non-consenting stranger. Negative utilitarianism may not be the proper course to take in our own lives, but thought experiments like this one suggest that negative utilitarianism is the proper course to take toward the lives of others who do not consent to our interference. Baum also assumes, contrary to Benatar’s express position, that death is not a harm to already-existing people. In fact, Benatar’s claims do not rest on any simplistic pleasure/pain conception of value; Benatar argues that death is a harm, even a painless death. It is, in fact, one of the great harms of life—every person born will suffer the harm of death. Most people think it’s morally acceptable to have babies. Most people think this despite the fact that the babies will certainly suffer a great deal during their lifetimes and may suffer an exceptional amount. Pronatalists generally want to point out the good things in life—the pleasant effects of puppies and sunsets—and to balance them against life’s harms. But bringing a child into the world necessarily entails harming a stranger (for one doesn’t know the values of one’s child prior to procreation).138 It is no different from dosing a stranger with ecstasy for no reason, except that the harms of life massively exceed the harms of ecstasy, and the pleasure of life, for many, is much less. Considering the non-consenting stranger’s pleasure in the ecstasy/peanut case is unthinkable; procreation advocates need to explain why considering his pleasure in coming into existence is just fine.139",
      "word_count": 1034,
      "character_count": 6281,
      "chapter_number": 20,
      "section_number": null,
      "paragraph_number": null,
      "start_position": 0,
      "end_position": 6281,
      "parent_chunk_id": null
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch20_p1",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "paragraph",
      "title": "Paragraph 1",
      "content": "Chapter Twelve: Hurting People and Doing Good A 2008 report from the United Kingdom’s Home Office Advisory Council on the Misuse of Drugs concluded that ecstasy (at least, MDMA) is not nearly as dangerous as was previously thought, either in terms of lethality or long-term health consequences. The Council even recommended changing the classification of MDMA from its present status as Class A substance (heroin, crack, and amphetamines prepared for injection are Class A) to the less-dangerous Class B (which includes marijuana and Ritalin). The recommendation was, of course, rejected. A February 2009 editorial in New Scientist135 took the logic a step further: Imagine you are seated at a table with two bowls in front of you. One contains peanuts, the other tablets of the illegal recreational drug MDMA (ecstasy). A stranger joins you, and you have to decide whether to give them a peanut or a pill. Which is safest? You should give them ecstasy, of course. A much larger percentage of people suffer a fatal acute reaction to peanuts than to MDMA. The implication is that, when acting upon a stranger, we should minimize his risk of death. (We might also consider our own willingness to endure, on the one hand, a stranger’s slight peanut breath, and on the other, a stranger clinging to our leg like a baby macaque for three hours, but that is a separate calculus.) The blogger Caledonian136 has a slightly different take: we should focus on the relative likelihood of harm, he says, rather than the relative likelihood of death. Both of these goals—acting to minimize the risk of death to a stranger, and acting to minimize his risk of harm—are laudable and widely shared. But there’s a glaring aspect of the utilitarian calculus that almost no one seriously considers in making the decision to administer a peanut or a dose of ecstasy. This is the differential positive utility to be gained by the stranger in each case. A peanut is marginally sustaining, but unless it’s been boiled with star anise and Sichuan peppercorns, it’s not particularly enjoyable. Ecstasy, on the other hand, is fucking awesome. Why doesn’t anybody consider the relative benefit to the stranger along with the relative harm? While many of us would certainly consider the pleasure of ecstasy in deciding whether to eat the pill or the peanut ourselves, it’s proper and coherent not to consider the pleasurable effects of a potentially harmful action when it will be inflicted upon a non-consenting stranger whose values we do not know. This illustrates Seana Shiffrin’s principal that, while it’s morally acceptable to harm a stranger without his consent in order to prevent worse harm (e.g., to administer ecstasy in order to avoid administering a peanut or to break someone’s arm in order to pull him from a burning car), it’s not morally acceptable to harm a stranger without his consent in order to provide a pure benefit. But the ecstasy example supports a stronger inference: when evaluating actions that will harm a non-consenting stranger, his potential pleasure doesn’t count. When we’re acting toward someone whose values we do not know, we should not think in terms of maximizing his utility, but in terms of minimizing our harm to him. The distinction between acting toward a non-consenting stranger whose values we do not know, and acting toward ourselves (or toward someone whose values we know), is one that is ignored by S.D. Baum in his article “Better to exist: a reply to Benatar.”137 Baum’s “reply” (to David Benatar’s position that it is always better not to bring people into existence) is, in relevant part, as follows: The benefits/harms asymmetry is commonly manifested (including in Benatar’s writing) in the claim that no amount of benefit, however large, can make up for any amount of harm, however small. This claim comes from an intuition that while we have a duty to reduce harm, we have no duty to increase benefit. The corresponding ethical framework is often called “negative utilitarianism.” Negative utilitarianism resembles maximin in its resolute focus on the worst off—as long as some of those worst off are in a state of harm, instead of just in a state of low benefit. Like maximin, negative utilitarianism can recommend that no one be brought into existence—and that all existing people be euthanised. I find negative utilitarianism decidedly unreasonable: our willingness to accept some harm in order to enjoy the benefits of another day seems praiseworthy, not mistaken. I thus urge the rejection of this manifestation of the benefits/harms asymmetry. Our own willingness to accept suffering in the interest of pleasure (or any other value) is no reason to think that it is right to inflict that same suffering on a non-consenting stranger. Negative utilitarianism may not be the proper course to take in our own lives, but thought experiments like this one suggest that negative utilitarianism is the proper course to take toward the lives of others who do not consent to our interference. Baum also assumes, contrary to Benatar’s express position, that death is not a harm to already-existing people. In fact, Benatar’s claims do not rest on any simplistic pleasure/pain conception of value; Benatar argues that death is a harm, even a painless death. It is, in fact, one of the great harms of life—every person born will suffer the harm of death. Most people think it’s morally acceptable to have babies. Most people think this despite the fact that the babies will certainly suffer a great deal during their lifetimes and may suffer an exceptional amount. Pronatalists generally want to point out the good things in life—the pleasant effects of puppies and sunsets—and to balance them against life’s harms. But bringing a child into the world necessarily entails harming a stranger (for one doesn’t know the values of one’s child prior to procreation).138 It is no different from dosing a stranger with ecstasy for no reason, except that the harms of life massively exceed the harms of ecstasy, and the pleasure of life, for many, is much less. Considering the non-consenting stranger’s pleasure in the ecstasy/peanut case is unthinkable; procreation advocates need to explain why considering his pleasure in coming into existence is just fine.139",
      "word_count": 1034,
      "character_count": 6281,
      "chapter_number": 20,
      "section_number": null,
      "paragraph_number": 1,
      "start_position": 0,
      "end_position": 6281,
      "parent_chunk_id": "sarah_perryevery_cra_unknown_ch20"
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch21",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "chapter",
      "title": "Chapter Thirteen: The World of Nature of Which We Are a Part",
      "content": "Chapter Thirteen: The World of Nature of Which We Are a Part The extent of the suffering of wild animals is literally unimaginable.140 We have a function in our minds for imagining suffering—remembering a dog bite, perhaps, or another nasty injury. And we have an abstract multiplication function in our minds as well. But this doesn’t get us even close to understanding the amount of suffering that occurs in nature in a single minute. What would it feel like to land on the surface of the sun? Answer: not like anything. You can’t even approach the surface of the sun; even millions of miles out, shielded by a spacecraft, a human body would disintegrate. We are physically incapable of perceiving how bad the surface of the sun would feel. Thus it is with the amount of suffering in the natural world (and, incidentally, its subset, the human world). 1. On The Ways In Which Nature Makes Andrea Yates Look Like June Cleaver Eurasian coots, a species of migratory water bird, may hatch up to nine chicks. But under normal circumstances, food is in short supply. The parent birds feed the baby birds tiny shrimp for the first three days after hatching. Then, mama coot turns into Mommy Dearest. A baby bird begs for food, as usual—but, with no warning, the parents “punish” it, biting the chick hard on its tiny head. The parents do this to all the chicks in turn. Eventually, one chick is singled out for special torture, and abused until it stops begging for food and starves to death. This process is repeated until only two or three chicks survive. Pelicans hatch three chicks, but under normal circumstances, only one survives. Instead of the parent birds doling out death, it’s the siblings—the two larger birds pluck at the smallest with their sharp beaks and knock it out of the nest. Then the conspirators turn on each other until only one chick is left. Sir David Attenborough141 himself acknowledges that this might be a bit cruel, by human standards. But, he assures us, it’s all for the best—in especially good years, a pelican or coot can raise an extra chick or two. So torturing baby birds to death serves the purpose of increasing the genetic fitness of the parents by a little bit. Does that really make it okay? 2. The Incoherence of Species-Relative Morality We are taught as children not to apply human standards of morality to animal behavior. We do not expect macaques to be egalitarian, nor male lions to refrain from killing cubs sired by other males. We should not, this theory goes, expect animals to raise the babies they produce to adulthood; we should not be dismayed if they, in fact, torture their young to death when it is advantageous for them to do so. Most people of our era have a strong, visceral inclination against cruelty to animals, just as we do against cruelty to human children. We judge animal suffering to be bad. Watching a nature documentary, we hope the impala can evade the lion, yet we also hope the lion cubs get fed somehow. But watch what your mind does when considering these two contradictory hopes. Does it come to a coherent resolution of the problem? Or does it just shrug its shoulders and spackle the problem over with some bullshit about the circle of life? Life must go on . . . end of thought. Is it okay that the impala gets eaten? That the cub dies? What about an old lion slowly dying in the hot sun? How about that little chick pictured above, getting abused and starved to death by its parents? Genesis 1:21 (KJV) says: And God created great whales, and every living creature that moveth, which the waters brought forth abundantly, after their kind, and every winged fowl after his kind: and God saw that it was good.” According the Judeo-Christian God, torturing baby coots to death is not just okay, but good. “God” gave us that whopper to swallow; can you swallow it? Human morality, some may argue, applies only to human actions—not to the actions of animals. I agree with this. For the most part, animals are not agents, but merely robots— machines executing programs created by natural selection. However, morality must certainly apply to human inaction, and especially our inaction in preventing harm, suffering, and awfulness. What is the moral justification for the “hands off ” dogma regarding nature? We often interfere with nature for the good of humans and human industry. Why not for the good of individual animals? Bloody Nature is a machine for pushing genes into the future. Does it really “know best”? 3. Respect for Species? Nature exists. We try to “conserve” ecosystems in their “natural” state (scare quotes because ecosystems evolve and change over time in response to environmental pressures, including those from other species). But who is this good for? Is it good for the animals themselves? Thomas Nagel considers the difficulty of this question in his essay “Birth, Death, and the Meaning of Life,” in his important book The View from Nowhere (from which my blog, which many of you are familiar with, took its title).142 While teaching at Princeton in the 70s, Professor Nagel noticed a sad little spider living in a urinal in the men’s bathroom. The spider appeared to Professor Nagel to have a crappy life, constantly getting peed on; “he didn’t seem to like it,” notes Nagel: Gradually our encounters began to oppress me. Of course it might be his natural habitat, but because he was trapped by the smooth porcelain overhang, there was no way for him to get out even if he wanted to, and no way to tell whether he wanted to…So one day toward the end of the term I took a paper towel from the wall dispenser and extended it to him. His legs grasped the end of the towel and I lifted him out and deposited him on the tile floor. He just sat there, not moving a muscle. I nudged him slightly with the towel, but nothing happened…I left, but when I came back two hours later he hadn’t moved. The next day I found him in the same place, his legs shriveled in that way characteristic of dead spiders. His corpse stayed there for a week, until they finally swept the floor. Professor Nagel acted with empathy toward the spider— treating the spider how he imagined the spider would want to be treated. But did he do the spider any good? Would non-interference by Professor Nagel have done the spider any good? The spider might have lived longer, scrambling away from piss streams a hundred times a day, and may have eventually made more spiders. Would that be a good thing? What do spiders want? Is there such a thing as a meaningful life for a spider? Does a spider’s life do the spider any good? There is a popular idea, born, I think, from applying the principles of liberalism where they do not belong—the idea that non-interference indicates respect for a species or animal, as if it were a person. (Where interference is allowed, it is to remedy some previous human interference.) This is also (idiotically) applied to human cultural systems, not just biological systems; in the human context, it is known as cultural relativism. And it is just as incoherent applied to animals as applied to folks slicing off the clitorises of babies. Let us for a moment suppose that we will treat individual animals as persons whose pleasures, pains, and desires we can identify and respect. In that case, empirically speaking, non-interference is a poor policy. We could do more to make animals suffer less by intervention than by complete non-intervention. On the other hand, perhaps it is the species that is our “person”—we should try to respect a species, or, perhaps, a whole complex ecosystem. But since species and ecosystems are not percipient beings capable of pleasure and suffering, by assigning them respect, we open up the question of the purpose of doing so. Who are ecosystems good for? Or are they perhaps mystically intrinsically good, as Jehovah would have us believe? 4. Use Nature As We Please? To some degree, nature au naturel is good for humans. We need trees and algae and fish in order to live. Genetic diversity, developed over millions of years, ensures the longevity of our biosphere. Being near green plants and animals makes us happy. We frequently violate our supposed policy of non-intervention with the natural world when doing so benefits humans, in some cases actively seeking the extinction of certain organisms (like smallpox). I don’t think this is wrong at all, because (a) smallpox doesn’t do anyone, including itself, any good by existing; and (b) smallpox causes untold suffering. But why draw the line at smallpox? It is my contention that not just smallpox, but all creatures, do not do themselves any good by existing—from piss-dodging spiders to coyotes to humans. Not only do we breathe oxygen and eat food produced by biological systems, we also appreciate the beauty of complex systems. Can we justify the suffering of baby coots because we think their ecosystem is interesting? Earlier generations of humans liked to torture animals for their own pleasure (and some people still do). We now judge this to be evil. But is standing by while animals torture each other in “natural” ways, when we have the power to stop it, any better than actively torturing animals? Responsible people spay or neuter their pets. Why not spay Nature Herself? We don’t even have to harm or kill animals in order to stop Nature from doing her evil deeds. We could simply prevent their reproduction, or even merely cease our current “conservation efforts” that involve breeding animals. Breeding wild animals and releasing them into the wild is doing the ugly work of Genesis all over again—and cruelly claiming that it’s “good.” 5. Is Being Human-Like Better? We are touched by human-like (or ideal-human-like) characteristics in animals—nurturing young, monogamy, neighborliness, cooperation. Humans, although we commit parental infanticide at a rate higher than any other great ape (as would be expected from our relative immaturity at birth), at least attempt to raise most of our young to adulthood. But is “human” really more “humane”? Compare the pelicans and coots to the rosella parrot. These parents feed “fairly”—that is, all chicks are fed equally, although they hatch at different times, so some chicks are larger than others. Large, older baby parrots even share their food with their smaller siblings! Aw. Sound good? Nice parrots. However, they are merely postponing the point at which the red teeth and claws come into the picture. These parrot parents produce more than two offspring. What do you think happens to most of them? They go off and found happy egalitarian parrot families of their own? Maybe for a little while. But a species can’t expand indefinitely. Most of these new parrots will get eaten or starve to death. The lucky few will go on to put dozens of new parrots into the world, for natural selection to claw apart and eat alive. r is evil, but K is not so great either. Antibiotics were not invented until World War II. Prior to that, any human parent faced the very real possibility of losing some or all of his children before they reached adulthood. Humans were visibly under the same selection pressures as the rest of the animals. However, for a couple of generations, we have managed to pretend that nearly all our offspring can survive to adulthood and bear children of their own. We must look to nature to remind ourselves that this is a temporary fantasy.",
      "word_count": 1966,
      "character_count": 11415,
      "chapter_number": 21,
      "section_number": null,
      "paragraph_number": null,
      "start_position": 0,
      "end_position": 11415,
      "parent_chunk_id": null
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch21_p1",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "paragraph",
      "title": "Paragraph 1",
      "content": "Chapter Thirteen: The World of Nature of Which We Are a Part The extent of the suffering of wild animals is literally unimaginable.140 We have a function in our minds for imagining suffering—remembering a dog bite, perhaps, or another nasty injury. And we have an abstract multiplication function in our minds as well. But this doesn’t get us even close to understanding the amount of suffering that occurs in nature in a single minute. What would it feel like to land on the surface of the sun? Answer: not like anything. You can’t even approach the surface of the sun; even millions of miles out, shielded by a spacecraft, a human body would disintegrate. We are physically incapable of perceiving how bad the surface of the sun would feel. Thus it is with the amount of suffering in the natural world (and, incidentally, its subset, the human world). 1. On The Ways In Which Nature Makes Andrea Yates Look Like June Cleaver Eurasian coots, a species of migratory water bird, may hatch up to nine chicks. But under normal circumstances, food is in short supply. The parent birds feed the baby birds tiny shrimp for the first three days after hatching. Then, mama coot turns into Mommy Dearest. A baby bird begs for food, as usual—but, with no warning, the parents “punish” it, biting the chick hard on its tiny head. The parents do this to all the chicks in turn. Eventually, one chick is singled out for special torture, and abused until it stops begging for food and starves to death. This process is repeated until only two or three chicks survive. Pelicans hatch three chicks, but under normal circumstances, only one survives. Instead of the parent birds doling out death, it’s the siblings—the two larger birds pluck at the smallest with their sharp beaks and knock it out of the nest. Then the conspirators turn on each other until only one chick is left. Sir David Attenborough141 himself acknowledges that this might be a bit cruel, by human standards. But, he assures us, it’s all for the best—in especially good years, a pelican or coot can raise an extra chick or two. So torturing baby birds to death serves the purpose of increasing the genetic fitness of the parents by a little bit. Does that really make it okay? 2. The Incoherence of Species-Relative Morality We are taught as children not to apply human standards of morality to animal behavior. We do not expect macaques to be egalitarian, nor male lions to refrain from killing cubs sired by other males. We should not, this theory goes, expect animals to raise the babies they produce to adulthood; we should not be dismayed if they, in fact, torture their young to death when it is advantageous for them to do so. Most people of our era have a strong, visceral inclination against cruelty to animals, just as we do against cruelty to human children. We judge animal suffering to be bad. Watching a nature documentary, we hope the impala can evade the lion, yet we also hope the lion cubs get fed somehow. But watch what your mind does when considering these two contradictory hopes. Does it come to a coherent resolution of the problem? Or does it just shrug its shoulders and spackle the problem over with some bullshit about the circle of life? Life must go on . . . end of thought. Is it okay that the impala gets eaten? That the cub dies? What about an old lion slowly dying in the hot sun? How about that little chick pictured above, getting abused and starved to death by its parents? Genesis 1:21 (KJV) says: And God created great whales, and every living creature that moveth, which the waters brought forth abundantly, after their kind, and every winged fowl after his kind: and God saw that it was good.” According the Judeo-Christian God, torturing baby coots to death is not just okay, but good. “God” gave us that whopper to swallow; can you swallow it? Human morality, some may argue, applies only to human actions—not to the actions of animals. I agree with this. For the most part, animals are not agents, but merely robots— machines executing programs created by natural selection. However, morality must certainly apply to human inaction, and especially our inaction in preventing harm, suffering, and awfulness. What is the moral justification for the “hands off ” dogma regarding nature? We often interfere with nature for the good of humans and human industry. Why not for the good of individual animals? Bloody Nature is a machine for pushing genes into the future. Does it really “know best”? 3. Respect for Species? Nature exists. We try to “conserve” ecosystems in their “natural” state (scare quotes because ecosystems evolve and change over time in response to environmental pressures, including those from other species). But who is this good for? Is it good for the animals themselves? Thomas Nagel considers the difficulty of this question in his essay “Birth, Death, and the Meaning of Life,” in his important book The View from Nowhere (from which my blog, which many of you are familiar with, took its title).142 While teaching at Princeton in the 70s, Professor Nagel noticed a sad little spider living in a urinal in the men’s bathroom. The spider appeared to Professor Nagel to have a crappy life, constantly getting peed on; “he didn’t seem to like it,” notes Nagel: Gradually our encounters began to oppress me. Of course it might be his natural habitat, but because he was trapped by the smooth porcelain overhang, there was no way for him to get out even if he wanted to, and no way to tell whether he wanted to…So one day toward the end of the term I took a paper towel from the wall dispenser and extended it to him. His legs grasped the end of the towel and I lifted him out and deposited him on the tile floor. He just sat there, not moving a muscle. I nudged him slightly with the towel, but nothing happened…I left, but when I came back two hours later he hadn’t moved. The next day I found him in the same place, his legs shriveled in that way characteristic of dead spiders. His corpse stayed there for a week, until they finally swept the floor. Professor Nagel acted with empathy toward the spider— treating the spider how he imagined the spider would want to be treated. But did he do the spider any good? Would non-interference by Professor Nagel have done the spider any good? The spider might have lived longer, scrambling away from piss streams a hundred times a day, and may have eventually made more spiders. Would that be a good thing? What do spiders want? Is there such a thing as a meaningful life for a spider? Does a spider’s life do the spider any good? There is a popular idea, born, I think, from applying the principles of liberalism where they do not belong—the idea that non-interference indicates respect for a species or animal, as if it were a person. (Where interference is allowed, it is to remedy some previous human interference.) This is also (idiotically) applied to human cultural systems, not just biological systems; in the human context, it is known as cultural relativism. And it is just as incoherent applied to animals as applied to folks slicing off the clitorises of babies. Let us for a moment suppose that we will treat individual animals as persons whose pleasures, pains, and desires we can identify and respect. In that case, empirically speaking, non-interference is a poor policy. We could do more to make animals suffer less by intervention than by complete non-intervention. On the other hand, perhaps it is the species that is our “person”—we should try to respect a species, or, perhaps, a whole complex ecosystem. But since species and ecosystems are not percipient beings capable of pleasure and suffering, by assigning them respect, we open up the question of the purpose of doing so. Who are ecosystems good for? Or are they perhaps mystically intrinsically good, as Jehovah would have us believe? 4. Use Nature As We Please? To some degree, nature au naturel is good for humans. We need trees and algae and fish in order to live. Genetic diversity, developed over millions of years, ensures the longevity of our biosphere. Being near green plants and animals makes us happy. We frequently violate our supposed policy of non-intervention with the natural world when doing so benefits humans, in some cases actively seeking the extinction of certain organisms (like smallpox). I don’t think this is wrong at all, because (a) smallpox doesn’t do anyone, including itself, any good by existing; and (b) smallpox causes untold suffering. But why draw the line at smallpox? It is my contention that not just smallpox, but all creatures, do not do themselves any good by existing—from piss-dodging spiders to coyotes to humans. Not only do we breathe oxygen and eat food produced by biological systems, we also appreciate the beauty of complex systems. Can we justify the suffering of baby coots because we think their ecosystem is interesting? Earlier generations of humans liked to torture animals for their own pleasure (and some people still do). We now judge this to be evil. But is standing by while animals torture each other in “natural” ways, when we have the power to stop it, any better than actively torturing animals? Responsible people spay or neuter their pets. Why not spay Nature Herself? We don’t even have to harm or kill animals in order to stop Nature from doing her evil deeds. We could simply prevent their reproduction, or even merely cease our current “conservation efforts” that involve breeding animals. Breeding wild animals and releasing them into the wild is doing the ugly work of Genesis all over again—and cruelly claiming that it’s “good.” 5. Is Being Human-Like Better? We are touched by human-like (or ideal-human-like) characteristics in animals—nurturing young, monogamy, neighborliness, cooperation. Humans, although we commit parental infanticide at a rate higher than any other great ape (as would be expected from our relative immaturity at birth), at least attempt to raise most of our young to adulthood. But is “human” really more “humane”? Compare the pelicans and coots to the rosella parrot. These parents feed “fairly”—that is, all chicks are fed equally, although they hatch at different times, so some chicks are larger than others. Large, older baby parrots even share their food with their smaller siblings! Aw. Sound good? Nice parrots. However, they are merely postponing the point at which the red teeth and claws come into the picture. These parrot parents produce more than two offspring. What do you think happens to most of them? They go off and found happy egalitarian parrot families of their own? Maybe for a little while. But a species can’t expand indefinitely. Most of these new parrots will get eaten or starve to death. The lucky few will go on to put dozens of new parrots into the world, for natural selection to claw apart and eat alive. r is evil, but K is not so great either. Antibiotics were not invented until World War II. Prior to that, any human parent faced the very real possibility of losing some or all of his children before they reached adulthood. Humans were visibly under the same selection pressures as the rest of the animals. However, for a couple of generations, we have managed to pretend that nearly all our offspring can survive to adulthood and bear children of their own. We must look to nature to remind ourselves that this is a temporary fantasy.",
      "word_count": 1966,
      "character_count": 11415,
      "chapter_number": 21,
      "section_number": null,
      "paragraph_number": 1,
      "start_position": 0,
      "end_position": 11415,
      "parent_chunk_id": "sarah_perryevery_cra_unknown_ch21"
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch22",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "chapter",
      "title": "Appendix: Living in the Epilogue: Social Policy as Palliative Care",
      "content": "Appendix: Living in the Epilogue: Social Policy as Palliative Care A self is a machine for making you concerned about your organism. —Antonio Damasio The Story as a Cognitive Bias The essence of consciousness, says Antonio Damasio, is the internal narrative—the story one tells oneself about oneself.143 The ability to create this narrative—to conceive of oneself, to project oneself into the past and the future, to connect events meaningfully—has proven to be a very effective evolutionary strategy to ensure that an organism acts to promote its own ends. Our evolutionary history ensures that we think in stories. Stories are so central to our thinking that it is hard to think about them. An old fish said to a couple of young fish, “Morning, boys! The water’s fine today!” and swam off. One young fish turned to the other young fish and asked, “What’s water?” Thus it is with humans and stories. Stories are extremely useful; as information-hungry, social creatures, we are as pleased to hear stories as dogs are to sniff the pee stains of other dogs. We love stories. We are stories. We think and remember in the form of stories. As Roger Schank puts it (in Tell Me a Story: A New Look at Real and Artificial Memory), “In the end all we have, machine or human, are stories and methods of finding and using those stories.” But stories are not real. They are constructs that we apply to the universe, but there is no story out in the universe. There is no “gist” or “point” to the universe, as stories have gists and points. We construct meaning to serve our evolutionarily-determined ends, and this is, I think, the most central of all the cognitive biases.",
      "word_count": 288,
      "character_count": 1662,
      "chapter_number": 22,
      "section_number": null,
      "paragraph_number": null,
      "start_position": 0,
      "end_position": 1662,
      "parent_chunk_id": null
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch22_p1",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "paragraph",
      "title": "Paragraph 1",
      "content": "Appendix: Living in the Epilogue: Social Policy as Palliative Care A self is a machine for making you concerned about your organism. —Antonio Damasio The Story as a Cognitive Bias The essence of consciousness, says Antonio Damasio, is the internal narrative—the story one tells oneself about oneself.143 The ability to create this narrative—to conceive of oneself, to project oneself into the past and the future, to connect events meaningfully—has proven to be a very effective evolutionary strategy to ensure that an organism acts to promote its own ends. Our evolutionary history ensures that we think in stories. Stories are so central to our thinking that it is hard to think about them. An old fish said to a couple of young fish, “Morning, boys! The water’s fine today!” and swam off. One young fish turned to the other young fish and asked, “What’s water?” Thus it is with humans and stories. Stories are extremely useful; as information-hungry, social creatures, we are as pleased to hear stories as dogs are to sniff the pee stains of other dogs. We love stories. We are stories. We think and remember in the form of stories. As Roger Schank puts it (in Tell Me a Story: A New Look at Real and Artificial Memory), “In the end all we have, machine or human, are stories and methods of finding and using those stories.” But stories are not real. They are constructs that we apply to the universe, but there is no story out in the universe. There is no “gist” or “point” to the universe, as stories have gists and points. We construct meaning to serve our evolutionarily-determined ends, and this is, I think, the most central of all the cognitive biases.",
      "word_count": 288,
      "character_count": 1662,
      "chapter_number": 22,
      "section_number": null,
      "paragraph_number": 1,
      "start_position": 0,
      "end_position": 1662,
      "parent_chunk_id": "sarah_perryevery_cra_unknown_ch22"
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch23",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "chapter",
      "title": "Living in the Epilogue",
      "content": "Living in the Epilogue A few years ago, I wanted to die all the time, every minute. I suffered intensely, and the main project of my life was to get through time. I researched suicide methods, made repeated attempts, but always failed, and was left with the conviction that suicide is extremely difficult. At some point, I changed my focus from trying to end my life to trying to make what years I am forced to endure less miserable. In the language of illness, I put myself in hospice and gave myself palliative care. I tried many therapies, including a six-month attempt at alcoholism. Many of my experimental palliative care therapies (including this) failed, but a few (including distance running and marriage) were extremely successful at making me not suffer all the time. Marriage is a kind of heaven, and I suspect that I am now happier than most people in the world. Life remains an irritation, but for me it is not the constant grind of pain and humiliation that it must be for millions of people. In many ways, my pro-death orientation makes life more pleasant, since I utterly lack the fear of death and all the cringing urgency that fear engenders. But there is something missing. Here is the problem, if it is a problem: I am not in a story. Living outside of any story—living without hope for the future, without the belief that one is part of a narrative—is confusing. It’s hard to get anything done when nothing has a point. For any not-immediately-pleasurable action (or inaction) I contemplate—getting up in the morning, vacuuming, answering the phone—there is no readily-available answer to the ever-present question in my mind: “why?” At least, there is no long-term “why.” Do I wish I were in a story again? Ultimately, no. Even if it were possible to imagine myself as a character in some narrative about to unfold, I don’t really want to. This would be sacrificing truth for comfort—and questionable comfort at that. I spoke about this with my closest friend years ago, and he suggested that I have had a story, and now I’m living in the “ever after” part. I am, for all relevant purposes, living in my own epilogue. This is also, I think, the status of people with terminal illness who are about to die: their story is essentially over. This is even true if you believe in an afterlife (including the transhumanist kind). There Are No Stories In Heaven There are no stories in heaven; heaven is all epilogue. It functions as a bookend on our stories; we may even call it the “hereafter,” as in “happily ever after.” There can be no conflict in heaven, so there can be no stories, either. Aristotle scholar Martha Nussbaum explores how grim it is for humans to live outside of a story, even in heaven. In her essay “Transcending Humanity,” she considers Odysseus’ choice to give up eternal youth and pleasure with Calypso in order to return to his wife and the certainty of inevitable death. She says, What, in the face of the recognized human attachment to transcendence, could justify such a choice? Odysseus has little to say. But what he does say makes it perfectly clear that the key is not any surpassing beauty in Penelope herself. He freely grants that from this point of view Calypso will be found superior. And he points to no superiority in Penelope that could counterbalance Calypso’s divine excellence. So he is not, it seems, choosing a glorious prize in spite of the fact that he has to face death to get it; that is not at all how he sees the issue. He is choosing the whole human package: mortal life, dangerous voyage, imperfect mortal aging woman. He is choosing, quite simply, what is his: his own history, the form of a human life and the possibilities of excellence, love, and achievement that inhabit that form. What, then, can he say to make that choice intelligible, once the alternative of divinity and agelessness is on the scene? And yet, to readers of the poem from ancient to modern times, Odysseus’ choice does seem intelligible, and also admirable—the only choice we would have our hero make. Odysseus’ choice is perfectly understandable because the alternative is so…boring. Without the possibility of loss, nothing is interesting. Without limitation, there is no possibility for excellence, which is, in the Aristotelian view at least, the purpose of a human being: We don’t quite know what it would be for this hero, known for his courage, craft, resourcefulness, and loyal love to enter into a life in which courage would atrophy, in which cunning and resourcefulness would have little point, since the risks with which they grapple would be removed, and in which love, insofar as it appears at all, would be very different in shape from the love that connects man to wife and child in the human world of the poem. And: The Greeks, no less than contemporary Americans, praise outstanding athletic performance as a wonderful instance of human excellence…But clearly, such achievement has point and value only relatively to the context of the human body, which imposes certain species-specific limits and creates certain possibilities of movement rather than others…But if this means that even races or contests between different animal species will usually seem pointless and odd, it means all the more that there will be no athletic excellence at all, and no meaningful concept of athletic excellence, in the life of a being that is, by nature, capable of anything and physically unlimited…What would such achievement be, in a being for whom it is all easy? What would be the rules of the game? But the real appeal of Penelope, and of the mortal world, compared to heaven, is the possibility of stories. We root for Odysseus to choose Penelope over immortality, says Nussbaum, because of this more general uneasiness about the shapelessness of the life Calypso offers: pleasure and kindliness and on and on, with no risks, no possibility of sacrifice, no grief, no children. All we need to do to see this is to compare accounts of lovemaking. Odysseus and Calypso “withdrew, and in a recess of the arching cavern they took their pleasure in love, and did not leave one another’s side.” That’s the end of that; the poet can say no more; for they have nothing to talk about, since they have done nothing and nothing has happened to them. As for the human husband and wife: The two in their room enjoyed the delights of love, then pleased one another with recounting what had befallen each. The queen told how much she had suffered in these halls, seeing always there the pernicious multitude of suitors who in wooing her had slaughtered so many beasts, fat sheep and oxen, and drawn so much wine from the great jars. The king told of the harm he had done to others and the misery he had endured himself. Penelope listened to him enraptured, and sleep did not fall upon her eyelids till he had told his tale to the end.144 It’s perfectly plain that the human pair are, at least from the viewpoint of the human reader, more interesting and more erotic. A sexuality divorced from conversation, from storytelling, from risk and adventure and the sharing of risk and adventure, seems extremely boring; and we feel that it is a great tribute to the goddess’s beauty that Odysseus retains his interest in her, after so much time. Life is quite unbearable for a human without the “risk and adventure” of a story-bound life. What we are looking for when we look for the “meaning of life” is the greater story. The unfortunate truth, suggested by science and vehemently denied by religion, is that there is no greater story. We may make up stories and allow them to shape our perceptions, but ultimately there is no story. We are all living in the epilogue of reality, or rather worse, because there never was a story. For many of us, our personal stories have run out— and it’s extremely difficult to push oneself into a new story once you see that all stories are vanity. It is like the difficulty of staying in a dream once one realizes one is dreaming. The Cheery and the Damned Why are drugs, prostitution, gambling and suicide illegal, when they clearly give so much relief to suffering people? I think it is because, at a societal level, we are deluded into thinking that happiness is possible, maybe even easy or likely, without these things. I have called this “cheery social policy.” The fundamental problem with this sort of cheeriness is the assumption that a good life—a pleasant life—is relatively easy to achieve. Cheery people are able to hold such a belief because they are able to ignore—and perhaps can’t even conceive of—the suffering of a significant minority of the population. A good life is not easily achieved for many of us. There is a majority belief that we need not use extraordinary means to achieve a happy and meaningful life. Behaviors that deviants engage in, perhaps in pursuit of a tolerable life—weird sex with lots of people, say, or using steroids or marijuana or LSD or benzodiazepines—strike cheery people as perplexing and frightening. For a cheery person, these behaviors are wholly unnecessary. Life is perfectly tolerable without them. And they increase the risk of harm! Who wants harm? What the cheery cannot imagine is the importance, the function of these behaviors, and others like them—the pursuit of the interesting, and the temporary suspension of the intolerability of existence, which intolerability (for many) the cheery do not even perceive, and therefore do not properly weight as a problem. In a blog post titled “Explanations for drug war”145 Jason Roy makes this point with respect to the drug prohibition. He quotes John Gray’s Straw Dogs: Drug use is a tacit admission of a forbidden truth. For most people happiness is beyond reach. Fulfillment is found not in daily life but escaping from it. Since happiness is unavailable, the mass of mankind seeks pleasure. Religious cultures could admit that earthly life was hard, for they promised another in which all tears would be wiped away. Their humanist successors affirm something still more incredible—that in future, even the near future, everyone can be happy. Societies founded on a faith in progress cannot admit the normal unhappiness of human life. As a result, they are bound to wage war on those who seek an artificial happiness in drugs. But it is not necessarily the case that prohibitionists think that life is great. It’s that they think it is meaningful—that we are in a story, and it’s worth participating in, win or lose. The idea that life is inherently worthwhile, and happiness easy to achieve, underlies many social policies, including prohibitions (legal or moral) on suicide, abortion, nonmarital sex, drugs, gambling, and even eating fatty food. On the other hand, if life were not inherently worthwhile, suicide would be understandable, and bringing a new life into the world would not be an unqualified good, but an uneasy question mark. Sex, drugs, and fun would be appropriate ways to treat oneself for the unwanted condition of life.",
      "word_count": 1888,
      "character_count": 11022,
      "chapter_number": 23,
      "section_number": null,
      "paragraph_number": null,
      "start_position": 0,
      "end_position": 11022,
      "parent_chunk_id": null
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch23_p1",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "paragraph",
      "title": "Paragraph 1",
      "content": "Living in the Epilogue A few years ago, I wanted to die all the time, every minute. I suffered intensely, and the main project of my life was to get through time. I researched suicide methods, made repeated attempts, but always failed, and was left with the conviction that suicide is extremely difficult. At some point, I changed my focus from trying to end my life to trying to make what years I am forced to endure less miserable. In the language of illness, I put myself in hospice and gave myself palliative care. I tried many therapies, including a six-month attempt at alcoholism. Many of my experimental palliative care therapies (including this) failed, but a few (including distance running and marriage) were extremely successful at making me not suffer all the time. Marriage is a kind of heaven, and I suspect that I am now happier than most people in the world. Life remains an irritation, but for me it is not the constant grind of pain and humiliation that it must be for millions of people. In many ways, my pro-death orientation makes life more pleasant, since I utterly lack the fear of death and all the cringing urgency that fear engenders. But there is something missing. Here is the problem, if it is a problem: I am not in a story. Living outside of any story—living without hope for the future, without the belief that one is part of a narrative—is confusing. It’s hard to get anything done when nothing has a point. For any not-immediately-pleasurable action (or inaction) I contemplate—getting up in the morning, vacuuming, answering the phone—there is no readily-available answer to the ever-present question in my mind: “why?” At least, there is no long-term “why.” Do I wish I were in a story again? Ultimately, no. Even if it were possible to imagine myself as a character in some narrative about to unfold, I don’t really want to. This would be sacrificing truth for comfort—and questionable comfort at that. I spoke about this with my closest friend years ago, and he suggested that I have had a story, and now I’m living in the “ever after” part. I am, for all relevant purposes, living in my own epilogue. This is also, I think, the status of people with terminal illness who are about to die: their story is essentially over. This is even true if you believe in an afterlife (including the transhumanist kind). There Are No Stories In Heaven There are no stories in heaven; heaven is all epilogue. It functions as a bookend on our stories; we may even call it the “hereafter,” as in “happily ever after.” There can be no conflict in heaven, so there can be no stories, either. Aristotle scholar Martha Nussbaum explores how grim it is for humans to live outside of a story, even in heaven. In her essay “Transcending Humanity,” she considers Odysseus’ choice to give up eternal youth and pleasure with Calypso in order to return to his wife and the certainty of inevitable death. She says, What, in the face of the recognized human attachment to transcendence, could justify such a choice? Odysseus has little to say. But what he does say makes it perfectly clear that the key is not any surpassing beauty in Penelope herself. He freely grants that from this point of view Calypso will be found superior. And he points to no superiority in Penelope that could counterbalance Calypso’s divine excellence. So he is not, it seems, choosing a glorious prize in spite of the fact that he has to face death to get it; that is not at all how he sees the issue. He is choosing the whole human package: mortal life, dangerous voyage, imperfect mortal aging woman. He is choosing, quite simply, what is his: his own history, the form of a human life and the possibilities of excellence, love, and achievement that inhabit that form. What, then, can he say to make that choice intelligible, once the alternative of divinity and agelessness is on the scene? And yet, to readers of the poem from ancient to modern times, Odysseus’ choice does seem intelligible, and also admirable—the only choice we would have our hero make. Odysseus’ choice is perfectly understandable because the alternative is so…boring. Without the possibility of loss, nothing is interesting. Without limitation, there is no possibility for excellence, which is, in the Aristotelian view at least, the purpose of a human being: We don’t quite know what it would be for this hero, known for his courage, craft, resourcefulness, and loyal love to enter into a life in which courage would atrophy, in which cunning and resourcefulness would have little point, since the risks with which they grapple would be removed, and in which love, insofar as it appears at all, would be very different in shape from the love that connects man to wife and child in the human world of the poem. And: The Greeks, no less than contemporary Americans, praise outstanding athletic performance as a wonderful instance of human excellence…But clearly, such achievement has point and value only relatively to the context of the human body, which imposes certain species-specific limits and creates certain possibilities of movement rather than others…But if this means that even races or contests between different animal species will usually seem pointless and odd, it means all the more that there will be no athletic excellence at all, and no meaningful concept of athletic excellence, in the life of a being that is, by nature, capable of anything and physically unlimited…What would such achievement be, in a being for whom it is all easy? What would be the rules of the game? But the real appeal of Penelope, and of the mortal world, compared to heaven, is the possibility of stories. We root for Odysseus to choose Penelope over immortality, says Nussbaum, because of this more general uneasiness about the shapelessness of the life Calypso offers: pleasure and kindliness and on and on, with no risks, no possibility of sacrifice, no grief, no children. All we need to do to see this is to compare accounts of lovemaking. Odysseus and Calypso “withdrew, and in a recess of the arching cavern they took their pleasure in love, and did not leave one another’s side.” That’s the end of that; the poet can say no more; for they have nothing to talk about, since they have done nothing and nothing has happened to them. As for the human husband and wife: The two in their room enjoyed the delights of love, then pleased one another with recounting what had befallen each. The queen told how much she had suffered in these halls, seeing always there the pernicious multitude of suitors who in wooing her had slaughtered so many beasts, fat sheep and oxen, and drawn so much wine from the great jars. The king told of the harm he had done to others and the misery he had endured himself. Penelope listened to him enraptured, and sleep did not fall upon her eyelids till he had told his tale to the end.144 It’s perfectly plain that the human pair are, at least from the viewpoint of the human reader, more interesting and more erotic. A sexuality divorced from conversation, from storytelling, from risk and adventure and the sharing of risk and adventure, seems extremely boring; and we feel that it is a great tribute to the goddess’s beauty that Odysseus retains his interest in her, after so much time. Life is quite unbearable for a human without the “risk and adventure” of a story-bound life. What we are looking for when we look for the “meaning of life” is the greater story. The unfortunate truth, suggested by science and vehemently denied by religion, is that there is no greater story. We may make up stories and allow them to shape our perceptions, but ultimately there is no story. We are all living in the epilogue of reality, or rather worse, because there never was a story. For many of us, our personal stories have run out— and it’s extremely difficult to push oneself into a new story once you see that all stories are vanity. It is like the difficulty of staying in a dream once one realizes one is dreaming. The Cheery and the Damned Why are drugs, prostitution, gambling and suicide illegal, when they clearly give so much relief to suffering people? I think it is because, at a societal level, we are deluded into thinking that happiness is possible, maybe even easy or likely, without these things. I have called this “cheery social policy.” The fundamental problem with this sort of cheeriness is the assumption that a good life—a pleasant life—is relatively easy to achieve. Cheery people are able to hold such a belief because they are able to ignore—and perhaps can’t even conceive of—the suffering of a significant minority of the population. A good life is not easily achieved for many of us. There is a majority belief that we need not use extraordinary means to achieve a happy and meaningful life. Behaviors that deviants engage in, perhaps in pursuit of a tolerable life—weird sex with lots of people, say, or using steroids or marijuana or LSD or benzodiazepines—strike cheery people as perplexing and frightening. For a cheery person, these behaviors are wholly unnecessary. Life is perfectly tolerable without them. And they increase the risk of harm! Who wants harm? What the cheery cannot imagine is the importance, the function of these behaviors, and others like them—the pursuit of the interesting, and the temporary suspension of the intolerability of existence, which intolerability (for many) the cheery do not even perceive, and therefore do not properly weight as a problem. In a blog post titled “Explanations for drug war”145 Jason Roy makes this point with respect to the drug prohibition. He quotes John Gray’s Straw Dogs: Drug use is a tacit admission of a forbidden truth. For most people happiness is beyond reach. Fulfillment is found not in daily life but escaping from it. Since happiness is unavailable, the mass of mankind seeks pleasure. Religious cultures could admit that earthly life was hard, for they promised another in which all tears would be wiped away. Their humanist successors affirm something still more incredible—that in future, even the near future, everyone can be happy. Societies founded on a faith in progress cannot admit the normal unhappiness of human life. As a result, they are bound to wage war on those who seek an artificial happiness in drugs. But it is not necessarily the case that prohibitionists think that life is great. It’s that they think it is meaningful—that we are in a story, and it’s worth participating in, win or lose. The idea that life is inherently worthwhile, and happiness easy to achieve, underlies many social policies, including prohibitions (legal or moral) on suicide, abortion, nonmarital sex, drugs, gambling, and even eating fatty food. On the other hand, if life were not inherently worthwhile, suicide would be understandable, and bringing a new life into the world would not be an unqualified good, but an uneasy question mark. Sex, drugs, and fun would be appropriate ways to treat oneself for the unwanted condition of life.",
      "word_count": 1888,
      "character_count": 11022,
      "chapter_number": 23,
      "section_number": null,
      "paragraph_number": 1,
      "start_position": 0,
      "end_position": 11022,
      "parent_chunk_id": "sarah_perryevery_cra_unknown_ch23"
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch24",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "chapter",
      "title": "Palliative Care: A Double Standard for People in the Epilogue",
      "content": "Palliative Care: A Double Standard for People in the Epilogue The terminally ill are at the end of their story. If you’re going to die anyway, what does it matter what you do? Take ecstasy. Go skydiving. Fuck a prostitute. Kill yourself. Who cares? There is a sense that, once you’re terminally ill and an official short-timer in life, what you do ceases to really matter. This is, I think, at the heart of the double standard our society imposes with regard to suicide and the other activities mentioned above. If you’re young and healthy, you have an obligation to stay alive and be sober and responsible. But if you’re toast anyway, anything goes. For the dying, we can conceive of allowing them pleasure as mercy. But we are not so eager to offer mercy to healthy people. That is because we mistakenly believe in the concept of health. Toward Social Policy as Palliative Care We are all terminally ill. Not one of us is going to survive. And our stories are delusions. Each one of us lives in The Matrix—a story-dream created by our minds. Happiness is not easy; meaning is elusive. Young, healthy people who find themselves miserable, or find that they no longer inhabit a story, have even more need of the kind of “palliative care” that we offer to terminally ill people, simply because young people have so much more time to get through. Eighty years! Ninety years! A hundred years of epilogue ahead of us? It’s crushingly boring to ponder. As Martha Nussbaum says, When Calypso speaks of “calm possession of this domain,” our hearts sink; for there’s no story in that… Stories have shaped and continue to shape the readers’ desires, giving them a preference for onward movement over stasis, for risk over self-sufficiency, for the human form of time over divine timelessness. They play upon and nourish the emotions—fear, anticipation, grief, hope—that presuppose the form of life of a being both needy and resourceful, both active and finite—and that seem to have their point and function only within the context of such a life. Regarding antinatalism, someone recently asked me if it was my belief that the bad outweighed the good, or whether I thought they weren’t even comparable. I believe the latter. Ray Brassier, in his introduction to Thomas Ligotti’s excellent The Conspiracy against the Human Race, puts it thus: The optimist fixes the exchange rate between joy and woe, thereby determining the value of life. The pessimist, who refuses the principle of exchange and the injunction to keep investing in the future no matter how worthless life’s currency in the present, is stigmatized as an unreliable investor. This is the view from hell. Hell is not the state of experiencing a great deal of suffering with no pleasure to “balance it out.” Hell is popping out of the notion of meaning altogether. And this Hell is the meta-condition that we are all in, whether we perceive it or not.",
      "word_count": 498,
      "character_count": 2904,
      "chapter_number": 24,
      "section_number": null,
      "paragraph_number": null,
      "start_position": 0,
      "end_position": 2904,
      "parent_chunk_id": null
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch24_p1",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "paragraph",
      "title": "Paragraph 1",
      "content": "Palliative Care: A Double Standard for People in the Epilogue The terminally ill are at the end of their story. If you’re going to die anyway, what does it matter what you do? Take ecstasy. Go skydiving. Fuck a prostitute. Kill yourself. Who cares? There is a sense that, once you’re terminally ill and an official short-timer in life, what you do ceases to really matter. This is, I think, at the heart of the double standard our society imposes with regard to suicide and the other activities mentioned above. If you’re young and healthy, you have an obligation to stay alive and be sober and responsible. But if you’re toast anyway, anything goes. For the dying, we can conceive of allowing them pleasure as mercy. But we are not so eager to offer mercy to healthy people. That is because we mistakenly believe in the concept of health. Toward Social Policy as Palliative Care We are all terminally ill. Not one of us is going to survive. And our stories are delusions. Each one of us lives in The Matrix—a story-dream created by our minds. Happiness is not easy; meaning is elusive. Young, healthy people who find themselves miserable, or find that they no longer inhabit a story, have even more need of the kind of “palliative care” that we offer to terminally ill people, simply because young people have so much more time to get through. Eighty years! Ninety years! A hundred years of epilogue ahead of us? It’s crushingly boring to ponder. As Martha Nussbaum says, When Calypso speaks of “calm possession of this domain,” our hearts sink; for there’s no story in that… Stories have shaped and continue to shape the readers’ desires, giving them a preference for onward movement over stasis, for risk over self-sufficiency, for the human form of time over divine timelessness. They play upon and nourish the emotions—fear, anticipation, grief, hope—that presuppose the form of life of a being both needy and resourceful, both active and finite—and that seem to have their point and function only within the context of such a life. Regarding antinatalism, someone recently asked me if it was my belief that the bad outweighed the good, or whether I thought they weren’t even comparable. I believe the latter. Ray Brassier, in his introduction to Thomas Ligotti’s excellent The Conspiracy against the Human Race, puts it thus: The optimist fixes the exchange rate between joy and woe, thereby determining the value of life. The pessimist, who refuses the principle of exchange and the injunction to keep investing in the future no matter how worthless life’s currency in the present, is stigmatized as an unreliable investor. This is the view from hell. Hell is not the state of experiencing a great deal of suffering with no pleasure to “balance it out.” Hell is popping out of the notion of meaning altogether. And this Hell is the meta-condition that we are all in, whether we perceive it or not.",
      "word_count": 498,
      "character_count": 2904,
      "chapter_number": 24,
      "section_number": null,
      "paragraph_number": 1,
      "start_position": 0,
      "end_position": 2904,
      "parent_chunk_id": "sarah_perryevery_cra_unknown_ch24"
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch25",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "chapter",
      "title": "Acknowledgments",
      "content": "Acknowledgments I would like to thank Chip Smith of Nine-Banded Books for bringing this book into existence over the past four years, for suggesting that I write it, and for encouragement, technical assistance, and friendship along the way. Thanks to everyone who has read early versions of this book and provided helpful criticism and editing assistance—Thomas Ligotti, Ann Sterzinger, Jim Crawford, Anita Dalton, Samuel Crowell and Sam Frank, among others. Thanks to Rob Sica for his philosophy scholarship and librarian assistance, and to readers and commenters of my blog. Thanks to my family, Nona Perry, Dan Perry, Nona Baker, Michelle Perry, Gleta and George Perry, and Kris and George Perry; and to my husband, Andrew Breese, for supporting my work and exploring ideas with me; and to my friends Sarah Lennon, Megan Robb, Phil Ogston, and C. Thi Nguyen. I would like to thank the late Dr. Jack Kevorkian for permission to use his evocative painting as cover art. Finally, I would like to thank Unaffiliated Smartypants Twitter for engaging with crazy ideas with me over the past few years (which acknowledgment is not meant to suggest that such a thing as Unaffiliated Smartypants Twitter exists).",
      "word_count": 196,
      "character_count": 1205,
      "chapter_number": 25,
      "section_number": null,
      "paragraph_number": null,
      "start_position": 0,
      "end_position": 1205,
      "parent_chunk_id": null
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch25_p1",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "paragraph",
      "title": "Paragraph 1",
      "content": "Acknowledgments I would like to thank Chip Smith of Nine-Banded Books for bringing this book into existence over the past four years, for suggesting that I write it, and for encouragement, technical assistance, and friendship along the way. Thanks to everyone who has read early versions of this book and provided helpful criticism and editing assistance—Thomas Ligotti, Ann Sterzinger, Jim Crawford, Anita Dalton, Samuel Crowell and Sam Frank, among others. Thanks to Rob Sica for his philosophy scholarship and librarian assistance, and to readers and commenters of my blog. Thanks to my family, Nona Perry, Dan Perry, Nona Baker, Michelle Perry, Gleta and George Perry, and Kris and George Perry; and to my husband, Andrew Breese, for supporting my work and exploring ideas with me; and to my friends Sarah Lennon, Megan Robb, Phil Ogston, and C. Thi Nguyen. I would like to thank the late Dr. Jack Kevorkian for permission to use his evocative painting as cover art. Finally, I would like to thank Unaffiliated Smartypants Twitter for engaging with crazy ideas with me over the past few years (which acknowledgment is not meant to suggest that such a thing as Unaffiliated Smartypants Twitter exists).",
      "word_count": 196,
      "character_count": 1205,
      "chapter_number": 25,
      "section_number": null,
      "paragraph_number": 1,
      "start_position": 0,
      "end_position": 1205,
      "parent_chunk_id": "sarah_perryevery_cra_unknown_ch25"
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch154",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "chapter",
      "title": "Chapter 156",
      "content": "[←126] “We asked [a poor rural Moroccan farm worker] what he would do if he had more money. He said he would buy more food. Then we asked him what he would do if he had even more money. He said he would buy better-tasting food. We were starting to feel very bad for him and his family, when we noticed the TV and other high-tech gadgets. Why had he bought all these things if he felt the family did not have enough to eat? He laughed, and said, “Oh, but television is more important than food!’” Quoted in: Banerjee, Abhijit, and Esther Duflo. 2011, April 25. More than one billion people are hungry in the world. Foreign Policy.",
      "word_count": 119,
      "character_count": 629,
      "chapter_number": 154,
      "section_number": null,
      "paragraph_number": null,
      "start_position": 0,
      "end_position": 629,
      "parent_chunk_id": null
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch154_p1",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "paragraph",
      "title": "Paragraph 1",
      "content": "[←126] “We asked [a poor rural Moroccan farm worker] what he would do if he had more money. He said he would buy more food. Then we asked him what he would do if he had even more money. He said he would buy better-tasting food. We were starting to feel very bad for him and his family, when we noticed the TV and other high-tech gadgets. Why had he bought all these things if he felt the family did not have enough to eat? He laughed, and said, “Oh, but television is more important than food!’” Quoted in: Banerjee, Abhijit, and Esther Duflo. 2011, April 25. More than one billion people are hungry in the world. Foreign Policy.",
      "word_count": 119,
      "character_count": 629,
      "chapter_number": 154,
      "section_number": null,
      "paragraph_number": 1,
      "start_position": 0,
      "end_position": 629,
      "parent_chunk_id": "sarah_perryevery_cra_unknown_ch154"
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch163",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "chapter",
      "title": "Chapter 165",
      "content": "[←135] Actually, the New Scientist is oversimplifying; there are two risks of death in each case. The first kind of risk is the risk that the stranger S has particular characteristics which will make any peanut, or any MDMA, lethal for him. The second kind of risk is that a particular ecstasy tablet or peanut will be lethal for any given stranger (e.g., the tablet purporting to be E is really, say, buprenophine, or the peanut is somehow infected with lethal levels of salmonella). The latter type of risk probably isn’t that significant, though. UK studies don’t seem to be finding lethal chemicals in street ecstasy. In Australia, the most common “fake ecstasy” is methamphetamine, which is not particularly lethal. As for peanuts, the CDC reports that the death rate from nontyphoidal Salmonella like the S. typhimurium that recently caused peanut recalls is about 00.78%. Editorial: Drugs drive politicians out of their mind. 2009, February 11. New Scientist.",
      "word_count": 158,
      "character_count": 966,
      "chapter_number": 163,
      "section_number": null,
      "paragraph_number": null,
      "start_position": 0,
      "end_position": 966,
      "parent_chunk_id": null
    },
    {
      "chunk_id": "sarah_perryevery_cra_unknown_ch163_p1",
      "book_id": "sarah_perryevery_cra_unknown",
      "chunk_type": "paragraph",
      "title": "Paragraph 1",
      "content": "[←135] Actually, the New Scientist is oversimplifying; there are two risks of death in each case. The first kind of risk is the risk that the stranger S has particular characteristics which will make any peanut, or any MDMA, lethal for him. The second kind of risk is that a particular ecstasy tablet or peanut will be lethal for any given stranger (e.g., the tablet purporting to be E is really, say, buprenophine, or the peanut is somehow infected with lethal levels of salmonella). The latter type of risk probably isn’t that significant, though. UK studies don’t seem to be finding lethal chemicals in street ecstasy. In Australia, the most common “fake ecstasy” is methamphetamine, which is not particularly lethal. As for peanuts, the CDC reports that the death rate from nontyphoidal Salmonella like the S. typhimurium that recently caused peanut recalls is about 00.78%. Editorial: Drugs drive politicians out of their mind. 2009, February 11. New Scientist.",
      "word_count": 158,
      "character_count": 966,
      "chapter_number": 163,
      "section_number": null,
      "paragraph_number": 1,
      "start_position": 0,
      "end_position": 966,
      "parent_chunk_id": "sarah_perryevery_cra_unknown_ch163"
    }
  ],
  "processing_info": {
    "processed_at": 1752212352.133365,
    "epub_path": "ebooks/downloads/Every Cradle is a Grave Rethinking the Ethics of Birth and - Sarah Perry.epub",
    "chapter_count": 22,
    "word_count": 55385,
    "chunk_count": 47
  }
}