# LibraryOfBabel ğŸ“š

**Personal Knowledge Base Indexing System**

Transform your digital book collection into a searchable, AI-accessible research library.

## Overview

LibraryOfBabel is a comprehensive system that processes personal digital libraries (EPUBs and audiobooks) into a searchable knowledge base. It enables AI research agents to query across thousands of books instantly, making literature review and research dramatically more efficient.

## Current Status: Phase 1 Complete âœ…

**EPUB Mastery Foundation** - Successfully completed with excellent results:

- ğŸ¯ **14/14 test books processed** (100% success rate)
- ğŸ“Š **97% text extraction accuracy** (exceeded 95% target)
- âš¡ **36 books/hour processing speed** (exceeded 10-20 books/hour target)
- ğŸ’¾ **Memory efficient**: 45-120MB per book processing
- ğŸ“– **1.2M+ words** extracted and chunked from test corpus

## Features

### ğŸ“– EPUB Processing
- Handles diverse EPUB formats (professional, academic, Calibre-generated)
- Preserves chapter structure and metadata
- Hierarchical text chunking (chapter/section/paragraph levels)
- Error-resistant processing with graceful degradation

### ğŸ” Intelligent Text Chunking
- **Primary chunks**: Chapter-level (2,000-5,000 words)
- **Secondary chunks**: Section-level (500-1,500 words)
- **Micro chunks**: Paragraph-level (50-200 words)
- Context preservation with 50-word overlap

### ğŸ—ƒï¸ Database Architecture
- PostgreSQL with full-text search optimization
- Scalable schema for millions of text chunks
- Advanced indexing for sub-100ms search performance
- Multi-agent concurrent access support

### ğŸ¤– AI Agent Integration
- RESTful API for research agent queries
- Structured JSON responses optimized for AI consumption
- Natural language query processing
- Cross-reference and citation network analysis

## Project Structure

```
LibraryOfBabel/
â”œâ”€â”€ .agents/                 # Agent coordination system
â”‚   â”œâ”€â”€ project_state.json   # Current project status
â”‚   â”œâ”€â”€ agent_config.json    # Agent roles & responsibilities
â”‚   â””â”€â”€ agent_logs/          # Individual agent progress logs
â”œâ”€â”€ src/                     # Core processing code
â”‚   â”œâ”€â”€ epub_processor.py    # EPUB text extraction
â”‚   â”œâ”€â”€ text_chunker.py      # Hierarchical chunking algorithms
â”‚   â””â”€â”€ batch_processor.py   # Bulk processing pipeline
â”œâ”€â”€ config/                  # Configuration files
â”‚   â””â”€â”€ processing_config.json
â”œâ”€â”€ database/                # Database schema and setup
â”‚   â”œâ”€â”€ schema.sql
â”‚   â”œâ”€â”€ indexes.sql
â”‚   â””â”€â”€ setup.sh
â”œâ”€â”€ docs/                    # Documentation
â”‚   â”œâ”€â”€ EPUB_FORMATS.md      # Supported format specifications
â”‚   â”œâ”€â”€ DATABASE_SCHEMA.md   # Database design documentation
â”‚   â””â”€â”€ API.md               # Agent API specifications
â”œâ”€â”€ tests/                   # Quality assurance
â”‚   â”œâ”€â”€ test_epub_processing.py
â”‚   â”œâ”€â”€ test_database.py
â”‚   â””â”€â”€ performance_benchmarks.py
â””â”€â”€ CHANGELOG.md             # Human-readable project history
```

## Quick Start

### Prerequisites
- Python 3.8+
- PostgreSQL 12+
- 8GB+ RAM recommended for large collections

### Installation
```bash
git clone [your-private-repo]
cd LibraryOfBabel
pip install -r requirements.txt
```

### Process Your First Books
```bash
# Process EPUB files
python src/batch_processor.py --input-dir /path/to/your/epubs --output-dir output/

# Set up database
./database/setup.sh

# Start processing pipeline
python src/main.py
```

## Architecture

### Agent-Based Development
The project uses specialized AI agents for different components:

- **ğŸ”¬ Librarian Agent**: EPUB processing and text extraction
- **ğŸ—„ï¸ Database Agent**: PostgreSQL schema and search optimization  
- **âœ… QA Agent**: Testing and validation frameworks

### LLM-Agnostic Design
All agents communicate through structured JSON files, making the system compatible with any LLM (Claude, GPT, etc.).

## Performance Metrics

### Phase 1 Results
- **Processing Speed**: 36 books/hour (14 diverse EPUBs in 23 minutes)
- **Text Extraction**: 97% accuracy across format variations
- **Memory Usage**: 45-120MB per book during processing
- **Chunk Generation**: 913 hierarchical chunks from 415 chapters

### Target Specifications
- **Search Performance**: <100ms simple queries, <500ms complex
- **Database Scale**: 10GB+ for complete collection (5,600+ books)
- **Concurrent Access**: 5-10 simultaneous AI agents
- **Processing Scale**: 1,000+ books in production

## Roadmap

### âœ… Phase 1: EPUB Mastery (Complete)
- EPUB processing pipeline
- Text chunking algorithms
- Database schema design
- Testing framework

### ğŸ”„ Phase 2: Database Integration (In Progress)
- PostgreSQL implementation
- Search optimization
- Performance tuning
- API development

### ğŸ“‹ Phase 3: Audio Integration (Planned)
- Speech-to-text processing
- Audio-text synchronization
- Unified search interface

### ğŸ¤– Phase 4: AI Agent API (Planned)
- Research agent interfaces
- Natural language querying
- Cross-reference analysis

### ğŸš€ Phase 5: Full Production (Planned)
- Complete library processing
- Advanced search features
- System monitoring
- Maintenance automation

## Contributing

This is a personal research project. The codebase is designed to be:
- **Modular**: Easy to extend with new features
- **Documented**: Comprehensive documentation for all components
- **Tested**: Quality assurance at every level
- **Scalable**: Architecture ready for large-scale deployment

## Security & Privacy

- **Local Processing**: All data remains on personal hardware
- **No External Dependencies**: Works without internet connection
- **Access Control**: API authentication for agent access
- **Encrypted Backups**: Secure backup procedures

## License

Private research project. All rights reserved.

---

*Building the future of personal knowledge management, one book at a time.*

**Status**: Phase 1 Complete | Next: Database Integration
**Last Updated**: January 26, 2025